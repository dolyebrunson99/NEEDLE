{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10-714 Homework 4\n",
    "\n",
    "In this homework, you will leverage all of the components built in the last three homeworks to solve some modern problems with high performing network structures. We will start by adding a few new ops leveraging our new CPU/CUDA backends. Then, you will implement convolution, and a convolutional neural network to train a classifier on the CIFAR-10 image classification dataset. Then, you will implement recurrent and long-short term memory (LSTM) neural networks, and do word-level prediction language modeling on the Penn Treebank dataset. \n",
    "\n",
    "As always, we will start by copying this notebook and getting the starting code.\n",
    "Reminder: __you must save a copy in drive__."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm -rf build python/needle/backend_ndarray/ndarray_backend*.so\n",
      "-- The C compiler identification is GNU 9.4.0\n",
      "-- The CXX compiler identification is GNU 9.4.0\n",
      "-- Detecting C compiler ABI info\n",
      "-- Detecting C compiler ABI info - done\n",
      "-- Check for working C compiler: /usr/bin/cc - skipped\n",
      "-- Detecting C compile features\n",
      "-- Detecting C compile features - done\n",
      "-- Detecting CXX compiler ABI info\n",
      "-- Detecting CXX compiler ABI info - done\n",
      "-- Check for working CXX compiler: /usr/bin/c++ - skipped\n",
      "-- Detecting CXX compile features\n",
      "-- Detecting CXX compile features - done\n",
      "-- Found Python: /home/soapg/.conda/envs/dlsys/bin/python3.11 (found version \"3.11.8\") found components: Development Interpreter Development.Module Development.Embed \n",
      "-- Performing Test HAS_FLTO\n",
      "-- Performing Test HAS_FLTO - Success\n",
      "-- Found pybind11: /home/soapg/.conda/envs/dlsys/lib/python3.11/site-packages/pybind11/include (found version \"2.11.1\")\n",
      "-- Performing Test CMAKE_HAVE_LIBC_PTHREAD\n",
      "-- Performing Test CMAKE_HAVE_LIBC_PTHREAD - Failed\n",
      "-- Looking for pthread_create in pthreads\n",
      "-- Looking for pthread_create in pthreads - not found\n",
      "-- Looking for pthread_create in pthread\n",
      "-- Looking for pthread_create in pthread - found\n",
      "-- Found Threads: TRUE  \n",
      "-- Found CUDA: /usr/local/cuda (found version \"12.1\") \n",
      "-- Found cuda, building cuda backend\n",
      "Wed Mar 13 16:16:34 2024       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 535.104.12             Driver Version: 535.104.12   CUDA Version: 12.2     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  Tesla T4                       On  | 00000000:00:1E.0 Off |                    0 |\n",
      "| N/A   24C    P8               9W /  70W |      2MiB / 15360MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|  No running processes found                                                           |\n",
      "+---------------------------------------------------------------------------------------+\n",
      "-- Autodetected CUDA architecture(s):  7.5\n",
      "-- Configuring done (2.1s)\n",
      "-- Generating done (0.0s)\n",
      "-- Build files have been written to: /home/soapg/NEEDLE/build\n",
      "make[1]: Entering directory '/home/soapg/NEEDLE/build'\n",
      "make[2]: Entering directory '/home/soapg/NEEDLE/build'\n",
      "make[3]: Entering directory '/home/soapg/NEEDLE/build'\n",
      "make[3]: Leaving directory '/home/soapg/NEEDLE/build'\n",
      "make[3]: Entering directory '/home/soapg/NEEDLE/build'\n",
      "[ 25%] \u001b[32mBuilding CXX object CMakeFiles/ndarray_backend_cpu.dir/src/ndarray_backend_cpu.cc.o\u001b[0m\n",
      "[ 50%] \u001b[32m\u001b[1mLinking CXX shared module /home/soapg/NEEDLE/python/needle/backend_ndarray/ndarray_backend_cpu.cpython-311-x86_64-linux-gnu.so\u001b[0m\n",
      "make[3]: Leaving directory '/home/soapg/NEEDLE/build'\n",
      "[ 50%] Built target ndarray_backend_cpu\n",
      "make[3]: Entering directory '/home/soapg/NEEDLE/build'\n",
      "[ 75%] \u001b[34m\u001b[1mBuilding NVCC (Device) object CMakeFiles/ndarray_backend_cuda.dir/src/ndarray_backend_cuda_generated_ndarray_backend_cuda.cu.o\u001b[0m\n",
      "/usr/include/c++/9/bits/stl_pair.h(442): error: argument list for class template \"std::pair\" is missing\n",
      "    template<typename _T1, typename _T2> pair(_T1, _T2) -> pair<_T1, _T2>;\n",
      "                                         ^\n",
      "\n",
      "/usr/include/c++/9/bits/stl_pair.h(442): error: expected a \")\"\n",
      "    template<typename _T1, typename _T2> pair(_T1, _T2) -> pair<_T1, _T2>;\n",
      "                                                 ^\n",
      "\n",
      "/usr/include/c++/9/bits/stl_pair.h(442): error: template parameter \"_T1\" may not be redeclared in this scope\n",
      "    template<typename _T1, typename _T2> pair(_T1, _T2) -> pair<_T1, _T2>;\n",
      "                                              ^\n",
      "\n",
      "/usr/include/c++/9/bits/stl_pair.h(442): error: expected a \";\"\n",
      "    template<typename _T1, typename _T2> pair(_T1, _T2) -> pair<_T1, _T2>;\n",
      "                                                        ^\n",
      "\n",
      "/usr/include/c++/9/bits/forward_list.h(1410): error: argument list for class template \"std::forward_list\" is missing\n",
      "      forward_list(_InputIterator, _InputIterator, _Allocator = _Allocator())\n",
      "      ^\n",
      "\n",
      "/usr/include/c++/9/bits/forward_list.h(1410): error: expected a \")\"\n",
      "      forward_list(_InputIterator, _InputIterator, _Allocator = _Allocator())\n",
      "                                 ^\n",
      "\n",
      "/usr/include/c++/9/bits/forward_list.h(1410): error: template parameter \"_InputIterator\" may not be redeclared in this scope\n",
      "      forward_list(_InputIterator, _InputIterator, _Allocator = _Allocator())\n",
      "                   ^\n",
      "\n",
      "/usr/include/c++/9/bits/forward_list.h(1411): error: expected a \";\"\n",
      "        -> forward_list<_ValT, _Allocator>;\n",
      "        ^\n",
      "\n",
      "/usr/include/c++/9/bits/basic_string.h(5992): error: argument list for class template \"std::__cxx11::basic_string\" is missing\n",
      "      basic_string(_InputIterator, _InputIterator, _Allocator = _Allocator())\n",
      "      ^\n",
      "\n",
      "/usr/include/c++/9/bits/basic_string.h(5992): error: expected a \")\"\n",
      "      basic_string(_InputIterator, _InputIterator, _Allocator = _Allocator())\n",
      "                                 ^\n",
      "\n",
      "/usr/include/c++/9/bits/basic_string.h(5992): error: template parameter \"_InputIterator\" may not be redeclared in this scope\n",
      "      basic_string(_InputIterator, _InputIterator, _Allocator = _Allocator())\n",
      "                   ^\n",
      "\n",
      "/usr/include/c++/9/bits/basic_string.h(5993): error: expected a \";\"\n",
      "        -> basic_string<_CharT, char_traits<_CharT>, _Allocator>;\n",
      "        ^\n",
      "\n",
      "/usr/include/c++/9/bits/basic_string.h(6000): error: argument list for class template \"std::__cxx11::basic_string\" is missing\n",
      "      basic_string(basic_string_view<_CharT, _Traits>, const _Allocator& = _Allocator())\n",
      "      ^\n",
      "\n",
      "/usr/include/c++/9/bits/basic_string.h(6000): error: expected a \")\"\n",
      "      basic_string(basic_string_view<_CharT, _Traits>, const _Allocator& = _Allocator())\n",
      "                                                     ^\n",
      "\n",
      "/usr/include/c++/9/bits/basic_string.h(6000): error: \"basic_string_view\" is not a function or static data member\n",
      "      basic_string(basic_string_view<_CharT, _Traits>, const _Allocator& = _Allocator())\n",
      "                   ^\n",
      "\n",
      "/usr/include/c++/9/bits/basic_string.h(6006): error: argument list for class template \"std::__cxx11::basic_string\" is missing\n",
      "      basic_string(basic_string_view<_CharT, _Traits>,\n",
      "      ^\n",
      "\n",
      "/usr/include/c++/9/bits/basic_string.h(6006): error: expected a \")\"\n",
      "      basic_string(basic_string_view<_CharT, _Traits>,\n",
      "                                                     ^\n",
      "\n",
      "/usr/include/c++/9/bits/basic_string.h(6006): error: \"basic_string_view\" is not a function or static data member\n",
      "      basic_string(basic_string_view<_CharT, _Traits>,\n",
      "                   ^\n",
      "\n",
      "/usr/include/c++/9/array(244): error: argument list for class template \"std::array\" is missing\n",
      "      array(_Tp, _Up...)\n",
      "      ^\n",
      "\n",
      "/usr/include/c++/9/array(244): error: expected a \")\"\n",
      "      array(_Tp, _Up...)\n",
      "               ^\n",
      "\n",
      "/usr/include/c++/9/array(244): error: template parameter \"_Tp\" may not be redeclared in this scope\n",
      "      array(_Tp, _Up...)\n",
      "            ^\n",
      "\n",
      "/usr/include/c++/9/array(245): error: expected a \";\"\n",
      "        -> array<enable_if_t<(is_same_v<_Tp, _Up> && ...), _Tp>,\n",
      "        ^\n",
      "\n",
      "/usr/include/c++/9/tuple(863): error: argument list for class template \"std::tuple\" is missing\n",
      "      tuple(_UTypes...) -> tuple<_UTypes...>;\n",
      "      ^\n",
      "\n",
      "/usr/include/c++/9/tuple(863): error: expected a \")\"\n",
      "      tuple(_UTypes...) -> tuple<_UTypes...>;\n",
      "                   ^\n",
      "\n",
      "/usr/include/c++/9/tuple(863): error: template parameter \"_UTypes\" may not be redeclared in this scope\n",
      "      tuple(_UTypes...) -> tuple<_UTypes...>;\n",
      "            ^\n",
      "\n",
      "/usr/include/c++/9/tuple(863): error: expected a \";\"\n",
      "      tuple(_UTypes...) -> tuple<_UTypes...>;\n",
      "                        ^\n",
      "\n",
      "/usr/include/c++/9/tuple(865): error: argument list for class template \"std::tuple\" is missing\n",
      "      tuple(pair<_T1, _T2>) -> tuple<_T1, _T2>;\n",
      "      ^\n",
      "\n",
      "/usr/include/c++/9/tuple(865): error: \"pair\" is not a function or static data member\n",
      "      tuple(pair<_T1, _T2>) -> tuple<_T1, _T2>;\n",
      "            ^\n",
      "\n",
      "/usr/include/c++/9/tuple(867): error: argument list for class template \"std::tuple\" is missing\n",
      "      tuple(allocator_arg_t, _Alloc, _UTypes...) -> tuple<_UTypes...>;\n",
      "      ^\n",
      "\n",
      "/usr/include/c++/9/tuple(867): error: expected a \")\"\n",
      "      tuple(allocator_arg_t, _Alloc, _UTypes...) -> tuple<_UTypes...>;\n",
      "                           ^\n",
      "\n",
      "/usr/include/c++/9/tuple(867): error: expected a \";\"\n",
      "      tuple(allocator_arg_t, _Alloc, _UTypes...) -> tuple<_UTypes...>;\n",
      "                                                 ^\n",
      "\n",
      "/usr/include/c++/9/tuple(869): error: argument list for class template \"std::tuple\" is missing\n",
      "      tuple(allocator_arg_t, _Alloc, pair<_T1, _T2>) -> tuple<_T1, _T2>;\n",
      "      ^\n",
      "\n",
      "/usr/include/c++/9/tuple(869): error: expected a \")\"\n",
      "      tuple(allocator_arg_t, _Alloc, pair<_T1, _T2>) -> tuple<_T1, _T2>;\n",
      "                           ^\n",
      "\n",
      "/usr/include/c++/9/tuple(868): error: declaration is incompatible with template parameter \"_UTypes\" (declared at line 866)\n",
      "    template<typename _Alloc, typename _T1, typename _T2>\n",
      "                                       ^\n",
      "\n",
      "/usr/include/c++/9/tuple(868): error: too many template parameters -- does not match previous declaration (declared at line 866)\n",
      "    template<typename _Alloc, typename _T1, typename _T2>\n",
      "                                                     ^\n",
      "\n",
      "/usr/include/c++/9/tuple(869): error: expected a \";\"\n",
      "      tuple(allocator_arg_t, _Alloc, pair<_T1, _T2>) -> tuple<_T1, _T2>;\n",
      "                                                     ^\n",
      "\n",
      "/usr/include/c++/9/tuple(871): error: argument list for class template \"std::tuple\" is missing\n",
      "      tuple(allocator_arg_t, _Alloc, tuple<_UTypes...>) -> tuple<_UTypes...>;\n",
      "      ^\n",
      "\n",
      "/usr/include/c++/9/tuple(871): error: expected a \")\"\n",
      "      tuple(allocator_arg_t, _Alloc, tuple<_UTypes...>) -> tuple<_UTypes...>;\n",
      "                           ^\n",
      "\n",
      "/usr/include/c++/9/tuple(870): error: declaration is incompatible with template parameter \"_T1\" (declared at line 868)\n",
      "    template<typename _Alloc, typename... _UTypes>\n",
      "                                          ^\n",
      "\n",
      "/usr/include/c++/9/tuple(870): error: too few template parameters -- does not match previous declaration (declared at line 868)\n",
      "    template<typename _Alloc, typename... _UTypes>\n",
      "                                          ^\n",
      "\n",
      "/usr/include/c++/9/tuple(871): error: expected a \";\"\n",
      "      tuple(allocator_arg_t, _Alloc, tuple<_UTypes...>) -> tuple<_UTypes...>;\n",
      "                                                        ^\n",
      "\n",
      "/usr/include/c++/9/tuple(885): error: argument list for variable template \"std::allocator_arg_t\" is missing\n",
      "   tuple(allocator_arg_t, const _Alloc&) { }\n",
      "         ^\n",
      "\n",
      "/usr/include/c++/9/tuple(887): error: argument list for variable template \"std::allocator_arg_t\" is missing\n",
      "   tuple(allocator_arg_t, const _Alloc&, const tuple&) { }\n",
      "         ^\n",
      "\n",
      "/usr/include/c++/9/tuple(966): error: argument list for variable template \"std::allocator_arg_t\" is missing\n",
      "             && !is_same<__remove_cvref_t<_U1>, allocator_arg_t>::value,\n",
      "                                                ^\n",
      "\n",
      "/usr/include/c++/9/tuple(976): error: argument list for variable template \"std::allocator_arg_t\" is missing\n",
      "             && !is_same<__remove_cvref_t<_U1>, allocator_arg_t>::value,\n",
      "                                                ^\n",
      "\n",
      "/usr/include/c++/9/tuple(1062): error: argument list for variable template \"std::allocator_arg_t\" is missing\n",
      "   tuple(allocator_arg_t __tag, const _Alloc& __a)\n",
      "         ^\n",
      "\n",
      "/usr/include/c++/9/tuple(1073): error: argument list for variable template \"std::allocator_arg_t\" is missing\n",
      "   tuple(allocator_arg_t __tag, const _Alloc& __a,\n",
      "         ^\n",
      "\n",
      "/usr/include/c++/9/tuple(1085): error: argument list for variable template \"std::allocator_arg_t\" is missing\n",
      "   explicit tuple(allocator_arg_t __tag, const _Alloc& __a,\n",
      "                  ^\n",
      "\n",
      "/usr/include/c++/9/tuple(1095): error: argument list for variable template \"std::allocator_arg_t\" is missing\n",
      "   tuple(allocator_arg_t __tag, const _Alloc& __a, _U1&& __a1, _U2&& __a2)\n",
      "         ^\n",
      "\n",
      "/usr/include/c++/9/tuple(1105): error: argument list for variable template \"std::allocator_arg_t\" is missing\n",
      "   explicit tuple(allocator_arg_t __tag, const _Alloc& __a,\n",
      "                  ^\n",
      "\n",
      "/usr/include/c++/9/tuple(1111): error: argument list for variable template \"std::allocator_arg_t\" is missing\n",
      "   tuple(allocator_arg_t __tag, const _Alloc& __a, const tuple& __in)\n",
      "         ^\n",
      "\n",
      "/usr/include/c++/9/tuple(1115): error: argument list for variable template \"std::allocator_arg_t\" is missing\n",
      "   tuple(allocator_arg_t __tag, const _Alloc& __a, tuple&& __in)\n",
      "         ^\n",
      "\n",
      "/usr/include/c++/9/tuple(1124): error: argument list for variable template \"std::allocator_arg_t\" is missing\n",
      "   tuple(allocator_arg_t __tag, const _Alloc& __a,\n",
      "         ^\n",
      "\n",
      "/usr/include/c++/9/tuple(1136): error: argument list for variable template \"std::allocator_arg_t\" is missing\n",
      "   explicit tuple(allocator_arg_t __tag, const _Alloc& __a,\n",
      "                  ^\n",
      "\n",
      "/usr/include/c++/9/tuple(1148): error: argument list for variable template \"std::allocator_arg_t\" is missing\n",
      "   tuple(allocator_arg_t __tag, const _Alloc& __a, tuple<_U1, _U2>&& __in)\n",
      "         ^\n",
      "\n",
      "/usr/include/c++/9/tuple(1158): error: argument list for variable template \"std::allocator_arg_t\" is missing\n",
      "   explicit tuple(allocator_arg_t __tag, const _Alloc& __a,\n",
      "                  ^\n",
      "\n",
      "/usr/include/c++/9/tuple(1169): error: argument list for variable template \"std::allocator_arg_t\" is missing\n",
      "          tuple(allocator_arg_t __tag, const _Alloc& __a,\n",
      "                ^\n",
      "\n",
      "/usr/include/c++/9/tuple(1179): error: argument list for variable template \"std::allocator_arg_t\" is missing\n",
      "          explicit tuple(allocator_arg_t __tag, const _Alloc& __a,\n",
      "                         ^\n",
      "\n",
      "/usr/include/c++/9/tuple(1189): error: argument list for variable template \"std::allocator_arg_t\" is missing\n",
      "          tuple(allocator_arg_t __tag, const _Alloc& __a, pair<_U1, _U2>&& __in)\n",
      "                ^\n",
      "\n",
      "/usr/include/c++/9/tuple(1199): error: argument list for variable template \"std::allocator_arg_t\" is missing\n",
      "          explicit tuple(allocator_arg_t __tag, const _Alloc& __a,\n",
      "                         ^\n",
      "\n",
      "/usr/include/c++/9/bits/refwrap.h(102): error: class template \"std::_Mem_fn_traits\" has already been defined\n",
      "  template<typename _Res, typename _Class, typename... _ArgTypes> struct _Mem_fn_traits<_Res (_Class::*)(_ArgTypes...) noexcept> : _Mem_fn_traits_base<_Res, _Class, _ArgTypes...> { using __vararg = false_type; }; template<typename _Res, typename _Class, typename... _ArgTypes> struct _Mem_fn_traits<_Res (_Class::*)(_ArgTypes... ...) noexcept> : _Mem_fn_traits_base<_Res, _Class, _ArgTypes...> { using __vararg = true_type; }; template<typename _Res, typename _Class, typename... _ArgTypes> struct _Mem_fn_traits<_Res (_Class::*)(_ArgTypes...) const noexcept> : _Mem_fn_traits_base<_Res, const _Class, _ArgTypes...> { using __vararg = false_type; }; template<typename _Res, typename _Class, typename... _ArgTypes> struct _Mem_fn_traits<_Res (_Class::*)(_ArgTypes... ...) const noexcept> : _Mem_fn_traits_base<_Res, const _Class, _ArgTypes...> { using __vararg = true_type; }; template<typename _Res, typename _Class, typename... _ArgTypes> struct _Mem_fn_traits<_Res (_Class::*)(_ArgTypes...) volatile noexcept> : _Mem_fn_traits_base<_Res, volatile _Class, _ArgTypes...> { using __vararg = false_type; }; template<typename _Res, typename _Class, typename... _ArgTypes> struct _Mem_fn_traits<_Res (_Class::*)(_ArgTypes... ...) volatile noexcept> : _Mem_fn_traits_base<_Res, volatile _Class, _ArgTypes...> { using __vararg = true_type; }; template<typename _Res, typename _Class, typename... _ArgTypes> struct _Mem_fn_traits<_Res (_Class::*)(_ArgTypes...) const volatile noexcept> : _Mem_fn_traits_base<_Res, const volatile _Class, _ArgTypes...> { using __vararg = false_type; }; template<typename _Res, typename _Class, typename... _ArgTypes> struct _Mem_fn_traits<_Res (_Class::*)(_ArgTypes... ...) const volatile noexcept> : _Mem_fn_traits_base<_Res, const volatile _Class, _ArgTypes...> { using __vararg = true_type; };\n",
      "                                                                         ^\n",
      "\n",
      "/usr/include/c++/9/bits/refwrap.h(102): error: class template \"std::_Mem_fn_traits\" has already been defined\n",
      "  template<typename _Res, typename _Class, typename... _ArgTypes> struct _Mem_fn_traits<_Res (_Class::*)(_ArgTypes...) noexcept> : _Mem_fn_traits_base<_Res, _Class, _ArgTypes...> { using __vararg = false_type; }; template<typename _Res, typename _Class, typename... _ArgTypes> struct _Mem_fn_traits<_Res (_Class::*)(_ArgTypes... ...) noexcept> : _Mem_fn_traits_base<_Res, _Class, _ArgTypes...> { using __vararg = true_type; }; template<typename _Res, typename _Class, typename... _ArgTypes> struct _Mem_fn_traits<_Res (_Class::*)(_ArgTypes...) const noexcept> : _Mem_fn_traits_base<_Res, const _Class, _ArgTypes...> { using __vararg = false_type; }; template<typename _Res, typename _Class, typename... _ArgTypes> struct _Mem_fn_traits<_Res (_Class::*)(_ArgTypes... ...) const noexcept> : _Mem_fn_traits_base<_Res, const _Class, _ArgTypes...> { using __vararg = true_type; }; template<typename _Res, typename _Class, typename... _ArgTypes> struct _Mem_fn_traits<_Res (_Class::*)(_ArgTypes...) volatile noexcept> : _Mem_fn_traits_base<_Res, volatile _Class, _ArgTypes...> { using __vararg = false_type; }; template<typename _Res, typename _Class, typename... _ArgTypes> struct _Mem_fn_traits<_Res (_Class::*)(_ArgTypes... ...) volatile noexcept> : _Mem_fn_traits_base<_Res, volatile _Class, _ArgTypes...> { using __vararg = true_type; }; template<typename _Res, typename _Class, typename... _ArgTypes> struct _Mem_fn_traits<_Res (_Class::*)(_ArgTypes...) const volatile noexcept> : _Mem_fn_traits_base<_Res, const volatile _Class, _ArgTypes...> { using __vararg = false_type; }; template<typename _Res, typename _Class, typename... _ArgTypes> struct _Mem_fn_traits<_Res (_Class::*)(_ArgTypes... ...) const volatile noexcept> : _Mem_fn_traits_base<_Res, const volatile _Class, _ArgTypes...> { using __vararg = true_type; };\n",
      "                                                                                                                                                                                                                                                                                            ^\n",
      "\n",
      "/usr/include/c++/9/bits/refwrap.h(102): error: class template \"std::_Mem_fn_traits\" has already been defined\n",
      "  template<typename _Res, typename _Class, typename... _ArgTypes> struct _Mem_fn_traits<_Res (_Class::*)(_ArgTypes...) noexcept> : _Mem_fn_traits_base<_Res, _Class, _ArgTypes...> { using __vararg = false_type; }; template<typename _Res, typename _Class, typename... _ArgTypes> struct _Mem_fn_traits<_Res (_Class::*)(_ArgTypes... ...) noexcept> : _Mem_fn_traits_base<_Res, _Class, _ArgTypes...> { using __vararg = true_type; }; template<typename _Res, typename _Class, typename... _ArgTypes> struct _Mem_fn_traits<_Res (_Class::*)(_ArgTypes...) const noexcept> : _Mem_fn_traits_base<_Res, const _Class, _ArgTypes...> { using __vararg = false_type; }; template<typename _Res, typename _Class, typename... _ArgTypes> struct _Mem_fn_traits<_Res (_Class::*)(_ArgTypes... ...) const noexcept> : _Mem_fn_traits_base<_Res, const _Class, _ArgTypes...> { using __vararg = true_type; }; template<typename _Res, typename _Class, typename... _ArgTypes> struct _Mem_fn_traits<_Res (_Class::*)(_ArgTypes...) volatile noexcept> : _Mem_fn_traits_base<_Res, volatile _Class, _ArgTypes...> { using __vararg = false_type; }; template<typename _Res, typename _Class, typename... _ArgTypes> struct _Mem_fn_traits<_Res (_Class::*)(_ArgTypes... ...) volatile noexcept> : _Mem_fn_traits_base<_Res, volatile _Class, _ArgTypes...> { using __vararg = true_type; }; template<typename _Res, typename _Class, typename... _ArgTypes> struct _Mem_fn_traits<_Res (_Class::*)(_ArgTypes...) const volatile noexcept> : _Mem_fn_traits_base<_Res, const volatile _Class, _ArgTypes...> { using __vararg = false_type; }; template<typename _Res, typename _Class, typename... _ArgTypes> struct _Mem_fn_traits<_Res (_Class::*)(_ArgTypes... ...) const volatile noexcept> : _Mem_fn_traits_base<_Res, const volatile _Class, _ArgTypes...> { using __vararg = true_type; };\n",
      "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  ^\n",
      "\n",
      "/usr/include/c++/9/bits/refwrap.h(102): error: class template \"std::_Mem_fn_traits\" has already been defined\n",
      "  template<typename _Res, typename _Class, typename... _ArgTypes> struct _Mem_fn_traits<_Res (_Class::*)(_ArgTypes...) noexcept> : _Mem_fn_traits_base<_Res, _Class, _ArgTypes...> { using __vararg = false_type; }; template<typename _Res, typename _Class, typename... _ArgTypes> struct _Mem_fn_traits<_Res (_Class::*)(_ArgTypes... ...) noexcept> : _Mem_fn_traits_base<_Res, _Class, _ArgTypes...> { using __vararg = true_type; }; template<typename _Res, typename _Class, typename... _ArgTypes> struct _Mem_fn_traits<_Res (_Class::*)(_ArgTypes...) const noexcept> : _Mem_fn_traits_base<_Res, const _Class, _ArgTypes...> { using __vararg = false_type; }; template<typename _Res, typename _Class, typename... _ArgTypes> struct _Mem_fn_traits<_Res (_Class::*)(_ArgTypes... ...) const noexcept> : _Mem_fn_traits_base<_Res, const _Class, _ArgTypes...> { using __vararg = true_type; }; template<typename _Res, typename _Class, typename... _ArgTypes> struct _Mem_fn_traits<_Res (_Class::*)(_ArgTypes...) volatile noexcept> : _Mem_fn_traits_base<_Res, volatile _Class, _ArgTypes...> { using __vararg = false_type; }; template<typename _Res, typename _Class, typename... _ArgTypes> struct _Mem_fn_traits<_Res (_Class::*)(_ArgTypes... ...) volatile noexcept> : _Mem_fn_traits_base<_Res, volatile _Class, _ArgTypes...> { using __vararg = true_type; }; template<typename _Res, typename _Class, typename... _ArgTypes> struct _Mem_fn_traits<_Res (_Class::*)(_ArgTypes...) const volatile noexcept> : _Mem_fn_traits_base<_Res, const volatile _Class, _ArgTypes...> { using __vararg = false_type; }; template<typename _Res, typename _Class, typename... _ArgTypes> struct _Mem_fn_traits<_Res (_Class::*)(_ArgTypes... ...) const volatile noexcept> : _Mem_fn_traits_base<_Res, const volatile _Class, _ArgTypes...> { using __vararg = true_type; };\n",
      "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 ^\n",
      "\n",
      "/usr/include/c++/9/bits/refwrap.h(102): error: class template \"std::_Mem_fn_traits\" has already been defined\n",
      "  template<typename _Res, typename _Class, typename... _ArgTypes> struct _Mem_fn_traits<_Res (_Class::*)(_ArgTypes...) noexcept> : _Mem_fn_traits_base<_Res, _Class, _ArgTypes...> { using __vararg = false_type; }; template<typename _Res, typename _Class, typename... _ArgTypes> struct _Mem_fn_traits<_Res (_Class::*)(_ArgTypes... ...) noexcept> : _Mem_fn_traits_base<_Res, _Class, _ArgTypes...> { using __vararg = true_type; }; template<typename _Res, typename _Class, typename... _ArgTypes> struct _Mem_fn_traits<_Res (_Class::*)(_ArgTypes...) const noexcept> : _Mem_fn_traits_base<_Res, const _Class, _ArgTypes...> { using __vararg = false_type; }; template<typename _Res, typename _Class, typename... _ArgTypes> struct _Mem_fn_traits<_Res (_Class::*)(_ArgTypes... ...) const noexcept> : _Mem_fn_traits_base<_Res, const _Class, _ArgTypes...> { using __vararg = true_type; }; template<typename _Res, typename _Class, typename... _ArgTypes> struct _Mem_fn_traits<_Res (_Class::*)(_ArgTypes...) volatile noexcept> : _Mem_fn_traits_base<_Res, volatile _Class, _ArgTypes...> { using __vararg = false_type; }; template<typename _Res, typename _Class, typename... _ArgTypes> struct _Mem_fn_traits<_Res (_Class::*)(_ArgTypes... ...) volatile noexcept> : _Mem_fn_traits_base<_Res, volatile _Class, _ArgTypes...> { using __vararg = true_type; }; template<typename _Res, typename _Class, typename... _ArgTypes> struct _Mem_fn_traits<_Res (_Class::*)(_ArgTypes...) const volatile noexcept> : _Mem_fn_traits_base<_Res, const volatile _Class, _ArgTypes...> { using __vararg = false_type; }; template<typename _Res, typename _Class, typename... _ArgTypes> struct _Mem_fn_traits<_Res (_Class::*)(_ArgTypes... ...) const volatile noexcept> : _Mem_fn_traits_base<_Res, const volatile _Class, _ArgTypes...> { using __vararg = true_type; };\n",
      "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   ^\n",
      "\n",
      "/usr/include/c++/9/bits/refwrap.h(102): error: class template \"std::_Mem_fn_traits\" has already been defined\n",
      "  template<typename _Res, typename _Class, typename... _ArgTypes> struct _Mem_fn_traits<_Res (_Class::*)(_ArgTypes...) noexcept> : _Mem_fn_traits_base<_Res, _Class, _ArgTypes...> { using __vararg = false_type; }; template<typename _Res, typename _Class, typename... _ArgTypes> struct _Mem_fn_traits<_Res (_Class::*)(_ArgTypes... ...) noexcept> : _Mem_fn_traits_base<_Res, _Class, _ArgTypes...> { using __vararg = true_type; }; template<typename _Res, typename _Class, typename... _ArgTypes> struct _Mem_fn_traits<_Res (_Class::*)(_ArgTypes...) const noexcept> : _Mem_fn_traits_base<_Res, const _Class, _ArgTypes...> { using __vararg = false_type; }; template<typename _Res, typename _Class, typename... _ArgTypes> struct _Mem_fn_traits<_Res (_Class::*)(_ArgTypes... ...) const noexcept> : _Mem_fn_traits_base<_Res, const _Class, _ArgTypes...> { using __vararg = true_type; }; template<typename _Res, typename _Class, typename... _ArgTypes> struct _Mem_fn_traits<_Res (_Class::*)(_ArgTypes...) volatile noexcept> : _Mem_fn_traits_base<_Res, volatile _Class, _ArgTypes...> { using __vararg = false_type; }; template<typename _Res, typename _Class, typename... _ArgTypes> struct _Mem_fn_traits<_Res (_Class::*)(_ArgTypes... ...) volatile noexcept> : _Mem_fn_traits_base<_Res, volatile _Class, _ArgTypes...> { using __vararg = true_type; }; template<typename _Res, typename _Class, typename... _ArgTypes> struct _Mem_fn_traits<_Res (_Class::*)(_ArgTypes...) const volatile noexcept> : _Mem_fn_traits_base<_Res, const volatile _Class, _ArgTypes...> { using __vararg = false_type; }; template<typename _Res, typename _Class, typename... _ArgTypes> struct _Mem_fn_traits<_Res (_Class::*)(_ArgTypes... ...) const volatile noexcept> : _Mem_fn_traits_base<_Res, const volatile _Class, _ArgTypes...> { using __vararg = true_type; };\n",
      "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        ^\n",
      "\n",
      "/usr/include/c++/9/bits/refwrap.h(102): error: class template \"std::_Mem_fn_traits\" has already been defined\n",
      "  template<typename _Res, typename _Class, typename... _ArgTypes> struct _Mem_fn_traits<_Res (_Class::*)(_ArgTypes...) noexcept> : _Mem_fn_traits_base<_Res, _Class, _ArgTypes...> { using __vararg = false_type; }; template<typename _Res, typename _Class, typename... _ArgTypes> struct _Mem_fn_traits<_Res (_Class::*)(_ArgTypes... ...) noexcept> : _Mem_fn_traits_base<_Res, _Class, _ArgTypes...> { using __vararg = true_type; }; template<typename _Res, typename _Class, typename... _ArgTypes> struct _Mem_fn_traits<_Res (_Class::*)(_ArgTypes...) const noexcept> : _Mem_fn_traits_base<_Res, const _Class, _ArgTypes...> { using __vararg = false_type; }; template<typename _Res, typename _Class, typename... _ArgTypes> struct _Mem_fn_traits<_Res (_Class::*)(_ArgTypes... ...) const noexcept> : _Mem_fn_traits_base<_Res, const _Class, _ArgTypes...> { using __vararg = true_type; }; template<typename _Res, typename _Class, typename... _ArgTypes> struct _Mem_fn_traits<_Res (_Class::*)(_ArgTypes...) volatile noexcept> : _Mem_fn_traits_base<_Res, volatile _Class, _ArgTypes...> { using __vararg = false_type; }; template<typename _Res, typename _Class, typename... _ArgTypes> struct _Mem_fn_traits<_Res (_Class::*)(_ArgTypes... ...) volatile noexcept> : _Mem_fn_traits_base<_Res, volatile _Class, _ArgTypes...> { using __vararg = true_type; }; template<typename _Res, typename _Class, typename... _ArgTypes> struct _Mem_fn_traits<_Res (_Class::*)(_ArgTypes...) const volatile noexcept> : _Mem_fn_traits_base<_Res, const volatile _Class, _ArgTypes...> { using __vararg = false_type; }; template<typename _Res, typename _Class, typename... _ArgTypes> struct _Mem_fn_traits<_Res (_Class::*)(_ArgTypes... ...) const volatile noexcept> : _Mem_fn_traits_base<_Res, const volatile _Class, _ArgTypes...> { using __vararg = true_type; };\n",
      "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                ^\n",
      "\n",
      "/usr/include/c++/9/bits/refwrap.h(102): error: class template \"std::_Mem_fn_traits\" has already been defined\n",
      "  template<typename _Res, typename _Class, typename... _ArgTypes> struct _Mem_fn_traits<_Res (_Class::*)(_ArgTypes...) noexcept> : _Mem_fn_traits_base<_Res, _Class, _ArgTypes...> { using __vararg = false_type; }; template<typename _Res, typename _Class, typename... _ArgTypes> struct _Mem_fn_traits<_Res (_Class::*)(_ArgTypes... ...) noexcept> : _Mem_fn_traits_base<_Res, _Class, _ArgTypes...> { using __vararg = true_type; }; template<typename _Res, typename _Class, typename... _ArgTypes> struct _Mem_fn_traits<_Res (_Class::*)(_ArgTypes...) const noexcept> : _Mem_fn_traits_base<_Res, const _Class, _ArgTypes...> { using __vararg = false_type; }; template<typename _Res, typename _Class, typename... _ArgTypes> struct _Mem_fn_traits<_Res (_Class::*)(_ArgTypes... ...) const noexcept> : _Mem_fn_traits_base<_Res, const _Class, _ArgTypes...> { using __vararg = true_type; }; template<typename _Res, typename _Class, typename... _ArgTypes> struct _Mem_fn_traits<_Res (_Class::*)(_ArgTypes...) volatile noexcept> : _Mem_fn_traits_base<_Res, volatile _Class, _ArgTypes...> { using __vararg = false_type; }; template<typename _Res, typename _Class, typename... _ArgTypes> struct _Mem_fn_traits<_Res (_Class::*)(_ArgTypes... ...) volatile noexcept> : _Mem_fn_traits_base<_Res, volatile _Class, _ArgTypes...> { using __vararg = true_type; }; template<typename _Res, typename _Class, typename... _ArgTypes> struct _Mem_fn_traits<_Res (_Class::*)(_ArgTypes...) const volatile noexcept> : _Mem_fn_traits_base<_Res, const volatile _Class, _ArgTypes...> { using __vararg = false_type; }; template<typename _Res, typename _Class, typename... _ArgTypes> struct _Mem_fn_traits<_Res (_Class::*)(_ArgTypes... ...) const volatile noexcept> : _Mem_fn_traits_base<_Res, const volatile _Class, _ArgTypes...> { using __vararg = true_type; };\n",
      "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 ^\n",
      "\n",
      "/usr/include/c++/9/bits/refwrap.h(103): error: class template \"std::_Mem_fn_traits\" has already been defined\n",
      "  template<typename _Res, typename _Class, typename... _ArgTypes> struct _Mem_fn_traits<_Res (_Class::*)(_ArgTypes...) & noexcept> : _Mem_fn_traits_base<_Res, _Class, _ArgTypes...> { using __vararg = false_type; }; template<typename _Res, typename _Class, typename... _ArgTypes> struct _Mem_fn_traits<_Res (_Class::*)(_ArgTypes... ...) & noexcept> : _Mem_fn_traits_base<_Res, _Class, _ArgTypes...> { using __vararg = true_type; }; template<typename _Res, typename _Class, typename... _ArgTypes> struct _Mem_fn_traits<_Res (_Class::*)(_ArgTypes...) const & noexcept> : _Mem_fn_traits_base<_Res, const _Class, _ArgTypes...> { using __vararg = false_type; }; template<typename _Res, typename _Class, typename... _ArgTypes> struct _Mem_fn_traits<_Res (_Class::*)(_ArgTypes... ...) const & noexcept> : _Mem_fn_traits_base<_Res, const _Class, _ArgTypes...> { using __vararg = true_type; }; template<typename _Res, typename _Class, typename... _ArgTypes> struct _Mem_fn_traits<_Res (_Class::*)(_ArgTypes...) volatile & noexcept> : _Mem_fn_traits_base<_Res, volatile _Class, _ArgTypes...> { using __vararg = false_type; }; template<typename _Res, typename _Class, typename... _ArgTypes> struct _Mem_fn_traits<_Res (_Class::*)(_ArgTypes... ...) volatile & noexcept> : _Mem_fn_traits_base<_Res, volatile _Class, _ArgTypes...> { using __vararg = true_type; }; template<typename _Res, typename _Class, typename... _ArgTypes> struct _Mem_fn_traits<_Res (_Class::*)(_ArgTypes...) const volatile & noexcept> : _Mem_fn_traits_base<_Res, const volatile _Class, _ArgTypes...> { using __vararg = false_type; }; template<typename _Res, typename _Class, typename... _ArgTypes> struct _Mem_fn_traits<_Res (_Class::*)(_ArgTypes... ...) const volatile & noexcept> : _Mem_fn_traits_base<_Res, const volatile _Class, _ArgTypes...> { using __vararg = true_type; };\n",
      "                                                                         ^\n",
      "\n",
      "/usr/include/c++/9/bits/refwrap.h(103): error: class template \"std::_Mem_fn_traits\" has already been defined\n",
      "  template<typename _Res, typename _Class, typename... _ArgTypes> struct _Mem_fn_traits<_Res (_Class::*)(_ArgTypes...) & noexcept> : _Mem_fn_traits_base<_Res, _Class, _ArgTypes...> { using __vararg = false_type; }; template<typename _Res, typename _Class, typename... _ArgTypes> struct _Mem_fn_traits<_Res (_Class::*)(_ArgTypes... ...) & noexcept> : _Mem_fn_traits_base<_Res, _Class, _ArgTypes...> { using __vararg = true_type; }; template<typename _Res, typename _Class, typename... _ArgTypes> struct _Mem_fn_traits<_Res (_Class::*)(_ArgTypes...) const & noexcept> : _Mem_fn_traits_base<_Res, const _Class, _ArgTypes...> { using __vararg = false_type; }; template<typename _Res, typename _Class, typename... _ArgTypes> struct _Mem_fn_traits<_Res (_Class::*)(_ArgTypes... ...) const & noexcept> : _Mem_fn_traits_base<_Res, const _Class, _ArgTypes...> { using __vararg = true_type; }; template<typename _Res, typename _Class, typename... _ArgTypes> struct _Mem_fn_traits<_Res (_Class::*)(_ArgTypes...) volatile & noexcept> : _Mem_fn_traits_base<_Res, volatile _Class, _ArgTypes...> { using __vararg = false_type; }; template<typename _Res, typename _Class, typename... _ArgTypes> struct _Mem_fn_traits<_Res (_Class::*)(_ArgTypes... ...) volatile & noexcept> : _Mem_fn_traits_base<_Res, volatile _Class, _ArgTypes...> { using __vararg = true_type; }; template<typename _Res, typename _Class, typename... _ArgTypes> struct _Mem_fn_traits<_Res (_Class::*)(_ArgTypes...) const volatile & noexcept> : _Mem_fn_traits_base<_Res, const volatile _Class, _ArgTypes...> { using __vararg = false_type; }; template<typename _Res, typename _Class, typename... _ArgTypes> struct _Mem_fn_traits<_Res (_Class::*)(_ArgTypes... ...) const volatile & noexcept> : _Mem_fn_traits_base<_Res, const volatile _Class, _ArgTypes...> { using __vararg = true_type; };\n",
      "                                                                                                                                                                                                                                                                                              ^\n",
      "\n",
      "/usr/include/c++/9/bits/refwrap.h(103): error: class template \"std::_Mem_fn_traits\" has already been defined\n",
      "  template<typename _Res, typename _Class, typename... _ArgTypes> struct _Mem_fn_traits<_Res (_Class::*)(_ArgTypes...) & noexcept> : _Mem_fn_traits_base<_Res, _Class, _ArgTypes...> { using __vararg = false_type; }; template<typename _Res, typename _Class, typename... _ArgTypes> struct _Mem_fn_traits<_Res (_Class::*)(_ArgTypes... ...) & noexcept> : _Mem_fn_traits_base<_Res, _Class, _ArgTypes...> { using __vararg = true_type; }; template<typename _Res, typename _Class, typename... _ArgTypes> struct _Mem_fn_traits<_Res (_Class::*)(_ArgTypes...) const & noexcept> : _Mem_fn_traits_base<_Res, const _Class, _ArgTypes...> { using __vararg = false_type; }; template<typename _Res, typename _Class, typename... _ArgTypes> struct _Mem_fn_traits<_Res (_Class::*)(_ArgTypes... ...) const & noexcept> : _Mem_fn_traits_base<_Res, const _Class, _ArgTypes...> { using __vararg = true_type; }; template<typename _Res, typename _Class, typename... _ArgTypes> struct _Mem_fn_traits<_Res (_Class::*)(_ArgTypes...) volatile & noexcept> : _Mem_fn_traits_base<_Res, volatile _Class, _ArgTypes...> { using __vararg = false_type; }; template<typename _Res, typename _Class, typename... _ArgTypes> struct _Mem_fn_traits<_Res (_Class::*)(_ArgTypes... ...) volatile & noexcept> : _Mem_fn_traits_base<_Res, volatile _Class, _ArgTypes...> { using __vararg = true_type; }; template<typename _Res, typename _Class, typename... _ArgTypes> struct _Mem_fn_traits<_Res (_Class::*)(_ArgTypes...) const volatile & noexcept> : _Mem_fn_traits_base<_Res, const volatile _Class, _ArgTypes...> { using __vararg = false_type; }; template<typename _Res, typename _Class, typename... _ArgTypes> struct _Mem_fn_traits<_Res (_Class::*)(_ArgTypes... ...) const volatile & noexcept> : _Mem_fn_traits_base<_Res, const volatile _Class, _ArgTypes...> { using __vararg = true_type; };\n",
      "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      ^\n",
      "\n",
      "/usr/include/c++/9/bits/refwrap.h(103): error: class template \"std::_Mem_fn_traits\" has already been defined\n",
      "  template<typename _Res, typename _Class, typename... _ArgTypes> struct _Mem_fn_traits<_Res (_Class::*)(_ArgTypes...) & noexcept> : _Mem_fn_traits_base<_Res, _Class, _ArgTypes...> { using __vararg = false_type; }; template<typename _Res, typename _Class, typename... _ArgTypes> struct _Mem_fn_traits<_Res (_Class::*)(_ArgTypes... ...) & noexcept> : _Mem_fn_traits_base<_Res, _Class, _ArgTypes...> { using __vararg = true_type; }; template<typename _Res, typename _Class, typename... _ArgTypes> struct _Mem_fn_traits<_Res (_Class::*)(_ArgTypes...) const & noexcept> : _Mem_fn_traits_base<_Res, const _Class, _ArgTypes...> { using __vararg = false_type; }; template<typename _Res, typename _Class, typename... _ArgTypes> struct _Mem_fn_traits<_Res (_Class::*)(_ArgTypes... ...) const & noexcept> : _Mem_fn_traits_base<_Res, const _Class, _ArgTypes...> { using __vararg = true_type; }; template<typename _Res, typename _Class, typename... _ArgTypes> struct _Mem_fn_traits<_Res (_Class::*)(_ArgTypes...) volatile & noexcept> : _Mem_fn_traits_base<_Res, volatile _Class, _ArgTypes...> { using __vararg = false_type; }; template<typename _Res, typename _Class, typename... _ArgTypes> struct _Mem_fn_traits<_Res (_Class::*)(_ArgTypes... ...) volatile & noexcept> : _Mem_fn_traits_base<_Res, volatile _Class, _ArgTypes...> { using __vararg = true_type; }; template<typename _Res, typename _Class, typename... _ArgTypes> struct _Mem_fn_traits<_Res (_Class::*)(_ArgTypes...) const volatile & noexcept> : _Mem_fn_traits_base<_Res, const volatile _Class, _ArgTypes...> { using __vararg = false_type; }; template<typename _Res, typename _Class, typename... _ArgTypes> struct _Mem_fn_traits<_Res (_Class::*)(_ArgTypes... ...) const volatile & noexcept> : _Mem_fn_traits_base<_Res, const volatile _Class, _ArgTypes...> { using __vararg = true_type; };\n",
      "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       ^\n",
      "\n",
      "/usr/include/c++/9/bits/refwrap.h(103): error: class template \"std::_Mem_fn_traits\" has already been defined\n",
      "  template<typename _Res, typename _Class, typename... _ArgTypes> struct _Mem_fn_traits<_Res (_Class::*)(_ArgTypes...) & noexcept> : _Mem_fn_traits_base<_Res, _Class, _ArgTypes...> { using __vararg = false_type; }; template<typename _Res, typename _Class, typename... _ArgTypes> struct _Mem_fn_traits<_Res (_Class::*)(_ArgTypes... ...) & noexcept> : _Mem_fn_traits_base<_Res, _Class, _ArgTypes...> { using __vararg = true_type; }; template<typename _Res, typename _Class, typename... _ArgTypes> struct _Mem_fn_traits<_Res (_Class::*)(_ArgTypes...) const & noexcept> : _Mem_fn_traits_base<_Res, const _Class, _ArgTypes...> { using __vararg = false_type; }; template<typename _Res, typename _Class, typename... _ArgTypes> struct _Mem_fn_traits<_Res (_Class::*)(_ArgTypes... ...) const & noexcept> : _Mem_fn_traits_base<_Res, const _Class, _ArgTypes...> { using __vararg = true_type; }; template<typename _Res, typename _Class, typename... _ArgTypes> struct _Mem_fn_traits<_Res (_Class::*)(_ArgTypes...) volatile & noexcept> : _Mem_fn_traits_base<_Res, volatile _Class, _ArgTypes...> { using __vararg = false_type; }; template<typename _Res, typename _Class, typename... _ArgTypes> struct _Mem_fn_traits<_Res (_Class::*)(_ArgTypes... ...) volatile & noexcept> : _Mem_fn_traits_base<_Res, volatile _Class, _ArgTypes...> { using __vararg = true_type; }; template<typename _Res, typename _Class, typename... _ArgTypes> struct _Mem_fn_traits<_Res (_Class::*)(_ArgTypes...) const volatile & noexcept> : _Mem_fn_traits_base<_Res, const volatile _Class, _ArgTypes...> { using __vararg = false_type; }; template<typename _Res, typename _Class, typename... _ArgTypes> struct _Mem_fn_traits<_Res (_Class::*)(_ArgTypes... ...) const volatile & noexcept> : _Mem_fn_traits_base<_Res, const volatile _Class, _ArgTypes...> { using __vararg = true_type; };\n",
      "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           ^\n",
      "\n",
      "/usr/include/c++/9/bits/refwrap.h(103): error: class template \"std::_Mem_fn_traits\" has already been defined\n",
      "  template<typename _Res, typename _Class, typename... _ArgTypes> struct _Mem_fn_traits<_Res (_Class::*)(_ArgTypes...) & noexcept> : _Mem_fn_traits_base<_Res, _Class, _ArgTypes...> { using __vararg = false_type; }; template<typename _Res, typename _Class, typename... _ArgTypes> struct _Mem_fn_traits<_Res (_Class::*)(_ArgTypes... ...) & noexcept> : _Mem_fn_traits_base<_Res, _Class, _ArgTypes...> { using __vararg = true_type; }; template<typename _Res, typename _Class, typename... _ArgTypes> struct _Mem_fn_traits<_Res (_Class::*)(_ArgTypes...) const & noexcept> : _Mem_fn_traits_base<_Res, const _Class, _ArgTypes...> { using __vararg = false_type; }; template<typename _Res, typename _Class, typename... _ArgTypes> struct _Mem_fn_traits<_Res (_Class::*)(_ArgTypes... ...) const & noexcept> : _Mem_fn_traits_base<_Res, const _Class, _ArgTypes...> { using __vararg = true_type; }; template<typename _Res, typename _Class, typename... _ArgTypes> struct _Mem_fn_traits<_Res (_Class::*)(_ArgTypes...) volatile & noexcept> : _Mem_fn_traits_base<_Res, volatile _Class, _ArgTypes...> { using __vararg = false_type; }; template<typename _Res, typename _Class, typename... _ArgTypes> struct _Mem_fn_traits<_Res (_Class::*)(_ArgTypes... ...) volatile & noexcept> : _Mem_fn_traits_base<_Res, volatile _Class, _ArgTypes...> { using __vararg = true_type; }; template<typename _Res, typename _Class, typename... _ArgTypes> struct _Mem_fn_traits<_Res (_Class::*)(_ArgTypes...) const volatile & noexcept> : _Mem_fn_traits_base<_Res, const volatile _Class, _ArgTypes...> { using __vararg = false_type; }; template<typename _Res, typename _Class, typename... _ArgTypes> struct _Mem_fn_traits<_Res (_Class::*)(_ArgTypes... ...) const volatile & noexcept> : _Mem_fn_traits_base<_Res, const volatile _Class, _ArgTypes...> { using __vararg = true_type; };\n",
      "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  ^\n",
      "\n",
      "/usr/include/c++/9/bits/refwrap.h(103): error: class template \"std::_Mem_fn_traits\" has already been defined\n",
      "  template<typename _Res, typename _Class, typename... _ArgTypes> struct _Mem_fn_traits<_Res (_Class::*)(_ArgTypes...) & noexcept> : _Mem_fn_traits_base<_Res, _Class, _ArgTypes...> { using __vararg = false_type; }; template<typename _Res, typename _Class, typename... _ArgTypes> struct _Mem_fn_traits<_Res (_Class::*)(_ArgTypes... ...) & noexcept> : _Mem_fn_traits_base<_Res, _Class, _ArgTypes...> { using __vararg = true_type; }; template<typename _Res, typename _Class, typename... _ArgTypes> struct _Mem_fn_traits<_Res (_Class::*)(_ArgTypes...) const & noexcept> : _Mem_fn_traits_base<_Res, const _Class, _ArgTypes...> { using __vararg = false_type; }; template<typename _Res, typename _Class, typename... _ArgTypes> struct _Mem_fn_traits<_Res (_Class::*)(_ArgTypes... ...) const & noexcept> : _Mem_fn_traits_base<_Res, const _Class, _ArgTypes...> { using __vararg = true_type; }; template<typename _Res, typename _Class, typename... _ArgTypes> struct _Mem_fn_traits<_Res (_Class::*)(_ArgTypes...) volatile & noexcept> : _Mem_fn_traits_base<_Res, volatile _Class, _ArgTypes...> { using __vararg = false_type; }; template<typename _Res, typename _Class, typename... _ArgTypes> struct _Mem_fn_traits<_Res (_Class::*)(_ArgTypes... ...) volatile & noexcept> : _Mem_fn_traits_base<_Res, volatile _Class, _ArgTypes...> { using __vararg = true_type; }; template<typename _Res, typename _Class, typename... _ArgTypes> struct _Mem_fn_traits<_Res (_Class::*)(_ArgTypes...) const volatile & noexcept> : _Mem_fn_traits_base<_Res, const volatile _Class, _ArgTypes...> { using __vararg = false_type; }; template<typename _Res, typename _Class, typename... _ArgTypes> struct _Mem_fn_traits<_Res (_Class::*)(_ArgTypes... ...) const volatile & noexcept> : _Mem_fn_traits_base<_Res, const volatile _Class, _ArgTypes...> { using __vararg = true_type; };\n",
      "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            ^\n",
      "\n",
      "/usr/include/c++/9/bits/refwrap.h(103): error: class template \"std::_Mem_fn_traits\" has already been defined\n",
      "  template<typename _Res, typename _Class, typename... _ArgTypes> struct _Mem_fn_traits<_Res (_Class::*)(_ArgTypes...) & noexcept> : _Mem_fn_traits_base<_Res, _Class, _ArgTypes...> { using __vararg = false_type; }; template<typename _Res, typename _Class, typename... _ArgTypes> struct _Mem_fn_traits<_Res (_Class::*)(_ArgTypes... ...) & noexcept> : _Mem_fn_traits_base<_Res, _Class, _ArgTypes...> { using __vararg = true_type; }; template<typename _Res, typename _Class, typename... _ArgTypes> struct _Mem_fn_traits<_Res (_Class::*)(_ArgTypes...) const & noexcept> : _Mem_fn_traits_base<_Res, const _Class, _ArgTypes...> { using __vararg = false_type; }; template<typename _Res, typename _Class, typename... _ArgTypes> struct _Mem_fn_traits<_Res (_Class::*)(_ArgTypes... ...) const & noexcept> : _Mem_fn_traits_base<_Res, const _Class, _ArgTypes...> { using __vararg = true_type; }; template<typename _Res, typename _Class, typename... _ArgTypes> struct _Mem_fn_traits<_Res (_Class::*)(_ArgTypes...) volatile & noexcept> : _Mem_fn_traits_base<_Res, volatile _Class, _ArgTypes...> { using __vararg = false_type; }; template<typename _Res, typename _Class, typename... _ArgTypes> struct _Mem_fn_traits<_Res (_Class::*)(_ArgTypes... ...) volatile & noexcept> : _Mem_fn_traits_base<_Res, volatile _Class, _ArgTypes...> { using __vararg = true_type; }; template<typename _Res, typename _Class, typename... _ArgTypes> struct _Mem_fn_traits<_Res (_Class::*)(_ArgTypes...) const volatile & noexcept> : _Mem_fn_traits_base<_Res, const volatile _Class, _ArgTypes...> { using __vararg = false_type; }; template<typename _Res, typename _Class, typename... _ArgTypes> struct _Mem_fn_traits<_Res (_Class::*)(_ArgTypes... ...) const volatile & noexcept> : _Mem_fn_traits_base<_Res, const volatile _Class, _ArgTypes...> { using __vararg = true_type; };\n",
      "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               ^\n",
      "\n",
      "/usr/include/c++/9/bits/refwrap.h(104): error: class template \"std::_Mem_fn_traits\" has already been defined\n",
      "  template<typename _Res, typename _Class, typename... _ArgTypes> struct _Mem_fn_traits<_Res (_Class::*)(_ArgTypes...) && noexcept> : _Mem_fn_traits_base<_Res, _Class, _ArgTypes...> { using __vararg = false_type; }; template<typename _Res, typename _Class, typename... _ArgTypes> struct _Mem_fn_traits<_Res (_Class::*)(_ArgTypes... ...) && noexcept> : _Mem_fn_traits_base<_Res, _Class, _ArgTypes...> { using __vararg = true_type; }; template<typename _Res, typename _Class, typename... _ArgTypes> struct _Mem_fn_traits<_Res (_Class::*)(_ArgTypes...) const && noexcept> : _Mem_fn_traits_base<_Res, const _Class, _ArgTypes...> { using __vararg = false_type; }; template<typename _Res, typename _Class, typename... _ArgTypes> struct _Mem_fn_traits<_Res (_Class::*)(_ArgTypes... ...) const && noexcept> : _Mem_fn_traits_base<_Res, const _Class, _ArgTypes...> { using __vararg = true_type; }; template<typename _Res, typename _Class, typename... _ArgTypes> struct _Mem_fn_traits<_Res (_Class::*)(_ArgTypes...) volatile && noexcept> : _Mem_fn_traits_base<_Res, volatile _Class, _ArgTypes...> { using __vararg = false_type; }; template<typename _Res, typename _Class, typename... _ArgTypes> struct _Mem_fn_traits<_Res (_Class::*)(_ArgTypes... ...) volatile && noexcept> : _Mem_fn_traits_base<_Res, volatile _Class, _ArgTypes...> { using __vararg = true_type; }; template<typename _Res, typename _Class, typename... _ArgTypes> struct _Mem_fn_traits<_Res (_Class::*)(_ArgTypes...) const volatile && noexcept> : _Mem_fn_traits_base<_Res, const volatile _Class, _ArgTypes...> { using __vararg = false_type; }; template<typename _Res, typename _Class, typename... _ArgTypes> struct _Mem_fn_traits<_Res (_Class::*)(_ArgTypes... ...) const volatile && noexcept> : _Mem_fn_traits_base<_Res, const volatile _Class, _ArgTypes...> { using __vararg = true_type; };\n",
      "                                                                         ^\n",
      "\n",
      "/usr/include/c++/9/bits/refwrap.h(104): error: class template \"std::_Mem_fn_traits\" has already been defined\n",
      "  template<typename _Res, typename _Class, typename... _ArgTypes> struct _Mem_fn_traits<_Res (_Class::*)(_ArgTypes...) && noexcept> : _Mem_fn_traits_base<_Res, _Class, _ArgTypes...> { using __vararg = false_type; }; template<typename _Res, typename _Class, typename... _ArgTypes> struct _Mem_fn_traits<_Res (_Class::*)(_ArgTypes... ...) && noexcept> : _Mem_fn_traits_base<_Res, _Class, _ArgTypes...> { using __vararg = true_type; }; template<typename _Res, typename _Class, typename... _ArgTypes> struct _Mem_fn_traits<_Res (_Class::*)(_ArgTypes...) const && noexcept> : _Mem_fn_traits_base<_Res, const _Class, _ArgTypes...> { using __vararg = false_type; }; template<typename _Res, typename _Class, typename... _ArgTypes> struct _Mem_fn_traits<_Res (_Class::*)(_ArgTypes... ...) const && noexcept> : _Mem_fn_traits_base<_Res, const _Class, _ArgTypes...> { using __vararg = true_type; }; template<typename _Res, typename _Class, typename... _ArgTypes> struct _Mem_fn_traits<_Res (_Class::*)(_ArgTypes...) volatile && noexcept> : _Mem_fn_traits_base<_Res, volatile _Class, _ArgTypes...> { using __vararg = false_type; }; template<typename _Res, typename _Class, typename... _ArgTypes> struct _Mem_fn_traits<_Res (_Class::*)(_ArgTypes... ...) volatile && noexcept> : _Mem_fn_traits_base<_Res, volatile _Class, _ArgTypes...> { using __vararg = true_type; }; template<typename _Res, typename _Class, typename... _ArgTypes> struct _Mem_fn_traits<_Res (_Class::*)(_ArgTypes...) const volatile && noexcept> : _Mem_fn_traits_base<_Res, const volatile _Class, _ArgTypes...> { using __vararg = false_type; }; template<typename _Res, typename _Class, typename... _ArgTypes> struct _Mem_fn_traits<_Res (_Class::*)(_ArgTypes... ...) const volatile && noexcept> : _Mem_fn_traits_base<_Res, const volatile _Class, _ArgTypes...> { using __vararg = true_type; };\n",
      "                                                                                                                                                                                                                                                                                               ^\n",
      "\n",
      "/usr/include/c++/9/bits/refwrap.h(104): error: class template \"std::_Mem_fn_traits\" has already been defined\n",
      "  template<typename _Res, typename _Class, typename... _ArgTypes> struct _Mem_fn_traits<_Res (_Class::*)(_ArgTypes...) && noexcept> : _Mem_fn_traits_base<_Res, _Class, _ArgTypes...> { using __vararg = false_type; }; template<typename _Res, typename _Class, typename... _ArgTypes> struct _Mem_fn_traits<_Res (_Class::*)(_ArgTypes... ...) && noexcept> : _Mem_fn_traits_base<_Res, _Class, _ArgTypes...> { using __vararg = true_type; }; template<typename _Res, typename _Class, typename... _ArgTypes> struct _Mem_fn_traits<_Res (_Class::*)(_ArgTypes...) const && noexcept> : _Mem_fn_traits_base<_Res, const _Class, _ArgTypes...> { using __vararg = false_type; }; template<typename _Res, typename _Class, typename... _ArgTypes> struct _Mem_fn_traits<_Res (_Class::*)(_ArgTypes... ...) const && noexcept> : _Mem_fn_traits_base<_Res, const _Class, _ArgTypes...> { using __vararg = true_type; }; template<typename _Res, typename _Class, typename... _ArgTypes> struct _Mem_fn_traits<_Res (_Class::*)(_ArgTypes...) volatile && noexcept> : _Mem_fn_traits_base<_Res, volatile _Class, _ArgTypes...> { using __vararg = false_type; }; template<typename _Res, typename _Class, typename... _ArgTypes> struct _Mem_fn_traits<_Res (_Class::*)(_ArgTypes... ...) volatile && noexcept> : _Mem_fn_traits_base<_Res, volatile _Class, _ArgTypes...> { using __vararg = true_type; }; template<typename _Res, typename _Class, typename... _ArgTypes> struct _Mem_fn_traits<_Res (_Class::*)(_ArgTypes...) const volatile && noexcept> : _Mem_fn_traits_base<_Res, const volatile _Class, _ArgTypes...> { using __vararg = false_type; }; template<typename _Res, typename _Class, typename... _ArgTypes> struct _Mem_fn_traits<_Res (_Class::*)(_ArgTypes... ...) const volatile && noexcept> : _Mem_fn_traits_base<_Res, const volatile _Class, _ArgTypes...> { using __vararg = true_type; };\n",
      "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        ^\n",
      "\n",
      "/usr/include/c++/9/bits/refwrap.h(104): error: class template \"std::_Mem_fn_traits\" has already been defined\n",
      "  template<typename _Res, typename _Class, typename... _ArgTypes> struct _Mem_fn_traits<_Res (_Class::*)(_ArgTypes...) && noexcept> : _Mem_fn_traits_base<_Res, _Class, _ArgTypes...> { using __vararg = false_type; }; template<typename _Res, typename _Class, typename... _ArgTypes> struct _Mem_fn_traits<_Res (_Class::*)(_ArgTypes... ...) && noexcept> : _Mem_fn_traits_base<_Res, _Class, _ArgTypes...> { using __vararg = true_type; }; template<typename _Res, typename _Class, typename... _ArgTypes> struct _Mem_fn_traits<_Res (_Class::*)(_ArgTypes...) const && noexcept> : _Mem_fn_traits_base<_Res, const _Class, _ArgTypes...> { using __vararg = false_type; }; template<typename _Res, typename _Class, typename... _ArgTypes> struct _Mem_fn_traits<_Res (_Class::*)(_ArgTypes... ...) const && noexcept> : _Mem_fn_traits_base<_Res, const _Class, _ArgTypes...> { using __vararg = true_type; }; template<typename _Res, typename _Class, typename... _ArgTypes> struct _Mem_fn_traits<_Res (_Class::*)(_ArgTypes...) volatile && noexcept> : _Mem_fn_traits_base<_Res, volatile _Class, _ArgTypes...> { using __vararg = false_type; }; template<typename _Res, typename _Class, typename... _ArgTypes> struct _Mem_fn_traits<_Res (_Class::*)(_ArgTypes... ...) volatile && noexcept> : _Mem_fn_traits_base<_Res, volatile _Class, _ArgTypes...> { using __vararg = true_type; }; template<typename _Res, typename _Class, typename... _ArgTypes> struct _Mem_fn_traits<_Res (_Class::*)(_ArgTypes...) const volatile && noexcept> : _Mem_fn_traits_base<_Res, const volatile _Class, _ArgTypes...> { using __vararg = false_type; }; template<typename _Res, typename _Class, typename... _ArgTypes> struct _Mem_fn_traits<_Res (_Class::*)(_ArgTypes... ...) const volatile && noexcept> : _Mem_fn_traits_base<_Res, const volatile _Class, _ArgTypes...> { using __vararg = true_type; };\n",
      "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          ^\n",
      "\n",
      "/usr/include/c++/9/bits/refwrap.h(104): error: class template \"std::_Mem_fn_traits\" has already been defined\n",
      "  template<typename _Res, typename _Class, typename... _ArgTypes> struct _Mem_fn_traits<_Res (_Class::*)(_ArgTypes...) && noexcept> : _Mem_fn_traits_base<_Res, _Class, _ArgTypes...> { using __vararg = false_type; }; template<typename _Res, typename _Class, typename... _ArgTypes> struct _Mem_fn_traits<_Res (_Class::*)(_ArgTypes... ...) && noexcept> : _Mem_fn_traits_base<_Res, _Class, _ArgTypes...> { using __vararg = true_type; }; template<typename _Res, typename _Class, typename... _ArgTypes> struct _Mem_fn_traits<_Res (_Class::*)(_ArgTypes...) const && noexcept> : _Mem_fn_traits_base<_Res, const _Class, _ArgTypes...> { using __vararg = false_type; }; template<typename _Res, typename _Class, typename... _ArgTypes> struct _Mem_fn_traits<_Res (_Class::*)(_ArgTypes... ...) const && noexcept> : _Mem_fn_traits_base<_Res, const _Class, _ArgTypes...> { using __vararg = true_type; }; template<typename _Res, typename _Class, typename... _ArgTypes> struct _Mem_fn_traits<_Res (_Class::*)(_ArgTypes...) volatile && noexcept> : _Mem_fn_traits_base<_Res, volatile _Class, _ArgTypes...> { using __vararg = false_type; }; template<typename _Res, typename _Class, typename... _ArgTypes> struct _Mem_fn_traits<_Res (_Class::*)(_ArgTypes... ...) volatile && noexcept> : _Mem_fn_traits_base<_Res, volatile _Class, _ArgTypes...> { using __vararg = true_type; }; template<typename _Res, typename _Class, typename... _ArgTypes> struct _Mem_fn_traits<_Res (_Class::*)(_ArgTypes...) const volatile && noexcept> : _Mem_fn_traits_base<_Res, const volatile _Class, _ArgTypes...> { using __vararg = false_type; }; template<typename _Res, typename _Class, typename... _ArgTypes> struct _Mem_fn_traits<_Res (_Class::*)(_ArgTypes... ...) const volatile && noexcept> : _Mem_fn_traits_base<_Res, const volatile _Class, _ArgTypes...> { using __vararg = true_type; };\n",
      "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               ^\n",
      "\n",
      "/usr/include/c++/9/bits/refwrap.h(104): error: class template \"std::_Mem_fn_traits\" has already been defined\n",
      "  template<typename _Res, typename _Class, typename... _ArgTypes> struct _Mem_fn_traits<_Res (_Class::*)(_ArgTypes...) && noexcept> : _Mem_fn_traits_base<_Res, _Class, _ArgTypes...> { using __vararg = false_type; }; template<typename _Res, typename _Class, typename... _ArgTypes> struct _Mem_fn_traits<_Res (_Class::*)(_ArgTypes... ...) && noexcept> : _Mem_fn_traits_base<_Res, _Class, _ArgTypes...> { using __vararg = true_type; }; template<typename _Res, typename _Class, typename... _ArgTypes> struct _Mem_fn_traits<_Res (_Class::*)(_ArgTypes...) const && noexcept> : _Mem_fn_traits_base<_Res, const _Class, _ArgTypes...> { using __vararg = false_type; }; template<typename _Res, typename _Class, typename... _ArgTypes> struct _Mem_fn_traits<_Res (_Class::*)(_ArgTypes... ...) const && noexcept> : _Mem_fn_traits_base<_Res, const _Class, _ArgTypes...> { using __vararg = true_type; }; template<typename _Res, typename _Class, typename... _ArgTypes> struct _Mem_fn_traits<_Res (_Class::*)(_ArgTypes...) volatile && noexcept> : _Mem_fn_traits_base<_Res, volatile _Class, _ArgTypes...> { using __vararg = false_type; }; template<typename _Res, typename _Class, typename... _ArgTypes> struct _Mem_fn_traits<_Res (_Class::*)(_ArgTypes... ...) volatile && noexcept> : _Mem_fn_traits_base<_Res, volatile _Class, _ArgTypes...> { using __vararg = true_type; }; template<typename _Res, typename _Class, typename... _ArgTypes> struct _Mem_fn_traits<_Res (_Class::*)(_ArgTypes...) const volatile && noexcept> : _Mem_fn_traits_base<_Res, const volatile _Class, _ArgTypes...> { using __vararg = false_type; }; template<typename _Res, typename _Class, typename... _ArgTypes> struct _Mem_fn_traits<_Res (_Class::*)(_ArgTypes... ...) const volatile && noexcept> : _Mem_fn_traits_base<_Res, const volatile _Class, _ArgTypes...> { using __vararg = true_type; };\n",
      "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       ^\n",
      "\n",
      "/usr/include/c++/9/bits/refwrap.h(104): error: class template \"std::_Mem_fn_traits\" has already been defined\n",
      "  template<typename _Res, typename _Class, typename... _ArgTypes> struct _Mem_fn_traits<_Res (_Class::*)(_ArgTypes...) && noexcept> : _Mem_fn_traits_base<_Res, _Class, _ArgTypes...> { using __vararg = false_type; }; template<typename _Res, typename _Class, typename... _ArgTypes> struct _Mem_fn_traits<_Res (_Class::*)(_ArgTypes... ...) && noexcept> : _Mem_fn_traits_base<_Res, _Class, _ArgTypes...> { using __vararg = true_type; }; template<typename _Res, typename _Class, typename... _ArgTypes> struct _Mem_fn_traits<_Res (_Class::*)(_ArgTypes...) const && noexcept> : _Mem_fn_traits_base<_Res, const _Class, _ArgTypes...> { using __vararg = false_type; }; template<typename _Res, typename _Class, typename... _ArgTypes> struct _Mem_fn_traits<_Res (_Class::*)(_ArgTypes... ...) const && noexcept> : _Mem_fn_traits_base<_Res, const _Class, _ArgTypes...> { using __vararg = true_type; }; template<typename _Res, typename _Class, typename... _ArgTypes> struct _Mem_fn_traits<_Res (_Class::*)(_ArgTypes...) volatile && noexcept> : _Mem_fn_traits_base<_Res, volatile _Class, _ArgTypes...> { using __vararg = false_type; }; template<typename _Res, typename _Class, typename... _ArgTypes> struct _Mem_fn_traits<_Res (_Class::*)(_ArgTypes... ...) volatile && noexcept> : _Mem_fn_traits_base<_Res, volatile _Class, _ArgTypes...> { using __vararg = true_type; }; template<typename _Res, typename _Class, typename... _ArgTypes> struct _Mem_fn_traits<_Res (_Class::*)(_ArgTypes...) const volatile && noexcept> : _Mem_fn_traits_base<_Res, const volatile _Class, _ArgTypes...> { using __vararg = false_type; }; template<typename _Res, typename _Class, typename... _ArgTypes> struct _Mem_fn_traits<_Res (_Class::*)(_ArgTypes... ...) const volatile && noexcept> : _Mem_fn_traits_base<_Res, const volatile _Class, _ArgTypes...> { using __vararg = true_type; };\n",
      "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  ^\n",
      "\n",
      "/usr/include/c++/9/bits/refwrap.h(104): error: class template \"std::_Mem_fn_traits\" has already been defined\n",
      "  template<typename _Res, typename _Class, typename... _ArgTypes> struct _Mem_fn_traits<_Res (_Class::*)(_ArgTypes...) && noexcept> : _Mem_fn_traits_base<_Res, _Class, _ArgTypes...> { using __vararg = false_type; }; template<typename _Res, typename _Class, typename... _ArgTypes> struct _Mem_fn_traits<_Res (_Class::*)(_ArgTypes... ...) && noexcept> : _Mem_fn_traits_base<_Res, _Class, _ArgTypes...> { using __vararg = true_type; }; template<typename _Res, typename _Class, typename... _ArgTypes> struct _Mem_fn_traits<_Res (_Class::*)(_ArgTypes...) const && noexcept> : _Mem_fn_traits_base<_Res, const _Class, _ArgTypes...> { using __vararg = false_type; }; template<typename _Res, typename _Class, typename... _ArgTypes> struct _Mem_fn_traits<_Res (_Class::*)(_ArgTypes... ...) const && noexcept> : _Mem_fn_traits_base<_Res, const _Class, _ArgTypes...> { using __vararg = true_type; }; template<typename _Res, typename _Class, typename... _ArgTypes> struct _Mem_fn_traits<_Res (_Class::*)(_ArgTypes...) volatile && noexcept> : _Mem_fn_traits_base<_Res, volatile _Class, _ArgTypes...> { using __vararg = false_type; }; template<typename _Res, typename _Class, typename... _ArgTypes> struct _Mem_fn_traits<_Res (_Class::*)(_ArgTypes... ...) volatile && noexcept> : _Mem_fn_traits_base<_Res, volatile _Class, _ArgTypes...> { using __vararg = true_type; }; template<typename _Res, typename _Class, typename... _ArgTypes> struct _Mem_fn_traits<_Res (_Class::*)(_ArgTypes...) const volatile && noexcept> : _Mem_fn_traits_base<_Res, const volatile _Class, _ArgTypes...> { using __vararg = false_type; }; template<typename _Res, typename _Class, typename... _ArgTypes> struct _Mem_fn_traits<_Res (_Class::*)(_ArgTypes... ...) const volatile && noexcept> : _Mem_fn_traits_base<_Res, const volatile _Class, _ArgTypes...> { using __vararg = true_type; };\n",
      "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      ^\n",
      "\n",
      "/usr/include/c++/9/bits/refwrap.h(346): error: argument list for class template \"std::reference_wrapper\" is missing\n",
      "      reference_wrapper(_Tp&) -> reference_wrapper<_Tp>;\n",
      "      ^\n",
      "\n",
      "/usr/include/c++/9/bits/refwrap.h(346): error: expected a \")\"\n",
      "      reference_wrapper(_Tp&) -> reference_wrapper<_Tp>;\n",
      "                           ^\n",
      "\n",
      "/usr/include/c++/9/bits/refwrap.h(345): error: too few template parameters -- does not match previous declaration (declared at line 243 of /usr/include/c++/9/array)\n",
      "    template<typename _Tp>\n",
      "                      ^\n",
      "\n",
      "/usr/include/c++/9/bits/refwrap.h(346): error: expected a \";\"\n",
      "      reference_wrapper(_Tp&) -> reference_wrapper<_Tp>;\n",
      "                              ^\n",
      "\n",
      "/usr/include/c++/9/bits/shared_ptr.h(375): error: argument list for class template \"std::shared_ptr\" is missing\n",
      "      shared_ptr(weak_ptr<_Tp>) -> shared_ptr<_Tp>;\n",
      "      ^\n",
      "\n",
      "/usr/include/c++/9/bits/shared_ptr.h(375): error: \"weak_ptr\" is not a function or static data member\n",
      "      shared_ptr(weak_ptr<_Tp>) -> shared_ptr<_Tp>;\n",
      "                 ^\n",
      "\n",
      "/usr/include/c++/9/bits/shared_ptr.h(377): error: argument list for class template \"std::shared_ptr\" is missing\n",
      "      shared_ptr(unique_ptr<_Tp, _Del>) -> shared_ptr<_Tp>;\n",
      "      ^\n",
      "\n",
      "/usr/include/c++/9/bits/shared_ptr.h(377): error: \"unique_ptr\" is not a function or static data member\n",
      "      shared_ptr(unique_ptr<_Tp, _Del>) -> shared_ptr<_Tp>;\n",
      "                 ^\n",
      "\n",
      "/usr/include/c++/9/bits/shared_ptr.h(600): error: argument list for class template \"std::weak_ptr\" is missing\n",
      "      weak_ptr(shared_ptr<_Tp>) -> weak_ptr<_Tp>;\n",
      "      ^\n",
      "\n",
      "/usr/include/c++/9/bits/shared_ptr.h(600): error: \"shared_ptr\" is not a function or static data member\n",
      "      weak_ptr(shared_ptr<_Tp>) -> weak_ptr<_Tp>;\n",
      "               ^\n",
      "\n",
      "/usr/include/c++/9/optional(1230): error: argument list for class template \"std::optional\" is missing\n",
      "    template <typename _Tp> optional(_Tp) -> optional<_Tp>;\n",
      "                            ^\n",
      "\n",
      "/usr/include/c++/9/optional(1230): error: too few template parameters -- does not match previous declaration (declared at line 243 of /usr/include/c++/9/array)\n",
      "    template <typename _Tp> optional(_Tp) -> optional<_Tp>;\n",
      "                       ^\n",
      "\n",
      "/usr/include/c++/9/optional(1230): error: expected a \";\"\n",
      "    template <typename _Tp> optional(_Tp) -> optional<_Tp>;\n",
      "                                          ^\n",
      "\n",
      "/usr/include/c++/9/bits/unordered_map.h(1152): error: argument list for class template \"std::unordered_map\" is missing\n",
      "      unordered_map(_InputIterator, _InputIterator,\n",
      "      ^\n",
      "\n",
      "/usr/include/c++/9/bits/unordered_map.h(1152): error: expected a \")\"\n",
      "      unordered_map(_InputIterator, _InputIterator,\n",
      "                                  ^\n",
      "\n",
      "/usr/include/c++/9/bits/unordered_map.h(1149): error: too many template parameters -- does not match previous declaration (declared at line 1409 of /usr/include/c++/9/bits/forward_list.h)\n",
      "      typename = _RequireNotAllocatorOrIntegral<_Hash>,\n",
      "               ^\n",
      "\n",
      "Error limit reached.\n",
      "100 errors detected in the compilation of \"/home/soapg/NEEDLE/src/ndarray_backend_cuda.cu\".\n",
      "Compilation terminated.\n",
      "\u001b[31mCMake Error at ndarray_backend_cuda_generated_ndarray_backend_cuda.cu.o.cmake:280 (message):\n",
      "  Error generating file\n",
      "  /home/soapg/NEEDLE/build/CMakeFiles/ndarray_backend_cuda.dir/src/./ndarray_backend_cuda_generated_ndarray_backend_cuda.cu.o\n",
      "\n",
      "\u001b[0m\n",
      "make[3]: *** [CMakeFiles/ndarray_backend_cuda.dir/build.make:77: CMakeFiles/ndarray_backend_cuda.dir/src/ndarray_backend_cuda_generated_ndarray_backend_cuda.cu.o] Error 1\n",
      "make[3]: Leaving directory '/home/soapg/NEEDLE/build'\n",
      "make[2]: *** [CMakeFiles/Makefile2:110: CMakeFiles/ndarray_backend_cuda.dir/all] Error 2\n",
      "make[2]: Leaving directory '/home/soapg/NEEDLE/build'\n",
      "make[1]: *** [Makefile:91: all] Error 2\n",
      "make[1]: Leaving directory '/home/soapg/NEEDLE/build'\n",
      "make: *** [Makefile:9: lib] Error 2\n"
     ]
    }
   ],
   "source": [
    "!make clean; make"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: PYTHONPATH=./python\n",
      "env: NEEDLE_BACKEND=nd\n"
     ]
    }
   ],
   "source": [
    "%set_env PYTHONPATH ./python\n",
    "%set_env NEEDLE_BACKEND nd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('./python')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cifar-10-batches-py/\n",
      "cifar-10-batches-py/data_batch_4\n",
      "cifar-10-batches-py/readme.html\n",
      "cifar-10-batches-py/test_batch\n",
      "cifar-10-batches-py/data_batch_3\n",
      "cifar-10-batches-py/batches.meta\n",
      "cifar-10-batches-py/data_batch_2\n",
      "cifar-10-batches-py/data_batch_5\n",
      "cifar-10-batches-py/data_batch_1\n"
     ]
    }
   ],
   "source": [
    "# Download the datasets you will be using for this assignment\n",
    "\n",
    "import urllib.request\n",
    "import os\n",
    "\n",
    "!mkdir -p './data/ptb'\n",
    "# Download Penn Treebank dataset\n",
    "ptb_data = \"https://raw.githubusercontent.com/wojzaremba/lstm/master/data/ptb.\"\n",
    "for f in ['train.txt', 'test.txt', 'valid.txt']:\n",
    "    if not os.path.exists(os.path.join('./data/ptb', f)):\n",
    "        urllib.request.urlretrieve(ptb_data + f, os.path.join('./data/ptb', f))\n",
    "\n",
    "# Download CIFAR-10 dataset\n",
    "if not os.path.isdir(\"./data/cifar-10-batches-py\"):\n",
    "    urllib.request.urlretrieve(\"https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\", \"./data/cifar-10-python.tar.gz\")\n",
    "    !tar -xvzf './data/cifar-10-python.tar.gz' -C './data'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To finish setting up the assignment, go ahead and fill in all the code in `python/needle/autograd.py` using your solution code from the previous homework. Also copy the solutions in `src/ndarray_backend_cpu.cc` and `src/ndarray_backend_cuda.cu` from homework 3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: ND Backend [10 pts]\n",
    "\n",
    "Recall that in homework 2, the `array_api` was imported as `numpy`. In this part, the goal is to write the necessary operations with `array_api` imported from the needle backend `NDArray` in `python/needle/backend_ndarray/ndarray.py`. Make sure to copy the solutions for `reshape`, `permute`, `broadcast_to` and `__getitem__` from homework 3.\n",
    "\n",
    "Fill in the following classes in `python/needle/ops_logarithmic.py` and `python/needle/ops_mathematic.py`:\n",
    "\n",
    "- `PowerScalar`\n",
    "- `EWiseDiv`\n",
    "- `DivScalar`\n",
    "- `Transpose`\n",
    "- `Reshape`\n",
    "- `BroadcastTo`\n",
    "- `Summation`\n",
    "- `MatMul`\n",
    "- `Negate`\n",
    "- `Log`\n",
    "- `Exp`\n",
    "- `ReLU`\n",
    "- `LogSumExp`\n",
    "- `Tanh` (new)\n",
    "- `Stack` (new)\n",
    "- `Split` (new)\n",
    "\n",
    "Note that for most of these, you already wrote the solutions in the previous homework and you should not change most part of your previous solution, if issues arise, please check if the `array_api` function used is supported in the needle backend. \n",
    "\n",
    "`TanhOp`, `Stack`, and `Split` are newly added. `Stack` concatenates same-sized tensors along a new axis, and `Split` undoes this operation. The gradients of the two operations can be written in terms of each other. We do not directly test `Split`, and only test the backward pass of `Stack` (for which we assume you used `Split`).\n",
    "\n",
    "**Note:** You may want to make your Summation op support sums over multiple axes; you will likely need it for the backward pass of the BroadcastTo op if yours supports broadcasting over multiple axes at a time. However, this is more about ease of use than necessity, and we leave this decision up to you (there are no corresponding tests).\n",
    "\n",
    "**Note:** Depending on your implementations, you may want to ensure that you call `.compact()` before reshaping arrays. (If this is necessary, you will run into corresponding error messages later in the assignment.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform linux -- Python 3.11.8, pytest-8.1.1, pluggy-1.4.0 -- /home/soapg/.conda/envs/dlsys/bin/python3\n",
      "cachedir: .pytest_cache\n",
      "rootdir: /home/soapg/NEEDLE\n",
      "collected 1803 items / 1685 deselected / 118 selected                          \u001b[0m\u001b[1m\n",
      "\n",
      "tests/hw4/test_nd_backend.py::test_ewise_fn[cpu-shape0-divide] \u001b[32mPASSED\u001b[0m\u001b[32m    [  0%]\u001b[0m\n",
      "tests/hw4/test_nd_backend.py::test_ewise_fn[cpu-shape0-subtract] \u001b[32mPASSED\u001b[0m\u001b[32m  [  1%]\u001b[0m\n",
      "tests/hw4/test_nd_backend.py::test_ewise_fn[cpu-shape1-divide] \u001b[32mPASSED\u001b[0m\u001b[32m    [  2%]\u001b[0m\n",
      "tests/hw4/test_nd_backend.py::test_ewise_fn[cpu-shape1-subtract] \u001b[32mPASSED\u001b[0m\u001b[32m  [  3%]\u001b[0m\n",
      "tests/hw4/test_nd_backend.py::test_ewise_fn[cuda-shape0-divide] \u001b[33mSKIPPED\u001b[0m\u001b[32m  [  4%]\u001b[0m\n",
      "tests/hw4/test_nd_backend.py::test_ewise_fn[cuda-shape0-subtract] \u001b[33mSKIPPED\u001b[0m\u001b[32m [  5%]\u001b[0m\n",
      "tests/hw4/test_nd_backend.py::test_ewise_fn[cuda-shape1-divide] \u001b[33mSKIPPED\u001b[0m\u001b[32m  [  5%]\u001b[0m\n",
      "tests/hw4/test_nd_backend.py::test_ewise_fn[cuda-shape1-subtract] \u001b[33mSKIPPED\u001b[0m\u001b[32m [  6%]\u001b[0m\n",
      "tests/hw4/test_nd_backend.py::test_scalar_fn[cpu-shape0-divide] \u001b[32mPASSED\u001b[0m\u001b[32m   [  7%]\u001b[0m\n",
      "tests/hw4/test_nd_backend.py::test_scalar_fn[cpu-shape0-subtract] \u001b[32mPASSED\u001b[0m\u001b[32m [  8%]\u001b[0m\n",
      "tests/hw4/test_nd_backend.py::test_scalar_fn[cpu-shape1-divide] \u001b[32mPASSED\u001b[0m\u001b[32m   [  9%]\u001b[0m\n",
      "tests/hw4/test_nd_backend.py::test_scalar_fn[cpu-shape1-subtract] \u001b[32mPASSED\u001b[0m\u001b[32m [ 10%]\u001b[0m\n",
      "tests/hw4/test_nd_backend.py::test_scalar_fn[cuda-shape0-divide] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 11%]\u001b[0m\n",
      "tests/hw4/test_nd_backend.py::test_scalar_fn[cuda-shape0-subtract] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 11%]\u001b[0m\n",
      "tests/hw4/test_nd_backend.py::test_scalar_fn[cuda-shape1-divide] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 12%]\u001b[0m\n",
      "tests/hw4/test_nd_backend.py::test_scalar_fn[cuda-shape1-subtract] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 13%]\u001b[0m\n",
      "tests/hw4/test_nd_backend.py::test_matmul[cpu-16-16-16] \u001b[32mPASSED\u001b[0m\u001b[32m           [ 14%]\u001b[0m\n",
      "tests/hw4/test_nd_backend.py::test_matmul[cpu-8-8-8] \u001b[32mPASSED\u001b[0m\u001b[32m              [ 15%]\u001b[0m\n",
      "tests/hw4/test_nd_backend.py::test_matmul[cpu-1-2-3] \u001b[32mPASSED\u001b[0m\u001b[32m              [ 16%]\u001b[0m\n",
      "tests/hw4/test_nd_backend.py::test_matmul[cpu-3-4-5] \u001b[32mPASSED\u001b[0m\u001b[32m              [ 16%]\u001b[0m\n",
      "tests/hw4/test_nd_backend.py::test_matmul[cpu-5-4-3] \u001b[32mPASSED\u001b[0m\u001b[32m              [ 17%]\u001b[0m\n",
      "tests/hw4/test_nd_backend.py::test_matmul[cpu-16-16-32] \u001b[32mPASSED\u001b[0m\u001b[32m           [ 18%]\u001b[0m\n",
      "tests/hw4/test_nd_backend.py::test_matmul[cpu-64-64-64] \u001b[32mPASSED\u001b[0m\u001b[32m           [ 19%]\u001b[0m\n",
      "tests/hw4/test_nd_backend.py::test_matmul[cpu-72-72-72] \u001b[32mPASSED\u001b[0m\u001b[32m           [ 20%]\u001b[0m\n",
      "tests/hw4/test_nd_backend.py::test_matmul[cpu-72-73-74] \u001b[32mPASSED\u001b[0m\u001b[32m           [ 21%]\u001b[0m\n",
      "tests/hw4/test_nd_backend.py::test_matmul[cpu-74-73-72] \u001b[32mPASSED\u001b[0m\u001b[32m           [ 22%]\u001b[0m\n",
      "tests/hw4/test_nd_backend.py::test_matmul[cpu-128-128-128] \u001b[32mPASSED\u001b[0m\u001b[32m        [ 22%]\u001b[0m\n",
      "tests/hw4/test_nd_backend.py::test_matmul[cuda-16-16-16] \u001b[33mSKIPPED\u001b[0m (No...)\u001b[32m [ 23%]\u001b[0m\n",
      "tests/hw4/test_nd_backend.py::test_matmul[cuda-8-8-8] \u001b[33mSKIPPED\u001b[0m (No GPU)\u001b[32m   [ 24%]\u001b[0m\n",
      "tests/hw4/test_nd_backend.py::test_matmul[cuda-1-2-3] \u001b[33mSKIPPED\u001b[0m (No GPU)\u001b[32m   [ 25%]\u001b[0m\n",
      "tests/hw4/test_nd_backend.py::test_matmul[cuda-3-4-5] \u001b[33mSKIPPED\u001b[0m (No GPU)\u001b[32m   [ 26%]\u001b[0m\n",
      "tests/hw4/test_nd_backend.py::test_matmul[cuda-5-4-3] \u001b[33mSKIPPED\u001b[0m (No GPU)\u001b[32m   [ 27%]\u001b[0m\n",
      "tests/hw4/test_nd_backend.py::test_matmul[cuda-16-16-32] \u001b[33mSKIPPED\u001b[0m (No...)\u001b[32m [ 27%]\u001b[0m\n",
      "tests/hw4/test_nd_backend.py::test_matmul[cuda-64-64-64] \u001b[33mSKIPPED\u001b[0m (No...)\u001b[32m [ 28%]\u001b[0m\n",
      "tests/hw4/test_nd_backend.py::test_matmul[cuda-72-72-72] \u001b[33mSKIPPED\u001b[0m (No...)\u001b[32m [ 29%]\u001b[0m\n",
      "tests/hw4/test_nd_backend.py::test_matmul[cuda-72-73-74] \u001b[33mSKIPPED\u001b[0m (No...)\u001b[32m [ 30%]\u001b[0m\n",
      "tests/hw4/test_nd_backend.py::test_matmul[cuda-74-73-72] \u001b[33mSKIPPED\u001b[0m (No...)\u001b[32m [ 31%]\u001b[0m\n",
      "tests/hw4/test_nd_backend.py::test_matmul[cuda-128-128-128] \u001b[33mSKIPPED\u001b[0m\u001b[32m      [ 32%]\u001b[0m\n",
      "tests/hw4/test_nd_backend.py::test_power[cpu-shape0] \u001b[32mPASSED\u001b[0m\u001b[32m              [ 33%]\u001b[0m\n",
      "tests/hw4/test_nd_backend.py::test_power[cpu-shape1] \u001b[32mPASSED\u001b[0m\u001b[32m              [ 33%]\u001b[0m\n",
      "tests/hw4/test_nd_backend.py::test_power[cuda-shape0] \u001b[33mSKIPPED\u001b[0m (No GPU)\u001b[32m   [ 34%]\u001b[0m\n",
      "tests/hw4/test_nd_backend.py::test_power[cuda-shape1] \u001b[33mSKIPPED\u001b[0m (No GPU)\u001b[32m   [ 35%]\u001b[0m\n",
      "tests/hw4/test_nd_backend.py::test_log[cpu-shape0] \u001b[32mPASSED\u001b[0m\u001b[32m                [ 36%]\u001b[0m\n",
      "tests/hw4/test_nd_backend.py::test_log[cpu-shape1] \u001b[32mPASSED\u001b[0m\u001b[32m                [ 37%]\u001b[0m\n",
      "tests/hw4/test_nd_backend.py::test_log[cuda-shape0] \u001b[33mSKIPPED\u001b[0m (No GPU)\u001b[32m     [ 38%]\u001b[0m\n",
      "tests/hw4/test_nd_backend.py::test_log[cuda-shape1] \u001b[33mSKIPPED\u001b[0m (No GPU)\u001b[32m     [ 38%]\u001b[0m\n",
      "tests/hw4/test_nd_backend.py::test_exp[cpu-shape0] \u001b[32mPASSED\u001b[0m\u001b[32m                [ 39%]\u001b[0m\n",
      "tests/hw4/test_nd_backend.py::test_exp[cpu-shape1] \u001b[32mPASSED\u001b[0m\u001b[32m                [ 40%]\u001b[0m\n",
      "tests/hw4/test_nd_backend.py::test_exp[cuda-shape0] \u001b[33mSKIPPED\u001b[0m (No GPU)\u001b[32m     [ 41%]\u001b[0m\n",
      "tests/hw4/test_nd_backend.py::test_exp[cuda-shape1] \u001b[33mSKIPPED\u001b[0m (No GPU)\u001b[32m     [ 42%]\u001b[0m\n",
      "tests/hw4/test_nd_backend.py::test_relu[cpu-shape0] \u001b[32mPASSED\u001b[0m\u001b[32m               [ 43%]\u001b[0m\n",
      "tests/hw4/test_nd_backend.py::test_relu[cpu-shape1] \u001b[32mPASSED\u001b[0m\u001b[32m               [ 44%]\u001b[0m\n",
      "tests/hw4/test_nd_backend.py::test_relu[cuda-shape0] \u001b[33mSKIPPED\u001b[0m (No GPU)\u001b[32m    [ 44%]\u001b[0m\n",
      "tests/hw4/test_nd_backend.py::test_relu[cuda-shape1] \u001b[33mSKIPPED\u001b[0m (No GPU)\u001b[32m    [ 45%]\u001b[0m\n",
      "tests/hw4/test_nd_backend.py::test_tanh[cpu-shape0] \u001b[32mPASSED\u001b[0m\u001b[32m               [ 46%]\u001b[0m\n",
      "tests/hw4/test_nd_backend.py::test_tanh[cpu-shape1] \u001b[32mPASSED\u001b[0m\u001b[32m               [ 47%]\u001b[0m\n",
      "tests/hw4/test_nd_backend.py::test_tanh[cuda-shape0] \u001b[33mSKIPPED\u001b[0m (No GPU)\u001b[32m    [ 48%]\u001b[0m\n",
      "tests/hw4/test_nd_backend.py::test_tanh[cuda-shape1] \u001b[33mSKIPPED\u001b[0m (No GPU)\u001b[32m    [ 49%]\u001b[0m\n",
      "tests/hw4/test_nd_backend.py::test_tanh_backward[cpu-shape0] \u001b[32mPASSED\u001b[0m\u001b[32m      [ 50%]\u001b[0m\n",
      "tests/hw4/test_nd_backend.py::test_tanh_backward[cpu-shape1] \u001b[32mPASSED\u001b[0m\u001b[32m      [ 50%]\u001b[0m\n",
      "tests/hw4/test_nd_backend.py::test_tanh_backward[cuda-shape0] \u001b[33mSKIPPED\u001b[0m\u001b[32m    [ 51%]\u001b[0m\n",
      "tests/hw4/test_nd_backend.py::test_tanh_backward[cuda-shape1] \u001b[33mSKIPPED\u001b[0m\u001b[32m    [ 52%]\u001b[0m\n",
      "tests/hw4/test_nd_backend.py::test_stack[cpu-shape0-0-1] \u001b[32mPASSED\u001b[0m\u001b[32m          [ 53%]\u001b[0m\n",
      "tests/hw4/test_nd_backend.py::test_stack[cpu-shape1-0-2] \u001b[32mPASSED\u001b[0m\u001b[32m          [ 54%]\u001b[0m\n",
      "tests/hw4/test_nd_backend.py::test_stack[cpu-shape2-2-5] \u001b[32mPASSED\u001b[0m\u001b[32m          [ 55%]\u001b[0m\n",
      "tests/hw4/test_nd_backend.py::test_stack[cuda-shape0-0-1] \u001b[33mSKIPPED\u001b[0m (N...)\u001b[32m [ 55%]\u001b[0m\n",
      "tests/hw4/test_nd_backend.py::test_stack[cuda-shape1-0-2] \u001b[33mSKIPPED\u001b[0m (N...)\u001b[32m [ 56%]\u001b[0m\n",
      "tests/hw4/test_nd_backend.py::test_stack[cuda-shape2-2-5] \u001b[33mSKIPPED\u001b[0m (N...)\u001b[32m [ 57%]\u001b[0m\n",
      "tests/hw4/test_nd_backend.py::test_stack_backward[cpu-shape0-0-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 58%]\u001b[0m\n",
      "tests/hw4/test_nd_backend.py::test_stack_backward[cpu-shape1-0-2] \u001b[32mPASSED\u001b[0m\u001b[32m [ 59%]\u001b[0m\n",
      "tests/hw4/test_nd_backend.py::test_stack_backward[cpu-shape2-2-5] \u001b[32mPASSED\u001b[0m\u001b[32m [ 60%]\u001b[0m\n",
      "tests/hw4/test_nd_backend.py::test_stack_backward[cuda-shape0-0-1] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 61%]\u001b[0m\n",
      "tests/hw4/test_nd_backend.py::test_stack_backward[cuda-shape1-0-2] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 61%]\u001b[0m\n",
      "tests/hw4/test_nd_backend.py::test_stack_backward[cuda-shape2-2-5] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 62%]\u001b[0m\n",
      "tests/hw4/test_nd_backend.py::test_summation[cpu-shape0-None] \u001b[32mPASSED\u001b[0m\u001b[32m     [ 63%]\u001b[0m\n",
      "tests/hw4/test_nd_backend.py::test_summation[cpu-shape1-0] \u001b[32mPASSED\u001b[0m\u001b[32m        [ 64%]\u001b[0m\n",
      "tests/hw4/test_nd_backend.py::test_summation[cpu-shape2-1] \u001b[32mPASSED\u001b[0m\u001b[32m        [ 65%]\u001b[0m\n",
      "tests/hw4/test_nd_backend.py::test_summation[cpu-shape3-2] \u001b[32mPASSED\u001b[0m\u001b[32m        [ 66%]\u001b[0m\n",
      "tests/hw4/test_nd_backend.py::test_summation[cuda-shape0-None] \u001b[33mSKIPPED\u001b[0m\u001b[32m   [ 66%]\u001b[0m\n",
      "tests/hw4/test_nd_backend.py::test_summation[cuda-shape1-0] \u001b[33mSKIPPED\u001b[0m\u001b[32m      [ 67%]\u001b[0m\n",
      "tests/hw4/test_nd_backend.py::test_summation[cuda-shape2-1] \u001b[33mSKIPPED\u001b[0m\u001b[32m      [ 68%]\u001b[0m\n",
      "tests/hw4/test_nd_backend.py::test_summation[cuda-shape3-2] \u001b[33mSKIPPED\u001b[0m\u001b[32m      [ 69%]\u001b[0m\n",
      "tests/hw4/test_nd_backend.py::test_summation_backward[cpu-shape0-None] \u001b[32mPASSED\u001b[0m\u001b[32m [ 70%]\u001b[0m\n",
      "tests/hw4/test_nd_backend.py::test_summation_backward[cpu-shape1-0] \u001b[32mPASSED\u001b[0m\u001b[32m [ 71%]\u001b[0m\n",
      "tests/hw4/test_nd_backend.py::test_summation_backward[cpu-shape2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 72%]\u001b[0m\n",
      "tests/hw4/test_nd_backend.py::test_summation_backward[cpu-shape3-2] \u001b[32mPASSED\u001b[0m\u001b[32m [ 72%]\u001b[0m\n",
      "tests/hw4/test_nd_backend.py::test_summation_backward[cuda-shape0-None] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 73%]\u001b[0m\n",
      "tests/hw4/test_nd_backend.py::test_summation_backward[cuda-shape1-0] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 74%]\u001b[0m\n",
      "tests/hw4/test_nd_backend.py::test_summation_backward[cuda-shape2-1] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 75%]\u001b[0m\n",
      "tests/hw4/test_nd_backend.py::test_summation_backward[cuda-shape3-2] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 76%]\u001b[0m\n",
      "tests/hw4/test_nd_backend.py::test_broadcast_to[cpu-shape0-shape_to0] \u001b[32mPASSED\u001b[0m\u001b[32m [ 77%]\u001b[0m\n",
      "tests/hw4/test_nd_backend.py::test_broadcast_to[cpu-shape1-shape_to1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 77%]\u001b[0m\n",
      "tests/hw4/test_nd_backend.py::test_broadcast_to[cuda-shape0-shape_to0] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 78%]\u001b[0m\n",
      "tests/hw4/test_nd_backend.py::test_broadcast_to[cuda-shape1-shape_to1] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 79%]\u001b[0m\n",
      "tests/hw4/test_nd_backend.py::test_reshape[cpu-shape0-shape_to0] \u001b[32mPASSED\u001b[0m\u001b[32m  [ 80%]\u001b[0m\n",
      "tests/hw4/test_nd_backend.py::test_reshape[cpu-shape1-shape_to1] \u001b[32mPASSED\u001b[0m\u001b[32m  [ 81%]\u001b[0m\n",
      "tests/hw4/test_nd_backend.py::test_reshape[cuda-shape0-shape_to0] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 82%]\u001b[0m\n",
      "tests/hw4/test_nd_backend.py::test_reshape[cuda-shape1-shape_to1] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 83%]\u001b[0m\n",
      "tests/hw4/test_nd_backend.py::test_transpose[cpu-axes0-shape0] \u001b[32mPASSED\u001b[0m\u001b[32m    [ 83%]\u001b[0m\n",
      "tests/hw4/test_nd_backend.py::test_transpose[cpu-axes0-shape1] \u001b[32mPASSED\u001b[0m\u001b[32m    [ 84%]\u001b[0m\n",
      "tests/hw4/test_nd_backend.py::test_transpose[cpu-axes1-shape0] \u001b[32mPASSED\u001b[0m\u001b[32m    [ 85%]\u001b[0m\n",
      "tests/hw4/test_nd_backend.py::test_transpose[cpu-axes1-shape1] \u001b[32mPASSED\u001b[0m\u001b[32m    [ 86%]\u001b[0m\n",
      "tests/hw4/test_nd_backend.py::test_transpose[cpu-None-shape0] \u001b[32mPASSED\u001b[0m\u001b[32m     [ 87%]\u001b[0m\n",
      "tests/hw4/test_nd_backend.py::test_transpose[cpu-None-shape1] \u001b[32mPASSED\u001b[0m\u001b[32m     [ 88%]\u001b[0m\n",
      "tests/hw4/test_nd_backend.py::test_transpose[cuda-axes0-shape0] \u001b[33mSKIPPED\u001b[0m\u001b[32m  [ 88%]\u001b[0m\n",
      "tests/hw4/test_nd_backend.py::test_transpose[cuda-axes0-shape1] \u001b[33mSKIPPED\u001b[0m\u001b[32m  [ 89%]\u001b[0m\n",
      "tests/hw4/test_nd_backend.py::test_transpose[cuda-axes1-shape0] \u001b[33mSKIPPED\u001b[0m\u001b[32m  [ 90%]\u001b[0m\n",
      "tests/hw4/test_nd_backend.py::test_transpose[cuda-axes1-shape1] \u001b[33mSKIPPED\u001b[0m\u001b[32m  [ 91%]\u001b[0m\n",
      "tests/hw4/test_nd_backend.py::test_transpose[cuda-None-shape0] \u001b[33mSKIPPED\u001b[0m\u001b[32m   [ 92%]\u001b[0m\n",
      "tests/hw4/test_nd_backend.py::test_transpose[cuda-None-shape1] \u001b[33mSKIPPED\u001b[0m\u001b[32m   [ 93%]\u001b[0m\n",
      "tests/hw4/test_nd_backend.py::test_logsumexp[cpu-shape0-None] \u001b[32mPASSED\u001b[0m\u001b[32m     [ 94%]\u001b[0m\n",
      "tests/hw4/test_nd_backend.py::test_logsumexp[cpu-shape1-0] \u001b[32mPASSED\u001b[0m\u001b[32m        [ 94%]\u001b[0m\n",
      "tests/hw4/test_nd_backend.py::test_logsumexp[cpu-shape2-1] \u001b[32mPASSED\u001b[0m\u001b[32m        [ 95%]\u001b[0m\n",
      "tests/hw4/test_nd_backend.py::test_logsumexp[cpu-shape3-2] \u001b[32mPASSED\u001b[0m\u001b[32m        [ 96%]\u001b[0m\n",
      "tests/hw4/test_nd_backend.py::test_logsumexp[cuda-shape0-None] \u001b[33mSKIPPED\u001b[0m\u001b[32m   [ 97%]\u001b[0m\n",
      "tests/hw4/test_nd_backend.py::test_logsumexp[cuda-shape1-0] \u001b[33mSKIPPED\u001b[0m\u001b[32m      [ 98%]\u001b[0m\n",
      "tests/hw4/test_nd_backend.py::test_logsumexp[cuda-shape2-1] \u001b[33mSKIPPED\u001b[0m\u001b[32m      [ 99%]\u001b[0m\n",
      "tests/hw4/test_nd_backend.py::test_logsumexp[cuda-shape3-2] \u001b[33mSKIPPED\u001b[0m\u001b[32m      [100%]\u001b[0m\n",
      "\n",
      "\u001b[32m=============== \u001b[32m\u001b[1m59 passed\u001b[0m, \u001b[33m59 skipped\u001b[0m, \u001b[33m1685 deselected\u001b[0m\u001b[32m in 1.86s\u001b[0m\u001b[32m ================\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python3 -m pytest -l -v -k \"nd_backend\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 -m mugrade submit \"YOUR KEY HERE\" -k \"new_nd_backend\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: CIFAR-10 dataset [10 points]\n",
    "\n",
    "Next, you will write support for the [CIFAR-10](https://www.cs.toronto.edu/~kriz/cifar.html) image classification dataset, which consists of 60,000 32x32 color images in 10 classes, with 6,000 images per class. There are 50k training images and 10k test images. \n",
    "\n",
    "Start by implementing the `__init__` function in the `CIFAR10Dataset` class in `python/needle/data/datasets/cifar10_dataset.py`. You can read in the link above how to properly read the CIFAR-10 dataset files you downloaded at the beginning of the homework. Also fill in `__getitem__` and `__len__`. Note that the return shape of the data from `__getitem__` should be in order (3, 32, 32).\n",
    "\n",
    "Copy `python/needle/data/data_transforms.py` and `python/needle/data/data_basic.py` from previous homeworks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform linux -- Python 3.11.8, pytest-8.1.1, pluggy-1.4.0 -- /home/soapg/.conda/envs/dlsys/bin/python3\n",
      "cachedir: .pytest_cache\n",
      "rootdir: /home/soapg/NEEDLE\n",
      "collected 1803 items / 1793 deselected / 10 selected                           \u001b[0m\u001b[1m\n",
      "\n",
      "tests/hw4/test_cifar_ptb_data.py::test_cifar10_dataset[True] \u001b[32mPASSED\u001b[0m\u001b[32m      [ 10%]\u001b[0m\n",
      "tests/hw4/test_cifar_ptb_data.py::test_cifar10_dataset[False] \u001b[32mPASSED\u001b[0m\u001b[32m     [ 20%]\u001b[0m\n",
      "tests/hw4/test_cifar_ptb_data.py::test_cifar10_loader[cpu-True-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 30%]\u001b[0m\n",
      "tests/hw4/test_cifar_ptb_data.py::test_cifar10_loader[cpu-True-15] \u001b[32mPASSED\u001b[0m\u001b[32m [ 40%]\u001b[0m\n",
      "tests/hw4/test_cifar_ptb_data.py::test_cifar10_loader[cpu-False-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 50%]\u001b[0m\n",
      "tests/hw4/test_cifar_ptb_data.py::test_cifar10_loader[cpu-False-15] \u001b[32mPASSED\u001b[0m\u001b[32m [ 60%]\u001b[0m\n",
      "tests/hw4/test_cifar_ptb_data.py::test_cifar10_loader[cuda-True-1] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 70%]\u001b[0m\n",
      "tests/hw4/test_cifar_ptb_data.py::test_cifar10_loader[cuda-True-15] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 80%]\u001b[0m\n",
      "tests/hw4/test_cifar_ptb_data.py::test_cifar10_loader[cuda-False-1] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 90%]\u001b[0m\n",
      "tests/hw4/test_cifar_ptb_data.py::test_cifar10_loader[cuda-False-15] \u001b[33mSKIPPED\u001b[0m\u001b[32m [100%]\u001b[0m\n",
      "\n",
      "\u001b[32m================ \u001b[32m\u001b[1m6 passed\u001b[0m, \u001b[33m4 skipped\u001b[0m, \u001b[33m1793 deselected\u001b[0m\u001b[32m in 2.90s\u001b[0m\u001b[32m =================\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python3 -m pytest -l -v -k \"test_cifar10\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 -m mugrade submit \"YOUR KEY HERE\" -k \"cifar10\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Part 3: Convolutional neural network [40 points]\n",
    "\n",
    "Here's an outline of what you will do in this task.\n",
    "\n",
    "In `python/needle/backend_ndarray/ndarray.py`, implement:\n",
    "- `flip`\n",
    "- `pad`\n",
    "\n",
    "In `python/needle/ops_mathematic.py`, implement (forward and backward):\n",
    "- `Flip`\n",
    "- `Dilate`\n",
    "- `UnDilate`\n",
    "- `Conv`\n",
    "\n",
    "In `python/needle/nn/nn_conv.py`, implement:\n",
    "- `Conv`\n",
    "\n",
    "In `apps/models.py`, fill in the `ResNet9` class.  \n",
    "\n",
    "In `apps/simple_ml.py`, fill in:\n",
    "- `epoch_general_cifar10`,\n",
    "- `train_cifar10`\n",
    "- `evaluate_cifar10`\n",
    "\n",
    "We have provided a `BatchNorm2d` implementation in `python/needle/nn/nn_basic.py` for you as a wrapper around your previous `BatchNorm1d` implementation. \n",
    "\n",
    "**Note**: Remember to copy the solution of `nn_basic.py` from previous homework, make sure to not overwrite the `BatchNorm2d` module."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Padding ndarrays\n",
    "\n",
    "Convolution as typically implemented in deep learning libraries cuts down the size of inputs;\n",
    "e.g., a (1, 32, 32, 3) image convolved with a 3x3 filter would give a (1, 30, 30, c) output.\n",
    "A way around this is to pad the input ndarray before performing convolution, e.g., pad with zeros to get a (1, 34, 34, 3) ndarray so that the result is (1, 32, 32, 3). \n",
    "\n",
    "Padding is also required for the backward pass of convolution.\n",
    "\n",
    "You should implement `pad` in `ndarray.py` to closely reflect the behavior of `np.pad`.\n",
    "That is, `pad` should take a tuple of 2-tuples with length equal to the number of dimensions of the array,\n",
    "where each element in the 2-tuple corresponds to \"left padding\" and \"right padding\", respectively.\n",
    "\n",
    "For example, if `A` is a (10, 32, 32, 8) ndarray (think NHWC), then `A.pad( (0, 0), (2, 2), (2, 2), (0, 0) )` would be a (10, 36, 36, 8) ndarray where the \"spatial\" dimension has been padded by two zeros on all sides."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform linux -- Python 3.11.8, pytest-8.1.1, pluggy-1.4.0 -- /home/soapg/.conda/envs/dlsys/bin/python3\n",
      "cachedir: .pytest_cache\n",
      "rootdir: /home/soapg/NEEDLE\n",
      "collected 1803 items / 1801 deselected / 2 selected                            \u001b[0m\u001b[1m\n",
      "\n",
      "tests/hw4/test_conv.py::test_pad_forward[params0-needle.backend_ndarray.ndarray_backend_cpu] \u001b[32mPASSED\u001b[0m\u001b[32m [ 50%]\u001b[0m\n",
      "tests/hw4/test_conv.py::test_pad_forward[params1-needle.backend_ndarray.ndarray_backend_cpu] \u001b[32mPASSED\u001b[0m\u001b[32m [100%]\u001b[0m\n",
      "\n",
      "\u001b[32m====================== \u001b[32m\u001b[1m2 passed\u001b[0m, \u001b[33m1801 deselected\u001b[0m\u001b[32m in 1.53s\u001b[0m\u001b[32m ======================\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python3 -m pytest -l -v -k \"pad_forward\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Flipping ndarrays & FlipOp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import ctypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some utility code for a demonstration below which you can probably ignore. It might be instructive to check out the `offset` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reads off the underlying data array in order (i.e., offset 0, offset 1, ..., offset n)\n",
    "# i.e., ignoring strides\n",
    "def raw_data(X):\n",
    "    X = np.array(X) # copy, thus compact X\n",
    "    return np.frombuffer(ctypes.string_at(X.ctypes.data, X.nbytes), dtype=X.dtype, count=X.size)\n",
    "\n",
    "# Xold and Xnew should reference the same underlying data\n",
    "def offset(Xold, Xnew):\n",
    "    assert Xold.itemsize == Xnew.itemsize\n",
    "    # compare addresses to the beginning of the arrays\n",
    "    return (Xnew.ctypes.data - Xold.ctypes.data)//Xnew.itemsize\n",
    "\n",
    "def strides(X):\n",
    "    return ', '.join([str(x//X.itemsize) for x in X.strides])\n",
    "\n",
    "def format_array(X, shape):\n",
    "    assert len(shape) == 3, \"I only made this formatting work for ndims = 3\"\n",
    "    def chunks(l, n):\n",
    "        n = max(1, n)\n",
    "        return (l[i:i+n] for i in range(0, len(l), n))\n",
    "    a = [str(x) if x >= 10 else ' ' + str(x) for x in X]\n",
    "    a = ['(' + ' '.join(y) + ')' for y in [x for x in chunks(a, shape[-1])]]\n",
    "    a = ['|' + ' '.join(y) + '|' for y in [x for x in chunks(a, shape[-2])]]\n",
    "    return '  '.join(a)\n",
    "\n",
    "def inspect_array(X, *, is_a_copy_of):\n",
    "    # compacts X, then reads it off in order\n",
    "    print('Data: %s' % format_array(raw_data(X), X.shape))\n",
    "    # compares address of X to copy_of, thus finding X's offset\n",
    "    print('Offset: %s' % offset(is_a_copy_of, X))\n",
    "    print('Strides: %s' % strides(X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "In order to implement the backwards pass of 2D convolution, we will (probably) need a function which _flips_\n",
    "axes of ndarrays. We say \"probably\" because you could probably cleverly implement your convolution forward\n",
    "function to avoid this. However, we think it is easiest to think about this if you have the ability to \"flip\" the kernel along its vertical and horizontal dimensions.\n",
    "\n",
    "We will try to build up your intuition for the \"flip\" operation below in order to help you figure out how to implement it in `ndarray.py`. To do that, we explore numpy's `np.flip` function below. One thing to note is that\n",
    "`flip` is typically implemented by using negative strides and changing the _offset_ of the underlying array.\n",
    "\n",
    "For example, flipping an array on _all_ of its axes is equivalent to reversing the array. In this case, you can imagine that we would want all the strides to be negative, and the offset to be the length of the array (to start at the end of the array and \"stride\" backwards).\n",
    "\n",
    "Since we did not explicitly support negative strides in our implementation for the last homework, we will merely call `NDArray.make` with them to make our \"flipped\" array and then immediately call `.compact()`. Other than changing unsigned ints to signed ints in a few places, we suspect your existing `compact` function should not have to change at all to accomodate negative strides. In the .cc and .cu files we distributed, we have already changed the function signatures to reflect this.\n",
    "\n",
    "Alternatively, you could simply implement `flip` in the CPU backend by copying memory, which you _may_ find more intuitive. We suggest following our mini tutorial below to keep your implementation Python-focused, since we believe it is involves approximately the same amount of effort to implement it slightly more naively in C."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use this array as reference for the other examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.arange(1, 25).reshape(3, 2, 4)\n",
    "inspect_array(A, is_a_copy_of=A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have put brackets around each axis of the array. Notice that for this array, the offset is 0 and the strides are all positive."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See what happens when you flip the array along the last axis below. \n",
    "Note that the `inspect_array` function compacts the array after flipping it so you can see the\n",
    "\"logical\" order of the data, and the offset is calculated by comparing the address of the **non**-compacted\n",
    "flipped array with that of `is_copy_of`, i.e., the array `A` we looked at above.\n",
    "\n",
    "That is, we are looking at how numpy calculates the strides and offset for flipped arrays in order\n",
    "to copy this behavior in our own implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inspect_array(np.flip(A, (2,)), is_a_copy_of=A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So flipping the last axis reverses the order of the elements within each 4-dimensional \"cell\", as you can see above. The stride corresponding to the axis we flipped has been negated. And the offset is 3 -- this makes sense, e.g., because we want the new \"first\" element of the array to be 4, which was at index 3 in `A`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inspect_array(np.flip(A, (1,)), is_a_copy_of=A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again for the middle axis: we negate the middle stride, and the offset is 4, which seems reasonable since we now want the first element to be 5, which was at index 4 in the original array `A`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inspect_array(np.flip(A, (0,)), is_a_copy_of=A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try to infer the more general algorithm for computing the offset given the axis to flip."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observe what happens when we flip _all_ axes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inspect_array(np.flip(A, (0,1,2)), is_a_copy_of=A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As mentioned earlier, the offset is then sufficient to point to the last element of the array, and this is just the \"reverse order\" version of `A`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we flip just axes 1 and 0..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inspect_array(np.flip(A, (0,1)), is_a_copy_of=A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The offset is 20. Looking back on our previous offset computations, do you notice something?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------\n",
    "\n",
    "With this exploration of numpy's ndarray flipping functionality, which uses negative strides and a custom offset,\n",
    "try to implement `flip` in `ndarray.py`. You also must implement \"flip\" forward and backward functions in `ops.py`; note that these should be extremely short.\n",
    "\n",
    "**Important:** You should call NDArray.make with the new strides and offset, and then immediately `.compact()` this array. The resulting array is then copied and has positive strides. We want this (less-than-optimal) behavior because we did not account for negative strides in our previous implementation. _Aside:_ If you want, consider where/if negative strides break your implementation. `__getitem__` definitely doesn't work due to how we processed slices; is there anything else? (_Note_: this isn't graded.)\n",
    "\n",
    "Also, if you want to instead add a `flip` operator on the CPU/CUDA backends, that's also okay.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform linux -- Python 3.11.8, pytest-8.1.1, pluggy-1.4.0 -- /home/soapg/.conda/envs/dlsys/bin/python3\n",
      "cachedir: .pytest_cache\n",
      "rootdir: /home/soapg/NEEDLE\n",
      "collected 1803 items / 1763 deselected / 40 selected                           \u001b[0m\u001b[1m\n",
      "\n",
      "tests/hw4/test_conv.py::test_flip_forward[params0-needle.backend_ndarray.ndarray_backend_cpu] \u001b[32mPASSED\u001b[0m\u001b[32m [  2%]\u001b[0m\n",
      "tests/hw4/test_conv.py::test_flip_forward[params0-device1] \u001b[33mSKIPPED\u001b[0m (...)\u001b[32m [  5%]\u001b[0m\n",
      "tests/hw4/test_conv.py::test_flip_forward[params1-needle.backend_ndarray.ndarray_backend_cpu] \u001b[32mPASSED\u001b[0m\u001b[32m [  7%]\u001b[0m\n",
      "tests/hw4/test_conv.py::test_flip_forward[params1-device1] \u001b[33mSKIPPED\u001b[0m (...)\u001b[32m [ 10%]\u001b[0m\n",
      "tests/hw4/test_conv.py::test_flip_forward[params2-needle.backend_ndarray.ndarray_backend_cpu] \u001b[32mPASSED\u001b[0m\u001b[32m [ 12%]\u001b[0m\n",
      "tests/hw4/test_conv.py::test_flip_forward[params2-device1] \u001b[33mSKIPPED\u001b[0m (...)\u001b[32m [ 15%]\u001b[0m\n",
      "tests/hw4/test_conv.py::test_flip_forward[params3-needle.backend_ndarray.ndarray_backend_cpu] \u001b[32mPASSED\u001b[0m\u001b[32m [ 17%]\u001b[0m\n",
      "tests/hw4/test_conv.py::test_flip_forward[params3-device1] \u001b[33mSKIPPED\u001b[0m (...)\u001b[32m [ 20%]\u001b[0m\n",
      "tests/hw4/test_conv.py::test_flip_forward[params4-needle.backend_ndarray.ndarray_backend_cpu] \u001b[32mPASSED\u001b[0m\u001b[32m [ 22%]\u001b[0m\n",
      "tests/hw4/test_conv.py::test_flip_forward[params4-device1] \u001b[33mSKIPPED\u001b[0m (...)\u001b[32m [ 25%]\u001b[0m\n",
      "tests/hw4/test_conv.py::test_flip_forward[params5-needle.backend_ndarray.ndarray_backend_cpu] \u001b[32mPASSED\u001b[0m\u001b[32m [ 27%]\u001b[0m\n",
      "tests/hw4/test_conv.py::test_flip_forward[params5-device1] \u001b[33mSKIPPED\u001b[0m (...)\u001b[32m [ 30%]\u001b[0m\n",
      "tests/hw4/test_conv.py::test_flip_forward[params6-needle.backend_ndarray.ndarray_backend_cpu] \u001b[32mPASSED\u001b[0m\u001b[32m [ 32%]\u001b[0m\n",
      "tests/hw4/test_conv.py::test_flip_forward[params6-device1] \u001b[33mSKIPPED\u001b[0m (...)\u001b[32m [ 35%]\u001b[0m\n",
      "tests/hw4/test_conv.py::test_flip_forward[params7-needle.backend_ndarray.ndarray_backend_cpu] \u001b[32mPASSED\u001b[0m\u001b[32m [ 37%]\u001b[0m\n",
      "tests/hw4/test_conv.py::test_flip_forward[params7-device1] \u001b[33mSKIPPED\u001b[0m (...)\u001b[32m [ 40%]\u001b[0m\n",
      "tests/hw4/test_conv.py::test_flip_forward[params8-needle.backend_ndarray.ndarray_backend_cpu] \u001b[32mPASSED\u001b[0m\u001b[32m [ 42%]\u001b[0m\n",
      "tests/hw4/test_conv.py::test_flip_forward[params8-device1] \u001b[33mSKIPPED\u001b[0m (...)\u001b[32m [ 45%]\u001b[0m\n",
      "tests/hw4/test_conv.py::test_flip_forward[params9-needle.backend_ndarray.ndarray_backend_cpu] \u001b[32mPASSED\u001b[0m\u001b[32m [ 47%]\u001b[0m\n",
      "tests/hw4/test_conv.py::test_flip_forward[params9-device1] \u001b[33mSKIPPED\u001b[0m (...)\u001b[32m [ 50%]\u001b[0m\n",
      "tests/hw4/test_conv.py::test_flip_backward[params0-needle.backend_ndarray.ndarray_backend_cpu] \u001b[32mPASSED\u001b[0m\u001b[32m [ 52%]\u001b[0m\n",
      "tests/hw4/test_conv.py::test_flip_backward[params0-device1] \u001b[33mSKIPPED\u001b[0m\u001b[32m      [ 55%]\u001b[0m\n",
      "tests/hw4/test_conv.py::test_flip_backward[params1-needle.backend_ndarray.ndarray_backend_cpu] \u001b[32mPASSED\u001b[0m\u001b[32m [ 57%]\u001b[0m\n",
      "tests/hw4/test_conv.py::test_flip_backward[params1-device1] \u001b[33mSKIPPED\u001b[0m\u001b[32m      [ 60%]\u001b[0m\n",
      "tests/hw4/test_conv.py::test_flip_backward[params2-needle.backend_ndarray.ndarray_backend_cpu] \u001b[32mPASSED\u001b[0m\u001b[32m [ 62%]\u001b[0m\n",
      "tests/hw4/test_conv.py::test_flip_backward[params2-device1] \u001b[33mSKIPPED\u001b[0m\u001b[32m      [ 65%]\u001b[0m\n",
      "tests/hw4/test_conv.py::test_flip_backward[params3-needle.backend_ndarray.ndarray_backend_cpu] \u001b[32mPASSED\u001b[0m\u001b[32m [ 67%]\u001b[0m\n",
      "tests/hw4/test_conv.py::test_flip_backward[params3-device1] \u001b[33mSKIPPED\u001b[0m\u001b[32m      [ 70%]\u001b[0m\n",
      "tests/hw4/test_conv.py::test_flip_backward[params4-needle.backend_ndarray.ndarray_backend_cpu] \u001b[32mPASSED\u001b[0m\u001b[32m [ 72%]\u001b[0m\n",
      "tests/hw4/test_conv.py::test_flip_backward[params4-device1] \u001b[33mSKIPPED\u001b[0m\u001b[32m      [ 75%]\u001b[0m\n",
      "tests/hw4/test_conv.py::test_flip_backward[params5-needle.backend_ndarray.ndarray_backend_cpu] \u001b[32mPASSED\u001b[0m\u001b[32m [ 77%]\u001b[0m\n",
      "tests/hw4/test_conv.py::test_flip_backward[params5-device1] \u001b[33mSKIPPED\u001b[0m\u001b[32m      [ 80%]\u001b[0m\n",
      "tests/hw4/test_conv.py::test_flip_backward[params6-needle.backend_ndarray.ndarray_backend_cpu] \u001b[32mPASSED\u001b[0m\u001b[32m [ 82%]\u001b[0m\n",
      "tests/hw4/test_conv.py::test_flip_backward[params6-device1] \u001b[33mSKIPPED\u001b[0m\u001b[32m      [ 85%]\u001b[0m\n",
      "tests/hw4/test_conv.py::test_flip_backward[params7-needle.backend_ndarray.ndarray_backend_cpu] \u001b[32mPASSED\u001b[0m\u001b[32m [ 87%]\u001b[0m\n",
      "tests/hw4/test_conv.py::test_flip_backward[params7-device1] \u001b[33mSKIPPED\u001b[0m\u001b[32m      [ 90%]\u001b[0m\n",
      "tests/hw4/test_conv.py::test_flip_backward[params8-needle.backend_ndarray.ndarray_backend_cpu] \u001b[32mPASSED\u001b[0m\u001b[32m [ 92%]\u001b[0m\n",
      "tests/hw4/test_conv.py::test_flip_backward[params8-device1] \u001b[33mSKIPPED\u001b[0m\u001b[32m      [ 95%]\u001b[0m\n",
      "tests/hw4/test_conv.py::test_flip_backward[params9-needle.backend_ndarray.ndarray_backend_cpu] \u001b[32mPASSED\u001b[0m\u001b[32m [ 97%]\u001b[0m\n",
      "tests/hw4/test_conv.py::test_flip_backward[params9-device1] \u001b[33mSKIPPED\u001b[0m\u001b[32m      [100%]\u001b[0m\n",
      "\n",
      "\u001b[32m=============== \u001b[32m\u001b[1m20 passed\u001b[0m, \u001b[33m20 skipped\u001b[0m, \u001b[33m1763 deselected\u001b[0m\u001b[32m in 1.80s\u001b[0m\u001b[32m ================\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python3 -m pytest -l -v -k \"flip\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dilation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dilation operator puts zeros between elements of an ndarray. We will need it for computing the backward pass of convolution when the stride of the convolution is greater than 1. As an example, dilation should do the following to a 2x2 matrix when dilated by 1 on both axes:\n",
    "\n",
    "$$\n",
    "\\begin{bmatrix}\n",
    "1 & 2 \\\\\n",
    "3 & 4\n",
    "\\end{bmatrix}\n",
    "\\Longrightarrow\n",
    "\\begin{bmatrix}\n",
    "1 & 0 & 2 & 0 \\\\\n",
    "0 & 0 & 0 & 0 \\\\\n",
    "3 & 0 & 4 & 0 \\\\\n",
    "0 & 0 & 0 & 0\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "To get some intuition for why we need dilation for the backward pass of strided convolution, consider a  `stride=2`, `padding=\"same\"`, `input_channels=output_channels=8` convolution applied to an input of size (10, 32, 32, 8). The resulting output will be of size (10, 16, 16, 8) due to the stride, and thus `out_grad` will have shape (10, 16, 16, 8). Yet, the gradient of the input needs to, of course, have shape (10, 32, 32, 8) -- so we must need to increase the size of `out_grad` in some way. Consider also that you could implement strided convolution as `Conv(x)[:, ::2, ::2, :]`, i.e., only keeping every other pixel in the spatial dimension.\n",
    "\n",
    "\n",
    "Implement `Dilate` in `ops.py`. This function takes two additional parameters (in attrs): the `dilation` amount and the `axes` to dilate. You must also implement the corresponding op `UnDilate`, whose forward pass will be used to implement the gradient of `Dilate`. (This is so we do not have to implement `GetItem` and `SetItem` ops, which can be highly inefficient to backprop through without additional optimizations.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform linux -- Python 3.11.8, pytest-8.1.1, pluggy-1.4.0 -- /home/soapg/.conda/envs/dlsys/bin/python3\n",
      "cachedir: .pytest_cache\n",
      "rootdir: /home/soapg/NEEDLE\n",
      "collected 1803 items / 1777 deselected / 26 selected                           \u001b[0m\u001b[1m\n",
      "\n",
      "tests/hw4/test_conv.py::test_dilate_forward[needle.backend_ndarray.ndarray_backend_cpu] \u001b[32mPASSED\u001b[0m\u001b[32m [  3%]\u001b[0m\n",
      "tests/hw4/test_conv.py::test_dilate_forward[device1] \u001b[33mSKIPPED\u001b[0m (No GPU)\u001b[32m    [  7%]\u001b[0m\n",
      "tests/hw4/test_conv.py::test_dilate_backward[params0-needle.backend_ndarray.ndarray_backend_cpu] \u001b[32mPASSED\u001b[0m\u001b[32m [ 11%]\u001b[0m\n",
      "tests/hw4/test_conv.py::test_dilate_backward[params0-device1] \u001b[33mSKIPPED\u001b[0m\u001b[32m    [ 15%]\u001b[0m\n",
      "tests/hw4/test_conv.py::test_dilate_backward[params1-needle.backend_ndarray.ndarray_backend_cpu] \u001b[32mPASSED\u001b[0m\u001b[32m [ 19%]\u001b[0m\n",
      "tests/hw4/test_conv.py::test_dilate_backward[params1-device1] \u001b[33mSKIPPED\u001b[0m\u001b[32m    [ 23%]\u001b[0m\n",
      "tests/hw4/test_conv.py::test_dilate_backward[params2-needle.backend_ndarray.ndarray_backend_cpu] \u001b[32mPASSED\u001b[0m\u001b[32m [ 26%]\u001b[0m\n",
      "tests/hw4/test_conv.py::test_dilate_backward[params2-device1] \u001b[33mSKIPPED\u001b[0m\u001b[32m    [ 30%]\u001b[0m\n",
      "tests/hw4/test_conv.py::test_dilate_backward[params3-needle.backend_ndarray.ndarray_backend_cpu] \u001b[32mPASSED\u001b[0m\u001b[32m [ 34%]\u001b[0m\n",
      "tests/hw4/test_conv.py::test_dilate_backward[params3-device1] \u001b[33mSKIPPED\u001b[0m\u001b[32m    [ 38%]\u001b[0m\n",
      "tests/hw4/test_conv.py::test_dilate_backward[params4-needle.backend_ndarray.ndarray_backend_cpu] \u001b[32mPASSED\u001b[0m\u001b[32m [ 42%]\u001b[0m\n",
      "tests/hw4/test_conv.py::test_dilate_backward[params4-device1] \u001b[33mSKIPPED\u001b[0m\u001b[32m    [ 46%]\u001b[0m\n",
      "tests/hw4/test_conv.py::test_dilate_backward[params5-needle.backend_ndarray.ndarray_backend_cpu] \u001b[32mPASSED\u001b[0m\u001b[32m [ 50%]\u001b[0m\n",
      "tests/hw4/test_conv.py::test_dilate_backward[params5-device1] \u001b[33mSKIPPED\u001b[0m\u001b[32m    [ 53%]\u001b[0m\n",
      "tests/hw4/test_conv.py::test_dilate_backward[params6-needle.backend_ndarray.ndarray_backend_cpu] \u001b[32mPASSED\u001b[0m\u001b[32m [ 57%]\u001b[0m\n",
      "tests/hw4/test_conv.py::test_dilate_backward[params6-device1] \u001b[33mSKIPPED\u001b[0m\u001b[32m    [ 61%]\u001b[0m\n",
      "tests/hw4/test_conv.py::test_dilate_backward[params7-needle.backend_ndarray.ndarray_backend_cpu] \u001b[32mPASSED\u001b[0m\u001b[32m [ 65%]\u001b[0m\n",
      "tests/hw4/test_conv.py::test_dilate_backward[params7-device1] \u001b[33mSKIPPED\u001b[0m\u001b[32m    [ 69%]\u001b[0m\n",
      "tests/hw4/test_conv.py::test_dilate_backward[params8-needle.backend_ndarray.ndarray_backend_cpu] \u001b[32mPASSED\u001b[0m\u001b[32m [ 73%]\u001b[0m\n",
      "tests/hw4/test_conv.py::test_dilate_backward[params8-device1] \u001b[33mSKIPPED\u001b[0m\u001b[32m    [ 76%]\u001b[0m\n",
      "tests/hw4/test_conv.py::test_dilate_backward[params9-needle.backend_ndarray.ndarray_backend_cpu] \u001b[32mPASSED\u001b[0m\u001b[32m [ 80%]\u001b[0m\n",
      "tests/hw4/test_conv.py::test_dilate_backward[params9-device1] \u001b[33mSKIPPED\u001b[0m\u001b[32m    [ 84%]\u001b[0m\n",
      "tests/hw4/test_conv.py::test_dilate_backward[params10-needle.backend_ndarray.ndarray_backend_cpu] \u001b[32mPASSED\u001b[0m\u001b[32m [ 88%]\u001b[0m\n",
      "tests/hw4/test_conv.py::test_dilate_backward[params10-device1] \u001b[33mSKIPPED\u001b[0m\u001b[32m   [ 92%]\u001b[0m\n",
      "tests/hw4/test_conv.py::test_dilate_backward[params11-needle.backend_ndarray.ndarray_backend_cpu] \u001b[32mPASSED\u001b[0m\u001b[32m [ 96%]\u001b[0m\n",
      "tests/hw4/test_conv.py::test_dilate_backward[params11-device1] \u001b[33mSKIPPED\u001b[0m\u001b[32m   [100%]\u001b[0m\n",
      "\n",
      "\u001b[32m=============== \u001b[32m\u001b[1m13 passed\u001b[0m, \u001b[33m13 skipped\u001b[0m, \u001b[33m1777 deselected\u001b[0m\u001b[32m in 1.72s\u001b[0m\u001b[32m ================\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python3 -m pytest -l -v -k \"dilate\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submit new ops (flip/dilation) to mugrade [10 points]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 -m mugrade submit \"YOUR KEY HERE\" -k \"new_ops\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolution forward\n",
    "\n",
    "Implement the forward pass of 2D multi-channel convolution in `ops.py`. You should probably refer to [this notebook](https://github.com/dlsyscourse/public_notebooks/blob/main/convolution_implementation.ipynb) from lecture, which implements 2D multi-channel convolution using im2col in numpy.\n",
    "\n",
    "**Note:** Your convolution op should accept tensors in the NHWC format, as in the example above, and weights in the format (kernel_size, kernel_size, input_channels, output_channels).\n",
    "\n",
    "However, you will need to add two additional features. Your convolution function should accept arguments for `padding` (default 0) and `stride` (default 1). For `padding`, you should simply apply your padding function to the spatial dimensions (i.e., axes 1 and 2). \n",
    "\n",
    "Implementing strided convolution should consist of a relatively small set of changes to your plain convolution implementation.\n",
    "\n",
    "We recommend implementing convolution without stride first, ensuring you pass some of the tests below, and then adding in stride."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform linux -- Python 3.11.8, pytest-8.1.1, pluggy-1.4.0 -- /home/soapg/.conda/envs/dlsys/bin/python3\n",
      "cachedir: .pytest_cache\n",
      "rootdir: /home/soapg/NEEDLE\n",
      "collected 1803 items / 1769 deselected / 34 selected                           \u001b[0m\u001b[1m\n",
      "\n",
      "tests/hw4/test_conv.py::test_op_conv[forward-needle.backend_ndarray.ndarray_backend_cpu-Z_shape0-W_shape0-1-0] \u001b[32mPASSED\u001b[0m\u001b[32m [  2%]\u001b[0m\n",
      "tests/hw4/test_conv.py::test_op_conv[forward-needle.backend_ndarray.ndarray_backend_cpu-Z_shape1-W_shape1-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [  5%]\u001b[0m\n",
      "tests/hw4/test_conv.py::test_op_conv[forward-needle.backend_ndarray.ndarray_backend_cpu-Z_shape2-W_shape2-1-2] \u001b[32mPASSED\u001b[0m\u001b[32m [  8%]\u001b[0m\n",
      "tests/hw4/test_conv.py::test_op_conv[forward-needle.backend_ndarray.ndarray_backend_cpu-Z_shape3-W_shape3-1-0] \u001b[32mPASSED\u001b[0m\u001b[32m [ 11%]\u001b[0m\n",
      "tests/hw4/test_conv.py::test_op_conv[forward-needle.backend_ndarray.ndarray_backend_cpu-Z_shape4-W_shape4-1-0] \u001b[32mPASSED\u001b[0m\u001b[32m [ 14%]\u001b[0m\n",
      "tests/hw4/test_conv.py::test_op_conv[forward-needle.backend_ndarray.ndarray_backend_cpu-Z_shape5-W_shape5-2-0] \u001b[32mPASSED\u001b[0m\u001b[32m [ 17%]\u001b[0m\n",
      "tests/hw4/test_conv.py::test_op_conv[forward-needle.backend_ndarray.ndarray_backend_cpu-Z_shape6-W_shape6-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 20%]\u001b[0m\n",
      "tests/hw4/test_conv.py::test_op_conv[forward-needle.backend_ndarray.ndarray_backend_cpu-Z_shape7-W_shape7-2-2] \u001b[32mPASSED\u001b[0m\u001b[32m [ 23%]\u001b[0m\n",
      "tests/hw4/test_conv.py::test_op_conv[forward-needle.backend_ndarray.ndarray_backend_cpu-Z_shape8-W_shape8-2-0] \u001b[32mPASSED\u001b[0m\u001b[32m [ 26%]\u001b[0m\n",
      "tests/hw4/test_conv.py::test_op_conv[forward-needle.backend_ndarray.ndarray_backend_cpu-Z_shape9-W_shape9-2-0] \u001b[32mPASSED\u001b[0m\u001b[32m [ 29%]\u001b[0m\n",
      "tests/hw4/test_conv.py::test_op_conv[forward-needle.backend_ndarray.ndarray_backend_cpu-Z_shape10-W_shape10-1-0] \u001b[32mPASSED\u001b[0m\u001b[32m [ 32%]\u001b[0m\n",
      "tests/hw4/test_conv.py::test_op_conv[forward-needle.backend_ndarray.ndarray_backend_cpu-Z_shape11-W_shape11-1-0] \u001b[32mPASSED\u001b[0m\u001b[32m [ 35%]\u001b[0m\n",
      "tests/hw4/test_conv.py::test_op_conv[forward-needle.backend_ndarray.ndarray_backend_cpu-Z_shape12-W_shape12-1-0] \u001b[32mPASSED\u001b[0m\u001b[32m [ 38%]\u001b[0m\n",
      "tests/hw4/test_conv.py::test_op_conv[forward-needle.backend_ndarray.ndarray_backend_cpu-Z_shape13-W_shape13-1-0] \u001b[32mPASSED\u001b[0m\u001b[32m [ 41%]\u001b[0m\n",
      "tests/hw4/test_conv.py::test_op_conv[forward-needle.backend_ndarray.ndarray_backend_cpu-Z_shape14-W_shape14-1-0] \u001b[32mPASSED\u001b[0m\u001b[32m [ 44%]\u001b[0m\n",
      "tests/hw4/test_conv.py::test_op_conv[forward-needle.backend_ndarray.ndarray_backend_cpu-Z_shape15-W_shape15-1-0] \u001b[32mPASSED\u001b[0m\u001b[32m [ 47%]\u001b[0m\n",
      "tests/hw4/test_conv.py::test_op_conv[forward-needle.backend_ndarray.ndarray_backend_cpu-Z_shape16-W_shape16-1-0] \u001b[32mPASSED\u001b[0m\u001b[32m [ 50%]\u001b[0m\n",
      "tests/hw4/test_conv.py::test_op_conv[forward-device1-Z_shape0-W_shape0-1-0] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 52%]\u001b[0m\n",
      "tests/hw4/test_conv.py::test_op_conv[forward-device1-Z_shape1-W_shape1-1-1] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 55%]\u001b[0m\n",
      "tests/hw4/test_conv.py::test_op_conv[forward-device1-Z_shape2-W_shape2-1-2] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 58%]\u001b[0m\n",
      "tests/hw4/test_conv.py::test_op_conv[forward-device1-Z_shape3-W_shape3-1-0] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 61%]\u001b[0m\n",
      "tests/hw4/test_conv.py::test_op_conv[forward-device1-Z_shape4-W_shape4-1-0] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 64%]\u001b[0m\n",
      "tests/hw4/test_conv.py::test_op_conv[forward-device1-Z_shape5-W_shape5-2-0] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 67%]\u001b[0m\n",
      "tests/hw4/test_conv.py::test_op_conv[forward-device1-Z_shape6-W_shape6-2-1] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 70%]\u001b[0m\n",
      "tests/hw4/test_conv.py::test_op_conv[forward-device1-Z_shape7-W_shape7-2-2] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 73%]\u001b[0m\n",
      "tests/hw4/test_conv.py::test_op_conv[forward-device1-Z_shape8-W_shape8-2-0] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 76%]\u001b[0m\n",
      "tests/hw4/test_conv.py::test_op_conv[forward-device1-Z_shape9-W_shape9-2-0] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 79%]\u001b[0m\n",
      "tests/hw4/test_conv.py::test_op_conv[forward-device1-Z_shape10-W_shape10-1-0] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 82%]\u001b[0m\n",
      "tests/hw4/test_conv.py::test_op_conv[forward-device1-Z_shape11-W_shape11-1-0] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 85%]\u001b[0m\n",
      "tests/hw4/test_conv.py::test_op_conv[forward-device1-Z_shape12-W_shape12-1-0] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 88%]\u001b[0m\n",
      "tests/hw4/test_conv.py::test_op_conv[forward-device1-Z_shape13-W_shape13-1-0] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 91%]\u001b[0m\n",
      "tests/hw4/test_conv.py::test_op_conv[forward-device1-Z_shape14-W_shape14-1-0] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 94%]\u001b[0m\n",
      "tests/hw4/test_conv.py::test_op_conv[forward-device1-Z_shape15-W_shape15-1-0] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 97%]\u001b[0m\n",
      "tests/hw4/test_conv.py::test_op_conv[forward-device1-Z_shape16-W_shape16-1-0] \u001b[33mSKIPPED\u001b[0m\u001b[32m [100%]\u001b[0m\n",
      "\n",
      "\u001b[32m=============== \u001b[32m\u001b[1m17 passed\u001b[0m, \u001b[33m17 skipped\u001b[0m, \u001b[33m1769 deselected\u001b[0m\u001b[32m in 1.60s\u001b[0m\u001b[32m ================\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python3 -m pytest -l -v -k \"op_conv and forward\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolution backward"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finding the gradients of 2D multi-channel convolution can be technically quite challenging (especially \"rigorously\"). We will try to provide some useful hints here. Basically, we encourage you to make use of the surprising fact that _whatever makes the dimensions work out is typically right_.\n",
    "\n",
    "Ultimately, the backward pass of convolution can be done in terms of the convolution operator itself, with some clever manipulations using `flip`, `dilate`, and multiple applications of `transpose` to both the arguments and the results.\n",
    "\n",
    "In the last section, we essentially implemented convolution as a matrix product: ignoring the various restride and reshape operations, we basically have something like `X @ W`, where `X` is the input and `W` is the weight. We also have `out_grad`, which is the same shape as `X @ W`. Now, you have already implemented the backward pass of matrix multiplication in a previous assignment, and we can use this knowledge to get some insight into the backward pass of convolution. In particular, referencing your matmul backward implementation, you may notice (heuristically speaking here):\n",
    "\n",
    "`X.grad = out_grad @ W.transpose` \\\n",
    "`W.grad = X.transpose @ out_grad`\n",
    "\n",
    "Surprisingly enough, things work out if we just assume that these are also convolutions (and now assuming that `out_grad`, `W`, and `X` are tensors amenable to 2D multi-channel convolution instead of matrices):\n",
    "\n",
    "`X.grad = ≈conv(≈out_grad, ≈W)` \\\n",
    "`W.grad = ≈conv(≈X, ≈out_grad)`\n",
    "\n",
    "In which the \"≈\" indicates that you need to apply some additional operators to these terms in order to get the dimensions to work out, such as permuting/transposing axes, dilating, changing the `padding=` argument to the convolution function, or permuting/transposing axes of the resulting convolution.\n",
    "\n",
    "As we saw on the [last few slides here](https://dlsyscourse.org/slides/conv_nets.pdf) in class, the transpose of a convolution can be found by simply flipping the kernel. Since we're working in 2D instead of 1D, this means flipping the kernel both vertically and horizontally (thus why we implemented `flip`).\n",
    "\n",
    "Summarizing some hints for both `X.grad` and `W.grad`:\n",
    "\n",
    "`X.grad`\n",
    "- The convolution of `out_grad` and `W`, with some operations applied to those\n",
    "- `W` should be flipped over both the kernel dimensions\n",
    "- If the convolution is strided, increase the size of `out_grad` with a corresponding dilation\n",
    "- Do an example to analyze dimensions: note the shape you want for `X.grad`, and think about how you must permute/transpose the arguments and add padding to the convolution to achieve this shape \n",
    "    - This padding depends on both the kernel size and the `padding` argument to the convolution\n",
    "\n",
    "`W.grad`\n",
    "- The convolution of `X` and `out_grad`, with some operations applied to those\n",
    "- The gradients of `W` must be accumulated over the batches; how can you make the conv operator itself do this accumulation?\n",
    "    - Consider turning batches into channels via transpose/permute\n",
    "- Analyze dimensions: how can you modify `X` and `out_grad` so that the shape of their convolution matches the shape of `W`? You may need to transpose/permute the result.\n",
    "    - Remember to account for the `padding` argument passed to convolution\n",
    "\n",
    "General tips\n",
    "- Deal with strided convolutions last (you should be able to just drop in `dilate` when you've passed most of the tests)\n",
    "- Start with the case where `padding=0`, then consider changing `padding` arguments\n",
    "- You can \"permute\" axes with multiple calls to `transpose`\n",
    "\n",
    "It might also be useful to skip ahead to nn.Conv, pass the forward tests, and then use both the tests below and the nn.Conv backward tests to debug your implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform linux -- Python 3.11.8, pytest-8.1.1, pluggy-1.4.0 -- /home/soapg/.conda/envs/dlsys/bin/python3\n",
      "cachedir: .pytest_cache\n",
      "rootdir: /home/soapg/NEEDLE\n",
      "collected 1803 items / 1769 deselected / 34 selected                           \u001b[0m\u001b[1m\n",
      "\n",
      "tests/hw4/test_conv.py::test_op_conv[backward-needle.backend_ndarray.ndarray_backend_cpu-Z_shape0-W_shape0-1-0] \u001b[32mPASSED\u001b[0m\u001b[32m [  2%]\u001b[0m\n",
      "tests/hw4/test_conv.py::test_op_conv[backward-needle.backend_ndarray.ndarray_backend_cpu-Z_shape1-W_shape1-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [  5%]\u001b[0m\n",
      "tests/hw4/test_conv.py::test_op_conv[backward-needle.backend_ndarray.ndarray_backend_cpu-Z_shape2-W_shape2-1-2] \u001b[32mPASSED\u001b[0m\u001b[32m [  8%]\u001b[0m\n",
      "tests/hw4/test_conv.py::test_op_conv[backward-needle.backend_ndarray.ndarray_backend_cpu-Z_shape3-W_shape3-1-0] \u001b[32mPASSED\u001b[0m\u001b[32m [ 11%]\u001b[0m\n",
      "tests/hw4/test_conv.py::test_op_conv[backward-needle.backend_ndarray.ndarray_backend_cpu-Z_shape4-W_shape4-1-0] \u001b[32mPASSED\u001b[0m\u001b[32m [ 14%]\u001b[0m\n",
      "tests/hw4/test_conv.py::test_op_conv[backward-needle.backend_ndarray.ndarray_backend_cpu-Z_shape5-W_shape5-2-0] \u001b[32mPASSED\u001b[0m\u001b[32m [ 17%]\u001b[0m\n",
      "tests/hw4/test_conv.py::test_op_conv[backward-needle.backend_ndarray.ndarray_backend_cpu-Z_shape6-W_shape6-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 20%]\u001b[0m\n",
      "tests/hw4/test_conv.py::test_op_conv[backward-needle.backend_ndarray.ndarray_backend_cpu-Z_shape7-W_shape7-2-2] \u001b[32mPASSED\u001b[0m\u001b[32m [ 23%]\u001b[0m\n",
      "tests/hw4/test_conv.py::test_op_conv[backward-needle.backend_ndarray.ndarray_backend_cpu-Z_shape8-W_shape8-2-0] \u001b[32mPASSED\u001b[0m\u001b[32m [ 26%]\u001b[0m\n",
      "tests/hw4/test_conv.py::test_op_conv[backward-needle.backend_ndarray.ndarray_backend_cpu-Z_shape9-W_shape9-2-0] \u001b[32mPASSED\u001b[0m\u001b[32m [ 29%]\u001b[0m\n",
      "tests/hw4/test_conv.py::test_op_conv[backward-needle.backend_ndarray.ndarray_backend_cpu-Z_shape10-W_shape10-1-0] \u001b[32mPASSED\u001b[0m\u001b[32m [ 32%]\u001b[0m\n",
      "tests/hw4/test_conv.py::test_op_conv[backward-needle.backend_ndarray.ndarray_backend_cpu-Z_shape11-W_shape11-1-0] \u001b[32mPASSED\u001b[0m\u001b[32m [ 35%]\u001b[0m\n",
      "tests/hw4/test_conv.py::test_op_conv[backward-needle.backend_ndarray.ndarray_backend_cpu-Z_shape12-W_shape12-1-0] \u001b[32mPASSED\u001b[0m\u001b[32m [ 38%]\u001b[0m\n",
      "tests/hw4/test_conv.py::test_op_conv[backward-needle.backend_ndarray.ndarray_backend_cpu-Z_shape13-W_shape13-1-0] \u001b[32mPASSED\u001b[0m\u001b[32m [ 41%]\u001b[0m\n",
      "tests/hw4/test_conv.py::test_op_conv[backward-needle.backend_ndarray.ndarray_backend_cpu-Z_shape14-W_shape14-1-0] \u001b[32mPASSED\u001b[0m\u001b[32m [ 44%]\u001b[0m\n",
      "tests/hw4/test_conv.py::test_op_conv[backward-needle.backend_ndarray.ndarray_backend_cpu-Z_shape15-W_shape15-1-0] \u001b[32mPASSED\u001b[0m\u001b[32m [ 47%]\u001b[0m\n",
      "tests/hw4/test_conv.py::test_op_conv[backward-needle.backend_ndarray.ndarray_backend_cpu-Z_shape16-W_shape16-1-0] \u001b[32mPASSED\u001b[0m\u001b[32m [ 50%]\u001b[0m\n",
      "tests/hw4/test_conv.py::test_op_conv[backward-device1-Z_shape0-W_shape0-1-0] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 52%]\u001b[0m\n",
      "tests/hw4/test_conv.py::test_op_conv[backward-device1-Z_shape1-W_shape1-1-1] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 55%]\u001b[0m\n",
      "tests/hw4/test_conv.py::test_op_conv[backward-device1-Z_shape2-W_shape2-1-2] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 58%]\u001b[0m\n",
      "tests/hw4/test_conv.py::test_op_conv[backward-device1-Z_shape3-W_shape3-1-0] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 61%]\u001b[0m\n",
      "tests/hw4/test_conv.py::test_op_conv[backward-device1-Z_shape4-W_shape4-1-0] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 64%]\u001b[0m\n",
      "tests/hw4/test_conv.py::test_op_conv[backward-device1-Z_shape5-W_shape5-2-0] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 67%]\u001b[0m\n",
      "tests/hw4/test_conv.py::test_op_conv[backward-device1-Z_shape6-W_shape6-2-1] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 70%]\u001b[0m\n",
      "tests/hw4/test_conv.py::test_op_conv[backward-device1-Z_shape7-W_shape7-2-2] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 73%]\u001b[0m\n",
      "tests/hw4/test_conv.py::test_op_conv[backward-device1-Z_shape8-W_shape8-2-0] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 76%]\u001b[0m\n",
      "tests/hw4/test_conv.py::test_op_conv[backward-device1-Z_shape9-W_shape9-2-0] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 79%]\u001b[0m\n",
      "tests/hw4/test_conv.py::test_op_conv[backward-device1-Z_shape10-W_shape10-1-0] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 82%]\u001b[0m\n",
      "tests/hw4/test_conv.py::test_op_conv[backward-device1-Z_shape11-W_shape11-1-0] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 85%]\u001b[0m\n",
      "tests/hw4/test_conv.py::test_op_conv[backward-device1-Z_shape12-W_shape12-1-0] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 88%]\u001b[0m\n",
      "tests/hw4/test_conv.py::test_op_conv[backward-device1-Z_shape13-W_shape13-1-0] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 91%]\u001b[0m\n",
      "tests/hw4/test_conv.py::test_op_conv[backward-device1-Z_shape14-W_shape14-1-0] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 94%]\u001b[0m\n",
      "tests/hw4/test_conv.py::test_op_conv[backward-device1-Z_shape15-W_shape15-1-0] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 97%]\u001b[0m\n",
      "tests/hw4/test_conv.py::test_op_conv[backward-device1-Z_shape16-W_shape16-1-0] \u001b[33mSKIPPED\u001b[0m\u001b[32m [100%]\u001b[0m\n",
      "\n",
      "\u001b[32m=============== \u001b[32m\u001b[1m17 passed\u001b[0m, \u001b[33m17 skipped\u001b[0m, \u001b[33m1769 deselected\u001b[0m\u001b[32m in 1.81s\u001b[0m\u001b[32m ================\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python3 -m pytest -l -v -k \"op_conv and backward\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### nn.Conv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Fixing init._calculate_fans for convolution\n",
    "Previously, we have implemented Kaiming uniform/normal initializations, where we essentially assigned `fan_in = input_size` and `fan_out = output_size`.\n",
    "For convolution, this becomes somewhat more detailed, in that you should multiply both of these by the \"receptive field size\", which is in this case just the product of the kernel sizes -- which in our case are always going to be the same, i.e., $k\\times k$ kernels.\n",
    "\n",
    "**You will need to edit your `kaiming_uniform` in `python/needle/init/init_initializers.py`, etc. init functions to support multidimensional arrays.** In particular, it should support a new `shape` argument which is then passed to, e.g., the underlying `rand` function. Specifically, if the argument `shape` is not None, then ignore `fan_in` and `fan_out` but use the value of `shape` for initializations.\n",
    "\n",
    "You can test this below; though it is not _directly_ graded, it must match ours to pass the nn.Conv mugrade tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform linux -- Python 3.11.8, pytest-8.1.1, pluggy-1.4.0 -- /home/soapg/.conda/envs/dlsys/bin/python3\n",
      "cachedir: .pytest_cache\n",
      "rootdir: /home/soapg/NEEDLE\n",
      "collected 1803 items / 1801 deselected / 2 selected                            \u001b[0m\u001b[1m\n",
      "\n",
      "tests/hw4/test_conv.py::test_init_kaiming_uniform[needle.backend_ndarray.ndarray_backend_cpu] \u001b[32mPASSED\u001b[0m\u001b[32m [ 50%]\u001b[0m\n",
      "tests/hw4/test_conv.py::test_init_kaiming_uniform[device1] \u001b[33mSKIPPED\u001b[0m (...)\u001b[32m [100%]\u001b[0m\n",
      "\n",
      "\u001b[32m================ \u001b[32m\u001b[1m1 passed\u001b[0m, \u001b[33m1 skipped\u001b[0m, \u001b[33m1801 deselected\u001b[0m\u001b[32m in 1.51s\u001b[0m\u001b[32m =================\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python3 -m pytest -l -v -k \"kaiming_uniform\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Implementing nn.Conv\n",
    "\n",
    "Essentially, nn.Conv is just a wrapper of the convolution operator we previously implemented\n",
    "which adds a bias term, initializes the weight and bias, and ensures that the padding is set so that the input and output dimensions are the same (in the `stride=1` case, anyways). \n",
    "\n",
    "Importantly, nn.Conv should support NCHW format instead of NHWC format. In particular, we think this makes more sense given our current BatchNorm implementation. You can implement this by applying `transpose` twice to both the input and output.  \n",
    "\n",
    "- Ensure nn.Conv works for (N, C, H, W) tensors even though we implemented the conv op for (N, H, W, C) tensors\n",
    "- Initialize the (k, k, i, o) weight tensor using Kaiming uniform initialization with default settings\n",
    "- Initialize the (o,) bias tensor using uniform initialization on the interval $\\pm$`1.0/(in_channels * kernel_size**2)**0.5`\n",
    "- Calculate the appropriate padding to ensure input and output dimensions are the same\n",
    "- Calculate the convolution, then add the properly-broadcasted bias term if present\n",
    "\n",
    "You can now test your nn.Conv against PyTorch's nn.Conv2d with the two PyTest calls below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform linux -- Python 3.11.8, pytest-8.1.1, pluggy-1.4.0 -- /home/soapg/.conda/envs/dlsys/bin/python3\n",
      "cachedir: .pytest_cache\n",
      "rootdir: /home/soapg/NEEDLE\n",
      "collected 1803 items / 1793 deselected / 10 selected                           \u001b[0m\u001b[1m\n",
      "\n",
      "tests/hw4/test_conv.py::test_nn_conv_forward[needle.backend_ndarray.ndarray_backend_cpu-4-8-16-3-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 10%]\u001b[0m\n",
      "tests/hw4/test_conv.py::test_nn_conv_forward[needle.backend_ndarray.ndarray_backend_cpu-32-8-16-3-2] \u001b[32mPASSED\u001b[0m\u001b[32m [ 20%]\u001b[0m\n",
      "tests/hw4/test_conv.py::test_nn_conv_forward[needle.backend_ndarray.ndarray_backend_cpu-32-8-8-3-2] \u001b[32mPASSED\u001b[0m\u001b[32m [ 30%]\u001b[0m\n",
      "tests/hw4/test_conv.py::test_nn_conv_forward[needle.backend_ndarray.ndarray_backend_cpu-32-16-8-3-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 40%]\u001b[0m\n",
      "tests/hw4/test_conv.py::test_nn_conv_forward[needle.backend_ndarray.ndarray_backend_cpu-32-16-8-3-2] \u001b[32mPASSED\u001b[0m\u001b[32m [ 50%]\u001b[0m\n",
      "tests/hw4/test_conv.py::test_nn_conv_forward[device1-4-8-16-3-1] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 60%]\u001b[0m\n",
      "tests/hw4/test_conv.py::test_nn_conv_forward[device1-32-8-16-3-2] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 70%]\u001b[0m\n",
      "tests/hw4/test_conv.py::test_nn_conv_forward[device1-32-8-8-3-2] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 80%]\u001b[0m\n",
      "tests/hw4/test_conv.py::test_nn_conv_forward[device1-32-16-8-3-1] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 90%]\u001b[0m\n",
      "tests/hw4/test_conv.py::test_nn_conv_forward[device1-32-16-8-3-2] \u001b[33mSKIPPED\u001b[0m\u001b[32m [100%]\u001b[0m\n",
      "\n",
      "\u001b[32m================ \u001b[32m\u001b[1m5 passed\u001b[0m, \u001b[33m5 skipped\u001b[0m, \u001b[33m1793 deselected\u001b[0m\u001b[32m in 1.62s\u001b[0m\u001b[32m =================\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python3 -m pytest -l -v -k \"nn_conv_forward\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 -m pytest -l -v -k \"nn_conv_backward\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submit nn.Conv to mugrade [20 points]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 -m mugrade submit \"YOUR KEY HERE\" -k \"conv_forward\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 -m mugrade submit \"YOUR KEY HERE\" -k \"conv_backward\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Implementing \"ResNet9\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will now use your convolutional layer to implement a model similar to _ResNet9_, which is known to be a reasonable model for getting good accuracy on CIFAR-10 quickly (see [here](https://github.com/davidcpage/cifar10-fast)). Our main change is that we used striding instead of pooling and divided all of the channels by 4 for the sake of performance (as our framework is not as well-optimized as industry-grade frameworks).\n",
    "\n",
    "In the figure below, before the linear layer, you should \"flatten\" the tensor. You can use the module `Flatten` in `nn_basic.py`, or you can simply use `.reshape` in the `forward()` method of your ResNet9.\n",
    "\n",
    "Make sure that you pass the device to all modules in your model; otherwise, you will get errors about mismatched devices when trying to run with CUDA.\n",
    "\n",
    "<center><img src=\"https://github.com/dlsyscourse/hw4/blob/main/ResNet9.png?raw=true\" alt=\"ResNet9\" style=\"width: 400px;\" /></center>\n",
    "\n",
    "We have tried to make it easier to pass the tests here than for previous assignments where you have implemented models. In particular, we are just going to make sure it has the right number of parameters and similar accuracy and loss after 1 or 2 batches of CIFAR-10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!python3 -m pytest -l -v -k \"resnet9\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can train a ResNet on CIFAR10: (remember to copy the solutions in `python/needle/optim.py` from previous homeworks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 -m pytest -l -v -k \"train_cifar10\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submit ResNet9 to mugrade [10 points]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 -m mugrade submit \"YOUR KEY HERE\" -k \"resnet9\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, you can train your model on CIFAR-10 using the following code. Note that this is likely going to be quite slow, and also  not all that accurate due to the lack of data augmentation. You should expect it to take around 500s per epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using needle backend\n"
     ]
    },
    {
     "ename": "NotImplementedError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[27], line 14\u001b[0m\n\u001b[1;32m      9\u001b[0m dataset \u001b[38;5;241m=\u001b[39m ndl\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mCIFAR10Dataset(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata/cifar-10-batches-py\u001b[39m\u001b[38;5;124m\"\u001b[39m, train\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     10\u001b[0m dataloader \u001b[38;5;241m=\u001b[39m ndl\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mDataLoader(\\\n\u001b[1;32m     11\u001b[0m          dataset\u001b[38;5;241m=\u001b[39mdataset,\n\u001b[1;32m     12\u001b[0m          batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m128\u001b[39m,\n\u001b[1;32m     13\u001b[0m          shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,)\n\u001b[0;32m---> 14\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mResNet9\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfloat32\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m train_cifar10(model, dataloader, n_epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, optimizer\u001b[38;5;241m=\u001b[39mndl\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mAdam,\n\u001b[1;32m     16\u001b[0m       lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.001\u001b[39m, weight_decay\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.001\u001b[39m)\n\u001b[1;32m     17\u001b[0m evaluate_cifar10(model, dataloader)\n",
      "File \u001b[0;32m~/NEEDLE/./apps/models.py:14\u001b[0m, in \u001b[0;36mResNet9.__init__\u001b[0;34m(self, device, dtype)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m()\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m### BEGIN YOUR SOLUTION ###\u001b[39;00m\n\u001b[0;32m---> 14\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m()\n",
      "\u001b[0;31mNotImplementedError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('./python')\n",
    "sys.path.append('./apps')\n",
    "import needle as ndl\n",
    "from models import ResNet9\n",
    "from simple_ml import train_cifar10, evaluate_cifar10\n",
    "\n",
    "device = ndl.cpu()\n",
    "dataset = ndl.data.CIFAR10Dataset(\"data/cifar-10-batches-py\", train=True)\n",
    "dataloader = ndl.data.DataLoader(\\\n",
    "         dataset=dataset,\n",
    "         batch_size=128,\n",
    "         shuffle=True,)\n",
    "model = ResNet9(device=device, dtype=\"float32\")\n",
    "train_cifar10(model, dataloader, n_epochs=10, optimizer=ndl.optim.Adam,\n",
    "      lr=0.001, weight_decay=0.001)\n",
    "evaluate_cifar10(model, dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Recurrent neural network [10 points]\n",
    "\n",
    "**Note:** In the following sections, you may find yourself wanting to index into tensors, i.e., to use getitem or setitem. However, we have not implemented these for tensors in our library; instead, you should use `stack` and `split` operations.\n",
    "\n",
    "In `python/needle/nn_sequence.py`, implement `RNNCell`.\n",
    "\n",
    "$h^\\prime = \\text{tanh}(xW_{ih} + b_{ih} + hW_{hh} + b_{hh})$. If nonlinearity is 'relu', then ReLU is used in place of tanh.\n",
    "\n",
    "All weights and biases should be initialized from $\\mathcal{U}(-\\sqrt{k}, \\sqrt{k})$ where $k=\\frac{1}{\\text{hidden\\_size}}$.\n",
    "\n",
    "In `python/needle/nn_sequence.py`, implement `RNN`.\n",
    "\n",
    "For each element in the input sequence, each layer computes the following function:\n",
    "\n",
    "$h_t = \\text{tanh}(x_tW_{ih} + b_{ih} + h_{(t-1)}W_{hh} + b_{hh})$\n",
    "\n",
    "where $h_t$ is the hidden state at time $t$, $x_t$ is the input at time $t$, and $h_{(t-1)}$ is the hidden state of the previous layer at time $t-1$ or the initial hidden state at time $0$. If nonlinearity is 'relu', then ReLU is used in place of tanh.\n",
    "\n",
    "In a multi-layer RNN, the input $x_t^{(l)}$ of the $l$-th layer ($l \\ge 2$) is the hidden state $h_t^{(l-1)}$ of the previous layer. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 -m pytest -l -v -k \"test_rnn\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 -m mugrade submit \"YOUR KEY HERE\" -k \"rnn\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5: Long short-term memory network [10 points]\n",
    "In `python/needle/nn/nn_sequence.py`, implement `Sigmoid`.\n",
    "\n",
    "$\\sigma(x) = \\frac{1}{1 + \\text{exp}(-x)}$\n",
    "\n",
    "In `python/needle/nn/nn_sequence.py`, implement `LSTMCell`.\n",
    "\n",
    "\\begin{align}\n",
    "i &= \\sigma(xW_{ii} + b_{ii} + hW_{hi} + b_{hi}) \\\\\n",
    "f &= \\sigma(xW_{if} + b_{if} + hW_{hf} + b_{hf}) \\\\\n",
    "g &= \\text{tanh}(xW_{ig} + b_{ig} + hW_{hg} + b_{hg}) \\\\\n",
    "o &= \\sigma(xW_{io} + b_{io} + hW_{ho} + b_{ho}) \\\\\n",
    "c^\\prime &= f * c + i * g \\\\\n",
    "h^\\prime &= o * \\text{tanh}(c^\\prime)\n",
    "\\end{align}\n",
    "\n",
    "where $\\sigma$ is the sigmoid function, and $i$, $f$, $g$, $o$ are the input, forget, cell, and output gates, respectively. \n",
    "\n",
    "All weights and biases should be initialized from $\\mathcal{U}(-\\sqrt{k}, \\sqrt{k})$ where $k=\\frac{1}{\\text{hidden}_\\text{size}}$.\n",
    "\n",
    "Now implement `LSTM` in `python/needle/nn/nn_sequence.py`, which applies a multi-layer LSTM RNN to an input sequence. For each element in the input sequence, each layer computes the following function:\n",
    "\n",
    "\\begin{align}\n",
    "i_t &= \\sigma(x_tW_{ii} + b_{ii} + h_{(t-1)}W_{hi} + b_{hi}) \\\\\n",
    "f_t &= \\sigma(x_tW_{if} + b_{if} + h_{(t-1)}W_{hf} + b_{hf}) \\\\\n",
    "g_t &= \\text{tanh}(x_tW_{ig} + b_{ig} + h_{(t-1)}W_{hg} + b_{hg}) \\\\\n",
    "o_t &= \\sigma(x_tW_{io} + b_{io} + h_{(t-1)}W_{ho} + b_{ho}) \\\\\n",
    "c_t &= f * c_{(t-1)} + i * g \\\\\n",
    "h_t &= o * \\text{tanh}(c_t)\n",
    "\\end{align},\n",
    "where $h_t$ is the hidden state at time $t$, $c_t$ is the cell state at time $t$, $x_t$ is the input at time $t$, $h_{(t-1)}$ is the hidden state of the layer at time $t-1$ or the initial hidden state at time $0$, and $i_t$, $f_t$, $g_t$, $o_t$ are the input, forget, cell, and output gates at time $t$ respectively. \n",
    "\n",
    "In a multi-layer LSTM, the input $x_t^{(l)}$ of the $l$-th layer ($l \\ge 2$) is the hidden state $h_t^{(l-1)}$ of the previous layer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 -m pytest -l -v -k \"test_lstm\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 -m mugrade submit \"YOUR KEY HERE\" -k \"lstm\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 6: Penn Treebank dataset [10 points]\n",
    "\n",
    "In word-level language modeling tasks, the model predicts the probability of the next word in the sequence, based on the words already observed in the sequence. You will write support for the Penn Treebank dataset, which consists of stories from the Wall Street Journal, to train and evaluate a language model on word-level prediction.\n",
    "\n",
    "In `python/needle/data/datasets/ptb_dataset.py`, start by implementing the `Dictionary` class, which creates a dictionary from a list of words, mapping each word to a unique integer.\n",
    "\n",
    "Next, we will use this `Dictionary` class to create a corpus from the train and test txt files in the Penn Treebank dataset that you downloaded at the beginning of the notebook. Implement the `tokenize` function in the `Corpus` class to do this.\n",
    "\n",
    "In order to prepare the data for training and evaluation, you will next implement the `batchify` function. Starting from sequential data, batchify arranges the dataset into columns. For instance, with the alphabet as the sequence and batch size 4, we'd get\n",
    "\n",
    "```\n",
    "┌ a g m s ┐\n",
    "│ b h n t │\n",
    "│ c i o u │\n",
    "│ d j p v │\n",
    "│ e k q w │\n",
    "└ f l r x ┘\n",
    "```\n",
    "\n",
    "These columns are treated as independent by the model, which means that the dependence of e. g. 'g' on 'f' cannot be learned, but allows more efficient batch processing.\n",
    "\n",
    "Next, implement the `get_batch` function. `get_batch` subdivides the source data into chunks of length `bptt`. If source is equal to the example output of the batchify function, with a bptt-limit of 2, we'd get the following two Variables for i = 0:\n",
    "```\n",
    "┌ a g m s ┐ ┌ b h n t ┐\n",
    "└ b h n t ┘ └ c i o u ┘\n",
    "```\n",
    "Note that despite the name of the function, the subdivison of data is not done along the batch dimension (i.e. dimension 1), since that was handled by the batchify function. The chunks are along dimension 0, corresponding to the seq_len dimension in the LSTM or RNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 -m pytest -l -v -k \"ptb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 -m mugrade submit \"YOUR KEY HERE\" -k \"ptb\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 7: Training a word-level language model [10 points]\n",
    "\n",
    "Finally, you will use the `RNN` and `LSTM` components you have written to construct a language model that we will train on the Penn Treebank dataset.\n",
    "\n",
    "First, in `python/needle/nn/nn_sequence.py` implement `Embedding`. Consider we have a dictionary with 1000 words. Then for a word which indexes into this dictionary, we can represent this word as a one-hot vector of size 1000, and then use a linear layer to project this to a vector of some embedding size.\n",
    "\n",
    "In `apps/models.py`, you can now implement `LanguageModel`. Your language model should consist of \n",
    "\n",
    "- An embedding layer (which maps word IDs to embeddings) \n",
    "- A sequence model (either RNN or LSTM)\n",
    "- A linear layer (which outputs probabilities of the next word)\n",
    "\n",
    "In `apps/simple_ml.py` implement `epoch_general_ptb`, `train_ptb`, and `evaluate_ptb`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform darwin -- Python 3.12.1, pytest-7.4.4, pluggy-1.3.0 -- /Users/jiayiguo/miniconda3/envs/dlsys/bin/python3\n",
      "cachedir: .pytest_cache\n",
      "rootdir: /Users/jiayiguo/Desktop/dlsys/hw4\n",
      "collected 1803 items / 1291 deselected / 512 selected                          \u001b[0m\u001b[1m\u001b[1m\n",
      "\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1-True-1-1-1-1-1] \u001b[31mFAILED\u001b[0m\u001b[31m [  0%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1-True-1-1-1-1-13] \u001b[31mFAILED\u001b[0m\u001b[31m [  0%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1-True-1-1-1-2-1] \u001b[31mFAILED\u001b[0m\u001b[31m [  0%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1-True-1-1-1-2-13] \u001b[31mFAILED\u001b[0m\u001b[31m [  0%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1-True-1-1-15-1-1] \u001b[31mFAILED\u001b[0m\u001b[31m [  0%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1-True-1-1-15-1-13] \u001b[31mFAILED\u001b[0m\u001b[31m [  1%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1-True-1-1-15-2-1] \u001b[31mFAILED\u001b[0m\u001b[31m [  1%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1-True-1-1-15-2-13] \u001b[31mFAILED\u001b[0m\u001b[31m [  1%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1-True-1-34-1-1-1] \u001b[31mFAILED\u001b[0m\u001b[31m [  1%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1-True-1-34-1-1-13] \u001b[31mFAILED\u001b[0m\u001b[31m [  1%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1-True-1-34-1-2-1] \u001b[31mFAILED\u001b[0m\u001b[31m [  2%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1-True-1-34-1-2-13] \u001b[31mFAILED\u001b[0m\u001b[31m [  2%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1-True-1-34-15-1-1] \u001b[31mFAILED\u001b[0m\u001b[31m [  2%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1-True-1-34-15-1-13] \u001b[31mFAILED\u001b[0m\u001b[31m [  2%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1-True-1-34-15-2-1] \u001b[31mFAILED\u001b[0m\u001b[31m [  2%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1-True-1-34-15-2-13] \u001b[31mFAILED\u001b[0m\u001b[31m [  3%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1-True-12-1-1-1-1] \u001b[31mFAILED\u001b[0m\u001b[31m [  3%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1-True-12-1-1-1-13] \u001b[31mFAILED\u001b[0m\u001b[31m [  3%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1-True-12-1-1-2-1] \u001b[31mFAILED\u001b[0m\u001b[31m [  3%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1-True-12-1-1-2-13] \u001b[31mFAILED\u001b[0m\u001b[31m [  3%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1-True-12-1-15-1-1] \u001b[31mFAILED\u001b[0m\u001b[31m [  4%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1-True-12-1-15-1-13] \u001b[31mFAILED\u001b[0m\u001b[31m [  4%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1-True-12-1-15-2-1] \u001b[31mFAILED\u001b[0m\u001b[31m [  4%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1-True-12-1-15-2-13] \u001b[31mFAILED\u001b[0m\u001b[31m [  4%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1-True-12-34-1-1-1] \u001b[31mFAILED\u001b[0m\u001b[31m [  4%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1-True-12-34-1-1-13] \u001b[31mFAILED\u001b[0m\u001b[31m [  5%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1-True-12-34-1-2-1] \u001b[31mFAILED\u001b[0m\u001b[31m [  5%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1-True-12-34-1-2-13] \u001b[31mFAILED\u001b[0m\u001b[31m [  5%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1-True-12-34-15-1-1] \u001b[31mFAILED\u001b[0m\u001b[31m [  5%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1-True-12-34-15-1-13] \u001b[31mFAILED\u001b[0m\u001b[31m [  5%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1-True-12-34-15-2-1] \u001b[31mFAILED\u001b[0m\u001b[31m [  6%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1-True-12-34-15-2-13] \u001b[31mFAILED\u001b[0m\u001b[31m [  6%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1-False-1-1-1-1-1] \u001b[31mFAILED\u001b[0m\u001b[31m [  6%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1-False-1-1-1-1-13] \u001b[31mFAILED\u001b[0m\u001b[31m [  6%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1-False-1-1-1-2-1] \u001b[31mFAILED\u001b[0m\u001b[31m [  6%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1-False-1-1-1-2-13] \u001b[31mFAILED\u001b[0m\u001b[31m [  7%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1-False-1-1-15-1-1] \u001b[31mFAILED\u001b[0m\u001b[31m [  7%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1-False-1-1-15-1-13] \u001b[31mFAILED\u001b[0m\u001b[31m [  7%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1-False-1-1-15-2-1] \u001b[31mFAILED\u001b[0m\u001b[31m [  7%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1-False-1-1-15-2-13] \u001b[31mFAILED\u001b[0m\u001b[31m [  7%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1-False-1-34-1-1-1] \u001b[31mFAILED\u001b[0m\u001b[31m [  8%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1-False-1-34-1-1-13] \u001b[31mFAILED\u001b[0m\u001b[31m [  8%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1-False-1-34-1-2-1] \u001b[31mFAILED\u001b[0m\u001b[31m [  8%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1-False-1-34-1-2-13] \u001b[31mFAILED\u001b[0m\u001b[31m [  8%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1-False-1-34-15-1-1] \u001b[31mFAILED\u001b[0m\u001b[31m [  8%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1-False-1-34-15-1-13] \u001b[31mFAILED\u001b[0m\u001b[31m [  8%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1-False-1-34-15-2-1] \u001b[31mFAILED\u001b[0m\u001b[31m [  9%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1-False-1-34-15-2-13] \u001b[31mFAILED\u001b[0m\u001b[31m [  9%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1-False-12-1-1-1-1] \u001b[31mFAILED\u001b[0m\u001b[31m [  9%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1-False-12-1-1-1-13] \u001b[31mFAILED\u001b[0m\u001b[31m [  9%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1-False-12-1-1-2-1] \u001b[31mFAILED\u001b[0m\u001b[31m [  9%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1-False-12-1-1-2-13] \u001b[31mFAILED\u001b[0m\u001b[31m [ 10%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1-False-12-1-15-1-1] \u001b[31mFAILED\u001b[0m\u001b[31m [ 10%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1-False-12-1-15-1-13] \u001b[31mFAILED\u001b[0m\u001b[31m [ 10%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1-False-12-1-15-2-1] \u001b[31mFAILED\u001b[0m\u001b[31m [ 10%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1-False-12-1-15-2-13] \u001b[31mFAILED\u001b[0m\u001b[31m [ 10%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1-False-12-34-1-1-1] \u001b[31mFAILED\u001b[0m\u001b[31m [ 11%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1-False-12-34-1-1-13] \u001b[31mFAILED\u001b[0m\u001b[31m [ 11%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1-False-12-34-1-2-1] \u001b[31mFAILED\u001b[0m\u001b[31m [ 11%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1-False-12-34-1-2-13] \u001b[31mFAILED\u001b[0m\u001b[31m [ 11%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1-False-12-34-15-1-1] \u001b[31mFAILED\u001b[0m\u001b[31m [ 11%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1-False-12-34-15-1-13] \u001b[31mFAILED\u001b[0m\u001b[31m [ 12%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1-False-12-34-15-2-1] \u001b[31mFAILED\u001b[0m\u001b[31m [ 12%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1-False-12-34-15-2-13] \u001b[31mFAILED\u001b[0m\u001b[31m [ 12%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1000-True-1-1-1-1-1] \u001b[31mFAILED\u001b[0m\u001b[31m [ 12%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1000-True-1-1-1-1-13] \u001b[31mFAILED\u001b[0m\u001b[31m [ 12%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1000-True-1-1-1-2-1] \u001b[31mFAILED\u001b[0m\u001b[31m [ 13%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1000-True-1-1-1-2-13] \u001b[31mFAILED\u001b[0m\u001b[31m [ 13%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1000-True-1-1-15-1-1] \u001b[31mFAILED\u001b[0m\u001b[31m [ 13%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1000-True-1-1-15-1-13] \u001b[31mFAILED\u001b[0m\u001b[31m [ 13%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1000-True-1-1-15-2-1] \u001b[31mFAILED\u001b[0m\u001b[31m [ 13%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1000-True-1-1-15-2-13] \u001b[31mFAILED\u001b[0m\u001b[31m [ 14%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1000-True-1-34-1-1-1] \u001b[31mFAILED\u001b[0m\u001b[31m [ 14%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1000-True-1-34-1-1-13] \u001b[31mFAILED\u001b[0m\u001b[31m [ 14%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1000-True-1-34-1-2-1] \u001b[31mFAILED\u001b[0m\u001b[31m [ 14%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1000-True-1-34-1-2-13] \u001b[31mFAILED\u001b[0m\u001b[31m [ 14%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1000-True-1-34-15-1-1] \u001b[31mFAILED\u001b[0m\u001b[31m [ 15%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1000-True-1-34-15-1-13] \u001b[31mFAILED\u001b[0m\u001b[31m [ 15%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1000-True-1-34-15-2-1] \u001b[31mFAILED\u001b[0m\u001b[31m [ 15%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1000-True-1-34-15-2-13] \u001b[31mFAILED\u001b[0m\u001b[31m [ 15%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1000-True-12-1-1-1-1] \u001b[31mFAILED\u001b[0m\u001b[31m [ 15%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1000-True-12-1-1-1-13] \u001b[31mFAILED\u001b[0m\u001b[31m [ 16%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1000-True-12-1-1-2-1] \u001b[31mFAILED\u001b[0m\u001b[31m [ 16%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1000-True-12-1-1-2-13] \u001b[31mFAILED\u001b[0m\u001b[31m [ 16%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1000-True-12-1-15-1-1] \u001b[31mFAILED\u001b[0m\u001b[31m [ 16%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1000-True-12-1-15-1-13] \u001b[31mFAILED\u001b[0m\u001b[31m [ 16%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1000-True-12-1-15-2-1] \u001b[31mFAILED\u001b[0m\u001b[31m [ 16%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1000-True-12-1-15-2-13] \u001b[31mFAILED\u001b[0m\u001b[31m [ 17%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1000-True-12-34-1-1-1] \u001b[31mFAILED\u001b[0m\u001b[31m [ 17%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1000-True-12-34-1-1-13] \u001b[31mFAILED\u001b[0m\u001b[31m [ 17%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1000-True-12-34-1-2-1] \u001b[31mFAILED\u001b[0m\u001b[31m [ 17%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1000-True-12-34-1-2-13] \u001b[31mFAILED\u001b[0m\u001b[31m [ 17%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1000-True-12-34-15-1-1] \u001b[31mFAILED\u001b[0m\u001b[31m [ 18%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1000-True-12-34-15-1-13] \u001b[31mFAILED\u001b[0m\u001b[31m [ 18%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1000-True-12-34-15-2-1] \u001b[31mFAILED\u001b[0m\u001b[31m [ 18%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1000-True-12-34-15-2-13] \u001b[31mFAILED\u001b[0m\u001b[31m [ 18%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1000-False-1-1-1-1-1] \u001b[31mFAILED\u001b[0m\u001b[31m [ 18%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1000-False-1-1-1-1-13] \u001b[31mFAILED\u001b[0m\u001b[31m [ 19%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1000-False-1-1-1-2-1] \u001b[31mFAILED\u001b[0m\u001b[31m [ 19%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1000-False-1-1-1-2-13] \u001b[31mFAILED\u001b[0m\u001b[31m [ 19%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1000-False-1-1-15-1-1] \u001b[31mFAILED\u001b[0m\u001b[31m [ 19%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1000-False-1-1-15-1-13] \u001b[31mFAILED\u001b[0m\u001b[31m [ 19%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1000-False-1-1-15-2-1] \u001b[31mFAILED\u001b[0m\u001b[31m [ 20%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1000-False-1-1-15-2-13] \u001b[31mFAILED\u001b[0m\u001b[31m [ 20%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1000-False-1-34-1-1-1] \u001b[31mFAILED\u001b[0m\u001b[31m [ 20%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1000-False-1-34-1-1-13] \u001b[31mFAILED\u001b[0m\u001b[31m [ 20%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1000-False-1-34-1-2-1] \u001b[31mFAILED\u001b[0m\u001b[31m [ 20%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1000-False-1-34-1-2-13] \u001b[31mFAILED\u001b[0m\u001b[31m [ 21%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1000-False-1-34-15-1-1] \u001b[31mFAILED\u001b[0m\u001b[31m [ 21%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1000-False-1-34-15-1-13] \u001b[31mFAILED\u001b[0m\u001b[31m [ 21%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1000-False-1-34-15-2-1] \u001b[31mFAILED\u001b[0m\u001b[31m [ 21%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1000-False-1-34-15-2-13] \u001b[31mFAILED\u001b[0m\u001b[31m [ 21%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1000-False-12-1-1-1-1] \u001b[31mFAILED\u001b[0m\u001b[31m [ 22%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1000-False-12-1-1-1-13] \u001b[31mFAILED\u001b[0m\u001b[31m [ 22%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1000-False-12-1-1-2-1] \u001b[31mFAILED\u001b[0m\u001b[31m [ 22%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1000-False-12-1-1-2-13] \u001b[31mFAILED\u001b[0m\u001b[31m [ 22%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1000-False-12-1-15-1-1] \u001b[31mFAILED\u001b[0m\u001b[31m [ 22%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1000-False-12-1-15-1-13] \u001b[31mFAILED\u001b[0m\u001b[31m [ 23%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1000-False-12-1-15-2-1] \u001b[31mFAILED\u001b[0m\u001b[31m [ 23%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1000-False-12-1-15-2-13] \u001b[31mFAILED\u001b[0m\u001b[31m [ 23%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1000-False-12-34-1-1-1] \u001b[31mFAILED\u001b[0m\u001b[31m [ 23%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1000-False-12-34-1-1-13] \u001b[31mFAILED\u001b[0m\u001b[31m [ 23%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1000-False-12-34-1-2-1] \u001b[31mFAILED\u001b[0m\u001b[31m [ 24%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1000-False-12-34-1-2-13] \u001b[31mFAILED\u001b[0m\u001b[31m [ 24%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1000-False-12-34-15-1-1] \u001b[31mFAILED\u001b[0m\u001b[31m [ 24%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1000-False-12-34-15-1-13] \u001b[31mFAILED\u001b[0m\u001b[31m [ 24%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1000-False-12-34-15-2-1] \u001b[31mFAILED\u001b[0m\u001b[31m [ 24%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1000-False-12-34-15-2-13] \u001b[31mFAILED\u001b[0m\u001b[31m [ 25%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1-True-1-1-1-1-1] \u001b[31mFAILED\u001b[0m\u001b[31m [ 25%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1-True-1-1-1-1-13] \u001b[31mFAILED\u001b[0m\u001b[31m [ 25%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1-True-1-1-1-2-1] \u001b[31mFAILED\u001b[0m\u001b[31m [ 25%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1-True-1-1-1-2-13] \u001b[31mFAILED\u001b[0m\u001b[31m [ 25%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1-True-1-1-15-1-1] \u001b[31mFAILED\u001b[0m\u001b[31m [ 25%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1-True-1-1-15-1-13] \u001b[31mFAILED\u001b[0m\u001b[31m [ 26%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1-True-1-1-15-2-1] \u001b[31mFAILED\u001b[0m\u001b[31m [ 26%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1-True-1-1-15-2-13] \u001b[31mFAILED\u001b[0m\u001b[31m [ 26%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1-True-1-34-1-1-1] \u001b[31mFAILED\u001b[0m\u001b[31m [ 26%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1-True-1-34-1-1-13] \u001b[31mFAILED\u001b[0m\u001b[31m [ 26%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1-True-1-34-1-2-1] \u001b[31mFAILED\u001b[0m\u001b[31m [ 27%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1-True-1-34-1-2-13] \u001b[31mFAILED\u001b[0m\u001b[31m [ 27%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1-True-1-34-15-1-1] \u001b[31mFAILED\u001b[0m\u001b[31m [ 27%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1-True-1-34-15-1-13] \u001b[31mFAILED\u001b[0m\u001b[31m [ 27%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1-True-1-34-15-2-1] \u001b[31mFAILED\u001b[0m\u001b[31m [ 27%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1-True-1-34-15-2-13] \u001b[31mFAILED\u001b[0m\u001b[31m [ 28%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1-True-12-1-1-1-1] \u001b[31mFAILED\u001b[0m\u001b[31m [ 28%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1-True-12-1-1-1-13] \u001b[31mFAILED\u001b[0m\u001b[31m [ 28%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1-True-12-1-1-2-1] \u001b[31mFAILED\u001b[0m\u001b[31m [ 28%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1-True-12-1-1-2-13] \u001b[31mFAILED\u001b[0m\u001b[31m [ 28%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1-True-12-1-15-1-1] \u001b[31mFAILED\u001b[0m\u001b[31m [ 29%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1-True-12-1-15-1-13] \u001b[31mFAILED\u001b[0m\u001b[31m [ 29%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1-True-12-1-15-2-1] \u001b[31mFAILED\u001b[0m\u001b[31m [ 29%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1-True-12-1-15-2-13] \u001b[31mFAILED\u001b[0m\u001b[31m [ 29%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1-True-12-34-1-1-1] \u001b[31mFAILED\u001b[0m\u001b[31m [ 29%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1-True-12-34-1-1-13] \u001b[31mFAILED\u001b[0m\u001b[31m [ 30%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1-True-12-34-1-2-1] \u001b[31mFAILED\u001b[0m\u001b[31m [ 30%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1-True-12-34-1-2-13] \u001b[31mFAILED\u001b[0m\u001b[31m [ 30%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1-True-12-34-15-1-1] \u001b[31mFAILED\u001b[0m\u001b[31m [ 30%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1-True-12-34-15-1-13] \u001b[31mFAILED\u001b[0m\u001b[31m [ 30%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1-True-12-34-15-2-1] \u001b[31mFAILED\u001b[0m\u001b[31m [ 31%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1-True-12-34-15-2-13] \u001b[31mFAILED\u001b[0m\u001b[31m [ 31%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1-False-1-1-1-1-1] \u001b[31mFAILED\u001b[0m\u001b[31m [ 31%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1-False-1-1-1-1-13] \u001b[31mFAILED\u001b[0m\u001b[31m [ 31%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1-False-1-1-1-2-1] \u001b[31mFAILED\u001b[0m\u001b[31m [ 31%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1-False-1-1-1-2-13] \u001b[31mFAILED\u001b[0m\u001b[31m [ 32%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1-False-1-1-15-1-1] \u001b[31mFAILED\u001b[0m\u001b[31m [ 32%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1-False-1-1-15-1-13] \u001b[31mFAILED\u001b[0m\u001b[31m [ 32%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1-False-1-1-15-2-1] \u001b[31mFAILED\u001b[0m\u001b[31m [ 32%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1-False-1-1-15-2-13] \u001b[31mFAILED\u001b[0m\u001b[31m [ 32%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1-False-1-34-1-1-1] \u001b[31mFAILED\u001b[0m\u001b[31m [ 33%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1-False-1-34-1-1-13] \u001b[31mFAILED\u001b[0m\u001b[31m [ 33%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1-False-1-34-1-2-1] \u001b[31mFAILED\u001b[0m\u001b[31m [ 33%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1-False-1-34-1-2-13] \u001b[31mFAILED\u001b[0m\u001b[31m [ 33%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1-False-1-34-15-1-1] \u001b[31mFAILED\u001b[0m\u001b[31m [ 33%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1-False-1-34-15-1-13] \u001b[31mFAILED\u001b[0m\u001b[31m [ 33%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1-False-1-34-15-2-1] \u001b[31mFAILED\u001b[0m\u001b[31m [ 34%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1-False-1-34-15-2-13] \u001b[31mFAILED\u001b[0m\u001b[31m [ 34%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1-False-12-1-1-1-1] \u001b[31mFAILED\u001b[0m\u001b[31m [ 34%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1-False-12-1-1-1-13] \u001b[31mFAILED\u001b[0m\u001b[31m [ 34%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1-False-12-1-1-2-1] \u001b[31mFAILED\u001b[0m\u001b[31m [ 34%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1-False-12-1-1-2-13] \u001b[31mFAILED\u001b[0m\u001b[31m [ 35%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1-False-12-1-15-1-1] \u001b[31mFAILED\u001b[0m\u001b[31m [ 35%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1-False-12-1-15-1-13] \u001b[31mFAILED\u001b[0m\u001b[31m [ 35%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1-False-12-1-15-2-1] \u001b[31mFAILED\u001b[0m\u001b[31m [ 35%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1-False-12-1-15-2-13] \u001b[31mFAILED\u001b[0m\u001b[31m [ 35%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1-False-12-34-1-1-1] \u001b[31mFAILED\u001b[0m\u001b[31m [ 36%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1-False-12-34-1-1-13] \u001b[31mFAILED\u001b[0m\u001b[31m [ 36%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1-False-12-34-1-2-1] \u001b[31mFAILED\u001b[0m\u001b[31m [ 36%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1-False-12-34-1-2-13] \u001b[31mFAILED\u001b[0m\u001b[31m [ 36%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1-False-12-34-15-1-1] \u001b[31mFAILED\u001b[0m\u001b[31m [ 36%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1-False-12-34-15-1-13] \u001b[31mFAILED\u001b[0m\u001b[31m [ 37%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1-False-12-34-15-2-1] \u001b[31mFAILED\u001b[0m\u001b[31m [ 37%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1-False-12-34-15-2-13] \u001b[31mFAILED\u001b[0m\u001b[31m [ 37%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1000-True-1-1-1-1-1] \u001b[31mFAILED\u001b[0m\u001b[31m [ 37%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1000-True-1-1-1-1-13] \u001b[31mFAILED\u001b[0m\u001b[31m [ 37%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1000-True-1-1-1-2-1] \u001b[31mFAILED\u001b[0m\u001b[31m [ 38%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1000-True-1-1-1-2-13] \u001b[31mFAILED\u001b[0m\u001b[31m [ 38%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1000-True-1-1-15-1-1] \u001b[31mFAILED\u001b[0m\u001b[31m [ 38%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1000-True-1-1-15-1-13] \u001b[31mFAILED\u001b[0m\u001b[31m [ 38%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1000-True-1-1-15-2-1] \u001b[31mFAILED\u001b[0m\u001b[31m [ 38%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1000-True-1-1-15-2-13] \u001b[31mFAILED\u001b[0m\u001b[31m [ 39%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1000-True-1-34-1-1-1] \u001b[31mFAILED\u001b[0m\u001b[31m [ 39%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1000-True-1-34-1-1-13] \u001b[31mFAILED\u001b[0m\u001b[31m [ 39%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1000-True-1-34-1-2-1] \u001b[31mFAILED\u001b[0m\u001b[31m [ 39%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1000-True-1-34-1-2-13] \u001b[31mFAILED\u001b[0m\u001b[31m [ 39%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1000-True-1-34-15-1-1] \u001b[31mFAILED\u001b[0m\u001b[31m [ 40%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1000-True-1-34-15-1-13] \u001b[31mFAILED\u001b[0m\u001b[31m [ 40%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1000-True-1-34-15-2-1] \u001b[31mFAILED\u001b[0m\u001b[31m [ 40%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1000-True-1-34-15-2-13] \u001b[31mFAILED\u001b[0m\u001b[31m [ 40%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1000-True-12-1-1-1-1] \u001b[31mFAILED\u001b[0m\u001b[31m [ 40%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1000-True-12-1-1-1-13] \u001b[31mFAILED\u001b[0m\u001b[31m [ 41%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1000-True-12-1-1-2-1] \u001b[31mFAILED\u001b[0m\u001b[31m [ 41%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1000-True-12-1-1-2-13] \u001b[31mFAILED\u001b[0m\u001b[31m [ 41%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1000-True-12-1-15-1-1] \u001b[31mFAILED\u001b[0m\u001b[31m [ 41%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1000-True-12-1-15-1-13] \u001b[31mFAILED\u001b[0m\u001b[31m [ 41%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1000-True-12-1-15-2-1] \u001b[31mFAILED\u001b[0m\u001b[31m [ 41%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1000-True-12-1-15-2-13] \u001b[31mFAILED\u001b[0m\u001b[31m [ 42%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1000-True-12-34-1-1-1] \u001b[31mFAILED\u001b[0m\u001b[31m [ 42%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1000-True-12-34-1-1-13] \u001b[31mFAILED\u001b[0m\u001b[31m [ 42%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1000-True-12-34-1-2-1] \u001b[31mFAILED\u001b[0m\u001b[31m [ 42%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1000-True-12-34-1-2-13] \u001b[31mFAILED\u001b[0m\u001b[31m [ 42%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1000-True-12-34-15-1-1] \u001b[31mFAILED\u001b[0m\u001b[31m [ 43%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1000-True-12-34-15-1-13] \u001b[31mFAILED\u001b[0m\u001b[31m [ 43%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1000-True-12-34-15-2-1] \u001b[31mFAILED\u001b[0m\u001b[31m [ 43%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1000-True-12-34-15-2-13] \u001b[31mFAILED\u001b[0m\u001b[31m [ 43%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1000-False-1-1-1-1-1] \u001b[31mFAILED\u001b[0m\u001b[31m [ 43%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1000-False-1-1-1-1-13] \u001b[31mFAILED\u001b[0m\u001b[31m [ 44%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1000-False-1-1-1-2-1] \u001b[31mFAILED\u001b[0m\u001b[31m [ 44%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1000-False-1-1-1-2-13] \u001b[31mFAILED\u001b[0m\u001b[31m [ 44%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1000-False-1-1-15-1-1] \u001b[31mFAILED\u001b[0m\u001b[31m [ 44%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1000-False-1-1-15-1-13] \u001b[31mFAILED\u001b[0m\u001b[31m [ 44%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1000-False-1-1-15-2-1] \u001b[31mFAILED\u001b[0m\u001b[31m [ 45%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1000-False-1-1-15-2-13] \u001b[31mFAILED\u001b[0m\u001b[31m [ 45%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1000-False-1-34-1-1-1] \u001b[31mFAILED\u001b[0m\u001b[31m [ 45%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1000-False-1-34-1-1-13] \u001b[31mFAILED\u001b[0m\u001b[31m [ 45%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1000-False-1-34-1-2-1] \u001b[31mFAILED\u001b[0m\u001b[31m [ 45%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1000-False-1-34-1-2-13] \u001b[31mFAILED\u001b[0m\u001b[31m [ 46%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1000-False-1-34-15-1-1] \u001b[31mFAILED\u001b[0m\u001b[31m [ 46%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1000-False-1-34-15-1-13] \u001b[31mFAILED\u001b[0m\u001b[31m [ 46%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1000-False-1-34-15-2-1] \u001b[31mFAILED\u001b[0m\u001b[31m [ 46%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1000-False-1-34-15-2-13] \u001b[31mFAILED\u001b[0m\u001b[31m [ 46%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1000-False-12-1-1-1-1] \u001b[31mFAILED\u001b[0m\u001b[31m [ 47%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1000-False-12-1-1-1-13] \u001b[31mFAILED\u001b[0m\u001b[31m [ 47%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1000-False-12-1-1-2-1] \u001b[31mFAILED\u001b[0m\u001b[31m [ 47%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1000-False-12-1-1-2-13] \u001b[31mFAILED\u001b[0m\u001b[31m [ 47%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1000-False-12-1-15-1-1] \u001b[31mFAILED\u001b[0m\u001b[31m [ 47%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1000-False-12-1-15-1-13] \u001b[31mFAILED\u001b[0m\u001b[31m [ 48%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1000-False-12-1-15-2-1] \u001b[31mFAILED\u001b[0m\u001b[31m [ 48%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1000-False-12-1-15-2-13] \u001b[31mFAILED\u001b[0m\u001b[31m [ 48%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1000-False-12-34-1-1-1] \u001b[31mFAILED\u001b[0m\u001b[31m [ 48%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1000-False-12-34-1-1-13] \u001b[31mFAILED\u001b[0m\u001b[31m [ 48%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1000-False-12-34-1-2-1] \u001b[31mFAILED\u001b[0m\u001b[31m [ 49%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1000-False-12-34-1-2-13] \u001b[31mFAILED\u001b[0m\u001b[31m [ 49%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1000-False-12-34-15-1-1] \u001b[31mFAILED\u001b[0m\u001b[31m [ 49%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1000-False-12-34-15-1-13] \u001b[31mFAILED\u001b[0m\u001b[31m [ 49%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1000-False-12-34-15-2-1] \u001b[31mFAILED\u001b[0m\u001b[31m [ 49%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1000-False-12-34-15-2-13] \u001b[31mFAILED\u001b[0m\u001b[31m [ 50%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1-True-1-1-1-1-1] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 50%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1-True-1-1-1-1-13] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 50%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1-True-1-1-1-2-1] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 50%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1-True-1-1-1-2-13] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 50%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1-True-1-1-15-1-1] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 50%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1-True-1-1-15-1-13] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 51%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1-True-1-1-15-2-1] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 51%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1-True-1-1-15-2-13] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 51%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1-True-1-34-1-1-1] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 51%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1-True-1-34-1-1-13] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 51%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1-True-1-34-1-2-1] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 52%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1-True-1-34-1-2-13] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 52%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1-True-1-34-15-1-1] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 52%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1-True-1-34-15-1-13] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 52%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1-True-1-34-15-2-1] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 52%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1-True-1-34-15-2-13] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 53%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1-True-12-1-1-1-1] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 53%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1-True-12-1-1-1-13] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 53%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1-True-12-1-1-2-1] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 53%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1-True-12-1-1-2-13] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 53%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1-True-12-1-15-1-1] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 54%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1-True-12-1-15-1-13] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 54%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1-True-12-1-15-2-1] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 54%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1-True-12-1-15-2-13] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 54%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1-True-12-34-1-1-1] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 54%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1-True-12-34-1-1-13] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 55%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1-True-12-34-1-2-1] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 55%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1-True-12-34-1-2-13] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 55%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1-True-12-34-15-1-1] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 55%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1-True-12-34-15-1-13] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 55%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1-True-12-34-15-2-1] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 56%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1-True-12-34-15-2-13] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 56%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1-False-1-1-1-1-1] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 56%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1-False-1-1-1-1-13] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 56%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1-False-1-1-1-2-1] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 56%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1-False-1-1-1-2-13] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 57%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1-False-1-1-15-1-1] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 57%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1-False-1-1-15-1-13] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 57%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1-False-1-1-15-2-1] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 57%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1-False-1-1-15-2-13] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 57%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1-False-1-34-1-1-1] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 58%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1-False-1-34-1-1-13] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 58%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1-False-1-34-1-2-1] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 58%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1-False-1-34-1-2-13] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 58%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1-False-1-34-15-1-1] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 58%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1-False-1-34-15-1-13] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 58%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1-False-1-34-15-2-1] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 59%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1-False-1-34-15-2-13] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 59%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1-False-12-1-1-1-1] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 59%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1-False-12-1-1-1-13] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 59%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1-False-12-1-1-2-1] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 59%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1-False-12-1-1-2-13] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 60%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1-False-12-1-15-1-1] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 60%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1-False-12-1-15-1-13] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 60%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1-False-12-1-15-2-1] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 60%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1-False-12-1-15-2-13] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 60%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1-False-12-34-1-1-1] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 61%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1-False-12-34-1-1-13] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 61%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1-False-12-34-1-2-1] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 61%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1-False-12-34-1-2-13] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 61%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1-False-12-34-15-1-1] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 61%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1-False-12-34-15-1-13] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 62%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1-False-12-34-15-2-1] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 62%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1-False-12-34-15-2-13] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 62%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1000-True-1-1-1-1-1] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 62%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1000-True-1-1-1-1-13] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 62%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1000-True-1-1-1-2-1] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 63%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1000-True-1-1-1-2-13] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 63%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1000-True-1-1-15-1-1] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 63%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1000-True-1-1-15-1-13] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 63%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1000-True-1-1-15-2-1] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 63%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1000-True-1-1-15-2-13] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 64%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1000-True-1-34-1-1-1] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 64%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1000-True-1-34-1-1-13] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 64%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1000-True-1-34-1-2-1] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 64%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1000-True-1-34-1-2-13] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 64%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1000-True-1-34-15-1-1] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 65%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1000-True-1-34-15-1-13] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 65%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1000-True-1-34-15-2-1] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 65%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1000-True-1-34-15-2-13] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 65%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1000-True-12-1-1-1-1] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 65%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1000-True-12-1-1-1-13] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 66%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1000-True-12-1-1-2-1] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 66%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1000-True-12-1-1-2-13] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 66%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1000-True-12-1-15-1-1] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 66%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1000-True-12-1-15-1-13] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 66%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1000-True-12-1-15-2-1] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 66%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1000-True-12-1-15-2-13] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 67%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1000-True-12-34-1-1-1] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 67%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1000-True-12-34-1-1-13] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 67%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1000-True-12-34-1-2-1] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 67%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1000-True-12-34-1-2-13] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 67%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1000-True-12-34-15-1-1] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 68%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1000-True-12-34-15-1-13] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 68%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1000-True-12-34-15-2-1] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 68%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1000-True-12-34-15-2-13] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 68%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1000-False-1-1-1-1-1] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 68%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1000-False-1-1-1-1-13] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 69%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1000-False-1-1-1-2-1] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 69%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1000-False-1-1-1-2-13] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 69%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1000-False-1-1-15-1-1] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 69%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1000-False-1-1-15-1-13] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 69%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1000-False-1-1-15-2-1] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 70%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1000-False-1-1-15-2-13] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 70%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1000-False-1-34-1-1-1] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 70%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1000-False-1-34-1-1-13] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 70%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1000-False-1-34-1-2-1] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 70%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1000-False-1-34-1-2-13] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 71%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1000-False-1-34-15-1-1] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 71%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1000-False-1-34-15-1-13] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 71%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1000-False-1-34-15-2-1] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 71%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1000-False-1-34-15-2-13] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 71%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1000-False-12-1-1-1-1] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 72%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1000-False-12-1-1-1-13] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 72%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1000-False-12-1-1-2-1] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 72%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1000-False-12-1-1-2-13] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 72%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1000-False-12-1-15-1-1] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 72%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1000-False-12-1-15-1-13] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 73%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1000-False-12-1-15-2-1] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 73%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1000-False-12-1-15-2-13] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 73%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1000-False-12-34-1-1-1] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 73%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1000-False-12-34-1-1-13] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 73%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1000-False-12-34-1-2-1] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 74%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1000-False-12-34-1-2-13] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 74%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1000-False-12-34-15-1-1] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 74%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1000-False-12-34-15-1-13] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 74%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1000-False-12-34-15-2-1] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 74%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1000-False-12-34-15-2-13] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 75%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1-True-1-1-1-1-1] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 75%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1-True-1-1-1-1-13] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 75%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1-True-1-1-1-2-1] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 75%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1-True-1-1-1-2-13] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 75%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1-True-1-1-15-1-1] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 75%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1-True-1-1-15-1-13] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 76%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1-True-1-1-15-2-1] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 76%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1-True-1-1-15-2-13] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 76%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1-True-1-34-1-1-1] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 76%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1-True-1-34-1-1-13] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 76%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1-True-1-34-1-2-1] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 77%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1-True-1-34-1-2-13] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 77%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1-True-1-34-15-1-1] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 77%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1-True-1-34-15-1-13] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 77%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1-True-1-34-15-2-1] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 77%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1-True-1-34-15-2-13] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 78%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1-True-12-1-1-1-1] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 78%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1-True-12-1-1-1-13] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 78%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1-True-12-1-1-2-1] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 78%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1-True-12-1-1-2-13] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 78%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1-True-12-1-15-1-1] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 79%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1-True-12-1-15-1-13] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 79%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1-True-12-1-15-2-1] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 79%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1-True-12-1-15-2-13] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 79%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1-True-12-34-1-1-1] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 79%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1-True-12-34-1-1-13] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 80%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1-True-12-34-1-2-1] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 80%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1-True-12-34-1-2-13] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 80%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1-True-12-34-15-1-1] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 80%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1-True-12-34-15-1-13] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 80%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1-True-12-34-15-2-1] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 81%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1-True-12-34-15-2-13] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 81%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1-False-1-1-1-1-1] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 81%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1-False-1-1-1-1-13] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 81%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1-False-1-1-1-2-1] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 81%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1-False-1-1-1-2-13] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 82%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1-False-1-1-15-1-1] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 82%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1-False-1-1-15-1-13] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 82%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1-False-1-1-15-2-1] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 82%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1-False-1-1-15-2-13] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 82%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1-False-1-34-1-1-1] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 83%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1-False-1-34-1-1-13] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 83%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1-False-1-34-1-2-1] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 83%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1-False-1-34-1-2-13] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 83%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1-False-1-34-15-1-1] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 83%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1-False-1-34-15-1-13] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 83%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1-False-1-34-15-2-1] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 84%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1-False-1-34-15-2-13] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 84%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1-False-12-1-1-1-1] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 84%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1-False-12-1-1-1-13] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 84%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1-False-12-1-1-2-1] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 84%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1-False-12-1-1-2-13] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 85%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1-False-12-1-15-1-1] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 85%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1-False-12-1-15-1-13] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 85%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1-False-12-1-15-2-1] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 85%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1-False-12-1-15-2-13] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 85%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1-False-12-34-1-1-1] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 86%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1-False-12-34-1-1-13] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 86%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1-False-12-34-1-2-1] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 86%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1-False-12-34-1-2-13] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 86%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1-False-12-34-15-1-1] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 86%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1-False-12-34-15-1-13] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 87%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1-False-12-34-15-2-1] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 87%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1-False-12-34-15-2-13] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 87%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1000-True-1-1-1-1-1] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 87%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1000-True-1-1-1-1-13] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 87%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1000-True-1-1-1-2-1] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 88%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1000-True-1-1-1-2-13] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 88%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1000-True-1-1-15-1-1] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 88%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1000-True-1-1-15-1-13] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 88%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1000-True-1-1-15-2-1] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 88%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1000-True-1-1-15-2-13] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 89%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1000-True-1-34-1-1-1] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 89%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1000-True-1-34-1-1-13] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 89%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1000-True-1-34-1-2-1] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 89%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1000-True-1-34-1-2-13] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 89%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1000-True-1-34-15-1-1] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 90%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1000-True-1-34-15-1-13] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 90%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1000-True-1-34-15-2-1] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 90%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1000-True-1-34-15-2-13] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 90%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1000-True-12-1-1-1-1] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 90%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1000-True-12-1-1-1-13] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 91%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1000-True-12-1-1-2-1] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 91%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1000-True-12-1-1-2-13] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 91%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1000-True-12-1-15-1-1] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 91%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1000-True-12-1-15-1-13] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 91%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1000-True-12-1-15-2-1] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 91%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1000-True-12-1-15-2-13] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 92%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1000-True-12-34-1-1-1] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 92%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1000-True-12-34-1-1-13] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 92%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1000-True-12-34-1-2-1] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 92%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1000-True-12-34-1-2-13] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 92%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1000-True-12-34-15-1-1] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 93%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1000-True-12-34-15-1-13] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 93%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1000-True-12-34-15-2-1] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 93%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1000-True-12-34-15-2-13] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 93%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1000-False-1-1-1-1-1] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 93%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1000-False-1-1-1-1-13] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 94%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1000-False-1-1-1-2-1] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 94%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1000-False-1-1-1-2-13] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 94%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1000-False-1-1-15-1-1] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 94%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1000-False-1-1-15-1-13] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 94%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1000-False-1-1-15-2-1] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 95%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1000-False-1-1-15-2-13] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 95%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1000-False-1-34-1-1-1] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 95%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1000-False-1-34-1-1-13] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 95%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1000-False-1-34-1-2-1] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 95%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1000-False-1-34-1-2-13] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 96%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1000-False-1-34-15-1-1] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 96%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1000-False-1-34-15-1-13] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 96%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1000-False-1-34-15-2-1] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 96%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1000-False-1-34-15-2-13] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 96%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1000-False-12-1-1-1-1] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 97%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1000-False-12-1-1-1-13] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 97%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1000-False-12-1-1-2-1] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 97%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1000-False-12-1-1-2-13] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 97%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1000-False-12-1-15-1-1] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 97%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1000-False-12-1-15-1-13] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 98%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1000-False-12-1-15-2-1] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 98%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1000-False-12-1-15-2-13] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 98%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1000-False-12-34-1-1-1] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 98%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1000-False-12-34-1-1-13] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 98%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1000-False-12-34-1-2-1] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 99%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1000-False-12-34-1-2-13] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 99%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1000-False-12-34-15-1-1] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 99%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1000-False-12-34-15-1-13] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 99%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1000-False-12-34-15-2-1] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 99%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1000-False-12-34-15-2-13] \u001b[33mSKIPPED\u001b[0m\u001b[31m [100%]\u001b[0m\n",
      "\n",
      "=================================== FAILURES ===================================\n",
      "\u001b[31m\u001b[1m_________ test_language_model_implementation[cpu-rnn-1-True-1-1-1-1-1] _________\u001b[0m\n",
      "\n",
      "seq_length = 1, num_layers = 1, batch_size = 1, embedding_size = 1\n",
      "hidden_size = 1, init_hidden = True, output_size = 1, seq_model = 'rnn'\n",
      "device = cpu()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\u001b[90m\u001b[39;49;00m\n",
      "                            init_hidden, output_size, seq_model, device):\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      ">       model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "batch_size = 1\n",
      "c0         = needle.Tensor([[[0.43650985]]])\n",
      "device     = cpu()\n",
      "embedding_size = 1\n",
      "h0         = needle.Tensor([[[1.7886285]]])\n",
      "hidden_size = 1\n",
      "init_hidden = True\n",
      "num_layers = 1\n",
      "output_size = 1\n",
      "seq_length = 1\n",
      "seq_model  = 'rnn'\n",
      "x          = array([[0.]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:201: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "self = <models.LanguageModel object at 0x15748cc20>, embedding_size = 1\n",
      "output_size = 1, hidden_size = 1, num_layers = 1, seq_model = 'rnn'\n",
      "device = cpu(), dtype = 'float32'\n",
      "\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92m__init__\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, embedding_size, output_size, hidden_size, num_layers=\u001b[94m1\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                 seq_model=\u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, device=\u001b[94mNone\u001b[39;49;00m, dtype=\u001b[33m\"\u001b[39;49;00m\u001b[33mfloat32\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"\u001b[39;49;00m\n",
      "    \u001b[33m    Consists of an embedding layer, a sequence model (either RNN or LSTM), and a\u001b[39;49;00m\n",
      "    \u001b[33m    linear layer.\u001b[39;49;00m\n",
      "    \u001b[33m    Parameters:\u001b[39;49;00m\n",
      "    \u001b[33m    output_size: Size of dictionary\u001b[39;49;00m\n",
      "    \u001b[33m    embedding_size: Size of embeddings\u001b[39;49;00m\n",
      "    \u001b[33m    hidden_size: The number of features in the hidden state of LSTM or RNN\u001b[39;49;00m\n",
      "    \u001b[33m    seq_model: 'rnn' or 'lstm', whether to use RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    num_layers: Number of layers in RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    \"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[96msuper\u001b[39;49;00m(LanguageModel, \u001b[96mself\u001b[39;49;00m).\u001b[92m__init__\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m### BEGIN YOUR SOLUTION\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94mraise\u001b[39;49;00m \u001b[96mNotImplementedError\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       NotImplementedError\u001b[0m\n",
      "\n",
      "__class__  = <class 'models.LanguageModel'>\n",
      "device     = cpu()\n",
      "dtype      = 'float32'\n",
      "embedding_size = 1\n",
      "hidden_size = 1\n",
      "num_layers = 1\n",
      "output_size = 1\n",
      "self       = <models.LanguageModel object at 0x15748cc20>\n",
      "seq_model  = 'rnn'\n",
      "\n",
      "\u001b[1m\u001b[31mapps/models.py\u001b[0m:38: NotImplementedError\n",
      "\u001b[31m\u001b[1m________ test_language_model_implementation[cpu-rnn-1-True-1-1-1-1-13] _________\u001b[0m\n",
      "\n",
      "seq_length = 13, num_layers = 1, batch_size = 1, embedding_size = 1\n",
      "hidden_size = 1, init_hidden = True, output_size = 1, seq_model = 'rnn'\n",
      "device = cpu()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\u001b[90m\u001b[39;49;00m\n",
      "                            init_hidden, output_size, seq_model, device):\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      ">       model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "batch_size = 1\n",
      "c0         = needle.Tensor([[[-1.8634927]]])\n",
      "device     = cpu()\n",
      "embedding_size = 1\n",
      "h0         = needle.Tensor([[[0.09649747]]])\n",
      "hidden_size = 1\n",
      "init_hidden = True\n",
      "num_layers = 1\n",
      "output_size = 1\n",
      "seq_length = 13\n",
      "seq_model  = 'rnn'\n",
      "x          = array([[0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:201: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "self = <models.LanguageModel object at 0x15748df40>, embedding_size = 1\n",
      "output_size = 1, hidden_size = 1, num_layers = 1, seq_model = 'rnn'\n",
      "device = cpu(), dtype = 'float32'\n",
      "\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92m__init__\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, embedding_size, output_size, hidden_size, num_layers=\u001b[94m1\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                 seq_model=\u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, device=\u001b[94mNone\u001b[39;49;00m, dtype=\u001b[33m\"\u001b[39;49;00m\u001b[33mfloat32\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"\u001b[39;49;00m\n",
      "    \u001b[33m    Consists of an embedding layer, a sequence model (either RNN or LSTM), and a\u001b[39;49;00m\n",
      "    \u001b[33m    linear layer.\u001b[39;49;00m\n",
      "    \u001b[33m    Parameters:\u001b[39;49;00m\n",
      "    \u001b[33m    output_size: Size of dictionary\u001b[39;49;00m\n",
      "    \u001b[33m    embedding_size: Size of embeddings\u001b[39;49;00m\n",
      "    \u001b[33m    hidden_size: The number of features in the hidden state of LSTM or RNN\u001b[39;49;00m\n",
      "    \u001b[33m    seq_model: 'rnn' or 'lstm', whether to use RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    num_layers: Number of layers in RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    \"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[96msuper\u001b[39;49;00m(LanguageModel, \u001b[96mself\u001b[39;49;00m).\u001b[92m__init__\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m### BEGIN YOUR SOLUTION\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94mraise\u001b[39;49;00m \u001b[96mNotImplementedError\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       NotImplementedError\u001b[0m\n",
      "\n",
      "__class__  = <class 'models.LanguageModel'>\n",
      "device     = cpu()\n",
      "dtype      = 'float32'\n",
      "embedding_size = 1\n",
      "hidden_size = 1\n",
      "num_layers = 1\n",
      "output_size = 1\n",
      "self       = <models.LanguageModel object at 0x15748df40>\n",
      "seq_model  = 'rnn'\n",
      "\n",
      "\u001b[1m\u001b[31mapps/models.py\u001b[0m:38: NotImplementedError\n",
      "\u001b[31m\u001b[1m_________ test_language_model_implementation[cpu-rnn-1-True-1-1-1-2-1] _________\u001b[0m\n",
      "\n",
      "seq_length = 1, num_layers = 2, batch_size = 1, embedding_size = 1\n",
      "hidden_size = 1, init_hidden = True, output_size = 1, seq_model = 'rnn'\n",
      "device = cpu()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\u001b[90m\u001b[39;49;00m\n",
      "                            init_hidden, output_size, seq_model, device):\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      ">       model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "batch_size = 1\n",
      "c0         = needle.Tensor([[[-0.08274148]]\n",
      "\n",
      " [[-0.6270007 ]]])\n",
      "device     = cpu()\n",
      "embedding_size = 1\n",
      "h0         = needle.Tensor([[[-0.27738822]]\n",
      "\n",
      " [[-0.35475898]]])\n",
      "hidden_size = 1\n",
      "init_hidden = True\n",
      "num_layers = 2\n",
      "output_size = 1\n",
      "seq_length = 1\n",
      "seq_model  = 'rnn'\n",
      "x          = array([[0.]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:201: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "self = <models.LanguageModel object at 0x15748d910>, embedding_size = 1\n",
      "output_size = 1, hidden_size = 1, num_layers = 2, seq_model = 'rnn'\n",
      "device = cpu(), dtype = 'float32'\n",
      "\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92m__init__\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, embedding_size, output_size, hidden_size, num_layers=\u001b[94m1\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                 seq_model=\u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, device=\u001b[94mNone\u001b[39;49;00m, dtype=\u001b[33m\"\u001b[39;49;00m\u001b[33mfloat32\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"\u001b[39;49;00m\n",
      "    \u001b[33m    Consists of an embedding layer, a sequence model (either RNN or LSTM), and a\u001b[39;49;00m\n",
      "    \u001b[33m    linear layer.\u001b[39;49;00m\n",
      "    \u001b[33m    Parameters:\u001b[39;49;00m\n",
      "    \u001b[33m    output_size: Size of dictionary\u001b[39;49;00m\n",
      "    \u001b[33m    embedding_size: Size of embeddings\u001b[39;49;00m\n",
      "    \u001b[33m    hidden_size: The number of features in the hidden state of LSTM or RNN\u001b[39;49;00m\n",
      "    \u001b[33m    seq_model: 'rnn' or 'lstm', whether to use RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    num_layers: Number of layers in RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    \"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[96msuper\u001b[39;49;00m(LanguageModel, \u001b[96mself\u001b[39;49;00m).\u001b[92m__init__\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m### BEGIN YOUR SOLUTION\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94mraise\u001b[39;49;00m \u001b[96mNotImplementedError\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       NotImplementedError\u001b[0m\n",
      "\n",
      "__class__  = <class 'models.LanguageModel'>\n",
      "device     = cpu()\n",
      "dtype      = 'float32'\n",
      "embedding_size = 1\n",
      "hidden_size = 1\n",
      "num_layers = 2\n",
      "output_size = 1\n",
      "self       = <models.LanguageModel object at 0x15748d910>\n",
      "seq_model  = 'rnn'\n",
      "\n",
      "\u001b[1m\u001b[31mapps/models.py\u001b[0m:38: NotImplementedError\n",
      "\u001b[31m\u001b[1m________ test_language_model_implementation[cpu-rnn-1-True-1-1-1-2-13] _________\u001b[0m\n",
      "\n",
      "seq_length = 13, num_layers = 2, batch_size = 1, embedding_size = 1\n",
      "hidden_size = 1, init_hidden = True, output_size = 1, seq_model = 'rnn'\n",
      "device = cpu()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\u001b[90m\u001b[39;49;00m\n",
      "                            init_hidden, output_size, seq_model, device):\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      ">       model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "batch_size = 1\n",
      "c0         = needle.Tensor([[[-1.3138647]]\n",
      "\n",
      " [[ 0.8846224]]])\n",
      "device     = cpu()\n",
      "embedding_size = 1\n",
      "h0         = needle.Tensor([[[-0.04381817]]\n",
      "\n",
      " [[-0.47721803]]])\n",
      "hidden_size = 1\n",
      "init_hidden = True\n",
      "num_layers = 2\n",
      "output_size = 1\n",
      "seq_length = 13\n",
      "seq_model  = 'rnn'\n",
      "x          = array([[0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:201: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "self = <models.LanguageModel object at 0x15748e390>, embedding_size = 1\n",
      "output_size = 1, hidden_size = 1, num_layers = 2, seq_model = 'rnn'\n",
      "device = cpu(), dtype = 'float32'\n",
      "\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92m__init__\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, embedding_size, output_size, hidden_size, num_layers=\u001b[94m1\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                 seq_model=\u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, device=\u001b[94mNone\u001b[39;49;00m, dtype=\u001b[33m\"\u001b[39;49;00m\u001b[33mfloat32\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"\u001b[39;49;00m\n",
      "    \u001b[33m    Consists of an embedding layer, a sequence model (either RNN or LSTM), and a\u001b[39;49;00m\n",
      "    \u001b[33m    linear layer.\u001b[39;49;00m\n",
      "    \u001b[33m    Parameters:\u001b[39;49;00m\n",
      "    \u001b[33m    output_size: Size of dictionary\u001b[39;49;00m\n",
      "    \u001b[33m    embedding_size: Size of embeddings\u001b[39;49;00m\n",
      "    \u001b[33m    hidden_size: The number of features in the hidden state of LSTM or RNN\u001b[39;49;00m\n",
      "    \u001b[33m    seq_model: 'rnn' or 'lstm', whether to use RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    num_layers: Number of layers in RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    \"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[96msuper\u001b[39;49;00m(LanguageModel, \u001b[96mself\u001b[39;49;00m).\u001b[92m__init__\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m### BEGIN YOUR SOLUTION\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94mraise\u001b[39;49;00m \u001b[96mNotImplementedError\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       NotImplementedError\u001b[0m\n",
      "\n",
      "__class__  = <class 'models.LanguageModel'>\n",
      "device     = cpu()\n",
      "dtype      = 'float32'\n",
      "embedding_size = 1\n",
      "hidden_size = 1\n",
      "num_layers = 2\n",
      "output_size = 1\n",
      "self       = <models.LanguageModel object at 0x15748e390>\n",
      "seq_model  = 'rnn'\n",
      "\n",
      "\u001b[1m\u001b[31mapps/models.py\u001b[0m:38: NotImplementedError\n",
      "\u001b[31m\u001b[1m________ test_language_model_implementation[cpu-rnn-1-True-1-1-15-1-1] _________\u001b[0m\n",
      "\n",
      "seq_length = 1, num_layers = 1, batch_size = 15, embedding_size = 1\n",
      "hidden_size = 1, init_hidden = True, output_size = 1, seq_model = 'rnn'\n",
      "device = cpu()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\u001b[90m\u001b[39;49;00m\n",
      "                            init_hidden, output_size, seq_model, device):\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      ">       model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "batch_size = 15\n",
      "c0         = needle.Tensor([[[-0.16051336]\n",
      "  [-0.7688364 ]\n",
      "  [-0.23003072]\n",
      "  [ 0.7450563 ]\n",
      "  [ 1.9761108 ]\n",
      "  [-1.2441233 ]\n",
      "  [-0.62...61 ]\n",
      "  [-2.419083  ]\n",
      "  [-0.923792  ]\n",
      "  [-1.0238757 ]\n",
      "  [ 1.1239779 ]\n",
      "  [-0.13191423]\n",
      "  [-1.6232854 ]\n",
      "  [ 0.64667547]]])\n",
      "device     = cpu()\n",
      "embedding_size = 1\n",
      "h0         = needle.Tensor([[[ 0.88131803]\n",
      "  [ 1.709573  ]\n",
      "  [ 0.05003364]\n",
      "  [-0.40467742]\n",
      "  [-0.54535997]\n",
      "  [-1.5464773 ]\n",
      "  [ 0.98...77 ]\n",
      "  [-1.1850466 ]\n",
      "  [-0.2056499 ]\n",
      "  [ 1.4861484 ]\n",
      "  [ 0.23671627]\n",
      "  [-1.0237851 ]\n",
      "  [-0.7129932 ]\n",
      "  [ 0.625245  ]]])\n",
      "hidden_size = 1\n",
      "init_hidden = True\n",
      "num_layers = 1\n",
      "output_size = 1\n",
      "seq_length = 1\n",
      "seq_model  = 'rnn'\n",
      "x          = array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "      dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:201: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "self = <models.LanguageModel object at 0x15748c4d0>, embedding_size = 1\n",
      "output_size = 1, hidden_size = 1, num_layers = 1, seq_model = 'rnn'\n",
      "device = cpu(), dtype = 'float32'\n",
      "\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92m__init__\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, embedding_size, output_size, hidden_size, num_layers=\u001b[94m1\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                 seq_model=\u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, device=\u001b[94mNone\u001b[39;49;00m, dtype=\u001b[33m\"\u001b[39;49;00m\u001b[33mfloat32\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"\u001b[39;49;00m\n",
      "    \u001b[33m    Consists of an embedding layer, a sequence model (either RNN or LSTM), and a\u001b[39;49;00m\n",
      "    \u001b[33m    linear layer.\u001b[39;49;00m\n",
      "    \u001b[33m    Parameters:\u001b[39;49;00m\n",
      "    \u001b[33m    output_size: Size of dictionary\u001b[39;49;00m\n",
      "    \u001b[33m    embedding_size: Size of embeddings\u001b[39;49;00m\n",
      "    \u001b[33m    hidden_size: The number of features in the hidden state of LSTM or RNN\u001b[39;49;00m\n",
      "    \u001b[33m    seq_model: 'rnn' or 'lstm', whether to use RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    num_layers: Number of layers in RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    \"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[96msuper\u001b[39;49;00m(LanguageModel, \u001b[96mself\u001b[39;49;00m).\u001b[92m__init__\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m### BEGIN YOUR SOLUTION\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94mraise\u001b[39;49;00m \u001b[96mNotImplementedError\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       NotImplementedError\u001b[0m\n",
      "\n",
      "__class__  = <class 'models.LanguageModel'>\n",
      "device     = cpu()\n",
      "dtype      = 'float32'\n",
      "embedding_size = 1\n",
      "hidden_size = 1\n",
      "num_layers = 1\n",
      "output_size = 1\n",
      "self       = <models.LanguageModel object at 0x15748c4d0>\n",
      "seq_model  = 'rnn'\n",
      "\n",
      "\u001b[1m\u001b[31mapps/models.py\u001b[0m:38: NotImplementedError\n",
      "\u001b[31m\u001b[1m________ test_language_model_implementation[cpu-rnn-1-True-1-1-15-1-13] ________\u001b[0m\n",
      "\n",
      "seq_length = 13, num_layers = 1, batch_size = 15, embedding_size = 1\n",
      "hidden_size = 1, init_hidden = True, output_size = 1, seq_model = 'rnn'\n",
      "device = cpu()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\u001b[90m\u001b[39;49;00m\n",
      "                            init_hidden, output_size, seq_model, device):\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      ">       model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "batch_size = 15\n",
      "c0         = needle.Tensor([[[-1.8608896 ]\n",
      "  [-0.6028851 ]\n",
      "  [-1.914472  ]\n",
      "  [ 1.0481476 ]\n",
      "  [ 1.3337379 ]\n",
      "  [-0.19741468]\n",
      "  [ 1.77...75 ]\n",
      "  [ 0.15061687]\n",
      "  [ 0.1529457 ]\n",
      "  [-1.0641953 ]\n",
      "  [ 0.43794662]\n",
      "  [ 1.9389784 ]\n",
      "  [-1.0249308 ]\n",
      "  [ 0.8993384 ]]])\n",
      "device     = cpu()\n",
      "embedding_size = 1\n",
      "h0         = needle.Tensor([[[-0.35627076]\n",
      "  [-1.743141  ]\n",
      "  [-0.59664965]\n",
      "  [-0.5885944 ]\n",
      "  [-0.8738823 ]\n",
      "  [ 0.02971382]\n",
      "  [-2.24...186]\n",
      "  [ 1.0131835 ]\n",
      "  [ 0.85279787]\n",
      "  [ 1.1081876 ]\n",
      "  [ 1.1193906 ]\n",
      "  [ 1.4875431 ]\n",
      "  [-1.1183007 ]\n",
      "  [ 0.8458334 ]]])\n",
      "hidden_size = 1\n",
      "init_hidden = True\n",
      "num_layers = 1\n",
      "output_size = 1\n",
      "seq_length = 13\n",
      "seq_model  = 'rnn'\n",
      "x          = array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0...0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "      dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:201: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "self = <models.LanguageModel object at 0x15748df40>, embedding_size = 1\n",
      "output_size = 1, hidden_size = 1, num_layers = 1, seq_model = 'rnn'\n",
      "device = cpu(), dtype = 'float32'\n",
      "\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92m__init__\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, embedding_size, output_size, hidden_size, num_layers=\u001b[94m1\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                 seq_model=\u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, device=\u001b[94mNone\u001b[39;49;00m, dtype=\u001b[33m\"\u001b[39;49;00m\u001b[33mfloat32\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"\u001b[39;49;00m\n",
      "    \u001b[33m    Consists of an embedding layer, a sequence model (either RNN or LSTM), and a\u001b[39;49;00m\n",
      "    \u001b[33m    linear layer.\u001b[39;49;00m\n",
      "    \u001b[33m    Parameters:\u001b[39;49;00m\n",
      "    \u001b[33m    output_size: Size of dictionary\u001b[39;49;00m\n",
      "    \u001b[33m    embedding_size: Size of embeddings\u001b[39;49;00m\n",
      "    \u001b[33m    hidden_size: The number of features in the hidden state of LSTM or RNN\u001b[39;49;00m\n",
      "    \u001b[33m    seq_model: 'rnn' or 'lstm', whether to use RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    num_layers: Number of layers in RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    \"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[96msuper\u001b[39;49;00m(LanguageModel, \u001b[96mself\u001b[39;49;00m).\u001b[92m__init__\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m### BEGIN YOUR SOLUTION\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94mraise\u001b[39;49;00m \u001b[96mNotImplementedError\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       NotImplementedError\u001b[0m\n",
      "\n",
      "__class__  = <class 'models.LanguageModel'>\n",
      "device     = cpu()\n",
      "dtype      = 'float32'\n",
      "embedding_size = 1\n",
      "hidden_size = 1\n",
      "num_layers = 1\n",
      "output_size = 1\n",
      "self       = <models.LanguageModel object at 0x15748df40>\n",
      "seq_model  = 'rnn'\n",
      "\n",
      "\u001b[1m\u001b[31mapps/models.py\u001b[0m:38: NotImplementedError\n",
      "\u001b[31m\u001b[1m________ test_language_model_implementation[cpu-rnn-1-True-1-1-15-2-1] _________\u001b[0m\n",
      "\n",
      "seq_length = 1, num_layers = 2, batch_size = 15, embedding_size = 1\n",
      "hidden_size = 1, init_hidden = True, output_size = 1, seq_model = 'rnn'\n",
      "device = cpu()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\u001b[90m\u001b[39;49;00m\n",
      "                            init_hidden, output_size, seq_model, device):\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      ">       model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "batch_size = 15\n",
      "c0         = needle.Tensor([[[-0.07974094]\n",
      "  [ 0.5644855 ]\n",
      "  [ 1.233471  ]\n",
      "  [ 0.1489864 ]\n",
      "  [-0.53058213]\n",
      "  [-0.7305266 ]\n",
      "  [ 0.64...027]\n",
      "  [ 0.28703517]\n",
      "  [-0.07744096]\n",
      "  [ 0.2760685 ]\n",
      "  [-0.6484109 ]\n",
      "  [-0.73746485]\n",
      "  [-0.1680901 ]\n",
      "  [ 1.9092768 ]]])\n",
      "device     = cpu()\n",
      "embedding_size = 1\n",
      "h0         = needle.Tensor([[[-0.15450685]\n",
      "  [ 1.7696273 ]\n",
      "  [ 0.48378834]\n",
      "  [ 0.6762164 ]\n",
      "  [ 0.64316326]\n",
      "  [ 0.24908671]\n",
      "  [-1.39...84 ]\n",
      "  [-0.10945433]\n",
      "  [ 0.6790716 ]\n",
      "  [-0.85543716]\n",
      "  [-0.30020607]\n",
      "  [ 2.1581492 ]\n",
      "  [ 0.8742857 ]\n",
      "  [-1.2935367 ]]])\n",
      "hidden_size = 1\n",
      "init_hidden = True\n",
      "num_layers = 2\n",
      "output_size = 1\n",
      "seq_length = 1\n",
      "seq_model  = 'rnn'\n",
      "x          = array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "      dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:201: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "self = <models.LanguageModel object at 0x15748fc50>, embedding_size = 1\n",
      "output_size = 1, hidden_size = 1, num_layers = 2, seq_model = 'rnn'\n",
      "device = cpu(), dtype = 'float32'\n",
      "\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92m__init__\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, embedding_size, output_size, hidden_size, num_layers=\u001b[94m1\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                 seq_model=\u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, device=\u001b[94mNone\u001b[39;49;00m, dtype=\u001b[33m\"\u001b[39;49;00m\u001b[33mfloat32\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"\u001b[39;49;00m\n",
      "    \u001b[33m    Consists of an embedding layer, a sequence model (either RNN or LSTM), and a\u001b[39;49;00m\n",
      "    \u001b[33m    linear layer.\u001b[39;49;00m\n",
      "    \u001b[33m    Parameters:\u001b[39;49;00m\n",
      "    \u001b[33m    output_size: Size of dictionary\u001b[39;49;00m\n",
      "    \u001b[33m    embedding_size: Size of embeddings\u001b[39;49;00m\n",
      "    \u001b[33m    hidden_size: The number of features in the hidden state of LSTM or RNN\u001b[39;49;00m\n",
      "    \u001b[33m    seq_model: 'rnn' or 'lstm', whether to use RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    num_layers: Number of layers in RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    \"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[96msuper\u001b[39;49;00m(LanguageModel, \u001b[96mself\u001b[39;49;00m).\u001b[92m__init__\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m### BEGIN YOUR SOLUTION\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94mraise\u001b[39;49;00m \u001b[96mNotImplementedError\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       NotImplementedError\u001b[0m\n",
      "\n",
      "__class__  = <class 'models.LanguageModel'>\n",
      "device     = cpu()\n",
      "dtype      = 'float32'\n",
      "embedding_size = 1\n",
      "hidden_size = 1\n",
      "num_layers = 2\n",
      "output_size = 1\n",
      "self       = <models.LanguageModel object at 0x15748fc50>\n",
      "seq_model  = 'rnn'\n",
      "\n",
      "\u001b[1m\u001b[31mapps/models.py\u001b[0m:38: NotImplementedError\n",
      "\u001b[31m\u001b[1m________ test_language_model_implementation[cpu-rnn-1-True-1-1-15-2-13] ________\u001b[0m\n",
      "\n",
      "seq_length = 13, num_layers = 2, batch_size = 15, embedding_size = 1\n",
      "hidden_size = 1, init_hidden = True, output_size = 1, seq_model = 'rnn'\n",
      "device = cpu()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\u001b[90m\u001b[39;49;00m\n",
      "                            init_hidden, output_size, seq_model, device):\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      ">       model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "batch_size = 15\n",
      "c0         = needle.Tensor([[[-0.26124048]\n",
      "  [-1.2980466 ]\n",
      "  [ 2.6761124 ]\n",
      "  [-0.07121903]\n",
      "  [-1.4866581 ]\n",
      "  [ 1.4086269 ]\n",
      "  [-1.07...36 ]\n",
      "  [-0.96077514]\n",
      "  [-1.0203593 ]\n",
      "  [ 0.27059343]\n",
      "  [ 0.6478298 ]\n",
      "  [-0.5603734 ]\n",
      "  [-0.58850163]\n",
      "  [-1.5465559 ]]])\n",
      "device     = cpu()\n",
      "embedding_size = 1\n",
      "h0         = needle.Tensor([[[ 0.81481457]\n",
      "  [-0.51999176]\n",
      "  [ 0.5587132 ]\n",
      "  [-0.47836465]\n",
      "  [-0.4572608 ]\n",
      "  [ 0.859284  ]\n",
      "  [-0.52...416]\n",
      "  [ 0.4246357 ]\n",
      "  [-0.72543347]\n",
      "  [-0.03494339]\n",
      "  [-0.14062002]\n",
      "  [ 0.9970884 ]\n",
      "  [-0.7959147 ]\n",
      "  [ 0.07274553]]])\n",
      "hidden_size = 1\n",
      "init_hidden = True\n",
      "num_layers = 2\n",
      "output_size = 1\n",
      "seq_length = 13\n",
      "seq_model  = 'rnn'\n",
      "x          = array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0...0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "      dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:201: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "self = <models.LanguageModel object at 0x1574b8290>, embedding_size = 1\n",
      "output_size = 1, hidden_size = 1, num_layers = 2, seq_model = 'rnn'\n",
      "device = cpu(), dtype = 'float32'\n",
      "\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92m__init__\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, embedding_size, output_size, hidden_size, num_layers=\u001b[94m1\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                 seq_model=\u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, device=\u001b[94mNone\u001b[39;49;00m, dtype=\u001b[33m\"\u001b[39;49;00m\u001b[33mfloat32\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"\u001b[39;49;00m\n",
      "    \u001b[33m    Consists of an embedding layer, a sequence model (either RNN or LSTM), and a\u001b[39;49;00m\n",
      "    \u001b[33m    linear layer.\u001b[39;49;00m\n",
      "    \u001b[33m    Parameters:\u001b[39;49;00m\n",
      "    \u001b[33m    output_size: Size of dictionary\u001b[39;49;00m\n",
      "    \u001b[33m    embedding_size: Size of embeddings\u001b[39;49;00m\n",
      "    \u001b[33m    hidden_size: The number of features in the hidden state of LSTM or RNN\u001b[39;49;00m\n",
      "    \u001b[33m    seq_model: 'rnn' or 'lstm', whether to use RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    num_layers: Number of layers in RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    \"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[96msuper\u001b[39;49;00m(LanguageModel, \u001b[96mself\u001b[39;49;00m).\u001b[92m__init__\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m### BEGIN YOUR SOLUTION\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94mraise\u001b[39;49;00m \u001b[96mNotImplementedError\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       NotImplementedError\u001b[0m\n",
      "\n",
      "__class__  = <class 'models.LanguageModel'>\n",
      "device     = cpu()\n",
      "dtype      = 'float32'\n",
      "embedding_size = 1\n",
      "hidden_size = 1\n",
      "num_layers = 2\n",
      "output_size = 1\n",
      "self       = <models.LanguageModel object at 0x1574b8290>\n",
      "seq_model  = 'rnn'\n",
      "\n",
      "\u001b[1m\u001b[31mapps/models.py\u001b[0m:38: NotImplementedError\n",
      "\u001b[31m\u001b[1m________ test_language_model_implementation[cpu-rnn-1-True-1-34-1-1-1] _________\u001b[0m\n",
      "\n",
      "seq_length = 1, num_layers = 1, batch_size = 1, embedding_size = 34\n",
      "hidden_size = 1, init_hidden = True, output_size = 1, seq_model = 'rnn'\n",
      "device = cpu()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\u001b[90m\u001b[39;49;00m\n",
      "                            init_hidden, output_size, seq_model, device):\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      ">       model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "batch_size = 1\n",
      "c0         = needle.Tensor([[[0.24816802]]])\n",
      "device     = cpu()\n",
      "embedding_size = 34\n",
      "h0         = needle.Tensor([[[-0.12776206]]])\n",
      "hidden_size = 1\n",
      "init_hidden = True\n",
      "num_layers = 1\n",
      "output_size = 1\n",
      "seq_length = 1\n",
      "seq_model  = 'rnn'\n",
      "x          = array([[0.]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:201: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "self = <models.LanguageModel object at 0x1574b92b0>, embedding_size = 34\n",
      "output_size = 1, hidden_size = 1, num_layers = 1, seq_model = 'rnn'\n",
      "device = cpu(), dtype = 'float32'\n",
      "\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92m__init__\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, embedding_size, output_size, hidden_size, num_layers=\u001b[94m1\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                 seq_model=\u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, device=\u001b[94mNone\u001b[39;49;00m, dtype=\u001b[33m\"\u001b[39;49;00m\u001b[33mfloat32\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"\u001b[39;49;00m\n",
      "    \u001b[33m    Consists of an embedding layer, a sequence model (either RNN or LSTM), and a\u001b[39;49;00m\n",
      "    \u001b[33m    linear layer.\u001b[39;49;00m\n",
      "    \u001b[33m    Parameters:\u001b[39;49;00m\n",
      "    \u001b[33m    output_size: Size of dictionary\u001b[39;49;00m\n",
      "    \u001b[33m    embedding_size: Size of embeddings\u001b[39;49;00m\n",
      "    \u001b[33m    hidden_size: The number of features in the hidden state of LSTM or RNN\u001b[39;49;00m\n",
      "    \u001b[33m    seq_model: 'rnn' or 'lstm', whether to use RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    num_layers: Number of layers in RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    \"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[96msuper\u001b[39;49;00m(LanguageModel, \u001b[96mself\u001b[39;49;00m).\u001b[92m__init__\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m### BEGIN YOUR SOLUTION\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94mraise\u001b[39;49;00m \u001b[96mNotImplementedError\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       NotImplementedError\u001b[0m\n",
      "\n",
      "__class__  = <class 'models.LanguageModel'>\n",
      "device     = cpu()\n",
      "dtype      = 'float32'\n",
      "embedding_size = 34\n",
      "hidden_size = 1\n",
      "num_layers = 1\n",
      "output_size = 1\n",
      "self       = <models.LanguageModel object at 0x1574b92b0>\n",
      "seq_model  = 'rnn'\n",
      "\n",
      "\u001b[1m\u001b[31mapps/models.py\u001b[0m:38: NotImplementedError\n",
      "\u001b[31m\u001b[1m________ test_language_model_implementation[cpu-rnn-1-True-1-34-1-1-13] ________\u001b[0m\n",
      "\n",
      "seq_length = 13, num_layers = 1, batch_size = 1, embedding_size = 34\n",
      "hidden_size = 1, init_hidden = True, output_size = 1, seq_model = 'rnn'\n",
      "device = cpu()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\u001b[90m\u001b[39;49;00m\n",
      "                            init_hidden, output_size, seq_model, device):\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      ">       model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "batch_size = 1\n",
      "c0         = needle.Tensor([[[-0.78270906]]])\n",
      "device     = cpu()\n",
      "embedding_size = 34\n",
      "h0         = needle.Tensor([[[0.44578096]]])\n",
      "hidden_size = 1\n",
      "init_hidden = True\n",
      "num_layers = 1\n",
      "output_size = 1\n",
      "seq_length = 13\n",
      "seq_model  = 'rnn'\n",
      "x          = array([[0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:201: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "self = <models.LanguageModel object at 0x1574baea0>, embedding_size = 34\n",
      "output_size = 1, hidden_size = 1, num_layers = 1, seq_model = 'rnn'\n",
      "device = cpu(), dtype = 'float32'\n",
      "\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92m__init__\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, embedding_size, output_size, hidden_size, num_layers=\u001b[94m1\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                 seq_model=\u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, device=\u001b[94mNone\u001b[39;49;00m, dtype=\u001b[33m\"\u001b[39;49;00m\u001b[33mfloat32\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"\u001b[39;49;00m\n",
      "    \u001b[33m    Consists of an embedding layer, a sequence model (either RNN or LSTM), and a\u001b[39;49;00m\n",
      "    \u001b[33m    linear layer.\u001b[39;49;00m\n",
      "    \u001b[33m    Parameters:\u001b[39;49;00m\n",
      "    \u001b[33m    output_size: Size of dictionary\u001b[39;49;00m\n",
      "    \u001b[33m    embedding_size: Size of embeddings\u001b[39;49;00m\n",
      "    \u001b[33m    hidden_size: The number of features in the hidden state of LSTM or RNN\u001b[39;49;00m\n",
      "    \u001b[33m    seq_model: 'rnn' or 'lstm', whether to use RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    num_layers: Number of layers in RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    \"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[96msuper\u001b[39;49;00m(LanguageModel, \u001b[96mself\u001b[39;49;00m).\u001b[92m__init__\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m### BEGIN YOUR SOLUTION\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94mraise\u001b[39;49;00m \u001b[96mNotImplementedError\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       NotImplementedError\u001b[0m\n",
      "\n",
      "__class__  = <class 'models.LanguageModel'>\n",
      "device     = cpu()\n",
      "dtype      = 'float32'\n",
      "embedding_size = 34\n",
      "hidden_size = 1\n",
      "num_layers = 1\n",
      "output_size = 1\n",
      "self       = <models.LanguageModel object at 0x1574baea0>\n",
      "seq_model  = 'rnn'\n",
      "\n",
      "\u001b[1m\u001b[31mapps/models.py\u001b[0m:38: NotImplementedError\n",
      "\u001b[31m\u001b[1m________ test_language_model_implementation[cpu-rnn-1-True-1-34-1-2-1] _________\u001b[0m\n",
      "\n",
      "seq_length = 1, num_layers = 2, batch_size = 1, embedding_size = 34\n",
      "hidden_size = 1, init_hidden = True, output_size = 1, seq_model = 'rnn'\n",
      "device = cpu()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\u001b[90m\u001b[39;49;00m\n",
      "                            init_hidden, output_size, seq_model, device):\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      ">       model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "batch_size = 1\n",
      "c0         = needle.Tensor([[[-0.0952376 ]]\n",
      "\n",
      " [[-0.52718776]]])\n",
      "device     = cpu()\n",
      "embedding_size = 34\n",
      "h0         = needle.Tensor([[[1.9884896]]\n",
      "\n",
      " [[1.1950583]]])\n",
      "hidden_size = 1\n",
      "init_hidden = True\n",
      "num_layers = 2\n",
      "output_size = 1\n",
      "seq_length = 1\n",
      "seq_model  = 'rnn'\n",
      "x          = array([[0.]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:201: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "self = <models.LanguageModel object at 0x1574ba360>, embedding_size = 34\n",
      "output_size = 1, hidden_size = 1, num_layers = 2, seq_model = 'rnn'\n",
      "device = cpu(), dtype = 'float32'\n",
      "\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92m__init__\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, embedding_size, output_size, hidden_size, num_layers=\u001b[94m1\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                 seq_model=\u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, device=\u001b[94mNone\u001b[39;49;00m, dtype=\u001b[33m\"\u001b[39;49;00m\u001b[33mfloat32\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"\u001b[39;49;00m\n",
      "    \u001b[33m    Consists of an embedding layer, a sequence model (either RNN or LSTM), and a\u001b[39;49;00m\n",
      "    \u001b[33m    linear layer.\u001b[39;49;00m\n",
      "    \u001b[33m    Parameters:\u001b[39;49;00m\n",
      "    \u001b[33m    output_size: Size of dictionary\u001b[39;49;00m\n",
      "    \u001b[33m    embedding_size: Size of embeddings\u001b[39;49;00m\n",
      "    \u001b[33m    hidden_size: The number of features in the hidden state of LSTM or RNN\u001b[39;49;00m\n",
      "    \u001b[33m    seq_model: 'rnn' or 'lstm', whether to use RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    num_layers: Number of layers in RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    \"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[96msuper\u001b[39;49;00m(LanguageModel, \u001b[96mself\u001b[39;49;00m).\u001b[92m__init__\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m### BEGIN YOUR SOLUTION\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94mraise\u001b[39;49;00m \u001b[96mNotImplementedError\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       NotImplementedError\u001b[0m\n",
      "\n",
      "__class__  = <class 'models.LanguageModel'>\n",
      "device     = cpu()\n",
      "dtype      = 'float32'\n",
      "embedding_size = 34\n",
      "hidden_size = 1\n",
      "num_layers = 2\n",
      "output_size = 1\n",
      "self       = <models.LanguageModel object at 0x1574ba360>\n",
      "seq_model  = 'rnn'\n",
      "\n",
      "\u001b[1m\u001b[31mapps/models.py\u001b[0m:38: NotImplementedError\n",
      "\u001b[31m\u001b[1m________ test_language_model_implementation[cpu-rnn-1-True-1-34-1-2-13] ________\u001b[0m\n",
      "\n",
      "seq_length = 13, num_layers = 2, batch_size = 1, embedding_size = 34\n",
      "hidden_size = 1, init_hidden = True, output_size = 1, seq_model = 'rnn'\n",
      "device = cpu()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\u001b[90m\u001b[39;49;00m\n",
      "                            init_hidden, output_size, seq_model, device):\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      ">       model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "batch_size = 1\n",
      "c0         = needle.Tensor([[[-0.01862772]]\n",
      "\n",
      " [[ 0.4835288 ]]])\n",
      "device     = cpu()\n",
      "embedding_size = 34\n",
      "h0         = needle.Tensor([[[-0.3215847 ]]\n",
      "\n",
      " [[ 0.15113038]]])\n",
      "hidden_size = 1\n",
      "init_hidden = True\n",
      "num_layers = 2\n",
      "output_size = 1\n",
      "seq_length = 13\n",
      "seq_model  = 'rnn'\n",
      "x          = array([[0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:201: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "self = <models.LanguageModel object at 0x1574bb9b0>, embedding_size = 34\n",
      "output_size = 1, hidden_size = 1, num_layers = 2, seq_model = 'rnn'\n",
      "device = cpu(), dtype = 'float32'\n",
      "\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92m__init__\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, embedding_size, output_size, hidden_size, num_layers=\u001b[94m1\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                 seq_model=\u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, device=\u001b[94mNone\u001b[39;49;00m, dtype=\u001b[33m\"\u001b[39;49;00m\u001b[33mfloat32\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"\u001b[39;49;00m\n",
      "    \u001b[33m    Consists of an embedding layer, a sequence model (either RNN or LSTM), and a\u001b[39;49;00m\n",
      "    \u001b[33m    linear layer.\u001b[39;49;00m\n",
      "    \u001b[33m    Parameters:\u001b[39;49;00m\n",
      "    \u001b[33m    output_size: Size of dictionary\u001b[39;49;00m\n",
      "    \u001b[33m    embedding_size: Size of embeddings\u001b[39;49;00m\n",
      "    \u001b[33m    hidden_size: The number of features in the hidden state of LSTM or RNN\u001b[39;49;00m\n",
      "    \u001b[33m    seq_model: 'rnn' or 'lstm', whether to use RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    num_layers: Number of layers in RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    \"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[96msuper\u001b[39;49;00m(LanguageModel, \u001b[96mself\u001b[39;49;00m).\u001b[92m__init__\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m### BEGIN YOUR SOLUTION\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94mraise\u001b[39;49;00m \u001b[96mNotImplementedError\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       NotImplementedError\u001b[0m\n",
      "\n",
      "__class__  = <class 'models.LanguageModel'>\n",
      "device     = cpu()\n",
      "dtype      = 'float32'\n",
      "embedding_size = 34\n",
      "hidden_size = 1\n",
      "num_layers = 2\n",
      "output_size = 1\n",
      "self       = <models.LanguageModel object at 0x1574bb9b0>\n",
      "seq_model  = 'rnn'\n",
      "\n",
      "\u001b[1m\u001b[31mapps/models.py\u001b[0m:38: NotImplementedError\n",
      "\u001b[31m\u001b[1m________ test_language_model_implementation[cpu-rnn-1-True-1-34-15-1-1] ________\u001b[0m\n",
      "\n",
      "seq_length = 1, num_layers = 1, batch_size = 15, embedding_size = 34\n",
      "hidden_size = 1, init_hidden = True, output_size = 1, seq_model = 'rnn'\n",
      "device = cpu()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\u001b[90m\u001b[39;49;00m\n",
      "                            init_hidden, output_size, seq_model, device):\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      ">       model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "batch_size = 15\n",
      "c0         = needle.Tensor([[[-0.2413848 ]\n",
      "  [-0.47552487]\n",
      "  [-0.16577703]\n",
      "  [-0.64971745]\n",
      "  [ 1.631383  ]\n",
      "  [-0.1676986 ]\n",
      "  [ 1.72...87 ]\n",
      "  [ 0.01842079]\n",
      "  [ 0.5619517 ]\n",
      "  [-0.29382125]\n",
      "  [ 1.0946531 ]\n",
      "  [ 0.63969237]\n",
      "  [-0.27460012]\n",
      "  [ 0.43500927]]])\n",
      "device     = cpu()\n",
      "embedding_size = 34\n",
      "h0         = needle.Tensor([[[ 0.7689652 ]\n",
      "  [ 1.3662429 ]\n",
      "  [ 1.1472648 ]\n",
      "  [-0.11022916]\n",
      "  [ 0.3882504 ]\n",
      "  [-0.3871272 ]\n",
      "  [-0.58...68 ]\n",
      "  [-0.45984614]\n",
      "  [ 1.9907378 ]\n",
      "  [-0.34903538]\n",
      "  [ 0.25282508]\n",
      "  [ 1.0894096 ]\n",
      "  [ 0.02392202]\n",
      "  [ 0.3931253 ]]])\n",
      "hidden_size = 1\n",
      "init_hidden = True\n",
      "num_layers = 1\n",
      "output_size = 1\n",
      "seq_length = 1\n",
      "seq_model  = 'rnn'\n",
      "x          = array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "      dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:201: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "self = <models.LanguageModel object at 0x1574ebb30>, embedding_size = 34\n",
      "output_size = 1, hidden_size = 1, num_layers = 1, seq_model = 'rnn'\n",
      "device = cpu(), dtype = 'float32'\n",
      "\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92m__init__\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, embedding_size, output_size, hidden_size, num_layers=\u001b[94m1\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                 seq_model=\u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, device=\u001b[94mNone\u001b[39;49;00m, dtype=\u001b[33m\"\u001b[39;49;00m\u001b[33mfloat32\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"\u001b[39;49;00m\n",
      "    \u001b[33m    Consists of an embedding layer, a sequence model (either RNN or LSTM), and a\u001b[39;49;00m\n",
      "    \u001b[33m    linear layer.\u001b[39;49;00m\n",
      "    \u001b[33m    Parameters:\u001b[39;49;00m\n",
      "    \u001b[33m    output_size: Size of dictionary\u001b[39;49;00m\n",
      "    \u001b[33m    embedding_size: Size of embeddings\u001b[39;49;00m\n",
      "    \u001b[33m    hidden_size: The number of features in the hidden state of LSTM or RNN\u001b[39;49;00m\n",
      "    \u001b[33m    seq_model: 'rnn' or 'lstm', whether to use RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    num_layers: Number of layers in RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    \"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[96msuper\u001b[39;49;00m(LanguageModel, \u001b[96mself\u001b[39;49;00m).\u001b[92m__init__\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m### BEGIN YOUR SOLUTION\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94mraise\u001b[39;49;00m \u001b[96mNotImplementedError\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       NotImplementedError\u001b[0m\n",
      "\n",
      "__class__  = <class 'models.LanguageModel'>\n",
      "device     = cpu()\n",
      "dtype      = 'float32'\n",
      "embedding_size = 34\n",
      "hidden_size = 1\n",
      "num_layers = 1\n",
      "output_size = 1\n",
      "self       = <models.LanguageModel object at 0x1574ebb30>\n",
      "seq_model  = 'rnn'\n",
      "\n",
      "\u001b[1m\u001b[31mapps/models.py\u001b[0m:38: NotImplementedError\n",
      "\u001b[31m\u001b[1m_______ test_language_model_implementation[cpu-rnn-1-True-1-34-15-1-13] ________\u001b[0m\n",
      "\n",
      "seq_length = 13, num_layers = 1, batch_size = 15, embedding_size = 34\n",
      "hidden_size = 1, init_hidden = True, output_size = 1, seq_model = 'rnn'\n",
      "device = cpu()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\u001b[90m\u001b[39;49;00m\n",
      "                            init_hidden, output_size, seq_model, device):\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      ">       model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "batch_size = 15\n",
      "c0         = needle.Tensor([[[ 0.16651951]\n",
      "  [ 1.7194766 ]\n",
      "  [-2.3592148 ]\n",
      "  [-0.57134897]\n",
      "  [ 0.26578704]\n",
      "  [-0.9120909 ]\n",
      "  [-0.15...09 ]\n",
      "  [-0.6544152 ]\n",
      "  [ 2.7119262 ]\n",
      "  [ 0.6274739 ]\n",
      "  [-0.05394785]\n",
      "  [ 1.3151672 ]\n",
      "  [-0.23733747]\n",
      "  [ 0.8853397 ]]])\n",
      "device     = cpu()\n",
      "embedding_size = 34\n",
      "h0         = needle.Tensor([[[ 2.8118784 ]\n",
      "  [ 0.25199512]\n",
      "  [ 0.29950234]\n",
      "  [-0.43999133]\n",
      "  [ 0.13349704]\n",
      "  [-1.2892612 ]\n",
      "  [-0.19...77 ]\n",
      "  [ 1.0672156 ]\n",
      "  [ 0.64142066]\n",
      "  [ 1.1039217 ]\n",
      "  [ 1.881755  ]\n",
      "  [ 0.5935881 ]\n",
      "  [ 2.0708785 ]\n",
      "  [ 1.0697984 ]]])\n",
      "hidden_size = 1\n",
      "init_hidden = True\n",
      "num_layers = 1\n",
      "output_size = 1\n",
      "seq_length = 13\n",
      "seq_model  = 'rnn'\n",
      "x          = array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0...0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "      dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:201: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "self = <models.LanguageModel object at 0x1574e91c0>, embedding_size = 34\n",
      "output_size = 1, hidden_size = 1, num_layers = 1, seq_model = 'rnn'\n",
      "device = cpu(), dtype = 'float32'\n",
      "\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92m__init__\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, embedding_size, output_size, hidden_size, num_layers=\u001b[94m1\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                 seq_model=\u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, device=\u001b[94mNone\u001b[39;49;00m, dtype=\u001b[33m\"\u001b[39;49;00m\u001b[33mfloat32\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"\u001b[39;49;00m\n",
      "    \u001b[33m    Consists of an embedding layer, a sequence model (either RNN or LSTM), and a\u001b[39;49;00m\n",
      "    \u001b[33m    linear layer.\u001b[39;49;00m\n",
      "    \u001b[33m    Parameters:\u001b[39;49;00m\n",
      "    \u001b[33m    output_size: Size of dictionary\u001b[39;49;00m\n",
      "    \u001b[33m    embedding_size: Size of embeddings\u001b[39;49;00m\n",
      "    \u001b[33m    hidden_size: The number of features in the hidden state of LSTM or RNN\u001b[39;49;00m\n",
      "    \u001b[33m    seq_model: 'rnn' or 'lstm', whether to use RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    num_layers: Number of layers in RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    \"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[96msuper\u001b[39;49;00m(LanguageModel, \u001b[96mself\u001b[39;49;00m).\u001b[92m__init__\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m### BEGIN YOUR SOLUTION\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94mraise\u001b[39;49;00m \u001b[96mNotImplementedError\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       NotImplementedError\u001b[0m\n",
      "\n",
      "__class__  = <class 'models.LanguageModel'>\n",
      "device     = cpu()\n",
      "dtype      = 'float32'\n",
      "embedding_size = 34\n",
      "hidden_size = 1\n",
      "num_layers = 1\n",
      "output_size = 1\n",
      "self       = <models.LanguageModel object at 0x1574e91c0>\n",
      "seq_model  = 'rnn'\n",
      "\n",
      "\u001b[1m\u001b[31mapps/models.py\u001b[0m:38: NotImplementedError\n",
      "\u001b[31m\u001b[1m________ test_language_model_implementation[cpu-rnn-1-True-1-34-15-2-1] ________\u001b[0m\n",
      "\n",
      "seq_length = 1, num_layers = 2, batch_size = 15, embedding_size = 34\n",
      "hidden_size = 1, init_hidden = True, output_size = 1, seq_model = 'rnn'\n",
      "device = cpu()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\u001b[90m\u001b[39;49;00m\n",
      "                            init_hidden, output_size, seq_model, device):\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      ">       model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "batch_size = 15\n",
      "c0         = needle.Tensor([[[-1.1127812 ]\n",
      "  [-1.6392963 ]\n",
      "  [ 0.3628035 ]\n",
      "  [-1.1590365 ]\n",
      "  [ 1.5032619 ]\n",
      "  [ 0.9083187 ]\n",
      "  [-1.02...723]\n",
      "  [-1.7948071 ]\n",
      "  [-0.02878565]\n",
      "  [-1.4739429 ]\n",
      "  [ 2.0196507 ]\n",
      "  [ 0.32626227]\n",
      "  [ 0.8613576 ]\n",
      "  [ 0.91900814]]])\n",
      "device     = cpu()\n",
      "embedding_size = 34\n",
      "h0         = needle.Tensor([[[ 0.35081583]\n",
      "  [ 1.6265736 ]\n",
      "  [-1.4198713 ]\n",
      "  [ 0.7657211 ]\n",
      "  [ 0.12224974]\n",
      "  [-1.1573833 ]\n",
      "  [ 1.06...342]\n",
      "  [-0.01497319]\n",
      "  [ 0.28755766]\n",
      "  [ 1.2640858 ]\n",
      "  [ 1.896901  ]\n",
      "  [-1.2058028 ]\n",
      "  [-0.61510855]\n",
      "  [-1.0621561 ]]])\n",
      "hidden_size = 1\n",
      "init_hidden = True\n",
      "num_layers = 2\n",
      "output_size = 1\n",
      "seq_length = 1\n",
      "seq_model  = 'rnn'\n",
      "x          = array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "      dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:201: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "self = <models.LanguageModel object at 0x1574e9eb0>, embedding_size = 34\n",
      "output_size = 1, hidden_size = 1, num_layers = 2, seq_model = 'rnn'\n",
      "device = cpu(), dtype = 'float32'\n",
      "\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92m__init__\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, embedding_size, output_size, hidden_size, num_layers=\u001b[94m1\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                 seq_model=\u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, device=\u001b[94mNone\u001b[39;49;00m, dtype=\u001b[33m\"\u001b[39;49;00m\u001b[33mfloat32\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"\u001b[39;49;00m\n",
      "    \u001b[33m    Consists of an embedding layer, a sequence model (either RNN or LSTM), and a\u001b[39;49;00m\n",
      "    \u001b[33m    linear layer.\u001b[39;49;00m\n",
      "    \u001b[33m    Parameters:\u001b[39;49;00m\n",
      "    \u001b[33m    output_size: Size of dictionary\u001b[39;49;00m\n",
      "    \u001b[33m    embedding_size: Size of embeddings\u001b[39;49;00m\n",
      "    \u001b[33m    hidden_size: The number of features in the hidden state of LSTM or RNN\u001b[39;49;00m\n",
      "    \u001b[33m    seq_model: 'rnn' or 'lstm', whether to use RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    num_layers: Number of layers in RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    \"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[96msuper\u001b[39;49;00m(LanguageModel, \u001b[96mself\u001b[39;49;00m).\u001b[92m__init__\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m### BEGIN YOUR SOLUTION\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94mraise\u001b[39;49;00m \u001b[96mNotImplementedError\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       NotImplementedError\u001b[0m\n",
      "\n",
      "__class__  = <class 'models.LanguageModel'>\n",
      "device     = cpu()\n",
      "dtype      = 'float32'\n",
      "embedding_size = 34\n",
      "hidden_size = 1\n",
      "num_layers = 2\n",
      "output_size = 1\n",
      "self       = <models.LanguageModel object at 0x1574e9eb0>\n",
      "seq_model  = 'rnn'\n",
      "\n",
      "\u001b[1m\u001b[31mapps/models.py\u001b[0m:38: NotImplementedError\n",
      "\u001b[31m\u001b[1m_______ test_language_model_implementation[cpu-rnn-1-True-1-34-15-2-13] ________\u001b[0m\n",
      "\n",
      "seq_length = 13, num_layers = 2, batch_size = 15, embedding_size = 34\n",
      "hidden_size = 1, init_hidden = True, output_size = 1, seq_model = 'rnn'\n",
      "device = cpu()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\u001b[90m\u001b[39;49;00m\n",
      "                            init_hidden, output_size, seq_model, device):\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      ">       model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "batch_size = 15\n",
      "c0         = needle.Tensor([[[ 0.12730852]\n",
      "  [ 0.23502702]\n",
      "  [-1.9450723 ]\n",
      "  [-1.1597229 ]\n",
      "  [-0.4758994 ]\n",
      "  [ 0.29684454]\n",
      "  [-0.00...076]\n",
      "  [ 1.1928052 ]\n",
      "  [-1.1390969 ]\n",
      "  [-1.3220297 ]\n",
      "  [-0.9983669 ]\n",
      "  [ 0.2543876 ]\n",
      "  [-1.8868369 ]\n",
      "  [ 0.09659374]]])\n",
      "device     = cpu()\n",
      "embedding_size = 34\n",
      "h0         = needle.Tensor([[[-1.3244886 ]\n",
      "  [-2.2817924 ]\n",
      "  [-0.32957816]\n",
      "  [ 0.89714974]\n",
      "  [ 0.09103451]\n",
      "  [ 0.7854322 ]\n",
      "  [ 0.93...616]\n",
      "  [-2.9839702 ]\n",
      "  [ 0.28318593]\n",
      "  [-0.06436017]\n",
      "  [-0.99579424]\n",
      "  [ 0.34379452]\n",
      "  [ 0.13801466]\n",
      "  [ 0.93950284]]])\n",
      "hidden_size = 1\n",
      "init_hidden = True\n",
      "num_layers = 2\n",
      "output_size = 1\n",
      "seq_length = 13\n",
      "seq_model  = 'rnn'\n",
      "x          = array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0...0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "      dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:201: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "self = <models.LanguageModel object at 0x1574eb290>, embedding_size = 34\n",
      "output_size = 1, hidden_size = 1, num_layers = 2, seq_model = 'rnn'\n",
      "device = cpu(), dtype = 'float32'\n",
      "\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92m__init__\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, embedding_size, output_size, hidden_size, num_layers=\u001b[94m1\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                 seq_model=\u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, device=\u001b[94mNone\u001b[39;49;00m, dtype=\u001b[33m\"\u001b[39;49;00m\u001b[33mfloat32\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"\u001b[39;49;00m\n",
      "    \u001b[33m    Consists of an embedding layer, a sequence model (either RNN or LSTM), and a\u001b[39;49;00m\n",
      "    \u001b[33m    linear layer.\u001b[39;49;00m\n",
      "    \u001b[33m    Parameters:\u001b[39;49;00m\n",
      "    \u001b[33m    output_size: Size of dictionary\u001b[39;49;00m\n",
      "    \u001b[33m    embedding_size: Size of embeddings\u001b[39;49;00m\n",
      "    \u001b[33m    hidden_size: The number of features in the hidden state of LSTM or RNN\u001b[39;49;00m\n",
      "    \u001b[33m    seq_model: 'rnn' or 'lstm', whether to use RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    num_layers: Number of layers in RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    \"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[96msuper\u001b[39;49;00m(LanguageModel, \u001b[96mself\u001b[39;49;00m).\u001b[92m__init__\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m### BEGIN YOUR SOLUTION\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94mraise\u001b[39;49;00m \u001b[96mNotImplementedError\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       NotImplementedError\u001b[0m\n",
      "\n",
      "__class__  = <class 'models.LanguageModel'>\n",
      "device     = cpu()\n",
      "dtype      = 'float32'\n",
      "embedding_size = 34\n",
      "hidden_size = 1\n",
      "num_layers = 2\n",
      "output_size = 1\n",
      "self       = <models.LanguageModel object at 0x1574eb290>\n",
      "seq_model  = 'rnn'\n",
      "\n",
      "\u001b[1m\u001b[31mapps/models.py\u001b[0m:38: NotImplementedError\n",
      "\u001b[31m\u001b[1m________ test_language_model_implementation[cpu-rnn-1-True-12-1-1-1-1] _________\u001b[0m\n",
      "\n",
      "seq_length = 1, num_layers = 1, batch_size = 1, embedding_size = 1\n",
      "hidden_size = 12, init_hidden = True, output_size = 1, seq_model = 'rnn'\n",
      "device = cpu()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\u001b[90m\u001b[39;49;00m\n",
      "                            init_hidden, output_size, seq_model, device):\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      ">       model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "batch_size = 1\n",
      "c0         = needle.Tensor([[[ 2.0463328   0.66698784  0.07909219 -0.96476346  0.08905337\n",
      "    0.7788969   1.2646449  -0.88051134  0.2364056   0.81560445\n",
      "    1.8608117   0.2555905 ]]])\n",
      "device     = cpu()\n",
      "embedding_size = 1\n",
      "h0         = needle.Tensor([[[-1.2862294  -1.1437218  -0.36917776  0.3805976  -0.6264145\n",
      "   -0.49204388 -0.04184423 -0.27273554 -2.6765213  -0.43010062\n",
      "    0.08496406  1.0977795 ]]])\n",
      "hidden_size = 12\n",
      "init_hidden = True\n",
      "num_layers = 1\n",
      "output_size = 1\n",
      "seq_length = 1\n",
      "seq_model  = 'rnn'\n",
      "x          = array([[0.]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:201: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "self = <models.LanguageModel object at 0x1574badb0>, embedding_size = 1\n",
      "output_size = 1, hidden_size = 12, num_layers = 1, seq_model = 'rnn'\n",
      "device = cpu(), dtype = 'float32'\n",
      "\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92m__init__\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, embedding_size, output_size, hidden_size, num_layers=\u001b[94m1\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                 seq_model=\u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, device=\u001b[94mNone\u001b[39;49;00m, dtype=\u001b[33m\"\u001b[39;49;00m\u001b[33mfloat32\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"\u001b[39;49;00m\n",
      "    \u001b[33m    Consists of an embedding layer, a sequence model (either RNN or LSTM), and a\u001b[39;49;00m\n",
      "    \u001b[33m    linear layer.\u001b[39;49;00m\n",
      "    \u001b[33m    Parameters:\u001b[39;49;00m\n",
      "    \u001b[33m    output_size: Size of dictionary\u001b[39;49;00m\n",
      "    \u001b[33m    embedding_size: Size of embeddings\u001b[39;49;00m\n",
      "    \u001b[33m    hidden_size: The number of features in the hidden state of LSTM or RNN\u001b[39;49;00m\n",
      "    \u001b[33m    seq_model: 'rnn' or 'lstm', whether to use RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    num_layers: Number of layers in RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    \"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[96msuper\u001b[39;49;00m(LanguageModel, \u001b[96mself\u001b[39;49;00m).\u001b[92m__init__\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m### BEGIN YOUR SOLUTION\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94mraise\u001b[39;49;00m \u001b[96mNotImplementedError\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       NotImplementedError\u001b[0m\n",
      "\n",
      "__class__  = <class 'models.LanguageModel'>\n",
      "device     = cpu()\n",
      "dtype      = 'float32'\n",
      "embedding_size = 1\n",
      "hidden_size = 12\n",
      "num_layers = 1\n",
      "output_size = 1\n",
      "self       = <models.LanguageModel object at 0x1574badb0>\n",
      "seq_model  = 'rnn'\n",
      "\n",
      "\u001b[1m\u001b[31mapps/models.py\u001b[0m:38: NotImplementedError\n",
      "\u001b[31m\u001b[1m________ test_language_model_implementation[cpu-rnn-1-True-12-1-1-1-13] ________\u001b[0m\n",
      "\n",
      "seq_length = 13, num_layers = 1, batch_size = 1, embedding_size = 1\n",
      "hidden_size = 12, init_hidden = True, output_size = 1, seq_model = 'rnn'\n",
      "device = cpu()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\u001b[90m\u001b[39;49;00m\n",
      "                            init_hidden, output_size, seq_model, device):\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      ">       model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "batch_size = 1\n",
      "c0         = needle.Tensor([[[ 1.2249857  -0.02973531 -1.8648058  -0.252816   -0.7128498\n",
      "   -1.5089171  -0.7903657   0.9606248   1.6809107  -0.48900604\n",
      "    1.0025358   1.1782221 ]]])\n",
      "device     = cpu()\n",
      "embedding_size = 1\n",
      "h0         = needle.Tensor([[[-0.5415037  -0.68959963 -0.35744074 -0.6519202   0.8265358\n",
      "    1.0693058   0.7248568   1.1921862  -0.45376855  0.38033506\n",
      "   -0.38466316  0.04365869]]])\n",
      "hidden_size = 12\n",
      "init_hidden = True\n",
      "num_layers = 1\n",
      "output_size = 1\n",
      "seq_length = 13\n",
      "seq_model  = 'rnn'\n",
      "x          = array([[0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:201: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "self = <models.LanguageModel object at 0x1574b8290>, embedding_size = 1\n",
      "output_size = 1, hidden_size = 12, num_layers = 1, seq_model = 'rnn'\n",
      "device = cpu(), dtype = 'float32'\n",
      "\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92m__init__\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, embedding_size, output_size, hidden_size, num_layers=\u001b[94m1\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                 seq_model=\u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, device=\u001b[94mNone\u001b[39;49;00m, dtype=\u001b[33m\"\u001b[39;49;00m\u001b[33mfloat32\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"\u001b[39;49;00m\n",
      "    \u001b[33m    Consists of an embedding layer, a sequence model (either RNN or LSTM), and a\u001b[39;49;00m\n",
      "    \u001b[33m    linear layer.\u001b[39;49;00m\n",
      "    \u001b[33m    Parameters:\u001b[39;49;00m\n",
      "    \u001b[33m    output_size: Size of dictionary\u001b[39;49;00m\n",
      "    \u001b[33m    embedding_size: Size of embeddings\u001b[39;49;00m\n",
      "    \u001b[33m    hidden_size: The number of features in the hidden state of LSTM or RNN\u001b[39;49;00m\n",
      "    \u001b[33m    seq_model: 'rnn' or 'lstm', whether to use RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    num_layers: Number of layers in RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    \"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[96msuper\u001b[39;49;00m(LanguageModel, \u001b[96mself\u001b[39;49;00m).\u001b[92m__init__\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m### BEGIN YOUR SOLUTION\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94mraise\u001b[39;49;00m \u001b[96mNotImplementedError\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       NotImplementedError\u001b[0m\n",
      "\n",
      "__class__  = <class 'models.LanguageModel'>\n",
      "device     = cpu()\n",
      "dtype      = 'float32'\n",
      "embedding_size = 1\n",
      "hidden_size = 12\n",
      "num_layers = 1\n",
      "output_size = 1\n",
      "self       = <models.LanguageModel object at 0x1574b8290>\n",
      "seq_model  = 'rnn'\n",
      "\n",
      "\u001b[1m\u001b[31mapps/models.py\u001b[0m:38: NotImplementedError\n",
      "\u001b[31m\u001b[1m________ test_language_model_implementation[cpu-rnn-1-True-12-1-1-2-1] _________\u001b[0m\n",
      "\n",
      "seq_length = 1, num_layers = 2, batch_size = 1, embedding_size = 1\n",
      "hidden_size = 12, init_hidden = True, output_size = 1, seq_model = 'rnn'\n",
      "device = cpu()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\u001b[90m\u001b[39;49;00m\n",
      "                            init_hidden, output_size, seq_model, device):\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      ">       model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "batch_size = 1\n",
      "c0         = needle.Tensor([[[-0.40834525 -0.63713485 -0.5395746  -1.4654721  -0.55320716\n",
      "    1.8608776  -0.90828395  0.0084189  -1...97 -0.7842054  -0.9148222\n",
      "   -0.8971398   0.32594928  0.5967932   0.4882425  -0.16943686\n",
      "   -1.3580452  -0.06711047]]])\n",
      "device     = cpu()\n",
      "embedding_size = 1\n",
      "h0         = needle.Tensor([[[-1.1597923  -0.03936271 -0.04446017  0.17238568 -1.5937508\n",
      "   -0.34914225  1.0578212   1.2622032   1....2  0.5190763  -0.10252395\n",
      "    1.2082386   0.25656015 -0.282505    0.96496576  0.25622177\n",
      "   -0.4129564   1.2772744 ]]])\n",
      "hidden_size = 12\n",
      "init_hidden = True\n",
      "num_layers = 2\n",
      "output_size = 1\n",
      "seq_length = 1\n",
      "seq_model  = 'rnn'\n",
      "x          = array([[0.]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:201: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "self = <models.LanguageModel object at 0x15748f860>, embedding_size = 1\n",
      "output_size = 1, hidden_size = 12, num_layers = 2, seq_model = 'rnn'\n",
      "device = cpu(), dtype = 'float32'\n",
      "\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92m__init__\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, embedding_size, output_size, hidden_size, num_layers=\u001b[94m1\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                 seq_model=\u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, device=\u001b[94mNone\u001b[39;49;00m, dtype=\u001b[33m\"\u001b[39;49;00m\u001b[33mfloat32\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"\u001b[39;49;00m\n",
      "    \u001b[33m    Consists of an embedding layer, a sequence model (either RNN or LSTM), and a\u001b[39;49;00m\n",
      "    \u001b[33m    linear layer.\u001b[39;49;00m\n",
      "    \u001b[33m    Parameters:\u001b[39;49;00m\n",
      "    \u001b[33m    output_size: Size of dictionary\u001b[39;49;00m\n",
      "    \u001b[33m    embedding_size: Size of embeddings\u001b[39;49;00m\n",
      "    \u001b[33m    hidden_size: The number of features in the hidden state of LSTM or RNN\u001b[39;49;00m\n",
      "    \u001b[33m    seq_model: 'rnn' or 'lstm', whether to use RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    num_layers: Number of layers in RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    \"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[96msuper\u001b[39;49;00m(LanguageModel, \u001b[96mself\u001b[39;49;00m).\u001b[92m__init__\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m### BEGIN YOUR SOLUTION\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94mraise\u001b[39;49;00m \u001b[96mNotImplementedError\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       NotImplementedError\u001b[0m\n",
      "\n",
      "__class__  = <class 'models.LanguageModel'>\n",
      "device     = cpu()\n",
      "dtype      = 'float32'\n",
      "embedding_size = 1\n",
      "hidden_size = 12\n",
      "num_layers = 2\n",
      "output_size = 1\n",
      "self       = <models.LanguageModel object at 0x15748f860>\n",
      "seq_model  = 'rnn'\n",
      "\n",
      "\u001b[1m\u001b[31mapps/models.py\u001b[0m:38: NotImplementedError\n",
      "\u001b[31m\u001b[1m________ test_language_model_implementation[cpu-rnn-1-True-12-1-1-2-13] ________\u001b[0m\n",
      "\n",
      "seq_length = 13, num_layers = 2, batch_size = 1, embedding_size = 1\n",
      "hidden_size = 12, init_hidden = True, output_size = 1, seq_model = 'rnn'\n",
      "device = cpu()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\u001b[90m\u001b[39;49;00m\n",
      "                            init_hidden, output_size, seq_model, device):\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      ">       model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "batch_size = 1\n",
      "c0         = needle.Tensor([[[ 0.43623212  0.88792574 -0.8238861   0.78636295 -0.29403326\n",
      "   -0.68785954 -0.22404361 -1.0046086  -0...4  -0.6872418   0.26412648\n",
      "    0.00881292 -0.83009565  1.0128123  -1.7457235  -1.2586466\n",
      "    0.1272951   2.1937633 ]]])\n",
      "device     = cpu()\n",
      "embedding_size = 1\n",
      "h0         = needle.Tensor([[[-0.92429376  0.8813011   0.5564429   0.74689156 -0.34836832\n",
      "   -1.8110192   0.9578964   1.2263213  -1...1   1.3716581   0.29453215\n",
      "   -0.65313816  0.879788   -1.9557672   1.8153064  -0.8162501\n",
      "    0.28598428 -0.39861616]]])\n",
      "hidden_size = 12\n",
      "init_hidden = True\n",
      "num_layers = 2\n",
      "output_size = 1\n",
      "seq_length = 13\n",
      "seq_model  = 'rnn'\n",
      "x          = array([[0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:201: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "self = <models.LanguageModel object at 0x15748ef90>, embedding_size = 1\n",
      "output_size = 1, hidden_size = 12, num_layers = 2, seq_model = 'rnn'\n",
      "device = cpu(), dtype = 'float32'\n",
      "\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92m__init__\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, embedding_size, output_size, hidden_size, num_layers=\u001b[94m1\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                 seq_model=\u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, device=\u001b[94mNone\u001b[39;49;00m, dtype=\u001b[33m\"\u001b[39;49;00m\u001b[33mfloat32\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"\u001b[39;49;00m\n",
      "    \u001b[33m    Consists of an embedding layer, a sequence model (either RNN or LSTM), and a\u001b[39;49;00m\n",
      "    \u001b[33m    linear layer.\u001b[39;49;00m\n",
      "    \u001b[33m    Parameters:\u001b[39;49;00m\n",
      "    \u001b[33m    output_size: Size of dictionary\u001b[39;49;00m\n",
      "    \u001b[33m    embedding_size: Size of embeddings\u001b[39;49;00m\n",
      "    \u001b[33m    hidden_size: The number of features in the hidden state of LSTM or RNN\u001b[39;49;00m\n",
      "    \u001b[33m    seq_model: 'rnn' or 'lstm', whether to use RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    num_layers: Number of layers in RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    \"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[96msuper\u001b[39;49;00m(LanguageModel, \u001b[96mself\u001b[39;49;00m).\u001b[92m__init__\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m### BEGIN YOUR SOLUTION\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94mraise\u001b[39;49;00m \u001b[96mNotImplementedError\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       NotImplementedError\u001b[0m\n",
      "\n",
      "__class__  = <class 'models.LanguageModel'>\n",
      "device     = cpu()\n",
      "dtype      = 'float32'\n",
      "embedding_size = 1\n",
      "hidden_size = 12\n",
      "num_layers = 2\n",
      "output_size = 1\n",
      "self       = <models.LanguageModel object at 0x15748ef90>\n",
      "seq_model  = 'rnn'\n",
      "\n",
      "\u001b[1m\u001b[31mapps/models.py\u001b[0m:38: NotImplementedError\n",
      "\u001b[31m\u001b[1m________ test_language_model_implementation[cpu-rnn-1-True-12-1-15-1-1] ________\u001b[0m\n",
      "\n",
      "seq_length = 1, num_layers = 1, batch_size = 15, embedding_size = 1\n",
      "hidden_size = 12, init_hidden = True, output_size = 1, seq_model = 'rnn'\n",
      "device = cpu()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\u001b[90m\u001b[39;49;00m\n",
      "                            init_hidden, output_size, seq_model, device):\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      ">       model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "batch_size = 15\n",
      "c0         = needle.Tensor([[[ 0.14783688  0.17897291  0.03444142  1.0262051   0.4878529\n",
      "   -0.5781107   0.12862004 -0.07596464  0....2   1.416147    0.12744248\n",
      "    0.95277196 -0.95161724 -0.79090655  0.24086618 -0.8180217\n",
      "    0.5717032   1.3750514 ]]])\n",
      "device     = cpu()\n",
      "embedding_size = 1\n",
      "h0         = needle.Tensor([[[ 0.41393414 -1.0052396   0.59265715  0.6833966   0.9378569\n",
      "   -0.40986454 -0.7997264   0.11821728  0....   0.6808841  -0.58784354\n",
      "   -0.8690319  -1.5063628  -0.10779898  1.0009477  -0.14793289\n",
      "    0.8822197   0.1754264 ]]])\n",
      "hidden_size = 12\n",
      "init_hidden = True\n",
      "num_layers = 1\n",
      "output_size = 1\n",
      "seq_length = 1\n",
      "seq_model  = 'rnn'\n",
      "x          = array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "      dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:201: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "self = <models.LanguageModel object at 0x1574eb8f0>, embedding_size = 1\n",
      "output_size = 1, hidden_size = 12, num_layers = 1, seq_model = 'rnn'\n",
      "device = cpu(), dtype = 'float32'\n",
      "\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92m__init__\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, embedding_size, output_size, hidden_size, num_layers=\u001b[94m1\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                 seq_model=\u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, device=\u001b[94mNone\u001b[39;49;00m, dtype=\u001b[33m\"\u001b[39;49;00m\u001b[33mfloat32\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"\u001b[39;49;00m\n",
      "    \u001b[33m    Consists of an embedding layer, a sequence model (either RNN or LSTM), and a\u001b[39;49;00m\n",
      "    \u001b[33m    linear layer.\u001b[39;49;00m\n",
      "    \u001b[33m    Parameters:\u001b[39;49;00m\n",
      "    \u001b[33m    output_size: Size of dictionary\u001b[39;49;00m\n",
      "    \u001b[33m    embedding_size: Size of embeddings\u001b[39;49;00m\n",
      "    \u001b[33m    hidden_size: The number of features in the hidden state of LSTM or RNN\u001b[39;49;00m\n",
      "    \u001b[33m    seq_model: 'rnn' or 'lstm', whether to use RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    num_layers: Number of layers in RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    \"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[96msuper\u001b[39;49;00m(LanguageModel, \u001b[96mself\u001b[39;49;00m).\u001b[92m__init__\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m### BEGIN YOUR SOLUTION\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94mraise\u001b[39;49;00m \u001b[96mNotImplementedError\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       NotImplementedError\u001b[0m\n",
      "\n",
      "__class__  = <class 'models.LanguageModel'>\n",
      "device     = cpu()\n",
      "dtype      = 'float32'\n",
      "embedding_size = 1\n",
      "hidden_size = 12\n",
      "num_layers = 1\n",
      "output_size = 1\n",
      "self       = <models.LanguageModel object at 0x1574eb8f0>\n",
      "seq_model  = 'rnn'\n",
      "\n",
      "\u001b[1m\u001b[31mapps/models.py\u001b[0m:38: NotImplementedError\n",
      "\u001b[31m\u001b[1m_______ test_language_model_implementation[cpu-rnn-1-True-12-1-15-1-13] ________\u001b[0m\n",
      "\n",
      "seq_length = 13, num_layers = 1, batch_size = 15, embedding_size = 1\n",
      "hidden_size = 12, init_hidden = True, output_size = 1, seq_model = 'rnn'\n",
      "device = cpu()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\u001b[90m\u001b[39;49;00m\n",
      "                            init_hidden, output_size, seq_model, device):\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      ">       model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "batch_size = 15\n",
      "c0         = needle.Tensor([[[-5.74731886e-01  1.33674514e+00 -6.74315244e-02  5.50874054e-01\n",
      "   -1.52097416e+00 -1.51930261e+00  5...  5.98948419e-01  1.77085412e+00  7.07832396e-01\n",
      "   -1.60486805e+00 -4.29420739e-01  1.42457891e+00  1.02739632e-01]]])\n",
      "device     = cpu()\n",
      "embedding_size = 1\n",
      "h0         = needle.Tensor([[[ 0.40353626 -0.7374315  -0.74847585  1.3653665  -0.7981358\n",
      "    0.08931731 -0.25889486  0.05302142  1....7813  0.91326797 -1.2870084\n",
      "    0.95644027 -3.027048   -0.91117555 -1.5898144   1.013753\n",
      "    0.2685242  -1.3121505 ]]])\n",
      "hidden_size = 12\n",
      "init_hidden = True\n",
      "num_layers = 1\n",
      "output_size = 1\n",
      "seq_length = 13\n",
      "seq_model  = 'rnn'\n",
      "x          = array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0...0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "      dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:201: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "self = <models.LanguageModel object at 0x1574eb350>, embedding_size = 1\n",
      "output_size = 1, hidden_size = 12, num_layers = 1, seq_model = 'rnn'\n",
      "device = cpu(), dtype = 'float32'\n",
      "\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92m__init__\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, embedding_size, output_size, hidden_size, num_layers=\u001b[94m1\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                 seq_model=\u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, device=\u001b[94mNone\u001b[39;49;00m, dtype=\u001b[33m\"\u001b[39;49;00m\u001b[33mfloat32\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"\u001b[39;49;00m\n",
      "    \u001b[33m    Consists of an embedding layer, a sequence model (either RNN or LSTM), and a\u001b[39;49;00m\n",
      "    \u001b[33m    linear layer.\u001b[39;49;00m\n",
      "    \u001b[33m    Parameters:\u001b[39;49;00m\n",
      "    \u001b[33m    output_size: Size of dictionary\u001b[39;49;00m\n",
      "    \u001b[33m    embedding_size: Size of embeddings\u001b[39;49;00m\n",
      "    \u001b[33m    hidden_size: The number of features in the hidden state of LSTM or RNN\u001b[39;49;00m\n",
      "    \u001b[33m    seq_model: 'rnn' or 'lstm', whether to use RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    num_layers: Number of layers in RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    \"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[96msuper\u001b[39;49;00m(LanguageModel, \u001b[96mself\u001b[39;49;00m).\u001b[92m__init__\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m### BEGIN YOUR SOLUTION\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94mraise\u001b[39;49;00m \u001b[96mNotImplementedError\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       NotImplementedError\u001b[0m\n",
      "\n",
      "__class__  = <class 'models.LanguageModel'>\n",
      "device     = cpu()\n",
      "dtype      = 'float32'\n",
      "embedding_size = 1\n",
      "hidden_size = 12\n",
      "num_layers = 1\n",
      "output_size = 1\n",
      "self       = <models.LanguageModel object at 0x1574eb350>\n",
      "seq_model  = 'rnn'\n",
      "\n",
      "\u001b[1m\u001b[31mapps/models.py\u001b[0m:38: NotImplementedError\n",
      "\u001b[31m\u001b[1m________ test_language_model_implementation[cpu-rnn-1-True-12-1-15-2-1] ________\u001b[0m\n",
      "\n",
      "seq_length = 1, num_layers = 2, batch_size = 15, embedding_size = 1\n",
      "hidden_size = 12, init_hidden = True, output_size = 1, seq_model = 'rnn'\n",
      "device = cpu()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\u001b[90m\u001b[39;49;00m\n",
      "                            init_hidden, output_size, seq_model, device):\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      ">       model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "batch_size = 15\n",
      "c0         = needle.Tensor([[[ 0.7374499   0.42549318 -1.1435869   1.6048503   1.2753828\n",
      "   -0.96096957  0.62793654  0.52593637 -0....5   0.6550992   1.4522525\n",
      "   -1.2037795  -2.0865777  -0.00881964 -0.09005287  0.81863153\n",
      "   -0.75460845  0.06351615]]])\n",
      "device     = cpu()\n",
      "embedding_size = 1\n",
      "h0         = needle.Tensor([[[ 1.6898173  -0.8045091  -0.63712156 -1.4309417  -0.46408877\n",
      "    1.1779947  -1.010014    0.7552366   0...31    0.66353494 -1.9224838\n",
      "    0.5288945   0.78240556 -1.5534164   0.89099205 -1.091646\n",
      "    1.0347095   0.04426667]]])\n",
      "hidden_size = 12\n",
      "init_hidden = True\n",
      "num_layers = 2\n",
      "output_size = 1\n",
      "seq_length = 1\n",
      "seq_model  = 'rnn'\n",
      "x          = array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "      dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:201: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "self = <models.LanguageModel object at 0x1575e3230>, embedding_size = 1\n",
      "output_size = 1, hidden_size = 12, num_layers = 2, seq_model = 'rnn'\n",
      "device = cpu(), dtype = 'float32'\n",
      "\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92m__init__\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, embedding_size, output_size, hidden_size, num_layers=\u001b[94m1\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                 seq_model=\u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, device=\u001b[94mNone\u001b[39;49;00m, dtype=\u001b[33m\"\u001b[39;49;00m\u001b[33mfloat32\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"\u001b[39;49;00m\n",
      "    \u001b[33m    Consists of an embedding layer, a sequence model (either RNN or LSTM), and a\u001b[39;49;00m\n",
      "    \u001b[33m    linear layer.\u001b[39;49;00m\n",
      "    \u001b[33m    Parameters:\u001b[39;49;00m\n",
      "    \u001b[33m    output_size: Size of dictionary\u001b[39;49;00m\n",
      "    \u001b[33m    embedding_size: Size of embeddings\u001b[39;49;00m\n",
      "    \u001b[33m    hidden_size: The number of features in the hidden state of LSTM or RNN\u001b[39;49;00m\n",
      "    \u001b[33m    seq_model: 'rnn' or 'lstm', whether to use RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    num_layers: Number of layers in RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    \"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[96msuper\u001b[39;49;00m(LanguageModel, \u001b[96mself\u001b[39;49;00m).\u001b[92m__init__\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m### BEGIN YOUR SOLUTION\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94mraise\u001b[39;49;00m \u001b[96mNotImplementedError\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       NotImplementedError\u001b[0m\n",
      "\n",
      "__class__  = <class 'models.LanguageModel'>\n",
      "device     = cpu()\n",
      "dtype      = 'float32'\n",
      "embedding_size = 1\n",
      "hidden_size = 12\n",
      "num_layers = 2\n",
      "output_size = 1\n",
      "self       = <models.LanguageModel object at 0x1575e3230>\n",
      "seq_model  = 'rnn'\n",
      "\n",
      "\u001b[1m\u001b[31mapps/models.py\u001b[0m:38: NotImplementedError\n",
      "\u001b[31m\u001b[1m_______ test_language_model_implementation[cpu-rnn-1-True-12-1-15-2-13] ________\u001b[0m\n",
      "\n",
      "seq_length = 13, num_layers = 2, batch_size = 15, embedding_size = 1\n",
      "hidden_size = 12, init_hidden = True, output_size = 1, seq_model = 'rnn'\n",
      "device = cpu()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\u001b[90m\u001b[39;49;00m\n",
      "                            init_hidden, output_size, seq_model, device):\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      ">       model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "batch_size = 15\n",
      "c0         = needle.Tensor([[[ 5.28949797e-01 -1.28822541e+00  2.53058267e+00  2.03306818e+00\n",
      "   -6.77316308e-01 -1.28454828e+00 -6... -4.53442395e-01 -9.81256604e-01  1.66769278e+00\n",
      "    1.22863209e+00  3.21657434e-02 -1.47215784e+00  1.95295721e-01]]])\n",
      "device     = cpu()\n",
      "embedding_size = 1\n",
      "h0         = needle.Tensor([[[-1.9021302  -1.2813807  -0.5920339  -0.49041998  0.48591456\n",
      "    1.177145   -1.466795    1.6390375  -0...4  0.27560294  0.18459094\n",
      "    2.202889   -0.6018994   0.6821991  -0.5181914  -0.44450006\n",
      "    1.0604218   0.42230165]]])\n",
      "hidden_size = 12\n",
      "init_hidden = True\n",
      "num_layers = 2\n",
      "output_size = 1\n",
      "seq_length = 13\n",
      "seq_model  = 'rnn'\n",
      "x          = array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0...0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "      dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:201: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "self = <models.LanguageModel object at 0x1575e0470>, embedding_size = 1\n",
      "output_size = 1, hidden_size = 12, num_layers = 2, seq_model = 'rnn'\n",
      "device = cpu(), dtype = 'float32'\n",
      "\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92m__init__\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, embedding_size, output_size, hidden_size, num_layers=\u001b[94m1\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                 seq_model=\u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, device=\u001b[94mNone\u001b[39;49;00m, dtype=\u001b[33m\"\u001b[39;49;00m\u001b[33mfloat32\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"\u001b[39;49;00m\n",
      "    \u001b[33m    Consists of an embedding layer, a sequence model (either RNN or LSTM), and a\u001b[39;49;00m\n",
      "    \u001b[33m    linear layer.\u001b[39;49;00m\n",
      "    \u001b[33m    Parameters:\u001b[39;49;00m\n",
      "    \u001b[33m    output_size: Size of dictionary\u001b[39;49;00m\n",
      "    \u001b[33m    embedding_size: Size of embeddings\u001b[39;49;00m\n",
      "    \u001b[33m    hidden_size: The number of features in the hidden state of LSTM or RNN\u001b[39;49;00m\n",
      "    \u001b[33m    seq_model: 'rnn' or 'lstm', whether to use RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    num_layers: Number of layers in RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    \"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[96msuper\u001b[39;49;00m(LanguageModel, \u001b[96mself\u001b[39;49;00m).\u001b[92m__init__\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m### BEGIN YOUR SOLUTION\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94mraise\u001b[39;49;00m \u001b[96mNotImplementedError\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       NotImplementedError\u001b[0m\n",
      "\n",
      "__class__  = <class 'models.LanguageModel'>\n",
      "device     = cpu()\n",
      "dtype      = 'float32'\n",
      "embedding_size = 1\n",
      "hidden_size = 12\n",
      "num_layers = 2\n",
      "output_size = 1\n",
      "self       = <models.LanguageModel object at 0x1575e0470>\n",
      "seq_model  = 'rnn'\n",
      "\n",
      "\u001b[1m\u001b[31mapps/models.py\u001b[0m:38: NotImplementedError\n",
      "\u001b[31m\u001b[1m________ test_language_model_implementation[cpu-rnn-1-True-12-34-1-1-1] ________\u001b[0m\n",
      "\n",
      "seq_length = 1, num_layers = 1, batch_size = 1, embedding_size = 34\n",
      "hidden_size = 12, init_hidden = True, output_size = 1, seq_model = 'rnn'\n",
      "device = cpu()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\u001b[90m\u001b[39;49;00m\n",
      "                            init_hidden, output_size, seq_model, device):\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      ">       model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "batch_size = 1\n",
      "c0         = needle.Tensor([[[ 1.0293834   0.8662794   0.01850934 -1.3245106   1.0551435\n",
      "   -0.5167841   0.16988657 -1.9219451  -0.27869958  0.3920085\n",
      "   -0.4536452   0.49369428]]])\n",
      "device     = cpu()\n",
      "embedding_size = 34\n",
      "h0         = needle.Tensor([[[ 0.37514427 -0.70561165 -1.6739657   1.6436132  -1.4521563\n",
      "    0.9447397  -0.7722078  -0.5006571   0.87423366 -1.2331978\n",
      "   -0.44206595 -0.1709349 ]]])\n",
      "hidden_size = 12\n",
      "init_hidden = True\n",
      "num_layers = 1\n",
      "output_size = 1\n",
      "seq_length = 1\n",
      "seq_model  = 'rnn'\n",
      "x          = array([[0.]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:201: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "self = <models.LanguageModel object at 0x1575e2750>, embedding_size = 34\n",
      "output_size = 1, hidden_size = 12, num_layers = 1, seq_model = 'rnn'\n",
      "device = cpu(), dtype = 'float32'\n",
      "\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92m__init__\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, embedding_size, output_size, hidden_size, num_layers=\u001b[94m1\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                 seq_model=\u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, device=\u001b[94mNone\u001b[39;49;00m, dtype=\u001b[33m\"\u001b[39;49;00m\u001b[33mfloat32\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"\u001b[39;49;00m\n",
      "    \u001b[33m    Consists of an embedding layer, a sequence model (either RNN or LSTM), and a\u001b[39;49;00m\n",
      "    \u001b[33m    linear layer.\u001b[39;49;00m\n",
      "    \u001b[33m    Parameters:\u001b[39;49;00m\n",
      "    \u001b[33m    output_size: Size of dictionary\u001b[39;49;00m\n",
      "    \u001b[33m    embedding_size: Size of embeddings\u001b[39;49;00m\n",
      "    \u001b[33m    hidden_size: The number of features in the hidden state of LSTM or RNN\u001b[39;49;00m\n",
      "    \u001b[33m    seq_model: 'rnn' or 'lstm', whether to use RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    num_layers: Number of layers in RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    \"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[96msuper\u001b[39;49;00m(LanguageModel, \u001b[96mself\u001b[39;49;00m).\u001b[92m__init__\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m### BEGIN YOUR SOLUTION\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94mraise\u001b[39;49;00m \u001b[96mNotImplementedError\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       NotImplementedError\u001b[0m\n",
      "\n",
      "__class__  = <class 'models.LanguageModel'>\n",
      "device     = cpu()\n",
      "dtype      = 'float32'\n",
      "embedding_size = 34\n",
      "hidden_size = 12\n",
      "num_layers = 1\n",
      "output_size = 1\n",
      "self       = <models.LanguageModel object at 0x1575e2750>\n",
      "seq_model  = 'rnn'\n",
      "\n",
      "\u001b[1m\u001b[31mapps/models.py\u001b[0m:38: NotImplementedError\n",
      "\u001b[31m\u001b[1m_______ test_language_model_implementation[cpu-rnn-1-True-12-34-1-1-13] ________\u001b[0m\n",
      "\n",
      "seq_length = 13, num_layers = 1, batch_size = 1, embedding_size = 34\n",
      "hidden_size = 12, init_hidden = True, output_size = 1, seq_model = 'rnn'\n",
      "device = cpu()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\u001b[90m\u001b[39;49;00m\n",
      "                            init_hidden, output_size, seq_model, device):\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      ">       model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "batch_size = 1\n",
      "c0         = needle.Tensor([[[ 0.15376581  0.44576818  0.43214673 -0.13530773  0.4820964\n",
      "    0.3875652  -0.4637615  -0.04378014 -1.4128344   0.61905223\n",
      "   -1.405655   -0.31640366]]])\n",
      "device     = cpu()\n",
      "embedding_size = 34\n",
      "h0         = needle.Tensor([[[ 1.165324    1.446208   -0.6459513  -1.6009898  -2.5100114\n",
      "   -0.4247561  -1.7005317   0.34715304 -2.1665516   0.9397284\n",
      "   -0.06049846 -1.6820211 ]]])\n",
      "hidden_size = 12\n",
      "init_hidden = True\n",
      "num_layers = 1\n",
      "output_size = 1\n",
      "seq_length = 13\n",
      "seq_model  = 'rnn'\n",
      "x          = array([[0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:201: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "self = <models.LanguageModel object at 0x1575e1970>, embedding_size = 34\n",
      "output_size = 1, hidden_size = 12, num_layers = 1, seq_model = 'rnn'\n",
      "device = cpu(), dtype = 'float32'\n",
      "\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92m__init__\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, embedding_size, output_size, hidden_size, num_layers=\u001b[94m1\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                 seq_model=\u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, device=\u001b[94mNone\u001b[39;49;00m, dtype=\u001b[33m\"\u001b[39;49;00m\u001b[33mfloat32\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"\u001b[39;49;00m\n",
      "    \u001b[33m    Consists of an embedding layer, a sequence model (either RNN or LSTM), and a\u001b[39;49;00m\n",
      "    \u001b[33m    linear layer.\u001b[39;49;00m\n",
      "    \u001b[33m    Parameters:\u001b[39;49;00m\n",
      "    \u001b[33m    output_size: Size of dictionary\u001b[39;49;00m\n",
      "    \u001b[33m    embedding_size: Size of embeddings\u001b[39;49;00m\n",
      "    \u001b[33m    hidden_size: The number of features in the hidden state of LSTM or RNN\u001b[39;49;00m\n",
      "    \u001b[33m    seq_model: 'rnn' or 'lstm', whether to use RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    num_layers: Number of layers in RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    \"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[96msuper\u001b[39;49;00m(LanguageModel, \u001b[96mself\u001b[39;49;00m).\u001b[92m__init__\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m### BEGIN YOUR SOLUTION\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94mraise\u001b[39;49;00m \u001b[96mNotImplementedError\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       NotImplementedError\u001b[0m\n",
      "\n",
      "__class__  = <class 'models.LanguageModel'>\n",
      "device     = cpu()\n",
      "dtype      = 'float32'\n",
      "embedding_size = 34\n",
      "hidden_size = 12\n",
      "num_layers = 1\n",
      "output_size = 1\n",
      "self       = <models.LanguageModel object at 0x1575e1970>\n",
      "seq_model  = 'rnn'\n",
      "\n",
      "\u001b[1m\u001b[31mapps/models.py\u001b[0m:38: NotImplementedError\n",
      "\u001b[31m\u001b[1m________ test_language_model_implementation[cpu-rnn-1-True-12-34-1-2-1] ________\u001b[0m\n",
      "\n",
      "seq_length = 1, num_layers = 2, batch_size = 1, embedding_size = 34\n",
      "hidden_size = 12, init_hidden = True, output_size = 1, seq_model = 'rnn'\n",
      "device = cpu()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\u001b[90m\u001b[39;49;00m\n",
      "                            init_hidden, output_size, seq_model, device):\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      ">       model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "batch_size = 1\n",
      "c0         = needle.Tensor([[[-0.76022667  0.77567685 -0.8374309   1.091132    1.2177745\n",
      "   -0.48615763  0.52667665  0.6699342  -0....7   0.8050818   0.47250122\n",
      "    0.6769637  -0.33459687  1.7193402  -0.78273064  0.7830858\n",
      "   -0.12340231 -0.23969215]]])\n",
      "device     = cpu()\n",
      "embedding_size = 34\n",
      "h0         = needle.Tensor([[[-1.2915709   0.782917    0.01962539 -1.1639514   0.11161879\n",
      "   -0.3650915   0.495774   -0.11833587 -0...55  0.97943413  0.7325072\n",
      "    1.116953    0.74262476 -0.53690535  2.0136156  -0.04043855\n",
      "   -0.6666789   1.3491971 ]]])\n",
      "hidden_size = 12\n",
      "init_hidden = True\n",
      "num_layers = 2\n",
      "output_size = 1\n",
      "seq_length = 1\n",
      "seq_model  = 'rnn'\n",
      "x          = array([[0.]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:201: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "self = <models.LanguageModel object at 0x15748cfb0>, embedding_size = 34\n",
      "output_size = 1, hidden_size = 12, num_layers = 2, seq_model = 'rnn'\n",
      "device = cpu(), dtype = 'float32'\n",
      "\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92m__init__\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, embedding_size, output_size, hidden_size, num_layers=\u001b[94m1\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                 seq_model=\u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, device=\u001b[94mNone\u001b[39;49;00m, dtype=\u001b[33m\"\u001b[39;49;00m\u001b[33mfloat32\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"\u001b[39;49;00m\n",
      "    \u001b[33m    Consists of an embedding layer, a sequence model (either RNN or LSTM), and a\u001b[39;49;00m\n",
      "    \u001b[33m    linear layer.\u001b[39;49;00m\n",
      "    \u001b[33m    Parameters:\u001b[39;49;00m\n",
      "    \u001b[33m    output_size: Size of dictionary\u001b[39;49;00m\n",
      "    \u001b[33m    embedding_size: Size of embeddings\u001b[39;49;00m\n",
      "    \u001b[33m    hidden_size: The number of features in the hidden state of LSTM or RNN\u001b[39;49;00m\n",
      "    \u001b[33m    seq_model: 'rnn' or 'lstm', whether to use RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    num_layers: Number of layers in RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    \"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[96msuper\u001b[39;49;00m(LanguageModel, \u001b[96mself\u001b[39;49;00m).\u001b[92m__init__\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m### BEGIN YOUR SOLUTION\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94mraise\u001b[39;49;00m \u001b[96mNotImplementedError\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       NotImplementedError\u001b[0m\n",
      "\n",
      "__class__  = <class 'models.LanguageModel'>\n",
      "device     = cpu()\n",
      "dtype      = 'float32'\n",
      "embedding_size = 34\n",
      "hidden_size = 12\n",
      "num_layers = 2\n",
      "output_size = 1\n",
      "self       = <models.LanguageModel object at 0x15748cfb0>\n",
      "seq_model  = 'rnn'\n",
      "\n",
      "\u001b[1m\u001b[31mapps/models.py\u001b[0m:38: NotImplementedError\n",
      "\u001b[31m\u001b[1m_______ test_language_model_implementation[cpu-rnn-1-True-12-34-1-2-13] ________\u001b[0m\n",
      "\n",
      "seq_length = 13, num_layers = 2, batch_size = 1, embedding_size = 34\n",
      "hidden_size = 12, init_hidden = True, output_size = 1, seq_model = 'rnn'\n",
      "device = cpu()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\u001b[90m\u001b[39;49;00m\n",
      "                            init_hidden, output_size, seq_model, device):\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      ">       model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "batch_size = 1\n",
      "c0         = needle.Tensor([[[ 0.55209506 -0.6562093  -1.0117992  -1.1626717  -0.88522863\n",
      "   -0.41438302  0.8526422   0.0237667  -0...4   0.60421467  0.04400238\n",
      "   -0.20509316 -0.9628545   0.42462835  2.1073213   0.5396769\n",
      "    0.55211544 -0.0928889 ]]])\n",
      "device     = cpu()\n",
      "embedding_size = 34\n",
      "h0         = needle.Tensor([[[ 2.0516927   0.57330114 -1.0559446   0.42630196 -0.3697205\n",
      "    1.8931679  -0.7226982   0.13680056 -0....724  0.60423565 -0.3135815\n",
      "    1.60188    -1.2811118   0.5105609  -1.1306317  -0.9002112\n",
      "   -1.4936928  -1.2175723 ]]])\n",
      "hidden_size = 12\n",
      "init_hidden = True\n",
      "num_layers = 2\n",
      "output_size = 1\n",
      "seq_length = 13\n",
      "seq_model  = 'rnn'\n",
      "x          = array([[0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:201: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "self = <models.LanguageModel object at 0x1574ba7e0>, embedding_size = 34\n",
      "output_size = 1, hidden_size = 12, num_layers = 2, seq_model = 'rnn'\n",
      "device = cpu(), dtype = 'float32'\n",
      "\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92m__init__\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, embedding_size, output_size, hidden_size, num_layers=\u001b[94m1\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                 seq_model=\u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, device=\u001b[94mNone\u001b[39;49;00m, dtype=\u001b[33m\"\u001b[39;49;00m\u001b[33mfloat32\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"\u001b[39;49;00m\n",
      "    \u001b[33m    Consists of an embedding layer, a sequence model (either RNN or LSTM), and a\u001b[39;49;00m\n",
      "    \u001b[33m    linear layer.\u001b[39;49;00m\n",
      "    \u001b[33m    Parameters:\u001b[39;49;00m\n",
      "    \u001b[33m    output_size: Size of dictionary\u001b[39;49;00m\n",
      "    \u001b[33m    embedding_size: Size of embeddings\u001b[39;49;00m\n",
      "    \u001b[33m    hidden_size: The number of features in the hidden state of LSTM or RNN\u001b[39;49;00m\n",
      "    \u001b[33m    seq_model: 'rnn' or 'lstm', whether to use RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    num_layers: Number of layers in RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    \"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[96msuper\u001b[39;49;00m(LanguageModel, \u001b[96mself\u001b[39;49;00m).\u001b[92m__init__\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m### BEGIN YOUR SOLUTION\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94mraise\u001b[39;49;00m \u001b[96mNotImplementedError\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       NotImplementedError\u001b[0m\n",
      "\n",
      "__class__  = <class 'models.LanguageModel'>\n",
      "device     = cpu()\n",
      "dtype      = 'float32'\n",
      "embedding_size = 34\n",
      "hidden_size = 12\n",
      "num_layers = 2\n",
      "output_size = 1\n",
      "self       = <models.LanguageModel object at 0x1574ba7e0>\n",
      "seq_model  = 'rnn'\n",
      "\n",
      "\u001b[1m\u001b[31mapps/models.py\u001b[0m:38: NotImplementedError\n",
      "\u001b[31m\u001b[1m_______ test_language_model_implementation[cpu-rnn-1-True-12-34-15-1-1] ________\u001b[0m\n",
      "\n",
      "seq_length = 1, num_layers = 1, batch_size = 15, embedding_size = 34\n",
      "hidden_size = 12, init_hidden = True, output_size = 1, seq_model = 'rnn'\n",
      "device = cpu()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\u001b[90m\u001b[39;49;00m\n",
      "                            init_hidden, output_size, seq_model, device):\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      ">       model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "batch_size = 15\n",
      "c0         = needle.Tensor([[[-0.05958214  0.9065367   0.2953639   0.12978919 -1.0011557\n",
      "   -0.9822504   0.6183368  -0.30966356  0....7312  0.61556464  1.891517\n",
      "    1.1093436   0.8131509   0.08620781 -1.9945866  -2.4438584\n",
      "   -0.97247624  2.2280502 ]]])\n",
      "device     = cpu()\n",
      "embedding_size = 34\n",
      "h0         = needle.Tensor([[[ 1.1546324  -0.3771556   2.8725996   0.25980425  0.07657579\n",
      "    1.2132034  -1.0588956  -0.6458007  -0...9  -1.0858743  -1.1571369\n",
      "   -1.9119931  -2.5301824   0.6338039  -0.75447494  0.04304891\n",
      "    1.116273   -0.5878709 ]]])\n",
      "hidden_size = 12\n",
      "init_hidden = True\n",
      "num_layers = 1\n",
      "output_size = 1\n",
      "seq_length = 1\n",
      "seq_model  = 'rnn'\n",
      "x          = array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "      dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:201: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "self = <models.LanguageModel object at 0x1575e2f00>, embedding_size = 34\n",
      "output_size = 1, hidden_size = 12, num_layers = 1, seq_model = 'rnn'\n",
      "device = cpu(), dtype = 'float32'\n",
      "\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92m__init__\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, embedding_size, output_size, hidden_size, num_layers=\u001b[94m1\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                 seq_model=\u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, device=\u001b[94mNone\u001b[39;49;00m, dtype=\u001b[33m\"\u001b[39;49;00m\u001b[33mfloat32\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"\u001b[39;49;00m\n",
      "    \u001b[33m    Consists of an embedding layer, a sequence model (either RNN or LSTM), and a\u001b[39;49;00m\n",
      "    \u001b[33m    linear layer.\u001b[39;49;00m\n",
      "    \u001b[33m    Parameters:\u001b[39;49;00m\n",
      "    \u001b[33m    output_size: Size of dictionary\u001b[39;49;00m\n",
      "    \u001b[33m    embedding_size: Size of embeddings\u001b[39;49;00m\n",
      "    \u001b[33m    hidden_size: The number of features in the hidden state of LSTM or RNN\u001b[39;49;00m\n",
      "    \u001b[33m    seq_model: 'rnn' or 'lstm', whether to use RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    num_layers: Number of layers in RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    \"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[96msuper\u001b[39;49;00m(LanguageModel, \u001b[96mself\u001b[39;49;00m).\u001b[92m__init__\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m### BEGIN YOUR SOLUTION\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94mraise\u001b[39;49;00m \u001b[96mNotImplementedError\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       NotImplementedError\u001b[0m\n",
      "\n",
      "__class__  = <class 'models.LanguageModel'>\n",
      "device     = cpu()\n",
      "dtype      = 'float32'\n",
      "embedding_size = 34\n",
      "hidden_size = 12\n",
      "num_layers = 1\n",
      "output_size = 1\n",
      "self       = <models.LanguageModel object at 0x1575e2f00>\n",
      "seq_model  = 'rnn'\n",
      "\n",
      "\u001b[1m\u001b[31mapps/models.py\u001b[0m:38: NotImplementedError\n",
      "\u001b[31m\u001b[1m_______ test_language_model_implementation[cpu-rnn-1-True-12-34-15-1-13] _______\u001b[0m\n",
      "\n",
      "seq_length = 13, num_layers = 1, batch_size = 15, embedding_size = 34\n",
      "hidden_size = 12, init_hidden = True, output_size = 1, seq_model = 'rnn'\n",
      "device = cpu()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\u001b[90m\u001b[39;49;00m\n",
      "                            init_hidden, output_size, seq_model, device):\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      ">       model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "batch_size = 15\n",
      "c0         = needle.Tensor([[[-0.09107991  0.50982314  0.22800104  0.7985687  -0.31999534\n",
      "    1.5330206  -1.5640532   0.22420467  0...3 -0.4521859  -0.76902336\n",
      "    0.599953   -0.8437698   0.74238026 -1.8931422   0.95422065\n",
      "    0.47608957  1.4524186 ]]])\n",
      "device     = cpu()\n",
      "embedding_size = 34\n",
      "h0         = needle.Tensor([[[-0.20885251 -0.4951286   0.4914312   1.0680518   0.32603425\n",
      "    0.5134832   0.30747187 -0.41345477 -0...5 -0.2833005   0.14324729\n",
      "    0.568857   -1.3732721   1.4977496  -1.0358081   0.09138356\n",
      "   -1.0702717  -0.5114276 ]]])\n",
      "hidden_size = 12\n",
      "init_hidden = True\n",
      "num_layers = 1\n",
      "output_size = 1\n",
      "seq_length = 13\n",
      "seq_model  = 'rnn'\n",
      "x          = array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0...0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "      dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:201: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "self = <models.LanguageModel object at 0x1575e3e00>, embedding_size = 34\n",
      "output_size = 1, hidden_size = 12, num_layers = 1, seq_model = 'rnn'\n",
      "device = cpu(), dtype = 'float32'\n",
      "\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92m__init__\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, embedding_size, output_size, hidden_size, num_layers=\u001b[94m1\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                 seq_model=\u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, device=\u001b[94mNone\u001b[39;49;00m, dtype=\u001b[33m\"\u001b[39;49;00m\u001b[33mfloat32\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"\u001b[39;49;00m\n",
      "    \u001b[33m    Consists of an embedding layer, a sequence model (either RNN or LSTM), and a\u001b[39;49;00m\n",
      "    \u001b[33m    linear layer.\u001b[39;49;00m\n",
      "    \u001b[33m    Parameters:\u001b[39;49;00m\n",
      "    \u001b[33m    output_size: Size of dictionary\u001b[39;49;00m\n",
      "    \u001b[33m    embedding_size: Size of embeddings\u001b[39;49;00m\n",
      "    \u001b[33m    hidden_size: The number of features in the hidden state of LSTM or RNN\u001b[39;49;00m\n",
      "    \u001b[33m    seq_model: 'rnn' or 'lstm', whether to use RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    num_layers: Number of layers in RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    \"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[96msuper\u001b[39;49;00m(LanguageModel, \u001b[96mself\u001b[39;49;00m).\u001b[92m__init__\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m### BEGIN YOUR SOLUTION\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94mraise\u001b[39;49;00m \u001b[96mNotImplementedError\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       NotImplementedError\u001b[0m\n",
      "\n",
      "__class__  = <class 'models.LanguageModel'>\n",
      "device     = cpu()\n",
      "dtype      = 'float32'\n",
      "embedding_size = 34\n",
      "hidden_size = 12\n",
      "num_layers = 1\n",
      "output_size = 1\n",
      "self       = <models.LanguageModel object at 0x1575e3e00>\n",
      "seq_model  = 'rnn'\n",
      "\n",
      "\u001b[1m\u001b[31mapps/models.py\u001b[0m:38: NotImplementedError\n",
      "\u001b[31m\u001b[1m_______ test_language_model_implementation[cpu-rnn-1-True-12-34-15-2-1] ________\u001b[0m\n",
      "\n",
      "seq_length = 1, num_layers = 2, batch_size = 15, embedding_size = 34\n",
      "hidden_size = 12, init_hidden = True, output_size = 1, seq_model = 'rnn'\n",
      "device = cpu()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\u001b[90m\u001b[39;49;00m\n",
      "                            init_hidden, output_size, seq_model, device):\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      ">       model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "batch_size = 15\n",
      "c0         = needle.Tensor([[[-0.79918975 -0.5476798  -1.6763017   0.3560542  -1.1851863\n",
      "    0.7979493   0.9706533   1.8136646   1....  -1.0394661  -0.54250383\n",
      "   -0.0569822   0.0398813  -1.2420905  -1.636925   -0.67094857\n",
      "    0.20124938  0.59079605]]])\n",
      "device     = cpu()\n",
      "embedding_size = 34\n",
      "h0         = needle.Tensor([[[ 6.30639672e-01  1.14308305e-01  3.24960142e-01 -2.03457761e+00\n",
      "   -2.98009783e-01  1.05494730e-01  1...  1.91887412e-02  5.66517651e-01  1.31763911e+00\n",
      "   -3.40619951e-01 -1.99674964e+00  4.43057865e-02  6.22034252e-01]]])\n",
      "hidden_size = 12\n",
      "init_hidden = True\n",
      "num_layers = 2\n",
      "output_size = 1\n",
      "seq_length = 1\n",
      "seq_model  = 'rnn'\n",
      "x          = array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "      dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:201: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "self = <models.LanguageModel object at 0x1575e0e60>, embedding_size = 34\n",
      "output_size = 1, hidden_size = 12, num_layers = 2, seq_model = 'rnn'\n",
      "device = cpu(), dtype = 'float32'\n",
      "\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92m__init__\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, embedding_size, output_size, hidden_size, num_layers=\u001b[94m1\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                 seq_model=\u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, device=\u001b[94mNone\u001b[39;49;00m, dtype=\u001b[33m\"\u001b[39;49;00m\u001b[33mfloat32\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"\u001b[39;49;00m\n",
      "    \u001b[33m    Consists of an embedding layer, a sequence model (either RNN or LSTM), and a\u001b[39;49;00m\n",
      "    \u001b[33m    linear layer.\u001b[39;49;00m\n",
      "    \u001b[33m    Parameters:\u001b[39;49;00m\n",
      "    \u001b[33m    output_size: Size of dictionary\u001b[39;49;00m\n",
      "    \u001b[33m    embedding_size: Size of embeddings\u001b[39;49;00m\n",
      "    \u001b[33m    hidden_size: The number of features in the hidden state of LSTM or RNN\u001b[39;49;00m\n",
      "    \u001b[33m    seq_model: 'rnn' or 'lstm', whether to use RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    num_layers: Number of layers in RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    \"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[96msuper\u001b[39;49;00m(LanguageModel, \u001b[96mself\u001b[39;49;00m).\u001b[92m__init__\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m### BEGIN YOUR SOLUTION\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94mraise\u001b[39;49;00m \u001b[96mNotImplementedError\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       NotImplementedError\u001b[0m\n",
      "\n",
      "__class__  = <class 'models.LanguageModel'>\n",
      "device     = cpu()\n",
      "dtype      = 'float32'\n",
      "embedding_size = 34\n",
      "hidden_size = 12\n",
      "num_layers = 2\n",
      "output_size = 1\n",
      "self       = <models.LanguageModel object at 0x1575e0e60>\n",
      "seq_model  = 'rnn'\n",
      "\n",
      "\u001b[1m\u001b[31mapps/models.py\u001b[0m:38: NotImplementedError\n",
      "\u001b[31m\u001b[1m_______ test_language_model_implementation[cpu-rnn-1-True-12-34-15-2-13] _______\u001b[0m\n",
      "\n",
      "seq_length = 13, num_layers = 2, batch_size = 15, embedding_size = 34\n",
      "hidden_size = 12, init_hidden = True, output_size = 1, seq_model = 'rnn'\n",
      "device = cpu()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\u001b[90m\u001b[39;49;00m\n",
      "                            init_hidden, output_size, seq_model, device):\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      ">       model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "batch_size = 15\n",
      "c0         = needle.Tensor([[[ 1.5902374  -0.30026695  0.8184724   0.1366433   0.7766194\n",
      "   -0.41294143 -0.67078114  1.4676217  -1....28  -0.38582703  1.0623308\n",
      "   -1.0145494   0.42880902  0.6690989  -0.36366764 -1.2604403\n",
      "    0.6452915   1.0287188 ]]])\n",
      "device     = cpu()\n",
      "embedding_size = 34\n",
      "h0         = needle.Tensor([[[-0.49787492  1.6812044  -1.3701173  -0.575512   -0.07374812\n",
      "    0.05780641  0.19121052 -0.87794465 -0...    0.17692302 -0.44288394\n",
      "    0.7169969   0.88552    -0.7594992  -0.2808648  -0.6913669\n",
      "    1.2390462   0.8941477 ]]])\n",
      "hidden_size = 12\n",
      "init_hidden = True\n",
      "num_layers = 2\n",
      "output_size = 1\n",
      "seq_length = 13\n",
      "seq_model  = 'rnn'\n",
      "x          = array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0...0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "      dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:201: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "self = <models.LanguageModel object at 0x1575ccbf0>, embedding_size = 34\n",
      "output_size = 1, hidden_size = 12, num_layers = 2, seq_model = 'rnn'\n",
      "device = cpu(), dtype = 'float32'\n",
      "\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92m__init__\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, embedding_size, output_size, hidden_size, num_layers=\u001b[94m1\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                 seq_model=\u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, device=\u001b[94mNone\u001b[39;49;00m, dtype=\u001b[33m\"\u001b[39;49;00m\u001b[33mfloat32\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"\u001b[39;49;00m\n",
      "    \u001b[33m    Consists of an embedding layer, a sequence model (either RNN or LSTM), and a\u001b[39;49;00m\n",
      "    \u001b[33m    linear layer.\u001b[39;49;00m\n",
      "    \u001b[33m    Parameters:\u001b[39;49;00m\n",
      "    \u001b[33m    output_size: Size of dictionary\u001b[39;49;00m\n",
      "    \u001b[33m    embedding_size: Size of embeddings\u001b[39;49;00m\n",
      "    \u001b[33m    hidden_size: The number of features in the hidden state of LSTM or RNN\u001b[39;49;00m\n",
      "    \u001b[33m    seq_model: 'rnn' or 'lstm', whether to use RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    num_layers: Number of layers in RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    \"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[96msuper\u001b[39;49;00m(LanguageModel, \u001b[96mself\u001b[39;49;00m).\u001b[92m__init__\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m### BEGIN YOUR SOLUTION\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94mraise\u001b[39;49;00m \u001b[96mNotImplementedError\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       NotImplementedError\u001b[0m\n",
      "\n",
      "__class__  = <class 'models.LanguageModel'>\n",
      "device     = cpu()\n",
      "dtype      = 'float32'\n",
      "embedding_size = 34\n",
      "hidden_size = 12\n",
      "num_layers = 2\n",
      "output_size = 1\n",
      "self       = <models.LanguageModel object at 0x1575ccbf0>\n",
      "seq_model  = 'rnn'\n",
      "\n",
      "\u001b[1m\u001b[31mapps/models.py\u001b[0m:38: NotImplementedError\n",
      "\u001b[31m\u001b[1m________ test_language_model_implementation[cpu-rnn-1-False-1-1-1-1-1] _________\u001b[0m\n",
      "\n",
      "seq_length = 1, num_layers = 1, batch_size = 1, embedding_size = 1\n",
      "hidden_size = 1, init_hidden = False, output_size = 1, seq_model = 'rnn'\n",
      "device = cpu()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\u001b[90m\u001b[39;49;00m\n",
      "                            init_hidden, output_size, seq_model, device):\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      ">       model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "batch_size = 1\n",
      "c0         = needle.Tensor([[[-0.48430687]]])\n",
      "device     = cpu()\n",
      "embedding_size = 1\n",
      "h0         = needle.Tensor([[[-0.47799978]]])\n",
      "hidden_size = 1\n",
      "init_hidden = False\n",
      "num_layers = 1\n",
      "output_size = 1\n",
      "seq_length = 1\n",
      "seq_model  = 'rnn'\n",
      "x          = array([[0.]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:201: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "self = <models.LanguageModel object at 0x1575cf710>, embedding_size = 1\n",
      "output_size = 1, hidden_size = 1, num_layers = 1, seq_model = 'rnn'\n",
      "device = cpu(), dtype = 'float32'\n",
      "\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92m__init__\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, embedding_size, output_size, hidden_size, num_layers=\u001b[94m1\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                 seq_model=\u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, device=\u001b[94mNone\u001b[39;49;00m, dtype=\u001b[33m\"\u001b[39;49;00m\u001b[33mfloat32\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"\u001b[39;49;00m\n",
      "    \u001b[33m    Consists of an embedding layer, a sequence model (either RNN or LSTM), and a\u001b[39;49;00m\n",
      "    \u001b[33m    linear layer.\u001b[39;49;00m\n",
      "    \u001b[33m    Parameters:\u001b[39;49;00m\n",
      "    \u001b[33m    output_size: Size of dictionary\u001b[39;49;00m\n",
      "    \u001b[33m    embedding_size: Size of embeddings\u001b[39;49;00m\n",
      "    \u001b[33m    hidden_size: The number of features in the hidden state of LSTM or RNN\u001b[39;49;00m\n",
      "    \u001b[33m    seq_model: 'rnn' or 'lstm', whether to use RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    num_layers: Number of layers in RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    \"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[96msuper\u001b[39;49;00m(LanguageModel, \u001b[96mself\u001b[39;49;00m).\u001b[92m__init__\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m### BEGIN YOUR SOLUTION\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94mraise\u001b[39;49;00m \u001b[96mNotImplementedError\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       NotImplementedError\u001b[0m\n",
      "\n",
      "__class__  = <class 'models.LanguageModel'>\n",
      "device     = cpu()\n",
      "dtype      = 'float32'\n",
      "embedding_size = 1\n",
      "hidden_size = 1\n",
      "num_layers = 1\n",
      "output_size = 1\n",
      "self       = <models.LanguageModel object at 0x1575cf710>\n",
      "seq_model  = 'rnn'\n",
      "\n",
      "\u001b[1m\u001b[31mapps/models.py\u001b[0m:38: NotImplementedError\n",
      "\u001b[31m\u001b[1m________ test_language_model_implementation[cpu-rnn-1-False-1-1-1-1-13] ________\u001b[0m\n",
      "\n",
      "seq_length = 13, num_layers = 1, batch_size = 1, embedding_size = 1\n",
      "hidden_size = 1, init_hidden = False, output_size = 1, seq_model = 'rnn'\n",
      "device = cpu()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\u001b[90m\u001b[39;49;00m\n",
      "                            init_hidden, output_size, seq_model, device):\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      ">       model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "batch_size = 1\n",
      "c0         = needle.Tensor([[[0.19321865]]])\n",
      "device     = cpu()\n",
      "embedding_size = 1\n",
      "h0         = needle.Tensor([[[-0.31058398]]])\n",
      "hidden_size = 1\n",
      "init_hidden = False\n",
      "num_layers = 1\n",
      "output_size = 1\n",
      "seq_length = 13\n",
      "seq_model  = 'rnn'\n",
      "x          = array([[0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:201: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "self = <models.LanguageModel object at 0x1575cfa40>, embedding_size = 1\n",
      "output_size = 1, hidden_size = 1, num_layers = 1, seq_model = 'rnn'\n",
      "device = cpu(), dtype = 'float32'\n",
      "\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92m__init__\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, embedding_size, output_size, hidden_size, num_layers=\u001b[94m1\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                 seq_model=\u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, device=\u001b[94mNone\u001b[39;49;00m, dtype=\u001b[33m\"\u001b[39;49;00m\u001b[33mfloat32\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"\u001b[39;49;00m\n",
      "    \u001b[33m    Consists of an embedding layer, a sequence model (either RNN or LSTM), and a\u001b[39;49;00m\n",
      "    \u001b[33m    linear layer.\u001b[39;49;00m\n",
      "    \u001b[33m    Parameters:\u001b[39;49;00m\n",
      "    \u001b[33m    output_size: Size of dictionary\u001b[39;49;00m\n",
      "    \u001b[33m    embedding_size: Size of embeddings\u001b[39;49;00m\n",
      "    \u001b[33m    hidden_size: The number of features in the hidden state of LSTM or RNN\u001b[39;49;00m\n",
      "    \u001b[33m    seq_model: 'rnn' or 'lstm', whether to use RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    num_layers: Number of layers in RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    \"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[96msuper\u001b[39;49;00m(LanguageModel, \u001b[96mself\u001b[39;49;00m).\u001b[92m__init__\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m### BEGIN YOUR SOLUTION\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94mraise\u001b[39;49;00m \u001b[96mNotImplementedError\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       NotImplementedError\u001b[0m\n",
      "\n",
      "__class__  = <class 'models.LanguageModel'>\n",
      "device     = cpu()\n",
      "dtype      = 'float32'\n",
      "embedding_size = 1\n",
      "hidden_size = 1\n",
      "num_layers = 1\n",
      "output_size = 1\n",
      "self       = <models.LanguageModel object at 0x1575cfa40>\n",
      "seq_model  = 'rnn'\n",
      "\n",
      "\u001b[1m\u001b[31mapps/models.py\u001b[0m:38: NotImplementedError\n",
      "\u001b[31m\u001b[1m________ test_language_model_implementation[cpu-rnn-1-False-1-1-1-2-1] _________\u001b[0m\n",
      "\n",
      "seq_length = 1, num_layers = 2, batch_size = 1, embedding_size = 1\n",
      "hidden_size = 1, init_hidden = False, output_size = 1, seq_model = 'rnn'\n",
      "device = cpu()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\u001b[90m\u001b[39;49;00m\n",
      "                            init_hidden, output_size, seq_model, device):\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      ">       model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "batch_size = 1\n",
      "c0         = needle.Tensor([[[0.8292596 ]]\n",
      "\n",
      " [[0.56768125]]])\n",
      "device     = cpu()\n",
      "embedding_size = 1\n",
      "h0         = needle.Tensor([[[ 0.19921295]]\n",
      "\n",
      " [[-0.22507696]]])\n",
      "hidden_size = 1\n",
      "init_hidden = False\n",
      "num_layers = 2\n",
      "output_size = 1\n",
      "seq_length = 1\n",
      "seq_model  = 'rnn'\n",
      "x          = array([[0.]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:201: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "self = <models.LanguageModel object at 0x1575cd0a0>, embedding_size = 1\n",
      "output_size = 1, hidden_size = 1, num_layers = 2, seq_model = 'rnn'\n",
      "device = cpu(), dtype = 'float32'\n",
      "\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92m__init__\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, embedding_size, output_size, hidden_size, num_layers=\u001b[94m1\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                 seq_model=\u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, device=\u001b[94mNone\u001b[39;49;00m, dtype=\u001b[33m\"\u001b[39;49;00m\u001b[33mfloat32\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"\u001b[39;49;00m\n",
      "    \u001b[33m    Consists of an embedding layer, a sequence model (either RNN or LSTM), and a\u001b[39;49;00m\n",
      "    \u001b[33m    linear layer.\u001b[39;49;00m\n",
      "    \u001b[33m    Parameters:\u001b[39;49;00m\n",
      "    \u001b[33m    output_size: Size of dictionary\u001b[39;49;00m\n",
      "    \u001b[33m    embedding_size: Size of embeddings\u001b[39;49;00m\n",
      "    \u001b[33m    hidden_size: The number of features in the hidden state of LSTM or RNN\u001b[39;49;00m\n",
      "    \u001b[33m    seq_model: 'rnn' or 'lstm', whether to use RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    num_layers: Number of layers in RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    \"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[96msuper\u001b[39;49;00m(LanguageModel, \u001b[96mself\u001b[39;49;00m).\u001b[92m__init__\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m### BEGIN YOUR SOLUTION\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94mraise\u001b[39;49;00m \u001b[96mNotImplementedError\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       NotImplementedError\u001b[0m\n",
      "\n",
      "__class__  = <class 'models.LanguageModel'>\n",
      "device     = cpu()\n",
      "dtype      = 'float32'\n",
      "embedding_size = 1\n",
      "hidden_size = 1\n",
      "num_layers = 2\n",
      "output_size = 1\n",
      "self       = <models.LanguageModel object at 0x1575cd0a0>\n",
      "seq_model  = 'rnn'\n",
      "\n",
      "\u001b[1m\u001b[31mapps/models.py\u001b[0m:38: NotImplementedError\n",
      "\u001b[31m\u001b[1m________ test_language_model_implementation[cpu-rnn-1-False-1-1-1-2-13] ________\u001b[0m\n",
      "\n",
      "seq_length = 13, num_layers = 2, batch_size = 1, embedding_size = 1\n",
      "hidden_size = 1, init_hidden = False, output_size = 1, seq_model = 'rnn'\n",
      "device = cpu()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\u001b[90m\u001b[39;49;00m\n",
      "                            init_hidden, output_size, seq_model, device):\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      ">       model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "batch_size = 1\n",
      "c0         = needle.Tensor([[[0.8908491]]\n",
      "\n",
      " [[1.8416747]]])\n",
      "device     = cpu()\n",
      "embedding_size = 1\n",
      "h0         = needle.Tensor([[[-0.26684883]]\n",
      "\n",
      " [[ 1.3521719 ]]])\n",
      "hidden_size = 1\n",
      "init_hidden = False\n",
      "num_layers = 2\n",
      "output_size = 1\n",
      "seq_length = 13\n",
      "seq_model  = 'rnn'\n",
      "x          = array([[0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:201: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "self = <models.LanguageModel object at 0x1575ce840>, embedding_size = 1\n",
      "output_size = 1, hidden_size = 1, num_layers = 2, seq_model = 'rnn'\n",
      "device = cpu(), dtype = 'float32'\n",
      "\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92m__init__\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, embedding_size, output_size, hidden_size, num_layers=\u001b[94m1\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                 seq_model=\u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, device=\u001b[94mNone\u001b[39;49;00m, dtype=\u001b[33m\"\u001b[39;49;00m\u001b[33mfloat32\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"\u001b[39;49;00m\n",
      "    \u001b[33m    Consists of an embedding layer, a sequence model (either RNN or LSTM), and a\u001b[39;49;00m\n",
      "    \u001b[33m    linear layer.\u001b[39;49;00m\n",
      "    \u001b[33m    Parameters:\u001b[39;49;00m\n",
      "    \u001b[33m    output_size: Size of dictionary\u001b[39;49;00m\n",
      "    \u001b[33m    embedding_size: Size of embeddings\u001b[39;49;00m\n",
      "    \u001b[33m    hidden_size: The number of features in the hidden state of LSTM or RNN\u001b[39;49;00m\n",
      "    \u001b[33m    seq_model: 'rnn' or 'lstm', whether to use RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    num_layers: Number of layers in RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    \"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[96msuper\u001b[39;49;00m(LanguageModel, \u001b[96mself\u001b[39;49;00m).\u001b[92m__init__\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m### BEGIN YOUR SOLUTION\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94mraise\u001b[39;49;00m \u001b[96mNotImplementedError\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       NotImplementedError\u001b[0m\n",
      "\n",
      "__class__  = <class 'models.LanguageModel'>\n",
      "device     = cpu()\n",
      "dtype      = 'float32'\n",
      "embedding_size = 1\n",
      "hidden_size = 1\n",
      "num_layers = 2\n",
      "output_size = 1\n",
      "self       = <models.LanguageModel object at 0x1575ce840>\n",
      "seq_model  = 'rnn'\n",
      "\n",
      "\u001b[1m\u001b[31mapps/models.py\u001b[0m:38: NotImplementedError\n",
      "\u001b[31m\u001b[1m________ test_language_model_implementation[cpu-rnn-1-False-1-1-15-1-1] ________\u001b[0m\n",
      "\n",
      "seq_length = 1, num_layers = 1, batch_size = 15, embedding_size = 1\n",
      "hidden_size = 1, init_hidden = False, output_size = 1, seq_model = 'rnn'\n",
      "device = cpu()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\u001b[90m\u001b[39;49;00m\n",
      "                            init_hidden, output_size, seq_model, device):\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      ">       model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "batch_size = 15\n",
      "c0         = needle.Tensor([[[-1.1310978 ]\n",
      "  [-0.5154373 ]\n",
      "  [-1.6162473 ]\n",
      "  [-0.6561854 ]\n",
      "  [-0.18826379]\n",
      "  [-0.37101388]\n",
      "  [-0.35...38 ]\n",
      "  [ 0.04914959]\n",
      "  [ 0.7346603 ]\n",
      "  [-0.36877   ]\n",
      "  [-0.88177717]\n",
      "  [ 0.95955485]\n",
      "  [-0.9342694 ]\n",
      "  [ 0.8440515 ]]])\n",
      "device     = cpu()\n",
      "embedding_size = 1\n",
      "h0         = needle.Tensor([[[-0.41486278]\n",
      "  [ 1.6541876 ]\n",
      "  [-0.12297556]\n",
      "  [-0.32709637]\n",
      "  [ 0.01879609]\n",
      "  [-1.7415758 ]\n",
      "  [ 0.86...1  ]\n",
      "  [-0.81826895]\n",
      "  [-0.2713657 ]\n",
      "  [ 1.3160232 ]\n",
      "  [-0.11017653]\n",
      "  [-0.24143538]\n",
      "  [ 0.6472366 ]\n",
      "  [-0.14374663]]])\n",
      "hidden_size = 1\n",
      "init_hidden = False\n",
      "num_layers = 1\n",
      "output_size = 1\n",
      "seq_length = 1\n",
      "seq_model  = 'rnn'\n",
      "x          = array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "      dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:201: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "self = <models.LanguageModel object at 0x15748d280>, embedding_size = 1\n",
      "output_size = 1, hidden_size = 1, num_layers = 1, seq_model = 'rnn'\n",
      "device = cpu(), dtype = 'float32'\n",
      "\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92m__init__\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, embedding_size, output_size, hidden_size, num_layers=\u001b[94m1\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                 seq_model=\u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, device=\u001b[94mNone\u001b[39;49;00m, dtype=\u001b[33m\"\u001b[39;49;00m\u001b[33mfloat32\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"\u001b[39;49;00m\n",
      "    \u001b[33m    Consists of an embedding layer, a sequence model (either RNN or LSTM), and a\u001b[39;49;00m\n",
      "    \u001b[33m    linear layer.\u001b[39;49;00m\n",
      "    \u001b[33m    Parameters:\u001b[39;49;00m\n",
      "    \u001b[33m    output_size: Size of dictionary\u001b[39;49;00m\n",
      "    \u001b[33m    embedding_size: Size of embeddings\u001b[39;49;00m\n",
      "    \u001b[33m    hidden_size: The number of features in the hidden state of LSTM or RNN\u001b[39;49;00m\n",
      "    \u001b[33m    seq_model: 'rnn' or 'lstm', whether to use RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    num_layers: Number of layers in RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    \"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[96msuper\u001b[39;49;00m(LanguageModel, \u001b[96mself\u001b[39;49;00m).\u001b[92m__init__\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m### BEGIN YOUR SOLUTION\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94mraise\u001b[39;49;00m \u001b[96mNotImplementedError\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       NotImplementedError\u001b[0m\n",
      "\n",
      "__class__  = <class 'models.LanguageModel'>\n",
      "device     = cpu()\n",
      "dtype      = 'float32'\n",
      "embedding_size = 1\n",
      "hidden_size = 1\n",
      "num_layers = 1\n",
      "output_size = 1\n",
      "self       = <models.LanguageModel object at 0x15748d280>\n",
      "seq_model  = 'rnn'\n",
      "\n",
      "\u001b[1m\u001b[31mapps/models.py\u001b[0m:38: NotImplementedError\n",
      "\u001b[31m\u001b[1m_______ test_language_model_implementation[cpu-rnn-1-False-1-1-15-1-13] ________\u001b[0m\n",
      "\n",
      "seq_length = 13, num_layers = 1, batch_size = 15, embedding_size = 1\n",
      "hidden_size = 1, init_hidden = False, output_size = 1, seq_model = 'rnn'\n",
      "device = cpu()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\u001b[90m\u001b[39;49;00m\n",
      "                            init_hidden, output_size, seq_model, device):\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      ">       model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "batch_size = 15\n",
      "c0         = needle.Tensor([[[ 0.6257778 ]\n",
      "  [-1.0889883 ]\n",
      "  [ 0.9991607 ]\n",
      "  [ 0.3536476 ]\n",
      "  [ 0.87513435]\n",
      "  [-0.7944371 ]\n",
      "  [ 0.47...235]\n",
      "  [-0.27211574]\n",
      "  [-0.44278264]\n",
      "  [ 0.5685636 ]\n",
      "  [-0.37518266]\n",
      "  [ 1.812673  ]\n",
      "  [-1.3205322 ]\n",
      "  [-0.01258553]]])\n",
      "device     = cpu()\n",
      "embedding_size = 1\n",
      "h0         = needle.Tensor([[[-1.0753093 ]\n",
      "  [-1.0097634 ]\n",
      "  [-0.8268276 ]\n",
      "  [ 1.0759372 ]\n",
      "  [ 1.2565506 ]\n",
      "  [-1.4241998 ]\n",
      "  [ 0.67...59 ]\n",
      "  [-1.764545  ]\n",
      "  [-0.44812968]\n",
      "  [-0.82442015]\n",
      "  [ 1.4472878 ]\n",
      "  [-0.8487079 ]\n",
      "  [-2.0396683 ]\n",
      "  [-1.1388057 ]]])\n",
      "hidden_size = 1\n",
      "init_hidden = False\n",
      "num_layers = 1\n",
      "output_size = 1\n",
      "seq_length = 13\n",
      "seq_model  = 'rnn'\n",
      "x          = array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0...0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "      dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:201: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "self = <models.LanguageModel object at 0x1575cf230>, embedding_size = 1\n",
      "output_size = 1, hidden_size = 1, num_layers = 1, seq_model = 'rnn'\n",
      "device = cpu(), dtype = 'float32'\n",
      "\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92m__init__\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, embedding_size, output_size, hidden_size, num_layers=\u001b[94m1\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                 seq_model=\u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, device=\u001b[94mNone\u001b[39;49;00m, dtype=\u001b[33m\"\u001b[39;49;00m\u001b[33mfloat32\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"\u001b[39;49;00m\n",
      "    \u001b[33m    Consists of an embedding layer, a sequence model (either RNN or LSTM), and a\u001b[39;49;00m\n",
      "    \u001b[33m    linear layer.\u001b[39;49;00m\n",
      "    \u001b[33m    Parameters:\u001b[39;49;00m\n",
      "    \u001b[33m    output_size: Size of dictionary\u001b[39;49;00m\n",
      "    \u001b[33m    embedding_size: Size of embeddings\u001b[39;49;00m\n",
      "    \u001b[33m    hidden_size: The number of features in the hidden state of LSTM or RNN\u001b[39;49;00m\n",
      "    \u001b[33m    seq_model: 'rnn' or 'lstm', whether to use RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    num_layers: Number of layers in RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    \"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[96msuper\u001b[39;49;00m(LanguageModel, \u001b[96mself\u001b[39;49;00m).\u001b[92m__init__\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m### BEGIN YOUR SOLUTION\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94mraise\u001b[39;49;00m \u001b[96mNotImplementedError\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       NotImplementedError\u001b[0m\n",
      "\n",
      "__class__  = <class 'models.LanguageModel'>\n",
      "device     = cpu()\n",
      "dtype      = 'float32'\n",
      "embedding_size = 1\n",
      "hidden_size = 1\n",
      "num_layers = 1\n",
      "output_size = 1\n",
      "self       = <models.LanguageModel object at 0x1575cf230>\n",
      "seq_model  = 'rnn'\n",
      "\n",
      "\u001b[1m\u001b[31mapps/models.py\u001b[0m:38: NotImplementedError\n",
      "\u001b[31m\u001b[1m________ test_language_model_implementation[cpu-rnn-1-False-1-1-15-2-1] ________\u001b[0m\n",
      "\n",
      "seq_length = 1, num_layers = 2, batch_size = 15, embedding_size = 1\n",
      "hidden_size = 1, init_hidden = False, output_size = 1, seq_model = 'rnn'\n",
      "device = cpu()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\u001b[90m\u001b[39;49;00m\n",
      "                            init_hidden, output_size, seq_model, device):\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      ">       model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "batch_size = 15\n",
      "c0         = needle.Tensor([[[ 5.3315306e-01]\n",
      "  [-4.4746235e-01]\n",
      "  [-5.0216943e-01]\n",
      "  [-5.8343512e-01]\n",
      "  [ 2.7666718e-04]\n",
      "  [-8.743...1]\n",
      "  [-1.1640015e+00]\n",
      "  [ 3.1724736e-01]\n",
      "  [-1.8041245e+00]\n",
      "  [ 3.7287524e-01]\n",
      "  [-2.1188986e+00]\n",
      "  [-2.1411645e+00]]])\n",
      "device     = cpu()\n",
      "embedding_size = 1\n",
      "h0         = needle.Tensor([[[ 0.468568  ]\n",
      "  [-0.41685423]\n",
      "  [ 2.0943394 ]\n",
      "  [ 0.11102327]\n",
      "  [ 1.0811166 ]\n",
      "  [ 0.7335674 ]\n",
      "  [ 0.23...395]\n",
      "  [ 1.1696284 ]\n",
      "  [-0.68872225]\n",
      "  [ 1.3474883 ]\n",
      "  [-0.38412264]\n",
      "  [ 0.7939115 ]\n",
      "  [ 0.41029286]\n",
      "  [-1.4575723 ]]])\n",
      "hidden_size = 1\n",
      "init_hidden = False\n",
      "num_layers = 2\n",
      "output_size = 1\n",
      "seq_length = 1\n",
      "seq_model  = 'rnn'\n",
      "x          = array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "      dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:201: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "self = <models.LanguageModel object at 0x1575cd400>, embedding_size = 1\n",
      "output_size = 1, hidden_size = 1, num_layers = 2, seq_model = 'rnn'\n",
      "device = cpu(), dtype = 'float32'\n",
      "\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92m__init__\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, embedding_size, output_size, hidden_size, num_layers=\u001b[94m1\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                 seq_model=\u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, device=\u001b[94mNone\u001b[39;49;00m, dtype=\u001b[33m\"\u001b[39;49;00m\u001b[33mfloat32\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"\u001b[39;49;00m\n",
      "    \u001b[33m    Consists of an embedding layer, a sequence model (either RNN or LSTM), and a\u001b[39;49;00m\n",
      "    \u001b[33m    linear layer.\u001b[39;49;00m\n",
      "    \u001b[33m    Parameters:\u001b[39;49;00m\n",
      "    \u001b[33m    output_size: Size of dictionary\u001b[39;49;00m\n",
      "    \u001b[33m    embedding_size: Size of embeddings\u001b[39;49;00m\n",
      "    \u001b[33m    hidden_size: The number of features in the hidden state of LSTM or RNN\u001b[39;49;00m\n",
      "    \u001b[33m    seq_model: 'rnn' or 'lstm', whether to use RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    num_layers: Number of layers in RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    \"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[96msuper\u001b[39;49;00m(LanguageModel, \u001b[96mself\u001b[39;49;00m).\u001b[92m__init__\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m### BEGIN YOUR SOLUTION\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94mraise\u001b[39;49;00m \u001b[96mNotImplementedError\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       NotImplementedError\u001b[0m\n",
      "\n",
      "__class__  = <class 'models.LanguageModel'>\n",
      "device     = cpu()\n",
      "dtype      = 'float32'\n",
      "embedding_size = 1\n",
      "hidden_size = 1\n",
      "num_layers = 2\n",
      "output_size = 1\n",
      "self       = <models.LanguageModel object at 0x1575cd400>\n",
      "seq_model  = 'rnn'\n",
      "\n",
      "\u001b[1m\u001b[31mapps/models.py\u001b[0m:38: NotImplementedError\n",
      "\u001b[31m\u001b[1m_______ test_language_model_implementation[cpu-rnn-1-False-1-1-15-2-13] ________\u001b[0m\n",
      "\n",
      "seq_length = 13, num_layers = 2, batch_size = 15, embedding_size = 1\n",
      "hidden_size = 1, init_hidden = False, output_size = 1, seq_model = 'rnn'\n",
      "device = cpu()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\u001b[90m\u001b[39;49;00m\n",
      "                            init_hidden, output_size, seq_model, device):\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      ">       model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "batch_size = 15\n",
      "c0         = needle.Tensor([[[-0.8423576 ]\n",
      "  [ 0.7276693 ]\n",
      "  [ 1.3440641 ]\n",
      "  [-0.50577784]\n",
      "  [ 0.40508687]\n",
      "  [ 1.3739959 ]\n",
      "  [-0.24...52 ]\n",
      "  [ 0.14175236]\n",
      "  [-0.01691748]\n",
      "  [ 0.621324  ]\n",
      "  [-1.0956389 ]\n",
      "  [-0.6800526 ]\n",
      "  [-1.3771951 ]\n",
      "  [ 0.3327745 ]]])\n",
      "device     = cpu()\n",
      "embedding_size = 1\n",
      "h0         = needle.Tensor([[[-0.43370086]\n",
      "  [-0.34345713]\n",
      "  [ 0.4155044 ]\n",
      "  [-1.0822341 ]\n",
      "  [ 1.3777537 ]\n",
      "  [-1.815824  ]\n",
      "  [ 0.38...16 ]\n",
      "  [-0.75568146]\n",
      "  [-1.1603814 ]\n",
      "  [-0.73548967]\n",
      "  [-0.33666885]\n",
      "  [ 2.0343332 ]\n",
      "  [-2.3930173 ]\n",
      "  [ 0.8508422 ]]])\n",
      "hidden_size = 1\n",
      "init_hidden = False\n",
      "num_layers = 2\n",
      "output_size = 1\n",
      "seq_length = 13\n",
      "seq_model  = 'rnn'\n",
      "x          = array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0...0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "      dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:201: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "self = <models.LanguageModel object at 0x1575e32f0>, embedding_size = 1\n",
      "output_size = 1, hidden_size = 1, num_layers = 2, seq_model = 'rnn'\n",
      "device = cpu(), dtype = 'float32'\n",
      "\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92m__init__\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, embedding_size, output_size, hidden_size, num_layers=\u001b[94m1\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                 seq_model=\u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, device=\u001b[94mNone\u001b[39;49;00m, dtype=\u001b[33m\"\u001b[39;49;00m\u001b[33mfloat32\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"\u001b[39;49;00m\n",
      "    \u001b[33m    Consists of an embedding layer, a sequence model (either RNN or LSTM), and a\u001b[39;49;00m\n",
      "    \u001b[33m    linear layer.\u001b[39;49;00m\n",
      "    \u001b[33m    Parameters:\u001b[39;49;00m\n",
      "    \u001b[33m    output_size: Size of dictionary\u001b[39;49;00m\n",
      "    \u001b[33m    embedding_size: Size of embeddings\u001b[39;49;00m\n",
      "    \u001b[33m    hidden_size: The number of features in the hidden state of LSTM or RNN\u001b[39;49;00m\n",
      "    \u001b[33m    seq_model: 'rnn' or 'lstm', whether to use RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    num_layers: Number of layers in RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    \"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[96msuper\u001b[39;49;00m(LanguageModel, \u001b[96mself\u001b[39;49;00m).\u001b[92m__init__\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m### BEGIN YOUR SOLUTION\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94mraise\u001b[39;49;00m \u001b[96mNotImplementedError\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       NotImplementedError\u001b[0m\n",
      "\n",
      "__class__  = <class 'models.LanguageModel'>\n",
      "device     = cpu()\n",
      "dtype      = 'float32'\n",
      "embedding_size = 1\n",
      "hidden_size = 1\n",
      "num_layers = 2\n",
      "output_size = 1\n",
      "self       = <models.LanguageModel object at 0x1575e32f0>\n",
      "seq_model  = 'rnn'\n",
      "\n",
      "\u001b[1m\u001b[31mapps/models.py\u001b[0m:38: NotImplementedError\n",
      "\u001b[31m\u001b[1m________ test_language_model_implementation[cpu-rnn-1-False-1-34-1-1-1] ________\u001b[0m\n",
      "\n",
      "seq_length = 1, num_layers = 1, batch_size = 1, embedding_size = 34\n",
      "hidden_size = 1, init_hidden = False, output_size = 1, seq_model = 'rnn'\n",
      "device = cpu()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\u001b[90m\u001b[39;49;00m\n",
      "                            init_hidden, output_size, seq_model, device):\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      ">       model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "batch_size = 1\n",
      "c0         = needle.Tensor([[[0.57511324]]])\n",
      "device     = cpu()\n",
      "embedding_size = 34\n",
      "h0         = needle.Tensor([[[0.8662027]]])\n",
      "hidden_size = 1\n",
      "init_hidden = False\n",
      "num_layers = 1\n",
      "output_size = 1\n",
      "seq_length = 1\n",
      "seq_model  = 'rnn'\n",
      "x          = array([[0.]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:201: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "self = <models.LanguageModel object at 0x1575e0110>, embedding_size = 34\n",
      "output_size = 1, hidden_size = 1, num_layers = 1, seq_model = 'rnn'\n",
      "device = cpu(), dtype = 'float32'\n",
      "\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92m__init__\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, embedding_size, output_size, hidden_size, num_layers=\u001b[94m1\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                 seq_model=\u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, device=\u001b[94mNone\u001b[39;49;00m, dtype=\u001b[33m\"\u001b[39;49;00m\u001b[33mfloat32\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"\u001b[39;49;00m\n",
      "    \u001b[33m    Consists of an embedding layer, a sequence model (either RNN or LSTM), and a\u001b[39;49;00m\n",
      "    \u001b[33m    linear layer.\u001b[39;49;00m\n",
      "    \u001b[33m    Parameters:\u001b[39;49;00m\n",
      "    \u001b[33m    output_size: Size of dictionary\u001b[39;49;00m\n",
      "    \u001b[33m    embedding_size: Size of embeddings\u001b[39;49;00m\n",
      "    \u001b[33m    hidden_size: The number of features in the hidden state of LSTM or RNN\u001b[39;49;00m\n",
      "    \u001b[33m    seq_model: 'rnn' or 'lstm', whether to use RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    num_layers: Number of layers in RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    \"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[96msuper\u001b[39;49;00m(LanguageModel, \u001b[96mself\u001b[39;49;00m).\u001b[92m__init__\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m### BEGIN YOUR SOLUTION\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94mraise\u001b[39;49;00m \u001b[96mNotImplementedError\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       NotImplementedError\u001b[0m\n",
      "\n",
      "__class__  = <class 'models.LanguageModel'>\n",
      "device     = cpu()\n",
      "dtype      = 'float32'\n",
      "embedding_size = 34\n",
      "hidden_size = 1\n",
      "num_layers = 1\n",
      "output_size = 1\n",
      "self       = <models.LanguageModel object at 0x1575e0110>\n",
      "seq_model  = 'rnn'\n",
      "\n",
      "\u001b[1m\u001b[31mapps/models.py\u001b[0m:38: NotImplementedError\n",
      "\u001b[31m\u001b[1m_______ test_language_model_implementation[cpu-rnn-1-False-1-34-1-1-13] ________\u001b[0m\n",
      "\n",
      "seq_length = 13, num_layers = 1, batch_size = 1, embedding_size = 34\n",
      "hidden_size = 1, init_hidden = False, output_size = 1, seq_model = 'rnn'\n",
      "device = cpu()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\u001b[90m\u001b[39;49;00m\n",
      "                            init_hidden, output_size, seq_model, device):\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      ">       model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "batch_size = 1\n",
      "c0         = needle.Tensor([[[-1.2935722]]])\n",
      "device     = cpu()\n",
      "embedding_size = 34\n",
      "h0         = needle.Tensor([[[0.62653863]]])\n",
      "hidden_size = 1\n",
      "init_hidden = False\n",
      "num_layers = 1\n",
      "output_size = 1\n",
      "seq_length = 13\n",
      "seq_model  = 'rnn'\n",
      "x          = array([[0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:201: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "self = <models.LanguageModel object at 0x1575e2f90>, embedding_size = 34\n",
      "output_size = 1, hidden_size = 1, num_layers = 1, seq_model = 'rnn'\n",
      "device = cpu(), dtype = 'float32'\n",
      "\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92m__init__\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, embedding_size, output_size, hidden_size, num_layers=\u001b[94m1\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                 seq_model=\u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, device=\u001b[94mNone\u001b[39;49;00m, dtype=\u001b[33m\"\u001b[39;49;00m\u001b[33mfloat32\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"\u001b[39;49;00m\n",
      "    \u001b[33m    Consists of an embedding layer, a sequence model (either RNN or LSTM), and a\u001b[39;49;00m\n",
      "    \u001b[33m    linear layer.\u001b[39;49;00m\n",
      "    \u001b[33m    Parameters:\u001b[39;49;00m\n",
      "    \u001b[33m    output_size: Size of dictionary\u001b[39;49;00m\n",
      "    \u001b[33m    embedding_size: Size of embeddings\u001b[39;49;00m\n",
      "    \u001b[33m    hidden_size: The number of features in the hidden state of LSTM or RNN\u001b[39;49;00m\n",
      "    \u001b[33m    seq_model: 'rnn' or 'lstm', whether to use RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    num_layers: Number of layers in RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    \"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[96msuper\u001b[39;49;00m(LanguageModel, \u001b[96mself\u001b[39;49;00m).\u001b[92m__init__\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m### BEGIN YOUR SOLUTION\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94mraise\u001b[39;49;00m \u001b[96mNotImplementedError\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       NotImplementedError\u001b[0m\n",
      "\n",
      "__class__  = <class 'models.LanguageModel'>\n",
      "device     = cpu()\n",
      "dtype      = 'float32'\n",
      "embedding_size = 34\n",
      "hidden_size = 1\n",
      "num_layers = 1\n",
      "output_size = 1\n",
      "self       = <models.LanguageModel object at 0x1575e2f90>\n",
      "seq_model  = 'rnn'\n",
      "\n",
      "\u001b[1m\u001b[31mapps/models.py\u001b[0m:38: NotImplementedError\n",
      "\u001b[31m\u001b[1m________ test_language_model_implementation[cpu-rnn-1-False-1-34-1-2-1] ________\u001b[0m\n",
      "\n",
      "seq_length = 1, num_layers = 2, batch_size = 1, embedding_size = 34\n",
      "hidden_size = 1, init_hidden = False, output_size = 1, seq_model = 'rnn'\n",
      "device = cpu()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\u001b[90m\u001b[39;49;00m\n",
      "                            init_hidden, output_size, seq_model, device):\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      ">       model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "batch_size = 1\n",
      "c0         = needle.Tensor([[[0.56824833]]\n",
      "\n",
      " [[1.6767553 ]]])\n",
      "device     = cpu()\n",
      "embedding_size = 34\n",
      "h0         = needle.Tensor([[[-0.26768908]]\n",
      "\n",
      " [[ 1.4703833 ]]])\n",
      "hidden_size = 1\n",
      "init_hidden = False\n",
      "num_layers = 2\n",
      "output_size = 1\n",
      "seq_length = 1\n",
      "seq_model  = 'rnn'\n",
      "x          = array([[0.]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:201: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "self = <models.LanguageModel object at 0x1575716d0>, embedding_size = 34\n",
      "output_size = 1, hidden_size = 1, num_layers = 2, seq_model = 'rnn'\n",
      "device = cpu(), dtype = 'float32'\n",
      "\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92m__init__\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, embedding_size, output_size, hidden_size, num_layers=\u001b[94m1\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                 seq_model=\u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, device=\u001b[94mNone\u001b[39;49;00m, dtype=\u001b[33m\"\u001b[39;49;00m\u001b[33mfloat32\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"\u001b[39;49;00m\n",
      "    \u001b[33m    Consists of an embedding layer, a sequence model (either RNN or LSTM), and a\u001b[39;49;00m\n",
      "    \u001b[33m    linear layer.\u001b[39;49;00m\n",
      "    \u001b[33m    Parameters:\u001b[39;49;00m\n",
      "    \u001b[33m    output_size: Size of dictionary\u001b[39;49;00m\n",
      "    \u001b[33m    embedding_size: Size of embeddings\u001b[39;49;00m\n",
      "    \u001b[33m    hidden_size: The number of features in the hidden state of LSTM or RNN\u001b[39;49;00m\n",
      "    \u001b[33m    seq_model: 'rnn' or 'lstm', whether to use RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    num_layers: Number of layers in RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    \"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[96msuper\u001b[39;49;00m(LanguageModel, \u001b[96mself\u001b[39;49;00m).\u001b[92m__init__\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m### BEGIN YOUR SOLUTION\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94mraise\u001b[39;49;00m \u001b[96mNotImplementedError\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       NotImplementedError\u001b[0m\n",
      "\n",
      "__class__  = <class 'models.LanguageModel'>\n",
      "device     = cpu()\n",
      "dtype      = 'float32'\n",
      "embedding_size = 34\n",
      "hidden_size = 1\n",
      "num_layers = 2\n",
      "output_size = 1\n",
      "self       = <models.LanguageModel object at 0x1575716d0>\n",
      "seq_model  = 'rnn'\n",
      "\n",
      "\u001b[1m\u001b[31mapps/models.py\u001b[0m:38: NotImplementedError\n",
      "\u001b[31m\u001b[1m_______ test_language_model_implementation[cpu-rnn-1-False-1-34-1-2-13] ________\u001b[0m\n",
      "\n",
      "seq_length = 13, num_layers = 2, batch_size = 1, embedding_size = 34\n",
      "hidden_size = 1, init_hidden = False, output_size = 1, seq_model = 'rnn'\n",
      "device = cpu()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\u001b[90m\u001b[39;49;00m\n",
      "                            init_hidden, output_size, seq_model, device):\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      ">       model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "batch_size = 1\n",
      "c0         = needle.Tensor([[[-0.63443327]]\n",
      "\n",
      " [[-1.632804  ]]])\n",
      "device     = cpu()\n",
      "embedding_size = 34\n",
      "h0         = needle.Tensor([[[0.6495195]]\n",
      "\n",
      " [[2.0180922]]])\n",
      "hidden_size = 1\n",
      "init_hidden = False\n",
      "num_layers = 2\n",
      "output_size = 1\n",
      "seq_length = 13\n",
      "seq_model  = 'rnn'\n",
      "x          = array([[0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:201: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "self = <models.LanguageModel object at 0x157572270>, embedding_size = 34\n",
      "output_size = 1, hidden_size = 1, num_layers = 2, seq_model = 'rnn'\n",
      "device = cpu(), dtype = 'float32'\n",
      "\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92m__init__\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, embedding_size, output_size, hidden_size, num_layers=\u001b[94m1\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                 seq_model=\u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, device=\u001b[94mNone\u001b[39;49;00m, dtype=\u001b[33m\"\u001b[39;49;00m\u001b[33mfloat32\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"\u001b[39;49;00m\n",
      "    \u001b[33m    Consists of an embedding layer, a sequence model (either RNN or LSTM), and a\u001b[39;49;00m\n",
      "    \u001b[33m    linear layer.\u001b[39;49;00m\n",
      "    \u001b[33m    Parameters:\u001b[39;49;00m\n",
      "    \u001b[33m    output_size: Size of dictionary\u001b[39;49;00m\n",
      "    \u001b[33m    embedding_size: Size of embeddings\u001b[39;49;00m\n",
      "    \u001b[33m    hidden_size: The number of features in the hidden state of LSTM or RNN\u001b[39;49;00m\n",
      "    \u001b[33m    seq_model: 'rnn' or 'lstm', whether to use RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    num_layers: Number of layers in RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    \"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[96msuper\u001b[39;49;00m(LanguageModel, \u001b[96mself\u001b[39;49;00m).\u001b[92m__init__\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m### BEGIN YOUR SOLUTION\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94mraise\u001b[39;49;00m \u001b[96mNotImplementedError\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       NotImplementedError\u001b[0m\n",
      "\n",
      "__class__  = <class 'models.LanguageModel'>\n",
      "device     = cpu()\n",
      "dtype      = 'float32'\n",
      "embedding_size = 34\n",
      "hidden_size = 1\n",
      "num_layers = 2\n",
      "output_size = 1\n",
      "self       = <models.LanguageModel object at 0x157572270>\n",
      "seq_model  = 'rnn'\n",
      "\n",
      "\u001b[1m\u001b[31mapps/models.py\u001b[0m:38: NotImplementedError\n",
      "\u001b[31m\u001b[1m_______ test_language_model_implementation[cpu-rnn-1-False-1-34-15-1-1] ________\u001b[0m\n",
      "\n",
      "seq_length = 1, num_layers = 1, batch_size = 15, embedding_size = 34\n",
      "hidden_size = 1, init_hidden = False, output_size = 1, seq_model = 'rnn'\n",
      "device = cpu()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\u001b[90m\u001b[39;49;00m\n",
      "                            init_hidden, output_size, seq_model, device):\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      ">       model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "batch_size = 15\n",
      "c0         = needle.Tensor([[[ 0.2890199 ]\n",
      "  [ 1.0742474 ]\n",
      "  [ 1.671132  ]\n",
      "  [-1.8815908 ]\n",
      "  [-0.1599452 ]\n",
      "  [ 0.55091715]\n",
      "  [-0.92...027]\n",
      "  [ 0.75383866]\n",
      "  [ 0.6697805 ]\n",
      "  [ 0.67018545]\n",
      "  [ 0.07449159]\n",
      "  [-0.10715851]\n",
      "  [ 0.1321494 ]\n",
      "  [ 0.10367519]]])\n",
      "device     = cpu()\n",
      "embedding_size = 34\n",
      "h0         = needle.Tensor([[[-1.4070585 ]\n",
      "  [-1.0695813 ]\n",
      "  [-0.28544822]\n",
      "  [-0.5084532 ]\n",
      "  [ 0.6082622 ]\n",
      "  [-0.05343039]\n",
      "  [ 0.59...55 ]\n",
      "  [ 0.16585295]\n",
      "  [-2.0466588 ]\n",
      "  [ 0.50417835]\n",
      "  [ 0.83135194]\n",
      "  [ 1.3346707 ]\n",
      "  [ 0.47089428]\n",
      "  [ 0.4876786 ]]])\n",
      "hidden_size = 1\n",
      "init_hidden = False\n",
      "num_layers = 1\n",
      "output_size = 1\n",
      "seq_length = 1\n",
      "seq_model  = 'rnn'\n",
      "x          = array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "      dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:201: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "self = <models.LanguageModel object at 0x157572e40>, embedding_size = 34\n",
      "output_size = 1, hidden_size = 1, num_layers = 1, seq_model = 'rnn'\n",
      "device = cpu(), dtype = 'float32'\n",
      "\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92m__init__\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, embedding_size, output_size, hidden_size, num_layers=\u001b[94m1\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                 seq_model=\u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, device=\u001b[94mNone\u001b[39;49;00m, dtype=\u001b[33m\"\u001b[39;49;00m\u001b[33mfloat32\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"\u001b[39;49;00m\n",
      "    \u001b[33m    Consists of an embedding layer, a sequence model (either RNN or LSTM), and a\u001b[39;49;00m\n",
      "    \u001b[33m    linear layer.\u001b[39;49;00m\n",
      "    \u001b[33m    Parameters:\u001b[39;49;00m\n",
      "    \u001b[33m    output_size: Size of dictionary\u001b[39;49;00m\n",
      "    \u001b[33m    embedding_size: Size of embeddings\u001b[39;49;00m\n",
      "    \u001b[33m    hidden_size: The number of features in the hidden state of LSTM or RNN\u001b[39;49;00m\n",
      "    \u001b[33m    seq_model: 'rnn' or 'lstm', whether to use RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    num_layers: Number of layers in RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    \"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[96msuper\u001b[39;49;00m(LanguageModel, \u001b[96mself\u001b[39;49;00m).\u001b[92m__init__\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m### BEGIN YOUR SOLUTION\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94mraise\u001b[39;49;00m \u001b[96mNotImplementedError\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       NotImplementedError\u001b[0m\n",
      "\n",
      "__class__  = <class 'models.LanguageModel'>\n",
      "device     = cpu()\n",
      "dtype      = 'float32'\n",
      "embedding_size = 34\n",
      "hidden_size = 1\n",
      "num_layers = 1\n",
      "output_size = 1\n",
      "self       = <models.LanguageModel object at 0x157572e40>\n",
      "seq_model  = 'rnn'\n",
      "\n",
      "\u001b[1m\u001b[31mapps/models.py\u001b[0m:38: NotImplementedError\n",
      "\u001b[31m\u001b[1m_______ test_language_model_implementation[cpu-rnn-1-False-1-34-15-1-13] _______\u001b[0m\n",
      "\n",
      "seq_length = 13, num_layers = 1, batch_size = 15, embedding_size = 34\n",
      "hidden_size = 1, init_hidden = False, output_size = 1, seq_model = 'rnn'\n",
      "device = cpu()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\u001b[90m\u001b[39;49;00m\n",
      "                            init_hidden, output_size, seq_model, device):\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      ">       model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "batch_size = 15\n",
      "c0         = needle.Tensor([[[-0.79758507]\n",
      "  [ 0.95949864]\n",
      "  [ 1.7407609 ]\n",
      "  [-0.14967822]\n",
      "  [-0.08489672]\n",
      "  [-0.9786369 ]\n",
      "  [-1.29...973]\n",
      "  [-0.47639278]\n",
      "  [ 0.60865444]\n",
      "  [ 2.036512  ]\n",
      "  [-0.478085  ]\n",
      "  [-0.48836496]\n",
      "  [ 1.0303522 ]\n",
      "  [-1.2959553 ]]])\n",
      "device     = cpu()\n",
      "embedding_size = 34\n",
      "h0         = needle.Tensor([[[ 0.34768122]\n",
      "  [ 0.5695176 ]\n",
      "  [-0.54611933]\n",
      "  [-0.04974693]\n",
      "  [ 0.06172722]\n",
      "  [-0.8397757 ]\n",
      "  [ 0.09...942]\n",
      "  [-0.99401206]\n",
      "  [ 0.1253987 ]\n",
      "  [-0.00936898]\n",
      "  [-2.1246035 ]\n",
      "  [-0.36941898]\n",
      "  [-0.60885745]\n",
      "  [-1.376379  ]]])\n",
      "hidden_size = 1\n",
      "init_hidden = False\n",
      "num_layers = 1\n",
      "output_size = 1\n",
      "seq_length = 13\n",
      "seq_model  = 'rnn'\n",
      "x          = array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0...0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "      dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:201: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "self = <models.LanguageModel object at 0x157573a10>, embedding_size = 34\n",
      "output_size = 1, hidden_size = 1, num_layers = 1, seq_model = 'rnn'\n",
      "device = cpu(), dtype = 'float32'\n",
      "\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92m__init__\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, embedding_size, output_size, hidden_size, num_layers=\u001b[94m1\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                 seq_model=\u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, device=\u001b[94mNone\u001b[39;49;00m, dtype=\u001b[33m\"\u001b[39;49;00m\u001b[33mfloat32\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"\u001b[39;49;00m\n",
      "    \u001b[33m    Consists of an embedding layer, a sequence model (either RNN or LSTM), and a\u001b[39;49;00m\n",
      "    \u001b[33m    linear layer.\u001b[39;49;00m\n",
      "    \u001b[33m    Parameters:\u001b[39;49;00m\n",
      "    \u001b[33m    output_size: Size of dictionary\u001b[39;49;00m\n",
      "    \u001b[33m    embedding_size: Size of embeddings\u001b[39;49;00m\n",
      "    \u001b[33m    hidden_size: The number of features in the hidden state of LSTM or RNN\u001b[39;49;00m\n",
      "    \u001b[33m    seq_model: 'rnn' or 'lstm', whether to use RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    num_layers: Number of layers in RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    \"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[96msuper\u001b[39;49;00m(LanguageModel, \u001b[96mself\u001b[39;49;00m).\u001b[92m__init__\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m### BEGIN YOUR SOLUTION\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94mraise\u001b[39;49;00m \u001b[96mNotImplementedError\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       NotImplementedError\u001b[0m\n",
      "\n",
      "__class__  = <class 'models.LanguageModel'>\n",
      "device     = cpu()\n",
      "dtype      = 'float32'\n",
      "embedding_size = 34\n",
      "hidden_size = 1\n",
      "num_layers = 1\n",
      "output_size = 1\n",
      "self       = <models.LanguageModel object at 0x157573a10>\n",
      "seq_model  = 'rnn'\n",
      "\n",
      "\u001b[1m\u001b[31mapps/models.py\u001b[0m:38: NotImplementedError\n",
      "\u001b[31m\u001b[1m_______ test_language_model_implementation[cpu-rnn-1-False-1-34-15-2-1] ________\u001b[0m\n",
      "\n",
      "seq_length = 1, num_layers = 2, batch_size = 15, embedding_size = 34\n",
      "hidden_size = 1, init_hidden = False, output_size = 1, seq_model = 'rnn'\n",
      "device = cpu()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\u001b[90m\u001b[39;49;00m\n",
      "                            init_hidden, output_size, seq_model, device):\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      ">       model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "batch_size = 15\n",
      "c0         = needle.Tensor([[[ 0.33554906]\n",
      "  [-0.89176446]\n",
      "  [-0.5837761 ]\n",
      "  [-0.4187147 ]\n",
      "  [-0.20707604]\n",
      "  [-1.8213238 ]\n",
      "  [ 1.00...556]\n",
      "  [ 1.0279566 ]\n",
      "  [-0.69100356]\n",
      "  [-1.0191495 ]\n",
      "  [ 0.5728706 ]\n",
      "  [ 0.1265898 ]\n",
      "  [-0.25223917]\n",
      "  [ 0.9346347 ]]])\n",
      "device     = cpu()\n",
      "embedding_size = 34\n",
      "h0         = needle.Tensor([[[ 2.299285  ]\n",
      "  [ 0.90273684]\n",
      "  [ 0.38235587]\n",
      "  [ 0.5417688 ]\n",
      "  [ 0.58244807]\n",
      "  [-0.31431425]\n",
      "  [ 0.17...985]\n",
      "  [ 2.307445  ]\n",
      "  [-1.6721666 ]\n",
      "  [ 0.1460034 ]\n",
      "  [ 0.05785487]\n",
      "  [ 0.9112908 ]\n",
      "  [ 0.87059784]\n",
      "  [-0.93809354]]])\n",
      "hidden_size = 1\n",
      "init_hidden = False\n",
      "num_layers = 2\n",
      "output_size = 1\n",
      "seq_length = 1\n",
      "seq_model  = 'rnn'\n",
      "x          = array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "      dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:201: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "self = <models.LanguageModel object at 0x157573590>, embedding_size = 34\n",
      "output_size = 1, hidden_size = 1, num_layers = 2, seq_model = 'rnn'\n",
      "device = cpu(), dtype = 'float32'\n",
      "\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92m__init__\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, embedding_size, output_size, hidden_size, num_layers=\u001b[94m1\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                 seq_model=\u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, device=\u001b[94mNone\u001b[39;49;00m, dtype=\u001b[33m\"\u001b[39;49;00m\u001b[33mfloat32\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"\u001b[39;49;00m\n",
      "    \u001b[33m    Consists of an embedding layer, a sequence model (either RNN or LSTM), and a\u001b[39;49;00m\n",
      "    \u001b[33m    linear layer.\u001b[39;49;00m\n",
      "    \u001b[33m    Parameters:\u001b[39;49;00m\n",
      "    \u001b[33m    output_size: Size of dictionary\u001b[39;49;00m\n",
      "    \u001b[33m    embedding_size: Size of embeddings\u001b[39;49;00m\n",
      "    \u001b[33m    hidden_size: The number of features in the hidden state of LSTM or RNN\u001b[39;49;00m\n",
      "    \u001b[33m    seq_model: 'rnn' or 'lstm', whether to use RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    num_layers: Number of layers in RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    \"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[96msuper\u001b[39;49;00m(LanguageModel, \u001b[96mself\u001b[39;49;00m).\u001b[92m__init__\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m### BEGIN YOUR SOLUTION\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94mraise\u001b[39;49;00m \u001b[96mNotImplementedError\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       NotImplementedError\u001b[0m\n",
      "\n",
      "__class__  = <class 'models.LanguageModel'>\n",
      "device     = cpu()\n",
      "dtype      = 'float32'\n",
      "embedding_size = 34\n",
      "hidden_size = 1\n",
      "num_layers = 2\n",
      "output_size = 1\n",
      "self       = <models.LanguageModel object at 0x157573590>\n",
      "seq_model  = 'rnn'\n",
      "\n",
      "\u001b[1m\u001b[31mapps/models.py\u001b[0m:38: NotImplementedError\n",
      "\u001b[31m\u001b[1m_______ test_language_model_implementation[cpu-rnn-1-False-1-34-15-2-13] _______\u001b[0m\n",
      "\n",
      "seq_length = 13, num_layers = 2, batch_size = 15, embedding_size = 34\n",
      "hidden_size = 1, init_hidden = False, output_size = 1, seq_model = 'rnn'\n",
      "device = cpu()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\u001b[90m\u001b[39;49;00m\n",
      "                            init_hidden, output_size, seq_model, device):\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      ">       model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "batch_size = 15\n",
      "c0         = needle.Tensor([[[ 0.14745219]\n",
      "  [ 1.087806  ]\n",
      "  [-1.4583077 ]\n",
      "  [-0.6842623 ]\n",
      "  [ 2.0154614 ]\n",
      "  [ 1.3546484 ]\n",
      "  [ 0.38...87 ]\n",
      "  [-0.48531514]\n",
      "  [ 0.10902203]\n",
      "  [-0.19793534]\n",
      "  [ 0.30895397]\n",
      "  [ 0.32101825]\n",
      "  [-0.57932734]\n",
      "  [ 0.87160873]]])\n",
      "device     = cpu()\n",
      "embedding_size = 34\n",
      "h0         = needle.Tensor([[[-1.633624  ]\n",
      "  [-1.883116  ]\n",
      "  [ 1.2035828 ]\n",
      "  [-1.7979985 ]\n",
      "  [-0.6055364 ]\n",
      "  [-1.0792046 ]\n",
      "  [-0.31...72 ]\n",
      "  [ 0.80055916]\n",
      "  [-1.0866619 ]\n",
      "  [-0.39712512]\n",
      "  [-0.25202912]\n",
      "  [ 1.3695183 ]\n",
      "  [ 0.60678315]\n",
      "  [-1.0994647 ]]])\n",
      "hidden_size = 1\n",
      "init_hidden = False\n",
      "num_layers = 2\n",
      "output_size = 1\n",
      "seq_length = 13\n",
      "seq_model  = 'rnn'\n",
      "x          = array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0...0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "      dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:201: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "self = <models.LanguageModel object at 0x15753b6b0>, embedding_size = 34\n",
      "output_size = 1, hidden_size = 1, num_layers = 2, seq_model = 'rnn'\n",
      "device = cpu(), dtype = 'float32'\n",
      "\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92m__init__\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, embedding_size, output_size, hidden_size, num_layers=\u001b[94m1\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                 seq_model=\u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, device=\u001b[94mNone\u001b[39;49;00m, dtype=\u001b[33m\"\u001b[39;49;00m\u001b[33mfloat32\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"\u001b[39;49;00m\n",
      "    \u001b[33m    Consists of an embedding layer, a sequence model (either RNN or LSTM), and a\u001b[39;49;00m\n",
      "    \u001b[33m    linear layer.\u001b[39;49;00m\n",
      "    \u001b[33m    Parameters:\u001b[39;49;00m\n",
      "    \u001b[33m    output_size: Size of dictionary\u001b[39;49;00m\n",
      "    \u001b[33m    embedding_size: Size of embeddings\u001b[39;49;00m\n",
      "    \u001b[33m    hidden_size: The number of features in the hidden state of LSTM or RNN\u001b[39;49;00m\n",
      "    \u001b[33m    seq_model: 'rnn' or 'lstm', whether to use RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    num_layers: Number of layers in RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    \"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[96msuper\u001b[39;49;00m(LanguageModel, \u001b[96mself\u001b[39;49;00m).\u001b[92m__init__\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m### BEGIN YOUR SOLUTION\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94mraise\u001b[39;49;00m \u001b[96mNotImplementedError\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       NotImplementedError\u001b[0m\n",
      "\n",
      "__class__  = <class 'models.LanguageModel'>\n",
      "device     = cpu()\n",
      "dtype      = 'float32'\n",
      "embedding_size = 34\n",
      "hidden_size = 1\n",
      "num_layers = 2\n",
      "output_size = 1\n",
      "self       = <models.LanguageModel object at 0x15753b6b0>\n",
      "seq_model  = 'rnn'\n",
      "\n",
      "\u001b[1m\u001b[31mapps/models.py\u001b[0m:38: NotImplementedError\n",
      "\u001b[31m\u001b[1m________ test_language_model_implementation[cpu-rnn-1-False-12-1-1-1-1] ________\u001b[0m\n",
      "\n",
      "seq_length = 1, num_layers = 1, batch_size = 1, embedding_size = 1\n",
      "hidden_size = 12, init_hidden = False, output_size = 1, seq_model = 'rnn'\n",
      "device = cpu()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\u001b[90m\u001b[39;49;00m\n",
      "                            init_hidden, output_size, seq_model, device):\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      ">       model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "batch_size = 1\n",
      "c0         = needle.Tensor([[[ 0.70449406 -0.19888376 -0.8001651  -1.3643508  -0.41026437\n",
      "    0.5369689   0.21011923  0.45299894  0.42057052  0.6466239\n",
      "   -0.06336317 -1.6751385 ]]])\n",
      "device     = cpu()\n",
      "embedding_size = 1\n",
      "h0         = needle.Tensor([[[ 0.6649214   0.01860549 -0.02754527 -0.15363753 -0.32825783\n",
      "   -1.0648812  -0.804535   -0.45373288  1.7315781  -1.3273187\n",
      "   -0.7590118   0.12748414]]])\n",
      "hidden_size = 12\n",
      "init_hidden = False\n",
      "num_layers = 1\n",
      "output_size = 1\n",
      "seq_length = 1\n",
      "seq_model  = 'rnn'\n",
      "x          = array([[0.]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:201: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "self = <models.LanguageModel object at 0x157573770>, embedding_size = 1\n",
      "output_size = 1, hidden_size = 12, num_layers = 1, seq_model = 'rnn'\n",
      "device = cpu(), dtype = 'float32'\n",
      "\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92m__init__\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, embedding_size, output_size, hidden_size, num_layers=\u001b[94m1\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                 seq_model=\u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, device=\u001b[94mNone\u001b[39;49;00m, dtype=\u001b[33m\"\u001b[39;49;00m\u001b[33mfloat32\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"\u001b[39;49;00m\n",
      "    \u001b[33m    Consists of an embedding layer, a sequence model (either RNN or LSTM), and a\u001b[39;49;00m\n",
      "    \u001b[33m    linear layer.\u001b[39;49;00m\n",
      "    \u001b[33m    Parameters:\u001b[39;49;00m\n",
      "    \u001b[33m    output_size: Size of dictionary\u001b[39;49;00m\n",
      "    \u001b[33m    embedding_size: Size of embeddings\u001b[39;49;00m\n",
      "    \u001b[33m    hidden_size: The number of features in the hidden state of LSTM or RNN\u001b[39;49;00m\n",
      "    \u001b[33m    seq_model: 'rnn' or 'lstm', whether to use RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    num_layers: Number of layers in RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    \"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[96msuper\u001b[39;49;00m(LanguageModel, \u001b[96mself\u001b[39;49;00m).\u001b[92m__init__\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m### BEGIN YOUR SOLUTION\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94mraise\u001b[39;49;00m \u001b[96mNotImplementedError\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       NotImplementedError\u001b[0m\n",
      "\n",
      "__class__  = <class 'models.LanguageModel'>\n",
      "device     = cpu()\n",
      "dtype      = 'float32'\n",
      "embedding_size = 1\n",
      "hidden_size = 12\n",
      "num_layers = 1\n",
      "output_size = 1\n",
      "self       = <models.LanguageModel object at 0x157573770>\n",
      "seq_model  = 'rnn'\n",
      "\n",
      "\u001b[1m\u001b[31mapps/models.py\u001b[0m:38: NotImplementedError\n",
      "\u001b[31m\u001b[1m_______ test_language_model_implementation[cpu-rnn-1-False-12-1-1-1-13] ________\u001b[0m\n",
      "\n",
      "seq_length = 13, num_layers = 1, batch_size = 1, embedding_size = 1\n",
      "hidden_size = 12, init_hidden = False, output_size = 1, seq_model = 'rnn'\n",
      "device = cpu()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\u001b[90m\u001b[39;49;00m\n",
      "                            init_hidden, output_size, seq_model, device):\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      ">       model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "batch_size = 1\n",
      "c0         = needle.Tensor([[[-0.9427954  -1.9210439   0.8329545  -0.90566343  0.09629202\n",
      "    1.718772    0.17082411  1.887053    1.9258986   0.7804652\n",
      "    0.9570188   0.3335438 ]]])\n",
      "device     = cpu()\n",
      "embedding_size = 1\n",
      "h0         = needle.Tensor([[[ 1.2062615   1.3163917   0.3449882  -2.2385197  -1.1789621\n",
      "    1.7376962   1.6578919  -0.60035384  0.1809476  -1.0877496\n",
      "    0.7626452  -0.2368808 ]]])\n",
      "hidden_size = 12\n",
      "init_hidden = False\n",
      "num_layers = 1\n",
      "output_size = 1\n",
      "seq_length = 13\n",
      "seq_model  = 'rnn'\n",
      "x          = array([[0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:201: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "self = <models.LanguageModel object at 0x157570500>, embedding_size = 1\n",
      "output_size = 1, hidden_size = 12, num_layers = 1, seq_model = 'rnn'\n",
      "device = cpu(), dtype = 'float32'\n",
      "\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92m__init__\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, embedding_size, output_size, hidden_size, num_layers=\u001b[94m1\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                 seq_model=\u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, device=\u001b[94mNone\u001b[39;49;00m, dtype=\u001b[33m\"\u001b[39;49;00m\u001b[33mfloat32\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"\u001b[39;49;00m\n",
      "    \u001b[33m    Consists of an embedding layer, a sequence model (either RNN or LSTM), and a\u001b[39;49;00m\n",
      "    \u001b[33m    linear layer.\u001b[39;49;00m\n",
      "    \u001b[33m    Parameters:\u001b[39;49;00m\n",
      "    \u001b[33m    output_size: Size of dictionary\u001b[39;49;00m\n",
      "    \u001b[33m    embedding_size: Size of embeddings\u001b[39;49;00m\n",
      "    \u001b[33m    hidden_size: The number of features in the hidden state of LSTM or RNN\u001b[39;49;00m\n",
      "    \u001b[33m    seq_model: 'rnn' or 'lstm', whether to use RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    num_layers: Number of layers in RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    \"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[96msuper\u001b[39;49;00m(LanguageModel, \u001b[96mself\u001b[39;49;00m).\u001b[92m__init__\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m### BEGIN YOUR SOLUTION\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94mraise\u001b[39;49;00m \u001b[96mNotImplementedError\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       NotImplementedError\u001b[0m\n",
      "\n",
      "__class__  = <class 'models.LanguageModel'>\n",
      "device     = cpu()\n",
      "dtype      = 'float32'\n",
      "embedding_size = 1\n",
      "hidden_size = 12\n",
      "num_layers = 1\n",
      "output_size = 1\n",
      "self       = <models.LanguageModel object at 0x157570500>\n",
      "seq_model  = 'rnn'\n",
      "\n",
      "\u001b[1m\u001b[31mapps/models.py\u001b[0m:38: NotImplementedError\n",
      "\u001b[31m\u001b[1m________ test_language_model_implementation[cpu-rnn-1-False-12-1-1-2-1] ________\u001b[0m\n",
      "\n",
      "seq_length = 1, num_layers = 2, batch_size = 1, embedding_size = 1\n",
      "hidden_size = 12, init_hidden = False, output_size = 1, seq_model = 'rnn'\n",
      "device = cpu()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\u001b[90m\u001b[39;49;00m\n",
      "                            init_hidden, output_size, seq_model, device):\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      ">       model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "batch_size = 1\n",
      "c0         = needle.Tensor([[[-0.06986237  0.44766515 -1.472785   -2.3975205  -0.15850265\n",
      "   -0.20040135 -0.37015533 -1.173495   -1...62  -0.66807675 -1.5923059\n",
      "   -1.5456218  -0.4060348  -0.49638316  0.6362443   1.1727791\n",
      "   -1.2439574  -0.48218754]]])\n",
      "device     = cpu()\n",
      "embedding_size = 1\n",
      "h0         = needle.Tensor([[[-0.06436208 -1.690757    1.3521905  -0.3318443  -0.34100726\n",
      "    0.88879603 -1.5401894  -0.14547336  0...   -0.03756098  0.14156732\n",
      "   -0.95844793 -0.88823783 -1.2304187  -0.3002827  -0.1951182\n",
      "    1.1175877   1.753931  ]]])\n",
      "hidden_size = 12\n",
      "init_hidden = False\n",
      "num_layers = 2\n",
      "output_size = 1\n",
      "seq_length = 1\n",
      "seq_model  = 'rnn'\n",
      "x          = array([[0.]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:201: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "self = <models.LanguageModel object at 0x1575e1310>, embedding_size = 1\n",
      "output_size = 1, hidden_size = 12, num_layers = 2, seq_model = 'rnn'\n",
      "device = cpu(), dtype = 'float32'\n",
      "\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92m__init__\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, embedding_size, output_size, hidden_size, num_layers=\u001b[94m1\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                 seq_model=\u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, device=\u001b[94mNone\u001b[39;49;00m, dtype=\u001b[33m\"\u001b[39;49;00m\u001b[33mfloat32\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"\u001b[39;49;00m\n",
      "    \u001b[33m    Consists of an embedding layer, a sequence model (either RNN or LSTM), and a\u001b[39;49;00m\n",
      "    \u001b[33m    linear layer.\u001b[39;49;00m\n",
      "    \u001b[33m    Parameters:\u001b[39;49;00m\n",
      "    \u001b[33m    output_size: Size of dictionary\u001b[39;49;00m\n",
      "    \u001b[33m    embedding_size: Size of embeddings\u001b[39;49;00m\n",
      "    \u001b[33m    hidden_size: The number of features in the hidden state of LSTM or RNN\u001b[39;49;00m\n",
      "    \u001b[33m    seq_model: 'rnn' or 'lstm', whether to use RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    num_layers: Number of layers in RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    \"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[96msuper\u001b[39;49;00m(LanguageModel, \u001b[96mself\u001b[39;49;00m).\u001b[92m__init__\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m### BEGIN YOUR SOLUTION\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94mraise\u001b[39;49;00m \u001b[96mNotImplementedError\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       NotImplementedError\u001b[0m\n",
      "\n",
      "__class__  = <class 'models.LanguageModel'>\n",
      "device     = cpu()\n",
      "dtype      = 'float32'\n",
      "embedding_size = 1\n",
      "hidden_size = 12\n",
      "num_layers = 2\n",
      "output_size = 1\n",
      "self       = <models.LanguageModel object at 0x1575e1310>\n",
      "seq_model  = 'rnn'\n",
      "\n",
      "\u001b[1m\u001b[31mapps/models.py\u001b[0m:38: NotImplementedError\n",
      "\u001b[31m\u001b[1m_______ test_language_model_implementation[cpu-rnn-1-False-12-1-1-2-13] ________\u001b[0m\n",
      "\n",
      "seq_length = 13, num_layers = 2, batch_size = 1, embedding_size = 1\n",
      "hidden_size = 12, init_hidden = False, output_size = 1, seq_model = 'rnn'\n",
      "device = cpu()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\u001b[90m\u001b[39;49;00m\n",
      "                            init_hidden, output_size, seq_model, device):\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      ">       model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "batch_size = 1\n",
      "c0         = needle.Tensor([[[ 0.8466815  -0.3062413   0.63241625  0.31242087 -0.42876074\n",
      "   -0.631543    0.7233847   0.51448345 -0...1706 -0.2220756  -2.636483\n",
      "   -0.6174581  -0.22716816 -0.22552367 -0.15370494 -1.4279032\n",
      "   -0.2018288  -0.31622577]]])\n",
      "device     = cpu()\n",
      "embedding_size = 1\n",
      "h0         = needle.Tensor([[[ 0.73473215  0.09879227  1.9872003  -0.16875663  0.72370464\n",
      "   -1.9005221  -0.9237637   1.208665    1...464 -0.25831306 -0.5294481\n",
      "    0.31488696 -0.42839098  0.8708853   0.40565568 -0.7014336\n",
      "   -0.5794942   0.00499871]]])\n",
      "hidden_size = 12\n",
      "init_hidden = False\n",
      "num_layers = 2\n",
      "output_size = 1\n",
      "seq_length = 13\n",
      "seq_model  = 'rnn'\n",
      "x          = array([[0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:201: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "self = <models.LanguageModel object at 0x1575ce510>, embedding_size = 1\n",
      "output_size = 1, hidden_size = 12, num_layers = 2, seq_model = 'rnn'\n",
      "device = cpu(), dtype = 'float32'\n",
      "\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92m__init__\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, embedding_size, output_size, hidden_size, num_layers=\u001b[94m1\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                 seq_model=\u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, device=\u001b[94mNone\u001b[39;49;00m, dtype=\u001b[33m\"\u001b[39;49;00m\u001b[33mfloat32\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"\u001b[39;49;00m\n",
      "    \u001b[33m    Consists of an embedding layer, a sequence model (either RNN or LSTM), and a\u001b[39;49;00m\n",
      "    \u001b[33m    linear layer.\u001b[39;49;00m\n",
      "    \u001b[33m    Parameters:\u001b[39;49;00m\n",
      "    \u001b[33m    output_size: Size of dictionary\u001b[39;49;00m\n",
      "    \u001b[33m    embedding_size: Size of embeddings\u001b[39;49;00m\n",
      "    \u001b[33m    hidden_size: The number of features in the hidden state of LSTM or RNN\u001b[39;49;00m\n",
      "    \u001b[33m    seq_model: 'rnn' or 'lstm', whether to use RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    num_layers: Number of layers in RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    \"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[96msuper\u001b[39;49;00m(LanguageModel, \u001b[96mself\u001b[39;49;00m).\u001b[92m__init__\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m### BEGIN YOUR SOLUTION\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94mraise\u001b[39;49;00m \u001b[96mNotImplementedError\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       NotImplementedError\u001b[0m\n",
      "\n",
      "__class__  = <class 'models.LanguageModel'>\n",
      "device     = cpu()\n",
      "dtype      = 'float32'\n",
      "embedding_size = 1\n",
      "hidden_size = 12\n",
      "num_layers = 2\n",
      "output_size = 1\n",
      "self       = <models.LanguageModel object at 0x1575ce510>\n",
      "seq_model  = 'rnn'\n",
      "\n",
      "\u001b[1m\u001b[31mapps/models.py\u001b[0m:38: NotImplementedError\n",
      "\u001b[31m\u001b[1m_______ test_language_model_implementation[cpu-rnn-1-False-12-1-15-1-1] ________\u001b[0m\n",
      "\n",
      "seq_length = 1, num_layers = 1, batch_size = 15, embedding_size = 1\n",
      "hidden_size = 12, init_hidden = False, output_size = 1, seq_model = 'rnn'\n",
      "device = cpu()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\u001b[90m\u001b[39;49;00m\n",
      "                            init_hidden, output_size, seq_model, device):\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      ">       model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "batch_size = 15\n",
      "c0         = needle.Tensor([[[ 0.3797827  -0.7252449  -1.1321009   0.4110264   0.9545402\n",
      "    0.20013355  0.04999675 -1.151657    0....  -1.2725475   0.75290513\n",
      "    0.39425537 -0.27204084  0.306229    0.10284786 -0.72827655\n",
      "   -0.18060078 -0.79060316]]])\n",
      "device     = cpu()\n",
      "embedding_size = 1\n",
      "h0         = needle.Tensor([[[ 2.5711489   0.83004344 -0.60805243  0.4300755  -0.08924733\n",
      "   -0.5596599  -0.16450654  0.58309734  0...6854  0.03045812  1.182551\n",
      "    0.7388071   0.9264771  -0.569219    0.6406546  -0.8797288\n",
      "    1.2106296  -1.1677871 ]]])\n",
      "hidden_size = 12\n",
      "init_hidden = False\n",
      "num_layers = 1\n",
      "output_size = 1\n",
      "seq_length = 1\n",
      "seq_model  = 'rnn'\n",
      "x          = array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "      dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:201: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "self = <models.LanguageModel object at 0x1574e9e50>, embedding_size = 1\n",
      "output_size = 1, hidden_size = 12, num_layers = 1, seq_model = 'rnn'\n",
      "device = cpu(), dtype = 'float32'\n",
      "\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92m__init__\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, embedding_size, output_size, hidden_size, num_layers=\u001b[94m1\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                 seq_model=\u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, device=\u001b[94mNone\u001b[39;49;00m, dtype=\u001b[33m\"\u001b[39;49;00m\u001b[33mfloat32\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"\u001b[39;49;00m\n",
      "    \u001b[33m    Consists of an embedding layer, a sequence model (either RNN or LSTM), and a\u001b[39;49;00m\n",
      "    \u001b[33m    linear layer.\u001b[39;49;00m\n",
      "    \u001b[33m    Parameters:\u001b[39;49;00m\n",
      "    \u001b[33m    output_size: Size of dictionary\u001b[39;49;00m\n",
      "    \u001b[33m    embedding_size: Size of embeddings\u001b[39;49;00m\n",
      "    \u001b[33m    hidden_size: The number of features in the hidden state of LSTM or RNN\u001b[39;49;00m\n",
      "    \u001b[33m    seq_model: 'rnn' or 'lstm', whether to use RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    num_layers: Number of layers in RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    \"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[96msuper\u001b[39;49;00m(LanguageModel, \u001b[96mself\u001b[39;49;00m).\u001b[92m__init__\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m### BEGIN YOUR SOLUTION\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94mraise\u001b[39;49;00m \u001b[96mNotImplementedError\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       NotImplementedError\u001b[0m\n",
      "\n",
      "__class__  = <class 'models.LanguageModel'>\n",
      "device     = cpu()\n",
      "dtype      = 'float32'\n",
      "embedding_size = 1\n",
      "hidden_size = 12\n",
      "num_layers = 1\n",
      "output_size = 1\n",
      "self       = <models.LanguageModel object at 0x1574e9e50>\n",
      "seq_model  = 'rnn'\n",
      "\n",
      "\u001b[1m\u001b[31mapps/models.py\u001b[0m:38: NotImplementedError\n",
      "\u001b[31m\u001b[1m_______ test_language_model_implementation[cpu-rnn-1-False-12-1-15-1-13] _______\u001b[0m\n",
      "\n",
      "seq_length = 13, num_layers = 1, batch_size = 15, embedding_size = 1\n",
      "hidden_size = 12, init_hidden = False, output_size = 1, seq_model = 'rnn'\n",
      "device = cpu()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\u001b[90m\u001b[39;49;00m\n",
      "                            init_hidden, output_size, seq_model, device):\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      ">       model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "batch_size = 15\n",
      "c0         = needle.Tensor([[[ 1.5722681   0.9562918   1.5931054   0.27083322 -1.6326915\n",
      "   -0.5266749  -2.1565177   0.73457724  1....763 -1.2835766  -1.7621416\n",
      "    0.6781221  -0.75983167  1.3043107  -0.7610835   1.4034997\n",
      "   -0.6048094  -0.32286686]]])\n",
      "device     = cpu()\n",
      "embedding_size = 1\n",
      "h0         = needle.Tensor([[[-0.44722477  0.43477702  0.7713157  -1.6230218  -0.7623796\n",
      "   -2.0482223  -0.00555082  1.3500781  -0....94 -0.24926284 -0.5569108\n",
      "    0.48490947 -1.3938909  -1.6917499   0.17627482 -0.12204475\n",
      "    1.0795654   0.45514184]]])\n",
      "hidden_size = 12\n",
      "init_hidden = False\n",
      "num_layers = 1\n",
      "output_size = 1\n",
      "seq_length = 13\n",
      "seq_model  = 'rnn'\n",
      "x          = array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0...0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "      dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:201: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "self = <models.LanguageModel object at 0x157539700>, embedding_size = 1\n",
      "output_size = 1, hidden_size = 12, num_layers = 1, seq_model = 'rnn'\n",
      "device = cpu(), dtype = 'float32'\n",
      "\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92m__init__\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, embedding_size, output_size, hidden_size, num_layers=\u001b[94m1\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                 seq_model=\u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, device=\u001b[94mNone\u001b[39;49;00m, dtype=\u001b[33m\"\u001b[39;49;00m\u001b[33mfloat32\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"\u001b[39;49;00m\n",
      "    \u001b[33m    Consists of an embedding layer, a sequence model (either RNN or LSTM), and a\u001b[39;49;00m\n",
      "    \u001b[33m    linear layer.\u001b[39;49;00m\n",
      "    \u001b[33m    Parameters:\u001b[39;49;00m\n",
      "    \u001b[33m    output_size: Size of dictionary\u001b[39;49;00m\n",
      "    \u001b[33m    embedding_size: Size of embeddings\u001b[39;49;00m\n",
      "    \u001b[33m    hidden_size: The number of features in the hidden state of LSTM or RNN\u001b[39;49;00m\n",
      "    \u001b[33m    seq_model: 'rnn' or 'lstm', whether to use RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    num_layers: Number of layers in RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    \"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[96msuper\u001b[39;49;00m(LanguageModel, \u001b[96mself\u001b[39;49;00m).\u001b[92m__init__\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m### BEGIN YOUR SOLUTION\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94mraise\u001b[39;49;00m \u001b[96mNotImplementedError\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       NotImplementedError\u001b[0m\n",
      "\n",
      "__class__  = <class 'models.LanguageModel'>\n",
      "device     = cpu()\n",
      "dtype      = 'float32'\n",
      "embedding_size = 1\n",
      "hidden_size = 12\n",
      "num_layers = 1\n",
      "output_size = 1\n",
      "self       = <models.LanguageModel object at 0x157539700>\n",
      "seq_model  = 'rnn'\n",
      "\n",
      "\u001b[1m\u001b[31mapps/models.py\u001b[0m:38: NotImplementedError\n",
      "\u001b[31m\u001b[1m_______ test_language_model_implementation[cpu-rnn-1-False-12-1-15-2-1] ________\u001b[0m\n",
      "\n",
      "seq_length = 1, num_layers = 2, batch_size = 15, embedding_size = 1\n",
      "hidden_size = 12, init_hidden = False, output_size = 1, seq_model = 'rnn'\n",
      "device = cpu()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\u001b[90m\u001b[39;49;00m\n",
      "                            init_hidden, output_size, seq_model, device):\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      ">       model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "batch_size = 15\n",
      "c0         = needle.Tensor([[[ 0.71713275  0.04660267 -1.9108758  -0.0923579   0.590154\n",
      "   -0.4601524   1.2344692  -1.6714144   0.0...17  -0.830875    0.05043184\n",
      "   -0.16175418  0.89131963  0.6797816   0.6889057  -1.759646\n",
      "    0.658888    0.5774378 ]]])\n",
      "device     = cpu()\n",
      "embedding_size = 1\n",
      "h0         = needle.Tensor([[[-0.15132289 -0.35855898 -0.41467297  0.05066269 -0.42384505\n",
      "   -0.6487163  -1.1721328  -0.7478094  -1...2   1.484035   -0.7376482\n",
      "    0.10514748 -0.45734152 -0.27750763  0.83161527  0.09751409\n",
      "   -0.2862733   1.1951181 ]]])\n",
      "hidden_size = 12\n",
      "init_hidden = False\n",
      "num_layers = 2\n",
      "output_size = 1\n",
      "seq_length = 1\n",
      "seq_model  = 'rnn'\n",
      "x          = array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "      dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:201: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "self = <models.LanguageModel object at 0x15753a4b0>, embedding_size = 1\n",
      "output_size = 1, hidden_size = 12, num_layers = 2, seq_model = 'rnn'\n",
      "device = cpu(), dtype = 'float32'\n",
      "\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92m__init__\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, embedding_size, output_size, hidden_size, num_layers=\u001b[94m1\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                 seq_model=\u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, device=\u001b[94mNone\u001b[39;49;00m, dtype=\u001b[33m\"\u001b[39;49;00m\u001b[33mfloat32\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"\u001b[39;49;00m\n",
      "    \u001b[33m    Consists of an embedding layer, a sequence model (either RNN or LSTM), and a\u001b[39;49;00m\n",
      "    \u001b[33m    linear layer.\u001b[39;49;00m\n",
      "    \u001b[33m    Parameters:\u001b[39;49;00m\n",
      "    \u001b[33m    output_size: Size of dictionary\u001b[39;49;00m\n",
      "    \u001b[33m    embedding_size: Size of embeddings\u001b[39;49;00m\n",
      "    \u001b[33m    hidden_size: The number of features in the hidden state of LSTM or RNN\u001b[39;49;00m\n",
      "    \u001b[33m    seq_model: 'rnn' or 'lstm', whether to use RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    num_layers: Number of layers in RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    \"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[96msuper\u001b[39;49;00m(LanguageModel, \u001b[96mself\u001b[39;49;00m).\u001b[92m__init__\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m### BEGIN YOUR SOLUTION\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94mraise\u001b[39;49;00m \u001b[96mNotImplementedError\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       NotImplementedError\u001b[0m\n",
      "\n",
      "__class__  = <class 'models.LanguageModel'>\n",
      "device     = cpu()\n",
      "dtype      = 'float32'\n",
      "embedding_size = 1\n",
      "hidden_size = 12\n",
      "num_layers = 2\n",
      "output_size = 1\n",
      "self       = <models.LanguageModel object at 0x15753a4b0>\n",
      "seq_model  = 'rnn'\n",
      "\n",
      "\u001b[1m\u001b[31mapps/models.py\u001b[0m:38: NotImplementedError\n",
      "\u001b[31m\u001b[1m_______ test_language_model_implementation[cpu-rnn-1-False-12-1-15-2-13] _______\u001b[0m\n",
      "\n",
      "seq_length = 13, num_layers = 2, batch_size = 15, embedding_size = 1\n",
      "hidden_size = 12, init_hidden = False, output_size = 1, seq_model = 'rnn'\n",
      "device = cpu()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\u001b[90m\u001b[39;49;00m\n",
      "                            init_hidden, output_size, seq_model, device):\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      ">       model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "batch_size = 15\n",
      "c0         = needle.Tensor([[[ 0.08257705 -0.9133937  -0.07492342 -0.86864823  0.5701724\n",
      "   -0.42464468  1.7367004   0.03205397 -1....6879 -0.35584784 -1.0277317\n",
      "   -0.47894603  0.29339638 -1.835135   -2.7485547   1.127195\n",
      "    0.56402737  0.28466466]]])\n",
      "device     = cpu()\n",
      "embedding_size = 1\n",
      "h0         = needle.Tensor([[[ 8.93483996e-01  3.14644277e-01  7.65719473e-01  7.06399202e-01\n",
      "    1.24097407e+00 -1.75560856e+00 -3...  1.05319762e+00  5.55240452e-01 -1.13815725e+00\n",
      "   -1.06343019e+00 -8.01836669e-01  1.63111150e+00  1.01938164e+00]]])\n",
      "hidden_size = 12\n",
      "init_hidden = False\n",
      "num_layers = 2\n",
      "output_size = 1\n",
      "seq_length = 13\n",
      "seq_model  = 'rnn'\n",
      "x          = array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0...0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "      dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:201: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "self = <models.LanguageModel object at 0x157539a30>, embedding_size = 1\n",
      "output_size = 1, hidden_size = 12, num_layers = 2, seq_model = 'rnn'\n",
      "device = cpu(), dtype = 'float32'\n",
      "\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92m__init__\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, embedding_size, output_size, hidden_size, num_layers=\u001b[94m1\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                 seq_model=\u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, device=\u001b[94mNone\u001b[39;49;00m, dtype=\u001b[33m\"\u001b[39;49;00m\u001b[33mfloat32\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"\u001b[39;49;00m\n",
      "    \u001b[33m    Consists of an embedding layer, a sequence model (either RNN or LSTM), and a\u001b[39;49;00m\n",
      "    \u001b[33m    linear layer.\u001b[39;49;00m\n",
      "    \u001b[33m    Parameters:\u001b[39;49;00m\n",
      "    \u001b[33m    output_size: Size of dictionary\u001b[39;49;00m\n",
      "    \u001b[33m    embedding_size: Size of embeddings\u001b[39;49;00m\n",
      "    \u001b[33m    hidden_size: The number of features in the hidden state of LSTM or RNN\u001b[39;49;00m\n",
      "    \u001b[33m    seq_model: 'rnn' or 'lstm', whether to use RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    num_layers: Number of layers in RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    \"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[96msuper\u001b[39;49;00m(LanguageModel, \u001b[96mself\u001b[39;49;00m).\u001b[92m__init__\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m### BEGIN YOUR SOLUTION\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94mraise\u001b[39;49;00m \u001b[96mNotImplementedError\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       NotImplementedError\u001b[0m\n",
      "\n",
      "__class__  = <class 'models.LanguageModel'>\n",
      "device     = cpu()\n",
      "dtype      = 'float32'\n",
      "embedding_size = 1\n",
      "hidden_size = 12\n",
      "num_layers = 2\n",
      "output_size = 1\n",
      "self       = <models.LanguageModel object at 0x157539a30>\n",
      "seq_model  = 'rnn'\n",
      "\n",
      "\u001b[1m\u001b[31mapps/models.py\u001b[0m:38: NotImplementedError\n",
      "\u001b[31m\u001b[1m_______ test_language_model_implementation[cpu-rnn-1-False-12-34-1-1-1] ________\u001b[0m\n",
      "\n",
      "seq_length = 1, num_layers = 1, batch_size = 1, embedding_size = 34\n",
      "hidden_size = 12, init_hidden = False, output_size = 1, seq_model = 'rnn'\n",
      "device = cpu()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\u001b[90m\u001b[39;49;00m\n",
      "                            init_hidden, output_size, seq_model, device):\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      ">       model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "batch_size = 1\n",
      "c0         = needle.Tensor([[[-0.18516837  0.84843165 -0.40096086 -1.7804327   1.082468\n",
      "    0.47522092 -2.097677   -0.32779312  0.5251969  -1.3850296\n",
      "    0.30497232  0.7304721 ]]])\n",
      "device     = cpu()\n",
      "embedding_size = 34\n",
      "h0         = needle.Tensor([[[ 0.23308843  0.6777615  -0.8824779  -0.00534214  0.32177678\n",
      "   -0.09992857  1.8793154   0.2750865  -0.49947745  0.29224676\n",
      "    1.3819755   0.12627651]]])\n",
      "hidden_size = 12\n",
      "init_hidden = False\n",
      "num_layers = 1\n",
      "output_size = 1\n",
      "seq_length = 1\n",
      "seq_model  = 'rnn'\n",
      "x          = array([[0.]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:201: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "self = <models.LanguageModel object at 0x157504530>, embedding_size = 34\n",
      "output_size = 1, hidden_size = 12, num_layers = 1, seq_model = 'rnn'\n",
      "device = cpu(), dtype = 'float32'\n",
      "\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92m__init__\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, embedding_size, output_size, hidden_size, num_layers=\u001b[94m1\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                 seq_model=\u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, device=\u001b[94mNone\u001b[39;49;00m, dtype=\u001b[33m\"\u001b[39;49;00m\u001b[33mfloat32\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"\u001b[39;49;00m\n",
      "    \u001b[33m    Consists of an embedding layer, a sequence model (either RNN or LSTM), and a\u001b[39;49;00m\n",
      "    \u001b[33m    linear layer.\u001b[39;49;00m\n",
      "    \u001b[33m    Parameters:\u001b[39;49;00m\n",
      "    \u001b[33m    output_size: Size of dictionary\u001b[39;49;00m\n",
      "    \u001b[33m    embedding_size: Size of embeddings\u001b[39;49;00m\n",
      "    \u001b[33m    hidden_size: The number of features in the hidden state of LSTM or RNN\u001b[39;49;00m\n",
      "    \u001b[33m    seq_model: 'rnn' or 'lstm', whether to use RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    num_layers: Number of layers in RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    \"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[96msuper\u001b[39;49;00m(LanguageModel, \u001b[96mself\u001b[39;49;00m).\u001b[92m__init__\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m### BEGIN YOUR SOLUTION\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94mraise\u001b[39;49;00m \u001b[96mNotImplementedError\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       NotImplementedError\u001b[0m\n",
      "\n",
      "__class__  = <class 'models.LanguageModel'>\n",
      "device     = cpu()\n",
      "dtype      = 'float32'\n",
      "embedding_size = 34\n",
      "hidden_size = 12\n",
      "num_layers = 1\n",
      "output_size = 1\n",
      "self       = <models.LanguageModel object at 0x157504530>\n",
      "seq_model  = 'rnn'\n",
      "\n",
      "\u001b[1m\u001b[31mapps/models.py\u001b[0m:38: NotImplementedError\n",
      "\u001b[31m\u001b[1m_______ test_language_model_implementation[cpu-rnn-1-False-12-34-1-1-13] _______\u001b[0m\n",
      "\n",
      "seq_length = 13, num_layers = 1, batch_size = 1, embedding_size = 34\n",
      "hidden_size = 12, init_hidden = False, output_size = 1, seq_model = 'rnn'\n",
      "device = cpu()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\u001b[90m\u001b[39;49;00m\n",
      "                            init_hidden, output_size, seq_model, device):\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      ">       model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "batch_size = 1\n",
      "c0         = needle.Tensor([[[-0.29261518 -0.84439415 -1.7771282  -0.3929005   0.96899134\n",
      "   -1.0501395   1.5415207  -1.1725138   1.2698616  -2.9738357\n",
      "    1.3037968   1.5327872 ]]])\n",
      "device     = cpu()\n",
      "embedding_size = 34\n",
      "h0         = needle.Tensor([[[ 1.234556    0.09797247  0.8246531   1.3023902  -0.38387185\n",
      "   -0.58285433  0.17511131  0.30708224  0.48296863 -0.3992309\n",
      "   -0.389272   -0.6375216 ]]])\n",
      "hidden_size = 12\n",
      "init_hidden = False\n",
      "num_layers = 1\n",
      "output_size = 1\n",
      "seq_length = 13\n",
      "seq_model  = 'rnn'\n",
      "x          = array([[0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:201: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "self = <models.LanguageModel object at 0x1575e1700>, embedding_size = 34\n",
      "output_size = 1, hidden_size = 12, num_layers = 1, seq_model = 'rnn'\n",
      "device = cpu(), dtype = 'float32'\n",
      "\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92m__init__\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, embedding_size, output_size, hidden_size, num_layers=\u001b[94m1\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                 seq_model=\u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, device=\u001b[94mNone\u001b[39;49;00m, dtype=\u001b[33m\"\u001b[39;49;00m\u001b[33mfloat32\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"\u001b[39;49;00m\n",
      "    \u001b[33m    Consists of an embedding layer, a sequence model (either RNN or LSTM), and a\u001b[39;49;00m\n",
      "    \u001b[33m    linear layer.\u001b[39;49;00m\n",
      "    \u001b[33m    Parameters:\u001b[39;49;00m\n",
      "    \u001b[33m    output_size: Size of dictionary\u001b[39;49;00m\n",
      "    \u001b[33m    embedding_size: Size of embeddings\u001b[39;49;00m\n",
      "    \u001b[33m    hidden_size: The number of features in the hidden state of LSTM or RNN\u001b[39;49;00m\n",
      "    \u001b[33m    seq_model: 'rnn' or 'lstm', whether to use RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    num_layers: Number of layers in RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    \"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[96msuper\u001b[39;49;00m(LanguageModel, \u001b[96mself\u001b[39;49;00m).\u001b[92m__init__\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m### BEGIN YOUR SOLUTION\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94mraise\u001b[39;49;00m \u001b[96mNotImplementedError\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       NotImplementedError\u001b[0m\n",
      "\n",
      "__class__  = <class 'models.LanguageModel'>\n",
      "device     = cpu()\n",
      "dtype      = 'float32'\n",
      "embedding_size = 34\n",
      "hidden_size = 12\n",
      "num_layers = 1\n",
      "output_size = 1\n",
      "self       = <models.LanguageModel object at 0x1575e1700>\n",
      "seq_model  = 'rnn'\n",
      "\n",
      "\u001b[1m\u001b[31mapps/models.py\u001b[0m:38: NotImplementedError\n",
      "\u001b[31m\u001b[1m_______ test_language_model_implementation[cpu-rnn-1-False-12-34-1-2-1] ________\u001b[0m\n",
      "\n",
      "seq_length = 1, num_layers = 2, batch_size = 1, embedding_size = 34\n",
      "hidden_size = 12, init_hidden = False, output_size = 1, seq_model = 'rnn'\n",
      "device = cpu()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\u001b[90m\u001b[39;49;00m\n",
      "                            init_hidden, output_size, seq_model, device):\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      ">       model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "batch_size = 1\n",
      "c0         = needle.Tensor([[[ 1.6446984   0.32776996 -2.526211   -0.6018761  -0.4011512\n",
      "   -0.37099785  2.1477838  -0.45267797 -1....16  -0.30463257  0.8700834\n",
      "    0.9606095   0.680513   -1.5242597  -0.3336345  -1.0910276\n",
      "    0.16599655 -1.2498497 ]]])\n",
      "device     = cpu()\n",
      "embedding_size = 34\n",
      "h0         = needle.Tensor([[[ 0.9878546  -0.91354185  0.96553874 -1.7671269   1.6991084\n",
      "   -0.4997083  -1.5901794  -0.23410472 -1....6 -1.861989    0.90838385\n",
      "   -0.58474666  1.7227957   1.1678298  -1.6334429  -0.47328436\n",
      "   -0.08037422 -1.4044303 ]]])\n",
      "hidden_size = 12\n",
      "init_hidden = False\n",
      "num_layers = 2\n",
      "output_size = 1\n",
      "seq_length = 1\n",
      "seq_model  = 'rnn'\n",
      "x          = array([[0.]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:201: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "self = <models.LanguageModel object at 0x1574b9e20>, embedding_size = 34\n",
      "output_size = 1, hidden_size = 12, num_layers = 2, seq_model = 'rnn'\n",
      "device = cpu(), dtype = 'float32'\n",
      "\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92m__init__\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, embedding_size, output_size, hidden_size, num_layers=\u001b[94m1\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                 seq_model=\u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, device=\u001b[94mNone\u001b[39;49;00m, dtype=\u001b[33m\"\u001b[39;49;00m\u001b[33mfloat32\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"\u001b[39;49;00m\n",
      "    \u001b[33m    Consists of an embedding layer, a sequence model (either RNN or LSTM), and a\u001b[39;49;00m\n",
      "    \u001b[33m    linear layer.\u001b[39;49;00m\n",
      "    \u001b[33m    Parameters:\u001b[39;49;00m\n",
      "    \u001b[33m    output_size: Size of dictionary\u001b[39;49;00m\n",
      "    \u001b[33m    embedding_size: Size of embeddings\u001b[39;49;00m\n",
      "    \u001b[33m    hidden_size: The number of features in the hidden state of LSTM or RNN\u001b[39;49;00m\n",
      "    \u001b[33m    seq_model: 'rnn' or 'lstm', whether to use RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    num_layers: Number of layers in RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    \"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[96msuper\u001b[39;49;00m(LanguageModel, \u001b[96mself\u001b[39;49;00m).\u001b[92m__init__\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m### BEGIN YOUR SOLUTION\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94mraise\u001b[39;49;00m \u001b[96mNotImplementedError\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       NotImplementedError\u001b[0m\n",
      "\n",
      "__class__  = <class 'models.LanguageModel'>\n",
      "device     = cpu()\n",
      "dtype      = 'float32'\n",
      "embedding_size = 34\n",
      "hidden_size = 12\n",
      "num_layers = 2\n",
      "output_size = 1\n",
      "self       = <models.LanguageModel object at 0x1574b9e20>\n",
      "seq_model  = 'rnn'\n",
      "\n",
      "\u001b[1m\u001b[31mapps/models.py\u001b[0m:38: NotImplementedError\n",
      "\u001b[31m\u001b[1m_______ test_language_model_implementation[cpu-rnn-1-False-12-34-1-2-13] _______\u001b[0m\n",
      "\n",
      "seq_length = 13, num_layers = 2, batch_size = 1, embedding_size = 34\n",
      "hidden_size = 12, init_hidden = False, output_size = 1, seq_model = 'rnn'\n",
      "device = cpu()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\u001b[90m\u001b[39;49;00m\n",
      "                            init_hidden, output_size, seq_model, device):\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      ">       model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "batch_size = 1\n",
      "c0         = needle.Tensor([[[-1.0933275  -0.33842522  1.062837   -0.15936224  2.1393554\n",
      "   -0.97184026 -0.9380997  -0.5595661   0....  -0.14082083 -0.34729955\n",
      "    0.37750864 -2.1587412  -0.00701258  1.3807257   0.38906983\n",
      "   -0.8187057  -0.08231934]]])\n",
      "device     = cpu()\n",
      "embedding_size = 34\n",
      "h0         = needle.Tensor([[[ 2.3921902  -0.770485    0.8012632   1.3547972  -1.2169852\n",
      "   -0.4982111   0.07870468 -1.1087458  -1....99 -1.4811137  -0.34614077\n",
      "    0.8336731   1.0212115   0.2176464  -1.4572057   0.6356759\n",
      "   -1.7061586   0.2062099 ]]])\n",
      "hidden_size = 12\n",
      "init_hidden = False\n",
      "num_layers = 2\n",
      "output_size = 1\n",
      "seq_length = 13\n",
      "seq_model  = 'rnn'\n",
      "x          = array([[0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:201: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "self = <models.LanguageModel object at 0x1574ebce0>, embedding_size = 34\n",
      "output_size = 1, hidden_size = 12, num_layers = 2, seq_model = 'rnn'\n",
      "device = cpu(), dtype = 'float32'\n",
      "\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92m__init__\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, embedding_size, output_size, hidden_size, num_layers=\u001b[94m1\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                 seq_model=\u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, device=\u001b[94mNone\u001b[39;49;00m, dtype=\u001b[33m\"\u001b[39;49;00m\u001b[33mfloat32\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"\u001b[39;49;00m\n",
      "    \u001b[33m    Consists of an embedding layer, a sequence model (either RNN or LSTM), and a\u001b[39;49;00m\n",
      "    \u001b[33m    linear layer.\u001b[39;49;00m\n",
      "    \u001b[33m    Parameters:\u001b[39;49;00m\n",
      "    \u001b[33m    output_size: Size of dictionary\u001b[39;49;00m\n",
      "    \u001b[33m    embedding_size: Size of embeddings\u001b[39;49;00m\n",
      "    \u001b[33m    hidden_size: The number of features in the hidden state of LSTM or RNN\u001b[39;49;00m\n",
      "    \u001b[33m    seq_model: 'rnn' or 'lstm', whether to use RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    num_layers: Number of layers in RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    \"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[96msuper\u001b[39;49;00m(LanguageModel, \u001b[96mself\u001b[39;49;00m).\u001b[92m__init__\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m### BEGIN YOUR SOLUTION\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94mraise\u001b[39;49;00m \u001b[96mNotImplementedError\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       NotImplementedError\u001b[0m\n",
      "\n",
      "__class__  = <class 'models.LanguageModel'>\n",
      "device     = cpu()\n",
      "dtype      = 'float32'\n",
      "embedding_size = 34\n",
      "hidden_size = 12\n",
      "num_layers = 2\n",
      "output_size = 1\n",
      "self       = <models.LanguageModel object at 0x1574ebce0>\n",
      "seq_model  = 'rnn'\n",
      "\n",
      "\u001b[1m\u001b[31mapps/models.py\u001b[0m:38: NotImplementedError\n",
      "\u001b[31m\u001b[1m_______ test_language_model_implementation[cpu-rnn-1-False-12-34-15-1-1] _______\u001b[0m\n",
      "\n",
      "seq_length = 1, num_layers = 1, batch_size = 15, embedding_size = 34\n",
      "hidden_size = 12, init_hidden = False, output_size = 1, seq_model = 'rnn'\n",
      "device = cpu()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\u001b[90m\u001b[39;49;00m\n",
      "                            init_hidden, output_size, seq_model, device):\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      ">       model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "batch_size = 15\n",
      "c0         = needle.Tensor([[[ 0.35188815 -0.9296509  -1.0297682  -0.37648192  0.21844634\n",
      "    0.18133076 -2.8737595   0.5415875   0...3   0.03236046  0.4000996\n",
      "   -0.8329689  -2.1228728   1.7049944  -0.28423256  0.74909276\n",
      "    0.25204194 -0.28242287]]])\n",
      "device     = cpu()\n",
      "embedding_size = 34\n",
      "h0         = needle.Tensor([[[ 1.5515622  -0.30976078  1.9709469  -0.5707163  -0.20567907\n",
      "    0.3270947   0.7321809  -0.6932914  -0...    0.8193793  -0.08732972\n",
      "   -0.43991762 -0.8511597  -1.2160093  -0.13925804 -0.4800508\n",
      "   -0.41872814  0.6130336 ]]])\n",
      "hidden_size = 12\n",
      "init_hidden = False\n",
      "num_layers = 1\n",
      "output_size = 1\n",
      "seq_length = 1\n",
      "seq_model  = 'rnn'\n",
      "x          = array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "      dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:201: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "self = <models.LanguageModel object at 0x15748ede0>, embedding_size = 34\n",
      "output_size = 1, hidden_size = 12, num_layers = 1, seq_model = 'rnn'\n",
      "device = cpu(), dtype = 'float32'\n",
      "\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92m__init__\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, embedding_size, output_size, hidden_size, num_layers=\u001b[94m1\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                 seq_model=\u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, device=\u001b[94mNone\u001b[39;49;00m, dtype=\u001b[33m\"\u001b[39;49;00m\u001b[33mfloat32\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"\u001b[39;49;00m\n",
      "    \u001b[33m    Consists of an embedding layer, a sequence model (either RNN or LSTM), and a\u001b[39;49;00m\n",
      "    \u001b[33m    linear layer.\u001b[39;49;00m\n",
      "    \u001b[33m    Parameters:\u001b[39;49;00m\n",
      "    \u001b[33m    output_size: Size of dictionary\u001b[39;49;00m\n",
      "    \u001b[33m    embedding_size: Size of embeddings\u001b[39;49;00m\n",
      "    \u001b[33m    hidden_size: The number of features in the hidden state of LSTM or RNN\u001b[39;49;00m\n",
      "    \u001b[33m    seq_model: 'rnn' or 'lstm', whether to use RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    num_layers: Number of layers in RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    \"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[96msuper\u001b[39;49;00m(LanguageModel, \u001b[96mself\u001b[39;49;00m).\u001b[92m__init__\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m### BEGIN YOUR SOLUTION\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94mraise\u001b[39;49;00m \u001b[96mNotImplementedError\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       NotImplementedError\u001b[0m\n",
      "\n",
      "__class__  = <class 'models.LanguageModel'>\n",
      "device     = cpu()\n",
      "dtype      = 'float32'\n",
      "embedding_size = 34\n",
      "hidden_size = 12\n",
      "num_layers = 1\n",
      "output_size = 1\n",
      "self       = <models.LanguageModel object at 0x15748ede0>\n",
      "seq_model  = 'rnn'\n",
      "\n",
      "\u001b[1m\u001b[31mapps/models.py\u001b[0m:38: NotImplementedError\n",
      "\u001b[31m\u001b[1m______ test_language_model_implementation[cpu-rnn-1-False-12-34-15-1-13] _______\u001b[0m\n",
      "\n",
      "seq_length = 13, num_layers = 1, batch_size = 15, embedding_size = 34\n",
      "hidden_size = 12, init_hidden = False, output_size = 1, seq_model = 'rnn'\n",
      "device = cpu()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\u001b[90m\u001b[39;49;00m\n",
      "                            init_hidden, output_size, seq_model, device):\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      ">       model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "batch_size = 15\n",
      "c0         = needle.Tensor([[[ 2.066288    0.04466493 -0.6632372   0.71252203  0.5258939\n",
      "   -0.34011003 -1.0488241   0.3207074   0....55 -0.11446822  1.2653801\n",
      "   -1.5027695  -0.3919044   0.2526938   0.47201365  0.66429317\n",
      "    0.88133687  2.287976  ]]])\n",
      "device     = cpu()\n",
      "embedding_size = 34\n",
      "h0         = needle.Tensor([[[-1.56483889e-01 -8.84848356e-01  8.72361124e-01 -6.45556390e-01\n",
      "    1.11199394e-01  8.27620983e-01 -5...  1.18138909e+00  1.32824826e+00 -3.48737955e-01\n",
      "   -2.74038106e-01 -1.09799695e+00 -1.96783471e+00 -1.42291009e+00]]])\n",
      "hidden_size = 12\n",
      "init_hidden = False\n",
      "num_layers = 1\n",
      "output_size = 1\n",
      "seq_length = 13\n",
      "seq_model  = 'rnn'\n",
      "x          = array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0...0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "      dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:201: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "self = <models.LanguageModel object at 0x157572ab0>, embedding_size = 34\n",
      "output_size = 1, hidden_size = 12, num_layers = 1, seq_model = 'rnn'\n",
      "device = cpu(), dtype = 'float32'\n",
      "\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92m__init__\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, embedding_size, output_size, hidden_size, num_layers=\u001b[94m1\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                 seq_model=\u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, device=\u001b[94mNone\u001b[39;49;00m, dtype=\u001b[33m\"\u001b[39;49;00m\u001b[33mfloat32\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"\u001b[39;49;00m\n",
      "    \u001b[33m    Consists of an embedding layer, a sequence model (either RNN or LSTM), and a\u001b[39;49;00m\n",
      "    \u001b[33m    linear layer.\u001b[39;49;00m\n",
      "    \u001b[33m    Parameters:\u001b[39;49;00m\n",
      "    \u001b[33m    output_size: Size of dictionary\u001b[39;49;00m\n",
      "    \u001b[33m    embedding_size: Size of embeddings\u001b[39;49;00m\n",
      "    \u001b[33m    hidden_size: The number of features in the hidden state of LSTM or RNN\u001b[39;49;00m\n",
      "    \u001b[33m    seq_model: 'rnn' or 'lstm', whether to use RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    num_layers: Number of layers in RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    \"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[96msuper\u001b[39;49;00m(LanguageModel, \u001b[96mself\u001b[39;49;00m).\u001b[92m__init__\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m### BEGIN YOUR SOLUTION\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94mraise\u001b[39;49;00m \u001b[96mNotImplementedError\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       NotImplementedError\u001b[0m\n",
      "\n",
      "__class__  = <class 'models.LanguageModel'>\n",
      "device     = cpu()\n",
      "dtype      = 'float32'\n",
      "embedding_size = 34\n",
      "hidden_size = 12\n",
      "num_layers = 1\n",
      "output_size = 1\n",
      "self       = <models.LanguageModel object at 0x157572ab0>\n",
      "seq_model  = 'rnn'\n",
      "\n",
      "\u001b[1m\u001b[31mapps/models.py\u001b[0m:38: NotImplementedError\n",
      "\u001b[31m\u001b[1m_______ test_language_model_implementation[cpu-rnn-1-False-12-34-15-2-1] _______\u001b[0m\n",
      "\n",
      "seq_length = 1, num_layers = 2, batch_size = 15, embedding_size = 34\n",
      "hidden_size = 12, init_hidden = False, output_size = 1, seq_model = 'rnn'\n",
      "device = cpu()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\u001b[90m\u001b[39;49;00m\n",
      "                            init_hidden, output_size, seq_model, device):\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      ">       model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "batch_size = 15\n",
      "c0         = needle.Tensor([[[-2.04815775e-01 -3.78738523e-01 -3.61049920e-01 -5.24891138e-01\n",
      "   -1.09032607e+00 -8.92781675e-01 -1... -6.93461061e-01  1.86682391e+00 -9.72330630e-01\n",
      "   -4.70717728e-01  5.75848460e-01 -1.47678900e+00 -7.98810303e-01]]])\n",
      "device     = cpu()\n",
      "embedding_size = 34\n",
      "h0         = needle.Tensor([[[ 1.8319432e-01 -6.1911219e-01 -3.0888724e+00  2.7802899e+00\n",
      "   -7.7070946e-01  1.1986561e-01 -8.89912...704e-01 -8.5211259e-01 -6.2139744e-01  1.3525114e+00\n",
      "    1.9176472e+00  2.2708995e+00 -1.8644458e-01  8.3447117e-01]]])\n",
      "hidden_size = 12\n",
      "init_hidden = False\n",
      "num_layers = 2\n",
      "output_size = 1\n",
      "seq_length = 1\n",
      "seq_model  = 'rnn'\n",
      "x          = array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "      dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:201: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "self = <models.LanguageModel object at 0x1575076b0>, embedding_size = 34\n",
      "output_size = 1, hidden_size = 12, num_layers = 2, seq_model = 'rnn'\n",
      "device = cpu(), dtype = 'float32'\n",
      "\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92m__init__\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, embedding_size, output_size, hidden_size, num_layers=\u001b[94m1\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                 seq_model=\u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, device=\u001b[94mNone\u001b[39;49;00m, dtype=\u001b[33m\"\u001b[39;49;00m\u001b[33mfloat32\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"\u001b[39;49;00m\n",
      "    \u001b[33m    Consists of an embedding layer, a sequence model (either RNN or LSTM), and a\u001b[39;49;00m\n",
      "    \u001b[33m    linear layer.\u001b[39;49;00m\n",
      "    \u001b[33m    Parameters:\u001b[39;49;00m\n",
      "    \u001b[33m    output_size: Size of dictionary\u001b[39;49;00m\n",
      "    \u001b[33m    embedding_size: Size of embeddings\u001b[39;49;00m\n",
      "    \u001b[33m    hidden_size: The number of features in the hidden state of LSTM or RNN\u001b[39;49;00m\n",
      "    \u001b[33m    seq_model: 'rnn' or 'lstm', whether to use RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    num_layers: Number of layers in RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    \"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[96msuper\u001b[39;49;00m(LanguageModel, \u001b[96mself\u001b[39;49;00m).\u001b[92m__init__\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m### BEGIN YOUR SOLUTION\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94mraise\u001b[39;49;00m \u001b[96mNotImplementedError\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       NotImplementedError\u001b[0m\n",
      "\n",
      "__class__  = <class 'models.LanguageModel'>\n",
      "device     = cpu()\n",
      "dtype      = 'float32'\n",
      "embedding_size = 34\n",
      "hidden_size = 12\n",
      "num_layers = 2\n",
      "output_size = 1\n",
      "self       = <models.LanguageModel object at 0x1575076b0>\n",
      "seq_model  = 'rnn'\n",
      "\n",
      "\u001b[1m\u001b[31mapps/models.py\u001b[0m:38: NotImplementedError\n",
      "\u001b[31m\u001b[1m______ test_language_model_implementation[cpu-rnn-1-False-12-34-15-2-13] _______\u001b[0m\n",
      "\n",
      "seq_length = 13, num_layers = 2, batch_size = 15, embedding_size = 34\n",
      "hidden_size = 12, init_hidden = False, output_size = 1, seq_model = 'rnn'\n",
      "device = cpu()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\u001b[90m\u001b[39;49;00m\n",
      "                            init_hidden, output_size, seq_model, device):\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      ">       model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "batch_size = 15\n",
      "c0         = needle.Tensor([[[ 1.71013363e-02  1.74930167e+00 -3.21078211e-01  1.11827672e+00\n",
      "    9.53765094e-01 -1.70552421e+00  1... -6.10701263e-01  7.22875953e-01 -3.07685924e+00\n",
      "   -2.11562201e-01 -8.22542489e-01  8.83387983e-01  4.96777624e-01]]])\n",
      "device     = cpu()\n",
      "embedding_size = 34\n",
      "h0         = needle.Tensor([[[-0.6967397   0.6949019  -0.7159207  -1.4277407  -0.27403766\n",
      "    2.040529    0.8710893   0.09651861  0...84  0.21997015  0.2582166\n",
      "    0.6449114   0.51691717  0.08227092  0.7761488   0.10384557\n",
      "   -0.58816206 -0.67203337]]])\n",
      "hidden_size = 12\n",
      "init_hidden = False\n",
      "num_layers = 2\n",
      "output_size = 1\n",
      "seq_length = 13\n",
      "seq_model  = 'rnn'\n",
      "x          = array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0...0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "      dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:201: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "self = <models.LanguageModel object at 0x15753b530>, embedding_size = 34\n",
      "output_size = 1, hidden_size = 12, num_layers = 2, seq_model = 'rnn'\n",
      "device = cpu(), dtype = 'float32'\n",
      "\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92m__init__\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, embedding_size, output_size, hidden_size, num_layers=\u001b[94m1\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                 seq_model=\u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, device=\u001b[94mNone\u001b[39;49;00m, dtype=\u001b[33m\"\u001b[39;49;00m\u001b[33mfloat32\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"\u001b[39;49;00m\n",
      "    \u001b[33m    Consists of an embedding layer, a sequence model (either RNN or LSTM), and a\u001b[39;49;00m\n",
      "    \u001b[33m    linear layer.\u001b[39;49;00m\n",
      "    \u001b[33m    Parameters:\u001b[39;49;00m\n",
      "    \u001b[33m    output_size: Size of dictionary\u001b[39;49;00m\n",
      "    \u001b[33m    embedding_size: Size of embeddings\u001b[39;49;00m\n",
      "    \u001b[33m    hidden_size: The number of features in the hidden state of LSTM or RNN\u001b[39;49;00m\n",
      "    \u001b[33m    seq_model: 'rnn' or 'lstm', whether to use RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    num_layers: Number of layers in RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    \"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[96msuper\u001b[39;49;00m(LanguageModel, \u001b[96mself\u001b[39;49;00m).\u001b[92m__init__\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m### BEGIN YOUR SOLUTION\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94mraise\u001b[39;49;00m \u001b[96mNotImplementedError\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       NotImplementedError\u001b[0m\n",
      "\n",
      "__class__  = <class 'models.LanguageModel'>\n",
      "device     = cpu()\n",
      "dtype      = 'float32'\n",
      "embedding_size = 34\n",
      "hidden_size = 12\n",
      "num_layers = 2\n",
      "output_size = 1\n",
      "self       = <models.LanguageModel object at 0x15753b530>\n",
      "seq_model  = 'rnn'\n",
      "\n",
      "\u001b[1m\u001b[31mapps/models.py\u001b[0m:38: NotImplementedError\n",
      "\u001b[31m\u001b[1m_______ test_language_model_implementation[cpu-rnn-1000-True-1-1-1-1-1] ________\u001b[0m\n",
      "\n",
      "seq_length = 1, num_layers = 1, batch_size = 1, embedding_size = 1\n",
      "hidden_size = 1, init_hidden = True, output_size = 1000, seq_model = 'rnn'\n",
      "device = cpu()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\u001b[90m\u001b[39;49;00m\n",
      "                            init_hidden, output_size, seq_model, device):\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      ">       model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "batch_size = 1\n",
      "c0         = needle.Tensor([[[-0.52956235]]])\n",
      "device     = cpu()\n",
      "embedding_size = 1\n",
      "h0         = needle.Tensor([[[1.5841573]]])\n",
      "hidden_size = 1\n",
      "init_hidden = True\n",
      "num_layers = 1\n",
      "output_size = 1000\n",
      "seq_length = 1\n",
      "seq_model  = 'rnn'\n",
      "x          = array([[865.]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:201: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "self = <models.LanguageModel object at 0x1575c68d0>, embedding_size = 1\n",
      "output_size = 1000, hidden_size = 1, num_layers = 1, seq_model = 'rnn'\n",
      "device = cpu(), dtype = 'float32'\n",
      "\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92m__init__\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, embedding_size, output_size, hidden_size, num_layers=\u001b[94m1\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                 seq_model=\u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, device=\u001b[94mNone\u001b[39;49;00m, dtype=\u001b[33m\"\u001b[39;49;00m\u001b[33mfloat32\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"\u001b[39;49;00m\n",
      "    \u001b[33m    Consists of an embedding layer, a sequence model (either RNN or LSTM), and a\u001b[39;49;00m\n",
      "    \u001b[33m    linear layer.\u001b[39;49;00m\n",
      "    \u001b[33m    Parameters:\u001b[39;49;00m\n",
      "    \u001b[33m    output_size: Size of dictionary\u001b[39;49;00m\n",
      "    \u001b[33m    embedding_size: Size of embeddings\u001b[39;49;00m\n",
      "    \u001b[33m    hidden_size: The number of features in the hidden state of LSTM or RNN\u001b[39;49;00m\n",
      "    \u001b[33m    seq_model: 'rnn' or 'lstm', whether to use RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    num_layers: Number of layers in RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    \"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[96msuper\u001b[39;49;00m(LanguageModel, \u001b[96mself\u001b[39;49;00m).\u001b[92m__init__\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m### BEGIN YOUR SOLUTION\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94mraise\u001b[39;49;00m \u001b[96mNotImplementedError\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       NotImplementedError\u001b[0m\n",
      "\n",
      "__class__  = <class 'models.LanguageModel'>\n",
      "device     = cpu()\n",
      "dtype      = 'float32'\n",
      "embedding_size = 1\n",
      "hidden_size = 1\n",
      "num_layers = 1\n",
      "output_size = 1000\n",
      "self       = <models.LanguageModel object at 0x1575c68d0>\n",
      "seq_model  = 'rnn'\n",
      "\n",
      "\u001b[1m\u001b[31mapps/models.py\u001b[0m:38: NotImplementedError\n",
      "\u001b[31m\u001b[1m_______ test_language_model_implementation[cpu-rnn-1000-True-1-1-1-1-13] _______\u001b[0m\n",
      "\n",
      "seq_length = 13, num_layers = 1, batch_size = 1, embedding_size = 1\n",
      "hidden_size = 1, init_hidden = True, output_size = 1000, seq_model = 'rnn'\n",
      "device = cpu()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\u001b[90m\u001b[39;49;00m\n",
      "                            init_hidden, output_size, seq_model, device):\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      ">       model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "batch_size = 1\n",
      "c0         = needle.Tensor([[[-0.3236722]]])\n",
      "device     = cpu()\n",
      "embedding_size = 1\n",
      "h0         = needle.Tensor([[[-0.74045336]]])\n",
      "hidden_size = 1\n",
      "init_hidden = True\n",
      "num_layers = 1\n",
      "output_size = 1000\n",
      "seq_length = 13\n",
      "seq_model  = 'rnn'\n",
      "x          = array([[729.],\n",
      "       [443.],\n",
      "       [763.],\n",
      "       [679.],\n",
      "       [247.],\n",
      "       [999.],\n",
      "       [365.],\n",
      "       [901.],\n",
      "       [ 75.],\n",
      "       [365.],\n",
      "       [ 73.],\n",
      "       [286.],\n",
      "       [666.]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:201: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "self = <models.LanguageModel object at 0x1575c5940>, embedding_size = 1\n",
      "output_size = 1000, hidden_size = 1, num_layers = 1, seq_model = 'rnn'\n",
      "device = cpu(), dtype = 'float32'\n",
      "\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92m__init__\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, embedding_size, output_size, hidden_size, num_layers=\u001b[94m1\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                 seq_model=\u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, device=\u001b[94mNone\u001b[39;49;00m, dtype=\u001b[33m\"\u001b[39;49;00m\u001b[33mfloat32\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"\u001b[39;49;00m\n",
      "    \u001b[33m    Consists of an embedding layer, a sequence model (either RNN or LSTM), and a\u001b[39;49;00m\n",
      "    \u001b[33m    linear layer.\u001b[39;49;00m\n",
      "    \u001b[33m    Parameters:\u001b[39;49;00m\n",
      "    \u001b[33m    output_size: Size of dictionary\u001b[39;49;00m\n",
      "    \u001b[33m    embedding_size: Size of embeddings\u001b[39;49;00m\n",
      "    \u001b[33m    hidden_size: The number of features in the hidden state of LSTM or RNN\u001b[39;49;00m\n",
      "    \u001b[33m    seq_model: 'rnn' or 'lstm', whether to use RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    num_layers: Number of layers in RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    \"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[96msuper\u001b[39;49;00m(LanguageModel, \u001b[96mself\u001b[39;49;00m).\u001b[92m__init__\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m### BEGIN YOUR SOLUTION\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94mraise\u001b[39;49;00m \u001b[96mNotImplementedError\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       NotImplementedError\u001b[0m\n",
      "\n",
      "__class__  = <class 'models.LanguageModel'>\n",
      "device     = cpu()\n",
      "dtype      = 'float32'\n",
      "embedding_size = 1\n",
      "hidden_size = 1\n",
      "num_layers = 1\n",
      "output_size = 1000\n",
      "self       = <models.LanguageModel object at 0x1575c5940>\n",
      "seq_model  = 'rnn'\n",
      "\n",
      "\u001b[1m\u001b[31mapps/models.py\u001b[0m:38: NotImplementedError\n",
      "\u001b[31m\u001b[1m_______ test_language_model_implementation[cpu-rnn-1000-True-1-1-1-2-1] ________\u001b[0m\n",
      "\n",
      "seq_length = 1, num_layers = 2, batch_size = 1, embedding_size = 1\n",
      "hidden_size = 1, init_hidden = True, output_size = 1000, seq_model = 'rnn'\n",
      "device = cpu()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\u001b[90m\u001b[39;49;00m\n",
      "                            init_hidden, output_size, seq_model, device):\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      ">       model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "batch_size = 1\n",
      "c0         = needle.Tensor([[[-1.0087727]]\n",
      "\n",
      " [[ 0.7420206]]])\n",
      "device     = cpu()\n",
      "embedding_size = 1\n",
      "h0         = needle.Tensor([[[-1.469012 ]]\n",
      "\n",
      " [[-0.9753243]]])\n",
      "hidden_size = 1\n",
      "init_hidden = True\n",
      "num_layers = 2\n",
      "output_size = 1000\n",
      "seq_length = 1\n",
      "seq_model  = 'rnn'\n",
      "x          = array([[15.]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:201: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "self = <models.LanguageModel object at 0x1575c4380>, embedding_size = 1\n",
      "output_size = 1000, hidden_size = 1, num_layers = 2, seq_model = 'rnn'\n",
      "device = cpu(), dtype = 'float32'\n",
      "\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92m__init__\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, embedding_size, output_size, hidden_size, num_layers=\u001b[94m1\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                 seq_model=\u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, device=\u001b[94mNone\u001b[39;49;00m, dtype=\u001b[33m\"\u001b[39;49;00m\u001b[33mfloat32\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"\u001b[39;49;00m\n",
      "    \u001b[33m    Consists of an embedding layer, a sequence model (either RNN or LSTM), and a\u001b[39;49;00m\n",
      "    \u001b[33m    linear layer.\u001b[39;49;00m\n",
      "    \u001b[33m    Parameters:\u001b[39;49;00m\n",
      "    \u001b[33m    output_size: Size of dictionary\u001b[39;49;00m\n",
      "    \u001b[33m    embedding_size: Size of embeddings\u001b[39;49;00m\n",
      "    \u001b[33m    hidden_size: The number of features in the hidden state of LSTM or RNN\u001b[39;49;00m\n",
      "    \u001b[33m    seq_model: 'rnn' or 'lstm', whether to use RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    num_layers: Number of layers in RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    \"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[96msuper\u001b[39;49;00m(LanguageModel, \u001b[96mself\u001b[39;49;00m).\u001b[92m__init__\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m### BEGIN YOUR SOLUTION\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94mraise\u001b[39;49;00m \u001b[96mNotImplementedError\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       NotImplementedError\u001b[0m\n",
      "\n",
      "__class__  = <class 'models.LanguageModel'>\n",
      "device     = cpu()\n",
      "dtype      = 'float32'\n",
      "embedding_size = 1\n",
      "hidden_size = 1\n",
      "num_layers = 2\n",
      "output_size = 1000\n",
      "self       = <models.LanguageModel object at 0x1575c4380>\n",
      "seq_model  = 'rnn'\n",
      "\n",
      "\u001b[1m\u001b[31mapps/models.py\u001b[0m:38: NotImplementedError\n",
      "\u001b[31m\u001b[1m_______ test_language_model_implementation[cpu-rnn-1000-True-1-1-1-2-13] _______\u001b[0m\n",
      "\n",
      "seq_length = 13, num_layers = 2, batch_size = 1, embedding_size = 1\n",
      "hidden_size = 1, init_hidden = True, output_size = 1000, seq_model = 'rnn'\n",
      "device = cpu()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\u001b[90m\u001b[39;49;00m\n",
      "                            init_hidden, output_size, seq_model, device):\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      ">       model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "batch_size = 1\n",
      "c0         = needle.Tensor([[[-1.4418368]]\n",
      "\n",
      " [[ 1.463462 ]]])\n",
      "device     = cpu()\n",
      "embedding_size = 1\n",
      "h0         = needle.Tensor([[[-0.06091025]]\n",
      "\n",
      " [[-0.6257162 ]]])\n",
      "hidden_size = 1\n",
      "init_hidden = True\n",
      "num_layers = 2\n",
      "output_size = 1000\n",
      "seq_length = 13\n",
      "seq_model  = 'rnn'\n",
      "x          = array([[687.],\n",
      "       [721.],\n",
      "       [146.],\n",
      "       [396.],\n",
      "       [953.],\n",
      "       [161.],\n",
      "       [ 92.],\n",
      "       [400.],\n",
      "       [491.],\n",
      "       [408.],\n",
      "       [325.],\n",
      "       [409.],\n",
      "       [479.]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:201: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "self = <models.LanguageModel object at 0x1575c58e0>, embedding_size = 1\n",
      "output_size = 1000, hidden_size = 1, num_layers = 2, seq_model = 'rnn'\n",
      "device = cpu(), dtype = 'float32'\n",
      "\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92m__init__\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, embedding_size, output_size, hidden_size, num_layers=\u001b[94m1\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                 seq_model=\u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, device=\u001b[94mNone\u001b[39;49;00m, dtype=\u001b[33m\"\u001b[39;49;00m\u001b[33mfloat32\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"\u001b[39;49;00m\n",
      "    \u001b[33m    Consists of an embedding layer, a sequence model (either RNN or LSTM), and a\u001b[39;49;00m\n",
      "    \u001b[33m    linear layer.\u001b[39;49;00m\n",
      "    \u001b[33m    Parameters:\u001b[39;49;00m\n",
      "    \u001b[33m    output_size: Size of dictionary\u001b[39;49;00m\n",
      "    \u001b[33m    embedding_size: Size of embeddings\u001b[39;49;00m\n",
      "    \u001b[33m    hidden_size: The number of features in the hidden state of LSTM or RNN\u001b[39;49;00m\n",
      "    \u001b[33m    seq_model: 'rnn' or 'lstm', whether to use RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    num_layers: Number of layers in RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    \"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[96msuper\u001b[39;49;00m(LanguageModel, \u001b[96mself\u001b[39;49;00m).\u001b[92m__init__\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m### BEGIN YOUR SOLUTION\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94mraise\u001b[39;49;00m \u001b[96mNotImplementedError\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       NotImplementedError\u001b[0m\n",
      "\n",
      "__class__  = <class 'models.LanguageModel'>\n",
      "device     = cpu()\n",
      "dtype      = 'float32'\n",
      "embedding_size = 1\n",
      "hidden_size = 1\n",
      "num_layers = 2\n",
      "output_size = 1000\n",
      "self       = <models.LanguageModel object at 0x1575c58e0>\n",
      "seq_model  = 'rnn'\n",
      "\n",
      "\u001b[1m\u001b[31mapps/models.py\u001b[0m:38: NotImplementedError\n",
      "\u001b[31m\u001b[1m_______ test_language_model_implementation[cpu-rnn-1000-True-1-1-15-1-1] _______\u001b[0m\n",
      "\n",
      "seq_length = 1, num_layers = 1, batch_size = 15, embedding_size = 1\n",
      "hidden_size = 1, init_hidden = True, output_size = 1000, seq_model = 'rnn'\n",
      "device = cpu()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\u001b[90m\u001b[39;49;00m\n",
      "                            init_hidden, output_size, seq_model, device):\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      ">       model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "batch_size = 15\n",
      "c0         = needle.Tensor([[[-0.33536378]\n",
      "  [-0.3527822 ]\n",
      "  [-0.80121607]\n",
      "  [ 0.5864015 ]\n",
      "  [ 0.51096594]\n",
      "  [-0.99677217]\n",
      "  [ 0.00...143]\n",
      "  [ 0.79439634]\n",
      "  [-1.0957028 ]\n",
      "  [-0.19293337]\n",
      "  [ 0.08198411]\n",
      "  [-0.17176469]\n",
      "  [-1.6875037 ]\n",
      "  [-0.61795247]]])\n",
      "device     = cpu()\n",
      "embedding_size = 1\n",
      "h0         = needle.Tensor([[[ 2.0758924 ]\n",
      "  [-0.5571941 ]\n",
      "  [-1.2921317 ]\n",
      "  [-0.8825191 ]\n",
      "  [ 0.7307552 ]\n",
      "  [-0.71593875]\n",
      "  [-0.15...814]\n",
      "  [-1.629311  ]\n",
      "  [-0.953445  ]\n",
      "  [ 0.2544584 ]\n",
      "  [ 1.7056148 ]\n",
      "  [ 0.32658622]\n",
      "  [ 1.1179682 ]\n",
      "  [ 0.8329803 ]]])\n",
      "hidden_size = 1\n",
      "init_hidden = True\n",
      "num_layers = 1\n",
      "output_size = 1000\n",
      "seq_length = 1\n",
      "seq_model  = 'rnn'\n",
      "x          = array([[342., 186., 348., 425., 185., 162., 140., 906., 845.,  63., 124.,\n",
      "        576., 915., 216., 508.]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:201: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "self = <models.LanguageModel object at 0x1574ba270>, embedding_size = 1\n",
      "output_size = 1000, hidden_size = 1, num_layers = 1, seq_model = 'rnn'\n",
      "device = cpu(), dtype = 'float32'\n",
      "\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92m__init__\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, embedding_size, output_size, hidden_size, num_layers=\u001b[94m1\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                 seq_model=\u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, device=\u001b[94mNone\u001b[39;49;00m, dtype=\u001b[33m\"\u001b[39;49;00m\u001b[33mfloat32\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"\u001b[39;49;00m\n",
      "    \u001b[33m    Consists of an embedding layer, a sequence model (either RNN or LSTM), and a\u001b[39;49;00m\n",
      "    \u001b[33m    linear layer.\u001b[39;49;00m\n",
      "    \u001b[33m    Parameters:\u001b[39;49;00m\n",
      "    \u001b[33m    output_size: Size of dictionary\u001b[39;49;00m\n",
      "    \u001b[33m    embedding_size: Size of embeddings\u001b[39;49;00m\n",
      "    \u001b[33m    hidden_size: The number of features in the hidden state of LSTM or RNN\u001b[39;49;00m\n",
      "    \u001b[33m    seq_model: 'rnn' or 'lstm', whether to use RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    num_layers: Number of layers in RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    \"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[96msuper\u001b[39;49;00m(LanguageModel, \u001b[96mself\u001b[39;49;00m).\u001b[92m__init__\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m### BEGIN YOUR SOLUTION\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94mraise\u001b[39;49;00m \u001b[96mNotImplementedError\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       NotImplementedError\u001b[0m\n",
      "\n",
      "__class__  = <class 'models.LanguageModel'>\n",
      "device     = cpu()\n",
      "dtype      = 'float32'\n",
      "embedding_size = 1\n",
      "hidden_size = 1\n",
      "num_layers = 1\n",
      "output_size = 1000\n",
      "self       = <models.LanguageModel object at 0x1574ba270>\n",
      "seq_model  = 'rnn'\n",
      "\n",
      "\u001b[1m\u001b[31mapps/models.py\u001b[0m:38: NotImplementedError\n",
      "\u001b[31m\u001b[1m______ test_language_model_implementation[cpu-rnn-1000-True-1-1-15-1-13] _______\u001b[0m\n",
      "\n",
      "seq_length = 13, num_layers = 1, batch_size = 15, embedding_size = 1\n",
      "hidden_size = 1, init_hidden = True, output_size = 1000, seq_model = 'rnn'\n",
      "device = cpu()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\u001b[90m\u001b[39;49;00m\n",
      "                            init_hidden, output_size, seq_model, device):\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      ">       model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "batch_size = 15\n",
      "c0         = needle.Tensor([[[-0.73804295]\n",
      "  [-0.31263173]\n",
      "  [ 0.5064766 ]\n",
      "  [ 1.0442836 ]\n",
      "  [-0.19324483]\n",
      "  [ 0.6197393 ]\n",
      "  [-0.54...33 ]\n",
      "  [ 0.23723085]\n",
      "  [ 1.1438284 ]\n",
      "  [ 0.20680709]\n",
      "  [ 1.1024399 ]\n",
      "  [-1.8882487 ]\n",
      "  [-0.47263333]\n",
      "  [-0.03160324]]])\n",
      "device     = cpu()\n",
      "embedding_size = 1\n",
      "h0         = needle.Tensor([[[ 0.6644065 ]\n",
      "  [ 1.7673849 ]\n",
      "  [ 0.865617  ]\n",
      "  [-0.12707496]\n",
      "  [ 0.33742613]\n",
      "  [-0.25690004]\n",
      "  [ 0.74...24 ]\n",
      "  [-0.20155431]\n",
      "  [ 1.718593  ]\n",
      "  [-0.89997536]\n",
      "  [-0.37776393]\n",
      "  [-1.8396733 ]\n",
      "  [-0.27369937]\n",
      "  [ 0.6952572 ]]])\n",
      "hidden_size = 1\n",
      "init_hidden = True\n",
      "num_layers = 1\n",
      "output_size = 1000\n",
      "seq_length = 13\n",
      "seq_model  = 'rnn'\n",
      "x          = array([[361.,  33., 521., 609., 268., 695., 220.,  84., 150., 283., 473.,\n",
      "        979., 811., 824.,  77.],\n",
      "       [ 77...    [642., 474., 125., 536., 412., 291., 382., 190., 380.,   4., 722.,\n",
      "        630., 252.,  36., 455.]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:201: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "self = <models.LanguageModel object at 0x1575c7710>, embedding_size = 1\n",
      "output_size = 1000, hidden_size = 1, num_layers = 1, seq_model = 'rnn'\n",
      "device = cpu(), dtype = 'float32'\n",
      "\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92m__init__\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, embedding_size, output_size, hidden_size, num_layers=\u001b[94m1\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                 seq_model=\u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, device=\u001b[94mNone\u001b[39;49;00m, dtype=\u001b[33m\"\u001b[39;49;00m\u001b[33mfloat32\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"\u001b[39;49;00m\n",
      "    \u001b[33m    Consists of an embedding layer, a sequence model (either RNN or LSTM), and a\u001b[39;49;00m\n",
      "    \u001b[33m    linear layer.\u001b[39;49;00m\n",
      "    \u001b[33m    Parameters:\u001b[39;49;00m\n",
      "    \u001b[33m    output_size: Size of dictionary\u001b[39;49;00m\n",
      "    \u001b[33m    embedding_size: Size of embeddings\u001b[39;49;00m\n",
      "    \u001b[33m    hidden_size: The number of features in the hidden state of LSTM or RNN\u001b[39;49;00m\n",
      "    \u001b[33m    seq_model: 'rnn' or 'lstm', whether to use RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    num_layers: Number of layers in RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    \"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[96msuper\u001b[39;49;00m(LanguageModel, \u001b[96mself\u001b[39;49;00m).\u001b[92m__init__\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m### BEGIN YOUR SOLUTION\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94mraise\u001b[39;49;00m \u001b[96mNotImplementedError\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       NotImplementedError\u001b[0m\n",
      "\n",
      "__class__  = <class 'models.LanguageModel'>\n",
      "device     = cpu()\n",
      "dtype      = 'float32'\n",
      "embedding_size = 1\n",
      "hidden_size = 1\n",
      "num_layers = 1\n",
      "output_size = 1000\n",
      "self       = <models.LanguageModel object at 0x1575c7710>\n",
      "seq_model  = 'rnn'\n",
      "\n",
      "\u001b[1m\u001b[31mapps/models.py\u001b[0m:38: NotImplementedError\n",
      "\u001b[31m\u001b[1m_______ test_language_model_implementation[cpu-rnn-1000-True-1-1-15-2-1] _______\u001b[0m\n",
      "\n",
      "seq_length = 1, num_layers = 2, batch_size = 15, embedding_size = 1\n",
      "hidden_size = 1, init_hidden = True, output_size = 1000, seq_model = 'rnn'\n",
      "device = cpu()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\u001b[90m\u001b[39;49;00m\n",
      "                            init_hidden, output_size, seq_model, device):\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      ">       model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "batch_size = 15\n",
      "c0         = needle.Tensor([[[ 0.9461241 ]\n",
      "  [-1.2971525 ]\n",
      "  [ 2.1637335 ]\n",
      "  [ 0.5205522 ]\n",
      "  [ 0.6258318 ]\n",
      "  [ 0.7533925 ]\n",
      "  [-0.74...618]\n",
      "  [-0.31272358]\n",
      "  [ 0.5982074 ]\n",
      "  [ 0.72254115]\n",
      "  [ 0.34575796]\n",
      "  [-0.78398436]\n",
      "  [ 0.04283158]\n",
      "  [-0.7087953 ]]])\n",
      "device     = cpu()\n",
      "embedding_size = 1\n",
      "h0         = needle.Tensor([[[-1.2233489 ]\n",
      "  [-1.6270093 ]\n",
      "  [-0.26186106]\n",
      "  [-0.97548956]\n",
      "  [ 0.5886973 ]\n",
      "  [-2.4239526 ]\n",
      "  [-1.11...05 ]\n",
      "  [-1.2165761 ]\n",
      "  [-1.6351    ]\n",
      "  [-0.6834182 ]\n",
      "  [ 0.8549731 ]\n",
      "  [-0.02866455]\n",
      "  [ 0.04898674]\n",
      "  [-0.0961371 ]]])\n",
      "hidden_size = 1\n",
      "init_hidden = True\n",
      "num_layers = 2\n",
      "output_size = 1000\n",
      "seq_length = 1\n",
      "seq_model  = 'rnn'\n",
      "x          = array([[150., 340., 693., 725., 838., 778., 383.,  46., 697., 680., 581.,\n",
      "        888., 106., 212., 832.]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:201: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "self = <models.LanguageModel object at 0x1575729c0>, embedding_size = 1\n",
      "output_size = 1000, hidden_size = 1, num_layers = 2, seq_model = 'rnn'\n",
      "device = cpu(), dtype = 'float32'\n",
      "\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92m__init__\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, embedding_size, output_size, hidden_size, num_layers=\u001b[94m1\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                 seq_model=\u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, device=\u001b[94mNone\u001b[39;49;00m, dtype=\u001b[33m\"\u001b[39;49;00m\u001b[33mfloat32\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"\u001b[39;49;00m\n",
      "    \u001b[33m    Consists of an embedding layer, a sequence model (either RNN or LSTM), and a\u001b[39;49;00m\n",
      "    \u001b[33m    linear layer.\u001b[39;49;00m\n",
      "    \u001b[33m    Parameters:\u001b[39;49;00m\n",
      "    \u001b[33m    output_size: Size of dictionary\u001b[39;49;00m\n",
      "    \u001b[33m    embedding_size: Size of embeddings\u001b[39;49;00m\n",
      "    \u001b[33m    hidden_size: The number of features in the hidden state of LSTM or RNN\u001b[39;49;00m\n",
      "    \u001b[33m    seq_model: 'rnn' or 'lstm', whether to use RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    num_layers: Number of layers in RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    \"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[96msuper\u001b[39;49;00m(LanguageModel, \u001b[96mself\u001b[39;49;00m).\u001b[92m__init__\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m### BEGIN YOUR SOLUTION\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94mraise\u001b[39;49;00m \u001b[96mNotImplementedError\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       NotImplementedError\u001b[0m\n",
      "\n",
      "__class__  = <class 'models.LanguageModel'>\n",
      "device     = cpu()\n",
      "dtype      = 'float32'\n",
      "embedding_size = 1\n",
      "hidden_size = 1\n",
      "num_layers = 2\n",
      "output_size = 1000\n",
      "self       = <models.LanguageModel object at 0x1575729c0>\n",
      "seq_model  = 'rnn'\n",
      "\n",
      "\u001b[1m\u001b[31mapps/models.py\u001b[0m:38: NotImplementedError\n",
      "\u001b[31m\u001b[1m______ test_language_model_implementation[cpu-rnn-1000-True-1-1-15-2-13] _______\u001b[0m\n",
      "\n",
      "seq_length = 13, num_layers = 2, batch_size = 15, embedding_size = 1\n",
      "hidden_size = 1, init_hidden = True, output_size = 1000, seq_model = 'rnn'\n",
      "device = cpu()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\u001b[90m\u001b[39;49;00m\n",
      "                            init_hidden, output_size, seq_model, device):\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      ">       model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "batch_size = 15\n",
      "c0         = needle.Tensor([[[-0.0316448 ]\n",
      "  [ 0.2749728 ]\n",
      "  [ 1.9425873 ]\n",
      "  [ 0.78683615]\n",
      "  [ 0.47932327]\n",
      "  [ 0.27567285]\n",
      "  [-1.18...154]\n",
      "  [ 0.6692859 ]\n",
      "  [ 0.9936586 ]\n",
      "  [-0.9664672 ]\n",
      "  [-0.564469  ]\n",
      "  [ 0.5449497 ]\n",
      "  [ 0.67536914]\n",
      "  [-0.5391992 ]]])\n",
      "device     = cpu()\n",
      "embedding_size = 1\n",
      "h0         = needle.Tensor([[[ 0.10065229]\n",
      "  [-0.56357175]\n",
      "  [-0.45626694]\n",
      "  [ 0.506624  ]\n",
      "  [ 1.1137632 ]\n",
      "  [ 0.68873215]\n",
      "  [ 0.08...49 ]\n",
      "  [ 2.4151845 ]\n",
      "  [ 0.77081287]\n",
      "  [-0.7070356 ]\n",
      "  [ 0.03712179]\n",
      "  [ 0.07501741]\n",
      "  [ 0.6993926 ]\n",
      "  [-0.17309773]]])\n",
      "hidden_size = 1\n",
      "init_hidden = True\n",
      "num_layers = 2\n",
      "output_size = 1000\n",
      "seq_length = 13\n",
      "seq_model  = 'rnn'\n",
      "x          = array([[527., 846., 972., 988., 391., 527., 379., 832., 203., 207.,  22.,\n",
      "        805., 137.,  89., 824.],\n",
      "       [672...    [940., 375.,  22., 558., 686., 507., 551., 799., 884., 304., 142.,\n",
      "        334., 420., 558., 596.]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:201: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "self = <models.LanguageModel object at 0x157504a70>, embedding_size = 1\n",
      "output_size = 1000, hidden_size = 1, num_layers = 2, seq_model = 'rnn'\n",
      "device = cpu(), dtype = 'float32'\n",
      "\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92m__init__\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, embedding_size, output_size, hidden_size, num_layers=\u001b[94m1\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                 seq_model=\u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, device=\u001b[94mNone\u001b[39;49;00m, dtype=\u001b[33m\"\u001b[39;49;00m\u001b[33mfloat32\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"\u001b[39;49;00m\n",
      "    \u001b[33m    Consists of an embedding layer, a sequence model (either RNN or LSTM), and a\u001b[39;49;00m\n",
      "    \u001b[33m    linear layer.\u001b[39;49;00m\n",
      "    \u001b[33m    Parameters:\u001b[39;49;00m\n",
      "    \u001b[33m    output_size: Size of dictionary\u001b[39;49;00m\n",
      "    \u001b[33m    embedding_size: Size of embeddings\u001b[39;49;00m\n",
      "    \u001b[33m    hidden_size: The number of features in the hidden state of LSTM or RNN\u001b[39;49;00m\n",
      "    \u001b[33m    seq_model: 'rnn' or 'lstm', whether to use RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    num_layers: Number of layers in RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    \"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[96msuper\u001b[39;49;00m(LanguageModel, \u001b[96mself\u001b[39;49;00m).\u001b[92m__init__\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m### BEGIN YOUR SOLUTION\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94mraise\u001b[39;49;00m \u001b[96mNotImplementedError\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       NotImplementedError\u001b[0m\n",
      "\n",
      "__class__  = <class 'models.LanguageModel'>\n",
      "device     = cpu()\n",
      "dtype      = 'float32'\n",
      "embedding_size = 1\n",
      "hidden_size = 1\n",
      "num_layers = 2\n",
      "output_size = 1000\n",
      "self       = <models.LanguageModel object at 0x157504a70>\n",
      "seq_model  = 'rnn'\n",
      "\n",
      "\u001b[1m\u001b[31mapps/models.py\u001b[0m:38: NotImplementedError\n",
      "\u001b[31m\u001b[1m_______ test_language_model_implementation[cpu-rnn-1000-True-1-34-1-1-1] _______\u001b[0m\n",
      "\n",
      "seq_length = 1, num_layers = 1, batch_size = 1, embedding_size = 34\n",
      "hidden_size = 1, init_hidden = True, output_size = 1000, seq_model = 'rnn'\n",
      "device = cpu()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\u001b[90m\u001b[39;49;00m\n",
      "                            init_hidden, output_size, seq_model, device):\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      ">       model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "batch_size = 1\n",
      "c0         = needle.Tensor([[[-0.83603823]]])\n",
      "device     = cpu()\n",
      "embedding_size = 34\n",
      "h0         = needle.Tensor([[[-1.7902639]]])\n",
      "hidden_size = 1\n",
      "init_hidden = True\n",
      "num_layers = 1\n",
      "output_size = 1000\n",
      "seq_length = 1\n",
      "seq_model  = 'rnn'\n",
      "x          = array([[980.]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:201: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "self = <models.LanguageModel object at 0x1575c5970>, embedding_size = 34\n",
      "output_size = 1000, hidden_size = 1, num_layers = 1, seq_model = 'rnn'\n",
      "device = cpu(), dtype = 'float32'\n",
      "\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92m__init__\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, embedding_size, output_size, hidden_size, num_layers=\u001b[94m1\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                 seq_model=\u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, device=\u001b[94mNone\u001b[39;49;00m, dtype=\u001b[33m\"\u001b[39;49;00m\u001b[33mfloat32\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"\u001b[39;49;00m\n",
      "    \u001b[33m    Consists of an embedding layer, a sequence model (either RNN or LSTM), and a\u001b[39;49;00m\n",
      "    \u001b[33m    linear layer.\u001b[39;49;00m\n",
      "    \u001b[33m    Parameters:\u001b[39;49;00m\n",
      "    \u001b[33m    output_size: Size of dictionary\u001b[39;49;00m\n",
      "    \u001b[33m    embedding_size: Size of embeddings\u001b[39;49;00m\n",
      "    \u001b[33m    hidden_size: The number of features in the hidden state of LSTM or RNN\u001b[39;49;00m\n",
      "    \u001b[33m    seq_model: 'rnn' or 'lstm', whether to use RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    num_layers: Number of layers in RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    \"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[96msuper\u001b[39;49;00m(LanguageModel, \u001b[96mself\u001b[39;49;00m).\u001b[92m__init__\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m### BEGIN YOUR SOLUTION\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94mraise\u001b[39;49;00m \u001b[96mNotImplementedError\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       NotImplementedError\u001b[0m\n",
      "\n",
      "__class__  = <class 'models.LanguageModel'>\n",
      "device     = cpu()\n",
      "dtype      = 'float32'\n",
      "embedding_size = 34\n",
      "hidden_size = 1\n",
      "num_layers = 1\n",
      "output_size = 1000\n",
      "self       = <models.LanguageModel object at 0x1575c5970>\n",
      "seq_model  = 'rnn'\n",
      "\n",
      "\u001b[1m\u001b[31mapps/models.py\u001b[0m:38: NotImplementedError\n",
      "\u001b[31m\u001b[1m______ test_language_model_implementation[cpu-rnn-1000-True-1-34-1-1-13] _______\u001b[0m\n",
      "\n",
      "seq_length = 13, num_layers = 1, batch_size = 1, embedding_size = 34\n",
      "hidden_size = 1, init_hidden = True, output_size = 1000, seq_model = 'rnn'\n",
      "device = cpu()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\u001b[90m\u001b[39;49;00m\n",
      "                            init_hidden, output_size, seq_model, device):\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      ">       model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "batch_size = 1\n",
      "c0         = needle.Tensor([[[-0.6044707]]])\n",
      "device     = cpu()\n",
      "embedding_size = 34\n",
      "h0         = needle.Tensor([[[-0.5515428]]])\n",
      "hidden_size = 1\n",
      "init_hidden = True\n",
      "num_layers = 1\n",
      "output_size = 1000\n",
      "seq_length = 13\n",
      "seq_model  = 'rnn'\n",
      "x          = array([[964.],\n",
      "       [466.],\n",
      "       [ 72.],\n",
      "       [735.],\n",
      "       [878.],\n",
      "       [934.],\n",
      "       [704.],\n",
      "       [339.],\n",
      "       [361.],\n",
      "       [388.],\n",
      "       [427.],\n",
      "       [ 98.],\n",
      "       [579.]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:201: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "self = <models.LanguageModel object at 0x1575c4fe0>, embedding_size = 34\n",
      "output_size = 1000, hidden_size = 1, num_layers = 1, seq_model = 'rnn'\n",
      "device = cpu(), dtype = 'float32'\n",
      "\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92m__init__\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, embedding_size, output_size, hidden_size, num_layers=\u001b[94m1\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                 seq_model=\u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, device=\u001b[94mNone\u001b[39;49;00m, dtype=\u001b[33m\"\u001b[39;49;00m\u001b[33mfloat32\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"\u001b[39;49;00m\n",
      "    \u001b[33m    Consists of an embedding layer, a sequence model (either RNN or LSTM), and a\u001b[39;49;00m\n",
      "    \u001b[33m    linear layer.\u001b[39;49;00m\n",
      "    \u001b[33m    Parameters:\u001b[39;49;00m\n",
      "    \u001b[33m    output_size: Size of dictionary\u001b[39;49;00m\n",
      "    \u001b[33m    embedding_size: Size of embeddings\u001b[39;49;00m\n",
      "    \u001b[33m    hidden_size: The number of features in the hidden state of LSTM or RNN\u001b[39;49;00m\n",
      "    \u001b[33m    seq_model: 'rnn' or 'lstm', whether to use RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    num_layers: Number of layers in RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    \"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[96msuper\u001b[39;49;00m(LanguageModel, \u001b[96mself\u001b[39;49;00m).\u001b[92m__init__\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m### BEGIN YOUR SOLUTION\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94mraise\u001b[39;49;00m \u001b[96mNotImplementedError\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       NotImplementedError\u001b[0m\n",
      "\n",
      "__class__  = <class 'models.LanguageModel'>\n",
      "device     = cpu()\n",
      "dtype      = 'float32'\n",
      "embedding_size = 34\n",
      "hidden_size = 1\n",
      "num_layers = 1\n",
      "output_size = 1000\n",
      "self       = <models.LanguageModel object at 0x1575c4fe0>\n",
      "seq_model  = 'rnn'\n",
      "\n",
      "\u001b[1m\u001b[31mapps/models.py\u001b[0m:38: NotImplementedError\n",
      "\u001b[31m\u001b[1m_______ test_language_model_implementation[cpu-rnn-1000-True-1-34-1-2-1] _______\u001b[0m\n",
      "\n",
      "seq_length = 1, num_layers = 2, batch_size = 1, embedding_size = 34\n",
      "hidden_size = 1, init_hidden = True, output_size = 1000, seq_model = 'rnn'\n",
      "device = cpu()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\u001b[90m\u001b[39;49;00m\n",
      "                            init_hidden, output_size, seq_model, device):\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      ">       model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "batch_size = 1\n",
      "c0         = needle.Tensor([[[0.0157521]]\n",
      "\n",
      " [[0.1439593]]])\n",
      "device     = cpu()\n",
      "embedding_size = 34\n",
      "h0         = needle.Tensor([[[1.2818164 ]]\n",
      "\n",
      " [[0.26121363]]])\n",
      "hidden_size = 1\n",
      "init_hidden = True\n",
      "num_layers = 2\n",
      "output_size = 1000\n",
      "seq_length = 1\n",
      "seq_model  = 'rnn'\n",
      "x          = array([[792.]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:201: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "self = <models.LanguageModel object at 0x15753bc50>, embedding_size = 34\n",
      "output_size = 1000, hidden_size = 1, num_layers = 2, seq_model = 'rnn'\n",
      "device = cpu(), dtype = 'float32'\n",
      "\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92m__init__\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, embedding_size, output_size, hidden_size, num_layers=\u001b[94m1\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                 seq_model=\u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, device=\u001b[94mNone\u001b[39;49;00m, dtype=\u001b[33m\"\u001b[39;49;00m\u001b[33mfloat32\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"\u001b[39;49;00m\n",
      "    \u001b[33m    Consists of an embedding layer, a sequence model (either RNN or LSTM), and a\u001b[39;49;00m\n",
      "    \u001b[33m    linear layer.\u001b[39;49;00m\n",
      "    \u001b[33m    Parameters:\u001b[39;49;00m\n",
      "    \u001b[33m    output_size: Size of dictionary\u001b[39;49;00m\n",
      "    \u001b[33m    embedding_size: Size of embeddings\u001b[39;49;00m\n",
      "    \u001b[33m    hidden_size: The number of features in the hidden state of LSTM or RNN\u001b[39;49;00m\n",
      "    \u001b[33m    seq_model: 'rnn' or 'lstm', whether to use RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    num_layers: Number of layers in RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    \"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[96msuper\u001b[39;49;00m(LanguageModel, \u001b[96mself\u001b[39;49;00m).\u001b[92m__init__\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m### BEGIN YOUR SOLUTION\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94mraise\u001b[39;49;00m \u001b[96mNotImplementedError\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       NotImplementedError\u001b[0m\n",
      "\n",
      "__class__  = <class 'models.LanguageModel'>\n",
      "device     = cpu()\n",
      "dtype      = 'float32'\n",
      "embedding_size = 34\n",
      "hidden_size = 1\n",
      "num_layers = 2\n",
      "output_size = 1000\n",
      "self       = <models.LanguageModel object at 0x15753bc50>\n",
      "seq_model  = 'rnn'\n",
      "\n",
      "\u001b[1m\u001b[31mapps/models.py\u001b[0m:38: NotImplementedError\n",
      "\u001b[31m\u001b[1m______ test_language_model_implementation[cpu-rnn-1000-True-1-34-1-2-13] _______\u001b[0m\n",
      "\n",
      "seq_length = 13, num_layers = 2, batch_size = 1, embedding_size = 34\n",
      "hidden_size = 1, init_hidden = True, output_size = 1000, seq_model = 'rnn'\n",
      "device = cpu()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\u001b[90m\u001b[39;49;00m\n",
      "                            init_hidden, output_size, seq_model, device):\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      ">       model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "batch_size = 1\n",
      "c0         = needle.Tensor([[[-0.29894355]]\n",
      "\n",
      " [[ 1.2706147 ]]])\n",
      "device     = cpu()\n",
      "embedding_size = 34\n",
      "h0         = needle.Tensor([[[0.00707644]]\n",
      "\n",
      " [[0.5254786 ]]])\n",
      "hidden_size = 1\n",
      "init_hidden = True\n",
      "num_layers = 2\n",
      "output_size = 1000\n",
      "seq_length = 13\n",
      "seq_model  = 'rnn'\n",
      "x          = array([[528.],\n",
      "       [545.],\n",
      "       [851.],\n",
      "       [850.],\n",
      "       [370.],\n",
      "       [  2.],\n",
      "       [614.],\n",
      "       [136.],\n",
      "       [133.],\n",
      "       [657.],\n",
      "       [ 71.],\n",
      "       [729.],\n",
      "       [132.]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:201: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "self = <models.LanguageModel object at 0x15753b4a0>, embedding_size = 34\n",
      "output_size = 1000, hidden_size = 1, num_layers = 2, seq_model = 'rnn'\n",
      "device = cpu(), dtype = 'float32'\n",
      "\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92m__init__\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, embedding_size, output_size, hidden_size, num_layers=\u001b[94m1\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                 seq_model=\u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, device=\u001b[94mNone\u001b[39;49;00m, dtype=\u001b[33m\"\u001b[39;49;00m\u001b[33mfloat32\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"\u001b[39;49;00m\n",
      "    \u001b[33m    Consists of an embedding layer, a sequence model (either RNN or LSTM), and a\u001b[39;49;00m\n",
      "    \u001b[33m    linear layer.\u001b[39;49;00m\n",
      "    \u001b[33m    Parameters:\u001b[39;49;00m\n",
      "    \u001b[33m    output_size: Size of dictionary\u001b[39;49;00m\n",
      "    \u001b[33m    embedding_size: Size of embeddings\u001b[39;49;00m\n",
      "    \u001b[33m    hidden_size: The number of features in the hidden state of LSTM or RNN\u001b[39;49;00m\n",
      "    \u001b[33m    seq_model: 'rnn' or 'lstm', whether to use RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    num_layers: Number of layers in RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    \"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[96msuper\u001b[39;49;00m(LanguageModel, \u001b[96mself\u001b[39;49;00m).\u001b[92m__init__\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m### BEGIN YOUR SOLUTION\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94mraise\u001b[39;49;00m \u001b[96mNotImplementedError\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       NotImplementedError\u001b[0m\n",
      "\n",
      "__class__  = <class 'models.LanguageModel'>\n",
      "device     = cpu()\n",
      "dtype      = 'float32'\n",
      "embedding_size = 34\n",
      "hidden_size = 1\n",
      "num_layers = 2\n",
      "output_size = 1000\n",
      "self       = <models.LanguageModel object at 0x15753b4a0>\n",
      "seq_model  = 'rnn'\n",
      "\n",
      "\u001b[1m\u001b[31mapps/models.py\u001b[0m:38: NotImplementedError\n",
      "\u001b[31m\u001b[1m______ test_language_model_implementation[cpu-rnn-1000-True-1-34-15-1-1] _______\u001b[0m\n",
      "\n",
      "seq_length = 1, num_layers = 1, batch_size = 15, embedding_size = 34\n",
      "hidden_size = 1, init_hidden = True, output_size = 1000, seq_model = 'rnn'\n",
      "device = cpu()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\u001b[90m\u001b[39;49;00m\n",
      "                            init_hidden, output_size, seq_model, device):\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      ">       model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "batch_size = 15\n",
      "c0         = needle.Tensor([[[-0.20119713]\n",
      "  [-1.257014  ]\n",
      "  [ 1.6697713 ]\n",
      "  [ 0.5175022 ]\n",
      "  [-0.4889475 ]\n",
      "  [ 0.24960577]\n",
      "  [ 0.23...792]\n",
      "  [ 0.43693337]\n",
      "  [ 0.31835207]\n",
      "  [-2.5510733 ]\n",
      "  [ 1.7028129 ]\n",
      "  [-1.5053847 ]\n",
      "  [ 0.9313206 ]\n",
      "  [-2.2504177 ]]])\n",
      "device     = cpu()\n",
      "embedding_size = 34\n",
      "h0         = needle.Tensor([[[ 0.68358845]\n",
      "  [ 1.4763523 ]\n",
      "  [ 2.6366107 ]\n",
      "  [-1.6190153 ]\n",
      "  [-0.3829432 ]\n",
      "  [ 0.35767102]\n",
      "  [-0.64...916]\n",
      "  [-0.41006672]\n",
      "  [ 0.05908708]\n",
      "  [-0.5135688 ]\n",
      "  [ 1.2193667 ]\n",
      "  [ 1.1846493 ]\n",
      "  [ 0.27096808]\n",
      "  [-0.0791824 ]]])\n",
      "hidden_size = 1\n",
      "init_hidden = True\n",
      "num_layers = 1\n",
      "output_size = 1000\n",
      "seq_length = 1\n",
      "seq_model  = 'rnn'\n",
      "x          = array([[533., 656., 405., 164., 970., 886., 671., 686., 450., 519., 660.,\n",
      "        394., 238., 165., 202.]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:201: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "self = <models.LanguageModel object at 0x15753a2a0>, embedding_size = 34\n",
      "output_size = 1000, hidden_size = 1, num_layers = 1, seq_model = 'rnn'\n",
      "device = cpu(), dtype = 'float32'\n",
      "\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92m__init__\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, embedding_size, output_size, hidden_size, num_layers=\u001b[94m1\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                 seq_model=\u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, device=\u001b[94mNone\u001b[39;49;00m, dtype=\u001b[33m\"\u001b[39;49;00m\u001b[33mfloat32\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"\u001b[39;49;00m\n",
      "    \u001b[33m    Consists of an embedding layer, a sequence model (either RNN or LSTM), and a\u001b[39;49;00m\n",
      "    \u001b[33m    linear layer.\u001b[39;49;00m\n",
      "    \u001b[33m    Parameters:\u001b[39;49;00m\n",
      "    \u001b[33m    output_size: Size of dictionary\u001b[39;49;00m\n",
      "    \u001b[33m    embedding_size: Size of embeddings\u001b[39;49;00m\n",
      "    \u001b[33m    hidden_size: The number of features in the hidden state of LSTM or RNN\u001b[39;49;00m\n",
      "    \u001b[33m    seq_model: 'rnn' or 'lstm', whether to use RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    num_layers: Number of layers in RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    \"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[96msuper\u001b[39;49;00m(LanguageModel, \u001b[96mself\u001b[39;49;00m).\u001b[92m__init__\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m### BEGIN YOUR SOLUTION\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94mraise\u001b[39;49;00m \u001b[96mNotImplementedError\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       NotImplementedError\u001b[0m\n",
      "\n",
      "__class__  = <class 'models.LanguageModel'>\n",
      "device     = cpu()\n",
      "dtype      = 'float32'\n",
      "embedding_size = 34\n",
      "hidden_size = 1\n",
      "num_layers = 1\n",
      "output_size = 1000\n",
      "self       = <models.LanguageModel object at 0x15753a2a0>\n",
      "seq_model  = 'rnn'\n",
      "\n",
      "\u001b[1m\u001b[31mapps/models.py\u001b[0m:38: NotImplementedError\n",
      "\u001b[31m\u001b[1m______ test_language_model_implementation[cpu-rnn-1000-True-1-34-15-1-13] ______\u001b[0m\n",
      "\n",
      "seq_length = 13, num_layers = 1, batch_size = 15, embedding_size = 34\n",
      "hidden_size = 1, init_hidden = True, output_size = 1000, seq_model = 'rnn'\n",
      "device = cpu()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\u001b[90m\u001b[39;49;00m\n",
      "                            init_hidden, output_size, seq_model, device):\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      ">       model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "batch_size = 15\n",
      "c0         = needle.Tensor([[[-0.6417907 ]\n",
      "  [-0.53883255]\n",
      "  [ 0.815451  ]\n",
      "  [ 1.2091922 ]\n",
      "  [-0.4699299 ]\n",
      "  [ 0.3996634 ]\n",
      "  [ 0.03...97 ]\n",
      "  [ 0.8323474 ]\n",
      "  [ 0.5515913 ]\n",
      "  [-0.23496695]\n",
      "  [ 0.32208169]\n",
      "  [ 2.5408301 ]\n",
      "  [ 1.4227568 ]\n",
      "  [ 0.84007037]]])\n",
      "device     = cpu()\n",
      "embedding_size = 34\n",
      "h0         = needle.Tensor([[[ 0.49630687]\n",
      "  [-0.6624161 ]\n",
      "  [-1.1363822 ]\n",
      "  [ 0.44865125]\n",
      "  [ 2.4333758 ]\n",
      "  [ 1.4415925 ]\n",
      "  [-0.02...93 ]\n",
      "  [-0.3685832 ]\n",
      "  [-0.49537656]\n",
      "  [ 1.0249119 ]\n",
      "  [ 2.8763535 ]\n",
      "  [ 1.384489  ]\n",
      "  [-0.55249   ]\n",
      "  [ 0.62271166]]])\n",
      "hidden_size = 1\n",
      "init_hidden = True\n",
      "num_layers = 1\n",
      "output_size = 1000\n",
      "seq_length = 13\n",
      "seq_model  = 'rnn'\n",
      "x          = array([[852., 828., 235., 661.,  44.,  97., 210., 849., 853., 360., 915.,\n",
      "        714., 185., 835., 856.],\n",
      "       [881...    [104., 563.,  10., 660., 823., 125., 599., 975., 622., 432., 328.,\n",
      "        748.,  22., 494., 285.]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:201: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "self = <models.LanguageModel object at 0x157505460>, embedding_size = 34\n",
      "output_size = 1000, hidden_size = 1, num_layers = 1, seq_model = 'rnn'\n",
      "device = cpu(), dtype = 'float32'\n",
      "\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92m__init__\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, embedding_size, output_size, hidden_size, num_layers=\u001b[94m1\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                 seq_model=\u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, device=\u001b[94mNone\u001b[39;49;00m, dtype=\u001b[33m\"\u001b[39;49;00m\u001b[33mfloat32\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"\u001b[39;49;00m\n",
      "    \u001b[33m    Consists of an embedding layer, a sequence model (either RNN or LSTM), and a\u001b[39;49;00m\n",
      "    \u001b[33m    linear layer.\u001b[39;49;00m\n",
      "    \u001b[33m    Parameters:\u001b[39;49;00m\n",
      "    \u001b[33m    output_size: Size of dictionary\u001b[39;49;00m\n",
      "    \u001b[33m    embedding_size: Size of embeddings\u001b[39;49;00m\n",
      "    \u001b[33m    hidden_size: The number of features in the hidden state of LSTM or RNN\u001b[39;49;00m\n",
      "    \u001b[33m    seq_model: 'rnn' or 'lstm', whether to use RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    num_layers: Number of layers in RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    \"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[96msuper\u001b[39;49;00m(LanguageModel, \u001b[96mself\u001b[39;49;00m).\u001b[92m__init__\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m### BEGIN YOUR SOLUTION\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94mraise\u001b[39;49;00m \u001b[96mNotImplementedError\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       NotImplementedError\u001b[0m\n",
      "\n",
      "__class__  = <class 'models.LanguageModel'>\n",
      "device     = cpu()\n",
      "dtype      = 'float32'\n",
      "embedding_size = 34\n",
      "hidden_size = 1\n",
      "num_layers = 1\n",
      "output_size = 1000\n",
      "self       = <models.LanguageModel object at 0x157505460>\n",
      "seq_model  = 'rnn'\n",
      "\n",
      "\u001b[1m\u001b[31mapps/models.py\u001b[0m:38: NotImplementedError\n",
      "\u001b[31m\u001b[1m______ test_language_model_implementation[cpu-rnn-1000-True-1-34-15-2-1] _______\u001b[0m\n",
      "\n",
      "seq_length = 1, num_layers = 2, batch_size = 15, embedding_size = 34\n",
      "hidden_size = 1, init_hidden = True, output_size = 1000, seq_model = 'rnn'\n",
      "device = cpu()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\u001b[90m\u001b[39;49;00m\n",
      "                            init_hidden, output_size, seq_model, device):\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      ">       model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "batch_size = 15\n",
      "c0         = needle.Tensor([[[-1.4867071 ]\n",
      "  [ 1.5281249 ]\n",
      "  [-0.8202565 ]\n",
      "  [-1.092006  ]\n",
      "  [-0.350905  ]\n",
      "  [-0.7560373 ]\n",
      "  [ 2.28...18 ]\n",
      "  [ 1.2054148 ]\n",
      "  [ 0.7961356 ]\n",
      "  [ 0.6508333 ]\n",
      "  [ 0.07676939]\n",
      "  [ 0.45520037]\n",
      "  [ 0.12880458]\n",
      "  [ 1.3623765 ]]])\n",
      "device     = cpu()\n",
      "embedding_size = 34\n",
      "h0         = needle.Tensor([[[-0.4141542 ]\n",
      "  [-0.02673983]\n",
      "  [-1.0689209 ]\n",
      "  [-0.9457821 ]\n",
      "  [ 0.86048657]\n",
      "  [ 0.46532694]\n",
      "  [-1.07...687]\n",
      "  [ 0.21101642]\n",
      "  [-0.14179912]\n",
      "  [-1.2378603 ]\n",
      "  [-0.78751236]\n",
      "  [-0.39430696]\n",
      "  [-0.7202132 ]\n",
      "  [ 0.01555045]]])\n",
      "hidden_size = 1\n",
      "init_hidden = True\n",
      "num_layers = 2\n",
      "output_size = 1000\n",
      "seq_length = 1\n",
      "seq_model  = 'rnn'\n",
      "x          = array([[151., 622., 135., 278., 483., 517., 118., 245., 532., 376., 769.,\n",
      "        868., 764., 337., 452.]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:201: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "self = <models.LanguageModel object at 0x15778ce30>, embedding_size = 34\n",
      "output_size = 1000, hidden_size = 1, num_layers = 2, seq_model = 'rnn'\n",
      "device = cpu(), dtype = 'float32'\n",
      "\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92m__init__\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, embedding_size, output_size, hidden_size, num_layers=\u001b[94m1\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                 seq_model=\u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, device=\u001b[94mNone\u001b[39;49;00m, dtype=\u001b[33m\"\u001b[39;49;00m\u001b[33mfloat32\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"\u001b[39;49;00m\n",
      "    \u001b[33m    Consists of an embedding layer, a sequence model (either RNN or LSTM), and a\u001b[39;49;00m\n",
      "    \u001b[33m    linear layer.\u001b[39;49;00m\n",
      "    \u001b[33m    Parameters:\u001b[39;49;00m\n",
      "    \u001b[33m    output_size: Size of dictionary\u001b[39;49;00m\n",
      "    \u001b[33m    embedding_size: Size of embeddings\u001b[39;49;00m\n",
      "    \u001b[33m    hidden_size: The number of features in the hidden state of LSTM or RNN\u001b[39;49;00m\n",
      "    \u001b[33m    seq_model: 'rnn' or 'lstm', whether to use RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    num_layers: Number of layers in RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    \"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[96msuper\u001b[39;49;00m(LanguageModel, \u001b[96mself\u001b[39;49;00m).\u001b[92m__init__\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m### BEGIN YOUR SOLUTION\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94mraise\u001b[39;49;00m \u001b[96mNotImplementedError\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       NotImplementedError\u001b[0m\n",
      "\n",
      "__class__  = <class 'models.LanguageModel'>\n",
      "device     = cpu()\n",
      "dtype      = 'float32'\n",
      "embedding_size = 34\n",
      "hidden_size = 1\n",
      "num_layers = 2\n",
      "output_size = 1000\n",
      "self       = <models.LanguageModel object at 0x15778ce30>\n",
      "seq_model  = 'rnn'\n",
      "\n",
      "\u001b[1m\u001b[31mapps/models.py\u001b[0m:38: NotImplementedError\n",
      "\u001b[31m\u001b[1m______ test_language_model_implementation[cpu-rnn-1000-True-1-34-15-2-13] ______\u001b[0m\n",
      "\n",
      "seq_length = 13, num_layers = 2, batch_size = 15, embedding_size = 34\n",
      "hidden_size = 1, init_hidden = True, output_size = 1000, seq_model = 'rnn'\n",
      "device = cpu()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\u001b[90m\u001b[39;49;00m\n",
      "                            init_hidden, output_size, seq_model, device):\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      ">       model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "batch_size = 15\n",
      "c0         = needle.Tensor([[[ 1.4880426 ]\n",
      "  [-0.55568874]\n",
      "  [-1.5919448 ]\n",
      "  [-0.7630543 ]\n",
      "  [ 1.7651755 ]\n",
      "  [-2.2697525 ]\n",
      "  [-1.46...57 ]\n",
      "  [ 0.19126275]\n",
      "  [-1.3612636 ]\n",
      "  [ 2.3239686 ]\n",
      "  [-0.07654231]\n",
      "  [ 0.089205  ]\n",
      "  [ 2.125376  ]\n",
      "  [-1.1209512 ]]])\n",
      "device     = cpu()\n",
      "embedding_size = 34\n",
      "h0         = needle.Tensor([[[ 0.985681  ]\n",
      "  [-1.0350657 ]\n",
      "  [-0.05011365]\n",
      "  [-0.5733269 ]\n",
      "  [ 2.2209275 ]\n",
      "  [-0.290028  ]\n",
      "  [-0.13...122]\n",
      "  [ 0.33749706]\n",
      "  [ 0.8450618 ]\n",
      "  [ 0.18793243]\n",
      "  [ 0.13709323]\n",
      "  [ 0.8783116 ]\n",
      "  [-1.569851  ]\n",
      "  [ 0.963696  ]]])\n",
      "hidden_size = 1\n",
      "init_hidden = True\n",
      "num_layers = 2\n",
      "output_size = 1000\n",
      "seq_length = 13\n",
      "seq_model  = 'rnn'\n",
      "x          = array([[717., 536., 175., 683.,  73., 690., 184., 600., 483., 301., 819.,\n",
      "        279., 953., 525., 931.],\n",
      "       [295...    [898.,  62., 918., 979., 744., 830., 443., 595., 183., 836., 882.,\n",
      "        385., 982., 904., 751.]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:201: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "self = <models.LanguageModel object at 0x15778e0f0>, embedding_size = 34\n",
      "output_size = 1000, hidden_size = 1, num_layers = 2, seq_model = 'rnn'\n",
      "device = cpu(), dtype = 'float32'\n",
      "\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92m__init__\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, embedding_size, output_size, hidden_size, num_layers=\u001b[94m1\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                 seq_model=\u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, device=\u001b[94mNone\u001b[39;49;00m, dtype=\u001b[33m\"\u001b[39;49;00m\u001b[33mfloat32\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"\u001b[39;49;00m\n",
      "    \u001b[33m    Consists of an embedding layer, a sequence model (either RNN or LSTM), and a\u001b[39;49;00m\n",
      "    \u001b[33m    linear layer.\u001b[39;49;00m\n",
      "    \u001b[33m    Parameters:\u001b[39;49;00m\n",
      "    \u001b[33m    output_size: Size of dictionary\u001b[39;49;00m\n",
      "    \u001b[33m    embedding_size: Size of embeddings\u001b[39;49;00m\n",
      "    \u001b[33m    hidden_size: The number of features in the hidden state of LSTM or RNN\u001b[39;49;00m\n",
      "    \u001b[33m    seq_model: 'rnn' or 'lstm', whether to use RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    num_layers: Number of layers in RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    \"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[96msuper\u001b[39;49;00m(LanguageModel, \u001b[96mself\u001b[39;49;00m).\u001b[92m__init__\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m### BEGIN YOUR SOLUTION\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94mraise\u001b[39;49;00m \u001b[96mNotImplementedError\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       NotImplementedError\u001b[0m\n",
      "\n",
      "__class__  = <class 'models.LanguageModel'>\n",
      "device     = cpu()\n",
      "dtype      = 'float32'\n",
      "embedding_size = 34\n",
      "hidden_size = 1\n",
      "num_layers = 2\n",
      "output_size = 1000\n",
      "self       = <models.LanguageModel object at 0x15778e0f0>\n",
      "seq_model  = 'rnn'\n",
      "\n",
      "\u001b[1m\u001b[31mapps/models.py\u001b[0m:38: NotImplementedError\n",
      "\u001b[31m\u001b[1m_______ test_language_model_implementation[cpu-rnn-1000-True-12-1-1-1-1] _______\u001b[0m\n",
      "\n",
      "seq_length = 1, num_layers = 1, batch_size = 1, embedding_size = 1\n",
      "hidden_size = 12, init_hidden = True, output_size = 1000, seq_model = 'rnn'\n",
      "device = cpu()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\u001b[90m\u001b[39;49;00m\n",
      "                            init_hidden, output_size, seq_model, device):\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      ">       model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "batch_size = 1\n",
      "c0         = needle.Tensor([[[ 0.10144395  1.5623348  -0.5617369  -0.74431205 -1.610661\n",
      "    1.4136994  -0.513343   -1.2581708  -0.01119993 -1.485222\n",
      "    0.442002    0.5484768 ]]])\n",
      "device     = cpu()\n",
      "embedding_size = 1\n",
      "h0         = needle.Tensor([[[ 0.00399513  0.5899451   2.1109774   0.00976851 -1.9817972\n",
      "   -0.08358814  0.5684428  -0.74124867 -1.0866358   0.928054\n",
      "   -0.2482574  -0.30680653]]])\n",
      "hidden_size = 12\n",
      "init_hidden = True\n",
      "num_layers = 1\n",
      "output_size = 1000\n",
      "seq_length = 1\n",
      "seq_model  = 'rnn'\n",
      "x          = array([[261.]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:201: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "self = <models.LanguageModel object at 0x1575c75c0>, embedding_size = 1\n",
      "output_size = 1000, hidden_size = 12, num_layers = 1, seq_model = 'rnn'\n",
      "device = cpu(), dtype = 'float32'\n",
      "\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92m__init__\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, embedding_size, output_size, hidden_size, num_layers=\u001b[94m1\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                 seq_model=\u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, device=\u001b[94mNone\u001b[39;49;00m, dtype=\u001b[33m\"\u001b[39;49;00m\u001b[33mfloat32\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"\u001b[39;49;00m\n",
      "    \u001b[33m    Consists of an embedding layer, a sequence model (either RNN or LSTM), and a\u001b[39;49;00m\n",
      "    \u001b[33m    linear layer.\u001b[39;49;00m\n",
      "    \u001b[33m    Parameters:\u001b[39;49;00m\n",
      "    \u001b[33m    output_size: Size of dictionary\u001b[39;49;00m\n",
      "    \u001b[33m    embedding_size: Size of embeddings\u001b[39;49;00m\n",
      "    \u001b[33m    hidden_size: The number of features in the hidden state of LSTM or RNN\u001b[39;49;00m\n",
      "    \u001b[33m    seq_model: 'rnn' or 'lstm', whether to use RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    num_layers: Number of layers in RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    \"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[96msuper\u001b[39;49;00m(LanguageModel, \u001b[96mself\u001b[39;49;00m).\u001b[92m__init__\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m### BEGIN YOUR SOLUTION\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94mraise\u001b[39;49;00m \u001b[96mNotImplementedError\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       NotImplementedError\u001b[0m\n",
      "\n",
      "__class__  = <class 'models.LanguageModel'>\n",
      "device     = cpu()\n",
      "dtype      = 'float32'\n",
      "embedding_size = 1\n",
      "hidden_size = 12\n",
      "num_layers = 1\n",
      "output_size = 1000\n",
      "self       = <models.LanguageModel object at 0x1575c75c0>\n",
      "seq_model  = 'rnn'\n",
      "\n",
      "\u001b[1m\u001b[31mapps/models.py\u001b[0m:38: NotImplementedError\n",
      "\u001b[31m\u001b[1m______ test_language_model_implementation[cpu-rnn-1000-True-12-1-1-1-13] _______\u001b[0m\n",
      "\n",
      "seq_length = 13, num_layers = 1, batch_size = 1, embedding_size = 1\n",
      "hidden_size = 12, init_hidden = True, output_size = 1000, seq_model = 'rnn'\n",
      "device = cpu()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\u001b[90m\u001b[39;49;00m\n",
      "                            init_hidden, output_size, seq_model, device):\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      ">       model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "batch_size = 1\n",
      "c0         = needle.Tensor([[[-1.3553092  -0.51838577  0.67394197 -0.87663937  0.3254928\n",
      "    0.33950302 -0.8824806  -1.5219283  -1.7140077   1.5743536\n",
      "    0.5918926  -0.5778406 ]]])\n",
      "device     = cpu()\n",
      "embedding_size = 1\n",
      "h0         = needle.Tensor([[[-2.1767104   0.20888735  0.8078327   0.38643178  1.9800594\n",
      "   -1.6594839  -0.08769149  0.38802943  0.2265389   1.2744339\n",
      "    0.8799623  -0.1344058 ]]])\n",
      "hidden_size = 12\n",
      "init_hidden = True\n",
      "num_layers = 1\n",
      "output_size = 1000\n",
      "seq_length = 13\n",
      "seq_model  = 'rnn'\n",
      "x          = array([[393.],\n",
      "       [940.],\n",
      "       [528.],\n",
      "       [656.],\n",
      "       [321.],\n",
      "       [913.],\n",
      "       [218.],\n",
      "       [592.],\n",
      "       [874.],\n",
      "       [260.],\n",
      "       [299.],\n",
      "       [684.],\n",
      "       [730.]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:201: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "self = <models.LanguageModel object at 0x1572baea0>, embedding_size = 1\n",
      "output_size = 1000, hidden_size = 12, num_layers = 1, seq_model = 'rnn'\n",
      "device = cpu(), dtype = 'float32'\n",
      "\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92m__init__\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, embedding_size, output_size, hidden_size, num_layers=\u001b[94m1\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                 seq_model=\u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, device=\u001b[94mNone\u001b[39;49;00m, dtype=\u001b[33m\"\u001b[39;49;00m\u001b[33mfloat32\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"\u001b[39;49;00m\n",
      "    \u001b[33m    Consists of an embedding layer, a sequence model (either RNN or LSTM), and a\u001b[39;49;00m\n",
      "    \u001b[33m    linear layer.\u001b[39;49;00m\n",
      "    \u001b[33m    Parameters:\u001b[39;49;00m\n",
      "    \u001b[33m    output_size: Size of dictionary\u001b[39;49;00m\n",
      "    \u001b[33m    embedding_size: Size of embeddings\u001b[39;49;00m\n",
      "    \u001b[33m    hidden_size: The number of features in the hidden state of LSTM or RNN\u001b[39;49;00m\n",
      "    \u001b[33m    seq_model: 'rnn' or 'lstm', whether to use RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    num_layers: Number of layers in RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    \"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[96msuper\u001b[39;49;00m(LanguageModel, \u001b[96mself\u001b[39;49;00m).\u001b[92m__init__\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m### BEGIN YOUR SOLUTION\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94mraise\u001b[39;49;00m \u001b[96mNotImplementedError\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       NotImplementedError\u001b[0m\n",
      "\n",
      "__class__  = <class 'models.LanguageModel'>\n",
      "device     = cpu()\n",
      "dtype      = 'float32'\n",
      "embedding_size = 1\n",
      "hidden_size = 12\n",
      "num_layers = 1\n",
      "output_size = 1000\n",
      "self       = <models.LanguageModel object at 0x1572baea0>\n",
      "seq_model  = 'rnn'\n",
      "\n",
      "\u001b[1m\u001b[31mapps/models.py\u001b[0m:38: NotImplementedError\n",
      "\u001b[31m\u001b[1m_______ test_language_model_implementation[cpu-rnn-1000-True-12-1-1-2-1] _______\u001b[0m\n",
      "\n",
      "seq_length = 1, num_layers = 2, batch_size = 1, embedding_size = 1\n",
      "hidden_size = 12, init_hidden = True, output_size = 1000, seq_model = 'rnn'\n",
      "device = cpu()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\u001b[90m\u001b[39;49;00m\n",
      "                            init_hidden, output_size, seq_model, device):\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      ">       model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "batch_size = 1\n",
      "c0         = needle.Tensor([[[-0.79406905 -0.08506909 -1.7587428  -1.0923567   1.1738697\n",
      "   -1.275666   -0.64091355  0.6032023  -0....9  -0.29258987 -0.6340986\n",
      "    0.5981643   1.6385993  -0.54781973 -0.8781099   0.00821633\n",
      "   -0.5960863   0.28230003]]])\n",
      "device     = cpu()\n",
      "embedding_size = 1\n",
      "h0         = needle.Tensor([[[-0.49928516  0.4028061  -0.4831587  -2.0980525   1.4461213\n",
      "   -0.11992151  0.87804997 -1.5657326   0....88 -1.4574355   2.5838547\n",
      "    0.6634226  -1.1440982  -2.244241    0.39712033  0.53856134\n",
      "    0.13235833  0.535803  ]]])\n",
      "hidden_size = 12\n",
      "init_hidden = True\n",
      "num_layers = 2\n",
      "output_size = 1000\n",
      "seq_length = 1\n",
      "seq_model  = 'rnn'\n",
      "x          = array([[949.]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:201: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "self = <models.LanguageModel object at 0x15778f1a0>, embedding_size = 1\n",
      "output_size = 1000, hidden_size = 12, num_layers = 2, seq_model = 'rnn'\n",
      "device = cpu(), dtype = 'float32'\n",
      "\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92m__init__\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, embedding_size, output_size, hidden_size, num_layers=\u001b[94m1\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                 seq_model=\u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, device=\u001b[94mNone\u001b[39;49;00m, dtype=\u001b[33m\"\u001b[39;49;00m\u001b[33mfloat32\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"\u001b[39;49;00m\n",
      "    \u001b[33m    Consists of an embedding layer, a sequence model (either RNN or LSTM), and a\u001b[39;49;00m\n",
      "    \u001b[33m    linear layer.\u001b[39;49;00m\n",
      "    \u001b[33m    Parameters:\u001b[39;49;00m\n",
      "    \u001b[33m    output_size: Size of dictionary\u001b[39;49;00m\n",
      "    \u001b[33m    embedding_size: Size of embeddings\u001b[39;49;00m\n",
      "    \u001b[33m    hidden_size: The number of features in the hidden state of LSTM or RNN\u001b[39;49;00m\n",
      "    \u001b[33m    seq_model: 'rnn' or 'lstm', whether to use RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    num_layers: Number of layers in RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    \"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[96msuper\u001b[39;49;00m(LanguageModel, \u001b[96mself\u001b[39;49;00m).\u001b[92m__init__\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m### BEGIN YOUR SOLUTION\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94mraise\u001b[39;49;00m \u001b[96mNotImplementedError\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       NotImplementedError\u001b[0m\n",
      "\n",
      "__class__  = <class 'models.LanguageModel'>\n",
      "device     = cpu()\n",
      "dtype      = 'float32'\n",
      "embedding_size = 1\n",
      "hidden_size = 12\n",
      "num_layers = 2\n",
      "output_size = 1000\n",
      "self       = <models.LanguageModel object at 0x15778f1a0>\n",
      "seq_model  = 'rnn'\n",
      "\n",
      "\u001b[1m\u001b[31mapps/models.py\u001b[0m:38: NotImplementedError\n",
      "\u001b[31m\u001b[1m______ test_language_model_implementation[cpu-rnn-1000-True-12-1-1-2-13] _______\u001b[0m\n",
      "\n",
      "seq_length = 13, num_layers = 2, batch_size = 1, embedding_size = 1\n",
      "hidden_size = 12, init_hidden = True, output_size = 1000, seq_model = 'rnn'\n",
      "device = cpu()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\u001b[90m\u001b[39;49;00m\n",
      "                            init_hidden, output_size, seq_model, device):\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      ">       model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "batch_size = 1\n",
      "c0         = needle.Tensor([[[ 0.66392493 -2.180201   -1.4341938  -0.7567478   0.7206525\n",
      "    0.8777277   0.09153967 -0.298721    0....323 -0.62298656  0.56977946\n",
      "   -1.0178145  -0.5104179  -0.6555654   0.05626285  0.786097\n",
      "    0.85537016 -1.0114998 ]]])\n",
      "device     = cpu()\n",
      "embedding_size = 1\n",
      "h0         = needle.Tensor([[[-1.6941996  -0.31764874 -0.3206344  -0.04092105 -0.48330957\n",
      "    0.7564456  -0.327775    0.09736803  0...7   0.15052311 -0.6052006\n",
      "   -1.4692967   0.4975619  -1.0027599  -0.2724502  -0.34941354\n",
      "    0.37691128  0.51128197]]])\n",
      "hidden_size = 12\n",
      "init_hidden = True\n",
      "num_layers = 2\n",
      "output_size = 1000\n",
      "seq_length = 13\n",
      "seq_model  = 'rnn'\n",
      "x          = array([[495.],\n",
      "       [210.],\n",
      "       [472.],\n",
      "       [132.],\n",
      "       [556.],\n",
      "       [  6.],\n",
      "       [331.],\n",
      "       [691.],\n",
      "       [ 51.],\n",
      "       [621.],\n",
      "       [860.],\n",
      "       [212.],\n",
      "       [662.]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:201: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "self = <models.LanguageModel object at 0x15778e180>, embedding_size = 1\n",
      "output_size = 1000, hidden_size = 12, num_layers = 2, seq_model = 'rnn'\n",
      "device = cpu(), dtype = 'float32'\n",
      "\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92m__init__\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, embedding_size, output_size, hidden_size, num_layers=\u001b[94m1\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                 seq_model=\u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, device=\u001b[94mNone\u001b[39;49;00m, dtype=\u001b[33m\"\u001b[39;49;00m\u001b[33mfloat32\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"\u001b[39;49;00m\n",
      "    \u001b[33m    Consists of an embedding layer, a sequence model (either RNN or LSTM), and a\u001b[39;49;00m\n",
      "    \u001b[33m    linear layer.\u001b[39;49;00m\n",
      "    \u001b[33m    Parameters:\u001b[39;49;00m\n",
      "    \u001b[33m    output_size: Size of dictionary\u001b[39;49;00m\n",
      "    \u001b[33m    embedding_size: Size of embeddings\u001b[39;49;00m\n",
      "    \u001b[33m    hidden_size: The number of features in the hidden state of LSTM or RNN\u001b[39;49;00m\n",
      "    \u001b[33m    seq_model: 'rnn' or 'lstm', whether to use RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    num_layers: Number of layers in RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    \"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[96msuper\u001b[39;49;00m(LanguageModel, \u001b[96mself\u001b[39;49;00m).\u001b[92m__init__\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m### BEGIN YOUR SOLUTION\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94mraise\u001b[39;49;00m \u001b[96mNotImplementedError\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       NotImplementedError\u001b[0m\n",
      "\n",
      "__class__  = <class 'models.LanguageModel'>\n",
      "device     = cpu()\n",
      "dtype      = 'float32'\n",
      "embedding_size = 1\n",
      "hidden_size = 12\n",
      "num_layers = 2\n",
      "output_size = 1000\n",
      "self       = <models.LanguageModel object at 0x15778e180>\n",
      "seq_model  = 'rnn'\n",
      "\n",
      "\u001b[1m\u001b[31mapps/models.py\u001b[0m:38: NotImplementedError\n",
      "\u001b[31m\u001b[1m______ test_language_model_implementation[cpu-rnn-1000-True-12-1-15-1-1] _______\u001b[0m\n",
      "\n",
      "seq_length = 1, num_layers = 1, batch_size = 15, embedding_size = 1\n",
      "hidden_size = 12, init_hidden = True, output_size = 1000, seq_model = 'rnn'\n",
      "device = cpu()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\u001b[90m\u001b[39;49;00m\n",
      "                            init_hidden, output_size, seq_model, device):\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      ">       model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "batch_size = 15\n",
      "c0         = needle.Tensor([[[ 2.71417499e-01  5.56546986e-01  1.66995823e+00  1.69255352e+00\n",
      "   -1.25079370e+00  8.82871568e-01 -1...  8.76231313e-01  4.06390309e-01  1.98941720e+00\n",
      "   -8.92416000e-01  1.33725572e-02 -1.03251028e+00 -1.89424604e-01]]])\n",
      "device     = cpu()\n",
      "embedding_size = 1\n",
      "h0         = needle.Tensor([[[ 1.02651775e-01  6.54092729e-01 -5.22293076e-02 -9.94766653e-01\n",
      "   -1.12088132e+00 -5.14741600e-01 -1...  9.22338217e-02  2.13858992e-01  9.74986479e-02\n",
      "   -8.42034742e-02 -9.34398472e-01 -2.32583001e-01 -3.72044325e-01]]])\n",
      "hidden_size = 12\n",
      "init_hidden = True\n",
      "num_layers = 1\n",
      "output_size = 1000\n",
      "seq_length = 1\n",
      "seq_model  = 'rnn'\n",
      "x          = array([[778., 264., 574., 933., 467., 938., 882., 937., 138., 726., 662.,\n",
      "        286., 711., 944., 786.]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:201: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "self = <models.LanguageModel object at 0x15778f710>, embedding_size = 1\n",
      "output_size = 1000, hidden_size = 12, num_layers = 1, seq_model = 'rnn'\n",
      "device = cpu(), dtype = 'float32'\n",
      "\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92m__init__\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, embedding_size, output_size, hidden_size, num_layers=\u001b[94m1\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                 seq_model=\u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, device=\u001b[94mNone\u001b[39;49;00m, dtype=\u001b[33m\"\u001b[39;49;00m\u001b[33mfloat32\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"\u001b[39;49;00m\n",
      "    \u001b[33m    Consists of an embedding layer, a sequence model (either RNN or LSTM), and a\u001b[39;49;00m\n",
      "    \u001b[33m    linear layer.\u001b[39;49;00m\n",
      "    \u001b[33m    Parameters:\u001b[39;49;00m\n",
      "    \u001b[33m    output_size: Size of dictionary\u001b[39;49;00m\n",
      "    \u001b[33m    embedding_size: Size of embeddings\u001b[39;49;00m\n",
      "    \u001b[33m    hidden_size: The number of features in the hidden state of LSTM or RNN\u001b[39;49;00m\n",
      "    \u001b[33m    seq_model: 'rnn' or 'lstm', whether to use RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    num_layers: Number of layers in RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    \"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[96msuper\u001b[39;49;00m(LanguageModel, \u001b[96mself\u001b[39;49;00m).\u001b[92m__init__\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m### BEGIN YOUR SOLUTION\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94mraise\u001b[39;49;00m \u001b[96mNotImplementedError\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       NotImplementedError\u001b[0m\n",
      "\n",
      "__class__  = <class 'models.LanguageModel'>\n",
      "device     = cpu()\n",
      "dtype      = 'float32'\n",
      "embedding_size = 1\n",
      "hidden_size = 12\n",
      "num_layers = 1\n",
      "output_size = 1000\n",
      "self       = <models.LanguageModel object at 0x15778f710>\n",
      "seq_model  = 'rnn'\n",
      "\n",
      "\u001b[1m\u001b[31mapps/models.py\u001b[0m:38: NotImplementedError\n",
      "\u001b[31m\u001b[1m______ test_language_model_implementation[cpu-rnn-1000-True-12-1-15-1-13] ______\u001b[0m\n",
      "\n",
      "seq_length = 13, num_layers = 1, batch_size = 15, embedding_size = 1\n",
      "hidden_size = 12, init_hidden = True, output_size = 1000, seq_model = 'rnn'\n",
      "device = cpu()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\u001b[90m\u001b[39;49;00m\n",
      "                            init_hidden, output_size, seq_model, device):\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      ">       model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "batch_size = 15\n",
      "c0         = needle.Tensor([[[ 1.0296639  -1.1058984   0.9554636   0.4014798   0.34537506\n",
      "   -0.3543348  -0.806648   -0.3312743  -1...79   1.0911947   0.394089\n",
      "    0.55531424 -0.5316955  -0.8948864  -1.8365861   0.29906303\n",
      "   -0.90477836  0.61187565]]])\n",
      "device     = cpu()\n",
      "embedding_size = 1\n",
      "h0         = needle.Tensor([[[ 1.24258220e+00 -4.65356141e-01  5.03700554e-01 -6.74257949e-02\n",
      "   -7.23577976e-01 -6.98550463e-01  7...  8.93333077e-01  9.44896102e-01  6.87301457e-01\n",
      "   -8.91780853e-02 -8.06687713e-01 -1.04536355e-01 -1.97446108e-01]]])\n",
      "hidden_size = 12\n",
      "init_hidden = True\n",
      "num_layers = 1\n",
      "output_size = 1000\n",
      "seq_length = 13\n",
      "seq_model  = 'rnn'\n",
      "x          = array([[638., 334., 984., 339.,  10., 339., 761.,  53.,  44., 483., 226.,\n",
      "        261., 924., 711., 530.],\n",
      "       [902...    [696., 426.,  87., 444., 632., 128., 180., 625., 532., 257., 783.,\n",
      "        570., 474., 193.,  72.]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:201: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "self = <models.LanguageModel object at 0x15778fb60>, embedding_size = 1\n",
      "output_size = 1000, hidden_size = 12, num_layers = 1, seq_model = 'rnn'\n",
      "device = cpu(), dtype = 'float32'\n",
      "\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92m__init__\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, embedding_size, output_size, hidden_size, num_layers=\u001b[94m1\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                 seq_model=\u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, device=\u001b[94mNone\u001b[39;49;00m, dtype=\u001b[33m\"\u001b[39;49;00m\u001b[33mfloat32\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"\u001b[39;49;00m\n",
      "    \u001b[33m    Consists of an embedding layer, a sequence model (either RNN or LSTM), and a\u001b[39;49;00m\n",
      "    \u001b[33m    linear layer.\u001b[39;49;00m\n",
      "    \u001b[33m    Parameters:\u001b[39;49;00m\n",
      "    \u001b[33m    output_size: Size of dictionary\u001b[39;49;00m\n",
      "    \u001b[33m    embedding_size: Size of embeddings\u001b[39;49;00m\n",
      "    \u001b[33m    hidden_size: The number of features in the hidden state of LSTM or RNN\u001b[39;49;00m\n",
      "    \u001b[33m    seq_model: 'rnn' or 'lstm', whether to use RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    num_layers: Number of layers in RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    \"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[96msuper\u001b[39;49;00m(LanguageModel, \u001b[96mself\u001b[39;49;00m).\u001b[92m__init__\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m### BEGIN YOUR SOLUTION\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94mraise\u001b[39;49;00m \u001b[96mNotImplementedError\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       NotImplementedError\u001b[0m\n",
      "\n",
      "__class__  = <class 'models.LanguageModel'>\n",
      "device     = cpu()\n",
      "dtype      = 'float32'\n",
      "embedding_size = 1\n",
      "hidden_size = 12\n",
      "num_layers = 1\n",
      "output_size = 1000\n",
      "self       = <models.LanguageModel object at 0x15778fb60>\n",
      "seq_model  = 'rnn'\n",
      "\n",
      "\u001b[1m\u001b[31mapps/models.py\u001b[0m:38: NotImplementedError\n",
      "\u001b[31m\u001b[1m______ test_language_model_implementation[cpu-rnn-1000-True-12-1-15-2-1] _______\u001b[0m\n",
      "\n",
      "seq_length = 1, num_layers = 2, batch_size = 15, embedding_size = 1\n",
      "hidden_size = 12, init_hidden = True, output_size = 1000, seq_model = 'rnn'\n",
      "device = cpu()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\u001b[90m\u001b[39;49;00m\n",
      "                            init_hidden, output_size, seq_model, device):\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      ">       model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "batch_size = 15\n",
      "c0         = needle.Tensor([[[ 6.92107499e-01 -8.33331943e-01  1.45814168e+00 -1.72919905e+00\n",
      "    6.21094525e-01 -1.43481779e+00 -1...  1.22209930e+00 -2.18277827e-01  4.48332638e-01\n",
      "   -1.14738476e+00  1.16779923e+00  6.16390705e-01  2.67477393e+00]]])\n",
      "device     = cpu()\n",
      "embedding_size = 1\n",
      "h0         = needle.Tensor([[[ 0.84389573 -0.67870885  0.8085575   0.19730867 -0.50979894\n",
      "   -1.5218301   1.8277615   0.95328075  1...46 -0.04883378  1.6558405\n",
      "    0.12065139  0.32246277  2.338745   -0.7582507  -0.72180355\n",
      "    0.96962154  0.11385481]]])\n",
      "hidden_size = 12\n",
      "init_hidden = True\n",
      "num_layers = 2\n",
      "output_size = 1000\n",
      "seq_length = 1\n",
      "seq_model  = 'rnn'\n",
      "x          = array([[434.,  88., 473., 733., 144., 368., 620., 198., 958., 744., 640.,\n",
      "        389., 386., 787., 500.]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:201: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "self = <models.LanguageModel object at 0x157505670>, embedding_size = 1\n",
      "output_size = 1000, hidden_size = 12, num_layers = 2, seq_model = 'rnn'\n",
      "device = cpu(), dtype = 'float32'\n",
      "\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92m__init__\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, embedding_size, output_size, hidden_size, num_layers=\u001b[94m1\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                 seq_model=\u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, device=\u001b[94mNone\u001b[39;49;00m, dtype=\u001b[33m\"\u001b[39;49;00m\u001b[33mfloat32\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"\u001b[39;49;00m\n",
      "    \u001b[33m    Consists of an embedding layer, a sequence model (either RNN or LSTM), and a\u001b[39;49;00m\n",
      "    \u001b[33m    linear layer.\u001b[39;49;00m\n",
      "    \u001b[33m    Parameters:\u001b[39;49;00m\n",
      "    \u001b[33m    output_size: Size of dictionary\u001b[39;49;00m\n",
      "    \u001b[33m    embedding_size: Size of embeddings\u001b[39;49;00m\n",
      "    \u001b[33m    hidden_size: The number of features in the hidden state of LSTM or RNN\u001b[39;49;00m\n",
      "    \u001b[33m    seq_model: 'rnn' or 'lstm', whether to use RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    num_layers: Number of layers in RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    \"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[96msuper\u001b[39;49;00m(LanguageModel, \u001b[96mself\u001b[39;49;00m).\u001b[92m__init__\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m### BEGIN YOUR SOLUTION\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94mraise\u001b[39;49;00m \u001b[96mNotImplementedError\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       NotImplementedError\u001b[0m\n",
      "\n",
      "__class__  = <class 'models.LanguageModel'>\n",
      "device     = cpu()\n",
      "dtype      = 'float32'\n",
      "embedding_size = 1\n",
      "hidden_size = 12\n",
      "num_layers = 2\n",
      "output_size = 1000\n",
      "self       = <models.LanguageModel object at 0x157505670>\n",
      "seq_model  = 'rnn'\n",
      "\n",
      "\u001b[1m\u001b[31mapps/models.py\u001b[0m:38: NotImplementedError\n",
      "\u001b[31m\u001b[1m______ test_language_model_implementation[cpu-rnn-1000-True-12-1-15-2-13] ______\u001b[0m\n",
      "\n",
      "seq_length = 13, num_layers = 2, batch_size = 15, embedding_size = 1\n",
      "hidden_size = 12, init_hidden = True, output_size = 1000, seq_model = 'rnn'\n",
      "device = cpu()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\u001b[90m\u001b[39;49;00m\n",
      "                            init_hidden, output_size, seq_model, device):\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      ">       model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "batch_size = 15\n",
      "c0         = needle.Tensor([[[ 3.06669235e-01  3.01962532e-02  8.51736486e-01 -2.29260862e-01\n",
      "    1.82541525e+00  2.20958614e+00 -7... -3.96838307e-01  2.62537670e+00  3.11649173e-01\n",
      "   -8.37997854e-01  1.83680880e+00 -1.17836821e+00 -1.22897363e+00]]])\n",
      "device     = cpu()\n",
      "embedding_size = 1\n",
      "h0         = needle.Tensor([[[ 1.2041938   0.16253737  2.4883754   0.31264913 -0.4446062\n",
      "   -1.7538438   0.844129    1.7806729  -0....492  1.0510294  -1.1051202\n",
      "    0.71125764  1.5780115   0.0432823  -1.0902846  -2.0578465\n",
      "   -0.27705348 -0.18597431]]])\n",
      "hidden_size = 12\n",
      "init_hidden = True\n",
      "num_layers = 2\n",
      "output_size = 1000\n",
      "seq_length = 13\n",
      "seq_model  = 'rnn'\n",
      "x          = array([[828., 514., 290., 846., 231., 321., 695., 789., 271., 336.,  46.,\n",
      "        980., 942., 344., 581.],\n",
      "       [391...    [788., 426., 700., 292., 737., 680., 422., 487., 104., 695., 907.,\n",
      "        328., 797., 998., 732.]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:201: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "self = <models.LanguageModel object at 0x157538680>, embedding_size = 1\n",
      "output_size = 1000, hidden_size = 12, num_layers = 2, seq_model = 'rnn'\n",
      "device = cpu(), dtype = 'float32'\n",
      "\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92m__init__\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, embedding_size, output_size, hidden_size, num_layers=\u001b[94m1\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                 seq_model=\u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, device=\u001b[94mNone\u001b[39;49;00m, dtype=\u001b[33m\"\u001b[39;49;00m\u001b[33mfloat32\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"\u001b[39;49;00m\n",
      "    \u001b[33m    Consists of an embedding layer, a sequence model (either RNN or LSTM), and a\u001b[39;49;00m\n",
      "    \u001b[33m    linear layer.\u001b[39;49;00m\n",
      "    \u001b[33m    Parameters:\u001b[39;49;00m\n",
      "    \u001b[33m    output_size: Size of dictionary\u001b[39;49;00m\n",
      "    \u001b[33m    embedding_size: Size of embeddings\u001b[39;49;00m\n",
      "    \u001b[33m    hidden_size: The number of features in the hidden state of LSTM or RNN\u001b[39;49;00m\n",
      "    \u001b[33m    seq_model: 'rnn' or 'lstm', whether to use RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    num_layers: Number of layers in RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    \"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[96msuper\u001b[39;49;00m(LanguageModel, \u001b[96mself\u001b[39;49;00m).\u001b[92m__init__\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m### BEGIN YOUR SOLUTION\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94mraise\u001b[39;49;00m \u001b[96mNotImplementedError\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       NotImplementedError\u001b[0m\n",
      "\n",
      "__class__  = <class 'models.LanguageModel'>\n",
      "device     = cpu()\n",
      "dtype      = 'float32'\n",
      "embedding_size = 1\n",
      "hidden_size = 12\n",
      "num_layers = 2\n",
      "output_size = 1000\n",
      "self       = <models.LanguageModel object at 0x157538680>\n",
      "seq_model  = 'rnn'\n",
      "\n",
      "\u001b[1m\u001b[31mapps/models.py\u001b[0m:38: NotImplementedError\n",
      "\u001b[31m\u001b[1m______ test_language_model_implementation[cpu-rnn-1000-True-12-34-1-1-1] _______\u001b[0m\n",
      "\n",
      "seq_length = 1, num_layers = 1, batch_size = 1, embedding_size = 34\n",
      "hidden_size = 12, init_hidden = True, output_size = 1000, seq_model = 'rnn'\n",
      "device = cpu()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\u001b[90m\u001b[39;49;00m\n",
      "                            init_hidden, output_size, seq_model, device):\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      ">       model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "batch_size = 1\n",
      "c0         = needle.Tensor([[[ 1.3899813  -0.5609725   0.22932537 -0.98744863 -0.06971748\n",
      "   -0.76047987 -0.2753823  -1.6434075   0.99328035 -0.36951748\n",
      "   -0.0475538  -0.42980328]]])\n",
      "device     = cpu()\n",
      "embedding_size = 34\n",
      "h0         = needle.Tensor([[[ 1.5680658   0.79404986  0.947876   -1.1698359   1.4934824\n",
      "    1.5115184   0.11406034 -0.64966184 -1.5904759   1.6519816\n",
      "   -1.5631645  -1.427995  ]]])\n",
      "hidden_size = 12\n",
      "init_hidden = True\n",
      "num_layers = 1\n",
      "output_size = 1000\n",
      "seq_length = 1\n",
      "seq_model  = 'rnn'\n",
      "x          = array([[795.]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:201: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "self = <models.LanguageModel object at 0x157504a10>, embedding_size = 34\n",
      "output_size = 1000, hidden_size = 12, num_layers = 1, seq_model = 'rnn'\n",
      "device = cpu(), dtype = 'float32'\n",
      "\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92m__init__\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, embedding_size, output_size, hidden_size, num_layers=\u001b[94m1\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                 seq_model=\u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, device=\u001b[94mNone\u001b[39;49;00m, dtype=\u001b[33m\"\u001b[39;49;00m\u001b[33mfloat32\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"\u001b[39;49;00m\n",
      "    \u001b[33m    Consists of an embedding layer, a sequence model (either RNN or LSTM), and a\u001b[39;49;00m\n",
      "    \u001b[33m    linear layer.\u001b[39;49;00m\n",
      "    \u001b[33m    Parameters:\u001b[39;49;00m\n",
      "    \u001b[33m    output_size: Size of dictionary\u001b[39;49;00m\n",
      "    \u001b[33m    embedding_size: Size of embeddings\u001b[39;49;00m\n",
      "    \u001b[33m    hidden_size: The number of features in the hidden state of LSTM or RNN\u001b[39;49;00m\n",
      "    \u001b[33m    seq_model: 'rnn' or 'lstm', whether to use RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    num_layers: Number of layers in RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    \"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[96msuper\u001b[39;49;00m(LanguageModel, \u001b[96mself\u001b[39;49;00m).\u001b[92m__init__\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m### BEGIN YOUR SOLUTION\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94mraise\u001b[39;49;00m \u001b[96mNotImplementedError\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       NotImplementedError\u001b[0m\n",
      "\n",
      "__class__  = <class 'models.LanguageModel'>\n",
      "device     = cpu()\n",
      "dtype      = 'float32'\n",
      "embedding_size = 34\n",
      "hidden_size = 12\n",
      "num_layers = 1\n",
      "output_size = 1000\n",
      "self       = <models.LanguageModel object at 0x157504a10>\n",
      "seq_model  = 'rnn'\n",
      "\n",
      "\u001b[1m\u001b[31mapps/models.py\u001b[0m:38: NotImplementedError\n",
      "\u001b[31m\u001b[1m______ test_language_model_implementation[cpu-rnn-1000-True-12-34-1-1-13] ______\u001b[0m\n",
      "\n",
      "seq_length = 13, num_layers = 1, batch_size = 1, embedding_size = 34\n",
      "hidden_size = 12, init_hidden = True, output_size = 1000, seq_model = 'rnn'\n",
      "device = cpu()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\u001b[90m\u001b[39;49;00m\n",
      "                            init_hidden, output_size, seq_model, device):\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      ">       model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "batch_size = 1\n",
      "c0         = needle.Tensor([[[-0.8966496  -0.45409185 -0.19522631 -1.7286016  -0.23701902\n",
      "    1.6240771  -1.1819947   0.42113942 -0.14759055 -0.08695081\n",
      "    0.23181288  1.2134862 ]]])\n",
      "device     = cpu()\n",
      "embedding_size = 34\n",
      "h0         = needle.Tensor([[[ 1.075893    0.10832448 -0.87009686  0.40803725  0.8432493\n",
      "    0.7045558  -0.18849392 -0.67598957  0.7445776   0.62981176\n",
      "   -2.178561   -2.8604975 ]]])\n",
      "hidden_size = 12\n",
      "init_hidden = True\n",
      "num_layers = 1\n",
      "output_size = 1000\n",
      "seq_length = 13\n",
      "seq_model  = 'rnn'\n",
      "x          = array([[150.],\n",
      "       [855.],\n",
      "       [756.],\n",
      "       [189.],\n",
      "       [ 50.],\n",
      "       [168.],\n",
      "       [681.],\n",
      "       [402.],\n",
      "       [989.],\n",
      "       [167.],\n",
      "       [ 13.],\n",
      "       [405.],\n",
      "       [159.]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:201: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "self = <models.LanguageModel object at 0x1575057c0>, embedding_size = 34\n",
      "output_size = 1000, hidden_size = 12, num_layers = 1, seq_model = 'rnn'\n",
      "device = cpu(), dtype = 'float32'\n",
      "\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92m__init__\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, embedding_size, output_size, hidden_size, num_layers=\u001b[94m1\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                 seq_model=\u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, device=\u001b[94mNone\u001b[39;49;00m, dtype=\u001b[33m\"\u001b[39;49;00m\u001b[33mfloat32\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"\u001b[39;49;00m\n",
      "    \u001b[33m    Consists of an embedding layer, a sequence model (either RNN or LSTM), and a\u001b[39;49;00m\n",
      "    \u001b[33m    linear layer.\u001b[39;49;00m\n",
      "    \u001b[33m    Parameters:\u001b[39;49;00m\n",
      "    \u001b[33m    output_size: Size of dictionary\u001b[39;49;00m\n",
      "    \u001b[33m    embedding_size: Size of embeddings\u001b[39;49;00m\n",
      "    \u001b[33m    hidden_size: The number of features in the hidden state of LSTM or RNN\u001b[39;49;00m\n",
      "    \u001b[33m    seq_model: 'rnn' or 'lstm', whether to use RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    num_layers: Number of layers in RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    \"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[96msuper\u001b[39;49;00m(LanguageModel, \u001b[96mself\u001b[39;49;00m).\u001b[92m__init__\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m### BEGIN YOUR SOLUTION\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94mraise\u001b[39;49;00m \u001b[96mNotImplementedError\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       NotImplementedError\u001b[0m\n",
      "\n",
      "__class__  = <class 'models.LanguageModel'>\n",
      "device     = cpu()\n",
      "dtype      = 'float32'\n",
      "embedding_size = 34\n",
      "hidden_size = 12\n",
      "num_layers = 1\n",
      "output_size = 1000\n",
      "self       = <models.LanguageModel object at 0x1575057c0>\n",
      "seq_model  = 'rnn'\n",
      "\n",
      "\u001b[1m\u001b[31mapps/models.py\u001b[0m:38: NotImplementedError\n",
      "\u001b[31m\u001b[1m______ test_language_model_implementation[cpu-rnn-1000-True-12-34-1-2-1] _______\u001b[0m\n",
      "\n",
      "seq_length = 1, num_layers = 2, batch_size = 1, embedding_size = 34\n",
      "hidden_size = 12, init_hidden = True, output_size = 1000, seq_model = 'rnn'\n",
      "device = cpu()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\u001b[90m\u001b[39;49;00m\n",
      "                            init_hidden, output_size, seq_model, device):\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      ">       model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "batch_size = 1\n",
      "c0         = needle.Tensor([[[ 0.3430828   0.50554764  0.53792626  1.582198    0.6622104\n",
      "   -1.7033292   1.2350092   0.09222789 -1....1  -0.03304705 -1.1552292\n",
      "   -0.77940565 -1.013374    1.825338   -0.5039186  -0.49116653\n",
      "    0.2766609   1.3740592 ]]])\n",
      "device     = cpu()\n",
      "embedding_size = 34\n",
      "h0         = needle.Tensor([[[ 0.0100261  -0.67327386  0.265452   -1.9041494   0.15268987\n",
      "   -0.13226385 -0.6176925   0.68430895 -0...12265  0.0419674  -0.9974881\n",
      "   -1.2133497   0.67911917 -0.2118437  -0.32629988  0.71138\n",
      "   -1.1393659   0.5895388 ]]])\n",
      "hidden_size = 12\n",
      "init_hidden = True\n",
      "num_layers = 2\n",
      "output_size = 1000\n",
      "seq_length = 1\n",
      "seq_model  = 'rnn'\n",
      "x          = array([[307.]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:201: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "self = <models.LanguageModel object at 0x15778cbf0>, embedding_size = 34\n",
      "output_size = 1000, hidden_size = 12, num_layers = 2, seq_model = 'rnn'\n",
      "device = cpu(), dtype = 'float32'\n",
      "\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92m__init__\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, embedding_size, output_size, hidden_size, num_layers=\u001b[94m1\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                 seq_model=\u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, device=\u001b[94mNone\u001b[39;49;00m, dtype=\u001b[33m\"\u001b[39;49;00m\u001b[33mfloat32\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"\u001b[39;49;00m\n",
      "    \u001b[33m    Consists of an embedding layer, a sequence model (either RNN or LSTM), and a\u001b[39;49;00m\n",
      "    \u001b[33m    linear layer.\u001b[39;49;00m\n",
      "    \u001b[33m    Parameters:\u001b[39;49;00m\n",
      "    \u001b[33m    output_size: Size of dictionary\u001b[39;49;00m\n",
      "    \u001b[33m    embedding_size: Size of embeddings\u001b[39;49;00m\n",
      "    \u001b[33m    hidden_size: The number of features in the hidden state of LSTM or RNN\u001b[39;49;00m\n",
      "    \u001b[33m    seq_model: 'rnn' or 'lstm', whether to use RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    num_layers: Number of layers in RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    \"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[96msuper\u001b[39;49;00m(LanguageModel, \u001b[96mself\u001b[39;49;00m).\u001b[92m__init__\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m### BEGIN YOUR SOLUTION\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94mraise\u001b[39;49;00m \u001b[96mNotImplementedError\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       NotImplementedError\u001b[0m\n",
      "\n",
      "__class__  = <class 'models.LanguageModel'>\n",
      "device     = cpu()\n",
      "dtype      = 'float32'\n",
      "embedding_size = 34\n",
      "hidden_size = 12\n",
      "num_layers = 2\n",
      "output_size = 1000\n",
      "self       = <models.LanguageModel object at 0x15778cbf0>\n",
      "seq_model  = 'rnn'\n",
      "\n",
      "\u001b[1m\u001b[31mapps/models.py\u001b[0m:38: NotImplementedError\n",
      "\u001b[31m\u001b[1m______ test_language_model_implementation[cpu-rnn-1000-True-12-34-1-2-13] ______\u001b[0m\n",
      "\n",
      "seq_length = 13, num_layers = 2, batch_size = 1, embedding_size = 34\n",
      "hidden_size = 12, init_hidden = True, output_size = 1000, seq_model = 'rnn'\n",
      "device = cpu()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\u001b[90m\u001b[39;49;00m\n",
      "                            init_hidden, output_size, seq_model, device):\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      ">       model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "batch_size = 1\n",
      "c0         = needle.Tensor([[[ 1.2682494  -1.5960301   0.50826377  2.5104074   0.17906071\n",
      "    0.16190949 -0.13606954 -0.8001186  -0...43  1.4378284  -2.4686923\n",
      "    0.20712833  0.9140036   0.42664018 -0.38316217 -0.29442522\n",
      "   -0.0552403  -1.1041042 ]]])\n",
      "device     = cpu()\n",
      "embedding_size = 34\n",
      "h0         = needle.Tensor([[[-0.30814156 -1.4923226  -0.48954445  0.65218467  0.8835967\n",
      "    0.75252086 -1.018513   -0.10998607 -1....6  -1.8637434  -0.09626433\n",
      "   -0.07168791 -1.1656667   0.4943664  -0.299935    0.8439495\n",
      "    1.9867417   0.69758815]]])\n",
      "hidden_size = 12\n",
      "init_hidden = True\n",
      "num_layers = 2\n",
      "output_size = 1000\n",
      "seq_length = 13\n",
      "seq_model  = 'rnn'\n",
      "x          = array([[610.],\n",
      "       [178.],\n",
      "       [229.],\n",
      "       [112.],\n",
      "       [125.],\n",
      "       [812.],\n",
      "       [614.],\n",
      "       [ 89.],\n",
      "       [269.],\n",
      "       [865.],\n",
      "       [ 17.],\n",
      "       [986.],\n",
      "       [228.]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:201: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "self = <models.LanguageModel object at 0x15748d4c0>, embedding_size = 34\n",
      "output_size = 1000, hidden_size = 12, num_layers = 2, seq_model = 'rnn'\n",
      "device = cpu(), dtype = 'float32'\n",
      "\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92m__init__\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, embedding_size, output_size, hidden_size, num_layers=\u001b[94m1\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                 seq_model=\u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, device=\u001b[94mNone\u001b[39;49;00m, dtype=\u001b[33m\"\u001b[39;49;00m\u001b[33mfloat32\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"\u001b[39;49;00m\n",
      "    \u001b[33m    Consists of an embedding layer, a sequence model (either RNN or LSTM), and a\u001b[39;49;00m\n",
      "    \u001b[33m    linear layer.\u001b[39;49;00m\n",
      "    \u001b[33m    Parameters:\u001b[39;49;00m\n",
      "    \u001b[33m    output_size: Size of dictionary\u001b[39;49;00m\n",
      "    \u001b[33m    embedding_size: Size of embeddings\u001b[39;49;00m\n",
      "    \u001b[33m    hidden_size: The number of features in the hidden state of LSTM or RNN\u001b[39;49;00m\n",
      "    \u001b[33m    seq_model: 'rnn' or 'lstm', whether to use RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    num_layers: Number of layers in RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    \"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[96msuper\u001b[39;49;00m(LanguageModel, \u001b[96mself\u001b[39;49;00m).\u001b[92m__init__\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m### BEGIN YOUR SOLUTION\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94mraise\u001b[39;49;00m \u001b[96mNotImplementedError\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       NotImplementedError\u001b[0m\n",
      "\n",
      "__class__  = <class 'models.LanguageModel'>\n",
      "device     = cpu()\n",
      "dtype      = 'float32'\n",
      "embedding_size = 34\n",
      "hidden_size = 12\n",
      "num_layers = 2\n",
      "output_size = 1000\n",
      "self       = <models.LanguageModel object at 0x15748d4c0>\n",
      "seq_model  = 'rnn'\n",
      "\n",
      "\u001b[1m\u001b[31mapps/models.py\u001b[0m:38: NotImplementedError\n",
      "\u001b[31m\u001b[1m______ test_language_model_implementation[cpu-rnn-1000-True-12-34-15-1-1] ______\u001b[0m\n",
      "\n",
      "seq_length = 1, num_layers = 1, batch_size = 15, embedding_size = 34\n",
      "hidden_size = 12, init_hidden = True, output_size = 1000, seq_model = 'rnn'\n",
      "device = cpu()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\u001b[90m\u001b[39;49;00m\n",
      "                            init_hidden, output_size, seq_model, device):\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      ">       model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "batch_size = 15\n",
      "c0         = needle.Tensor([[[-0.024165    0.8010999   0.27199203 -0.3247982   0.38887838\n",
      "    0.58469033 -1.859843   -1.0067904   0...46  1.7818168   1.1195363\n",
      "   -0.9670267  -2.1162283  -0.1556996  -0.09017624 -0.96860117\n",
      "    0.17766595  0.6596033 ]]])\n",
      "device     = cpu()\n",
      "embedding_size = 34\n",
      "h0         = needle.Tensor([[[-9.15772676e-01 -1.76275063e+00  4.05001074e-01 -8.06610286e-02\n",
      "    8.60131204e-01  1.17718661e+00 -1...  1.18275404e+00  8.99725482e-02  6.48922145e-01\n",
      "    3.86666477e-01  1.06505597e+00 -6.05148733e-01  2.54012555e-01]]])\n",
      "hidden_size = 12\n",
      "init_hidden = True\n",
      "num_layers = 1\n",
      "output_size = 1000\n",
      "seq_length = 1\n",
      "seq_model  = 'rnn'\n",
      "x          = array([[216., 934., 711., 971., 841.,  83., 317., 738., 539.,  65., 961.,\n",
      "        657., 482., 378., 853.]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:201: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "self = <models.LanguageModel object at 0x1575c7bc0>, embedding_size = 34\n",
      "output_size = 1000, hidden_size = 12, num_layers = 1, seq_model = 'rnn'\n",
      "device = cpu(), dtype = 'float32'\n",
      "\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92m__init__\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, embedding_size, output_size, hidden_size, num_layers=\u001b[94m1\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                 seq_model=\u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, device=\u001b[94mNone\u001b[39;49;00m, dtype=\u001b[33m\"\u001b[39;49;00m\u001b[33mfloat32\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"\u001b[39;49;00m\n",
      "    \u001b[33m    Consists of an embedding layer, a sequence model (either RNN or LSTM), and a\u001b[39;49;00m\n",
      "    \u001b[33m    linear layer.\u001b[39;49;00m\n",
      "    \u001b[33m    Parameters:\u001b[39;49;00m\n",
      "    \u001b[33m    output_size: Size of dictionary\u001b[39;49;00m\n",
      "    \u001b[33m    embedding_size: Size of embeddings\u001b[39;49;00m\n",
      "    \u001b[33m    hidden_size: The number of features in the hidden state of LSTM or RNN\u001b[39;49;00m\n",
      "    \u001b[33m    seq_model: 'rnn' or 'lstm', whether to use RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    num_layers: Number of layers in RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    \"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[96msuper\u001b[39;49;00m(LanguageModel, \u001b[96mself\u001b[39;49;00m).\u001b[92m__init__\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m### BEGIN YOUR SOLUTION\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94mraise\u001b[39;49;00m \u001b[96mNotImplementedError\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       NotImplementedError\u001b[0m\n",
      "\n",
      "__class__  = <class 'models.LanguageModel'>\n",
      "device     = cpu()\n",
      "dtype      = 'float32'\n",
      "embedding_size = 34\n",
      "hidden_size = 12\n",
      "num_layers = 1\n",
      "output_size = 1000\n",
      "self       = <models.LanguageModel object at 0x1575c7bc0>\n",
      "seq_model  = 'rnn'\n",
      "\n",
      "\u001b[1m\u001b[31mapps/models.py\u001b[0m:38: NotImplementedError\n",
      "\u001b[31m\u001b[1m_____ test_language_model_implementation[cpu-rnn-1000-True-12-34-15-1-13] ______\u001b[0m\n",
      "\n",
      "seq_length = 13, num_layers = 1, batch_size = 15, embedding_size = 34\n",
      "hidden_size = 12, init_hidden = True, output_size = 1000, seq_model = 'rnn'\n",
      "device = cpu()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\u001b[90m\u001b[39;49;00m\n",
      "                            init_hidden, output_size, seq_model, device):\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      ">       model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "batch_size = 15\n",
      "c0         = needle.Tensor([[[ 6.4146951e-02 -2.5554502e-01 -2.9885146e-01 -1.8012408e+00\n",
      "   -5.8891124e-01  2.1469741e+00 -2.26892...778e+00 -9.4585931e-01 -9.5461555e-02  6.0393050e-02\n",
      "   -9.3023783e-01 -1.1543717e-01 -9.2590982e-01  2.2443419e+00]]])\n",
      "device     = cpu()\n",
      "embedding_size = 34\n",
      "h0         = needle.Tensor([[[ 3.87901664e-01  3.21940452e-01  3.13025087e-01  1.86818707e+00\n",
      "   -2.41347492e-01 -4.55367833e-01 -1... -3.51398051e-01  2.58573508e+00 -6.09997630e-01\n",
      "   -8.31076145e-01  6.25262082e-01 -3.96085054e-01  3.71377379e-01]]])\n",
      "hidden_size = 12\n",
      "init_hidden = True\n",
      "num_layers = 1\n",
      "output_size = 1000\n",
      "seq_length = 13\n",
      "seq_model  = 'rnn'\n",
      "x          = array([[831., 714., 341., 533., 638., 151., 439., 114., 273., 125., 712.,\n",
      "        758., 559., 222., 227.],\n",
      "       [133...    [ 17., 906., 883., 960., 897., 574., 147., 251., 957., 342., 527.,\n",
      "        798., 329.,  89., 327.]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:201: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "self = <models.LanguageModel object at 0x1575060f0>, embedding_size = 34\n",
      "output_size = 1000, hidden_size = 12, num_layers = 1, seq_model = 'rnn'\n",
      "device = cpu(), dtype = 'float32'\n",
      "\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92m__init__\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, embedding_size, output_size, hidden_size, num_layers=\u001b[94m1\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                 seq_model=\u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, device=\u001b[94mNone\u001b[39;49;00m, dtype=\u001b[33m\"\u001b[39;49;00m\u001b[33mfloat32\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"\u001b[39;49;00m\n",
      "    \u001b[33m    Consists of an embedding layer, a sequence model (either RNN or LSTM), and a\u001b[39;49;00m\n",
      "    \u001b[33m    linear layer.\u001b[39;49;00m\n",
      "    \u001b[33m    Parameters:\u001b[39;49;00m\n",
      "    \u001b[33m    output_size: Size of dictionary\u001b[39;49;00m\n",
      "    \u001b[33m    embedding_size: Size of embeddings\u001b[39;49;00m\n",
      "    \u001b[33m    hidden_size: The number of features in the hidden state of LSTM or RNN\u001b[39;49;00m\n",
      "    \u001b[33m    seq_model: 'rnn' or 'lstm', whether to use RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    num_layers: Number of layers in RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    \"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[96msuper\u001b[39;49;00m(LanguageModel, \u001b[96mself\u001b[39;49;00m).\u001b[92m__init__\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m### BEGIN YOUR SOLUTION\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94mraise\u001b[39;49;00m \u001b[96mNotImplementedError\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       NotImplementedError\u001b[0m\n",
      "\n",
      "__class__  = <class 'models.LanguageModel'>\n",
      "device     = cpu()\n",
      "dtype      = 'float32'\n",
      "embedding_size = 34\n",
      "hidden_size = 12\n",
      "num_layers = 1\n",
      "output_size = 1000\n",
      "self       = <models.LanguageModel object at 0x1575060f0>\n",
      "seq_model  = 'rnn'\n",
      "\n",
      "\u001b[1m\u001b[31mapps/models.py\u001b[0m:38: NotImplementedError\n",
      "\u001b[31m\u001b[1m______ test_language_model_implementation[cpu-rnn-1000-True-12-34-15-2-1] ______\u001b[0m\n",
      "\n",
      "seq_length = 1, num_layers = 2, batch_size = 15, embedding_size = 34\n",
      "hidden_size = 12, init_hidden = True, output_size = 1000, seq_model = 'rnn'\n",
      "device = cpu()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\u001b[90m\u001b[39;49;00m\n",
      "                            init_hidden, output_size, seq_model, device):\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      ">       model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "batch_size = 15\n",
      "c0         = needle.Tensor([[[ 4.13938701e-01  8.60594865e-03  1.38236964e+00  1.34944606e+00\n",
      "    3.28176200e-01  2.12630898e-01  1... -6.44544065e-01 -4.26442996e-02 -9.63435113e-01\n",
      "   -1.39889717e+00 -7.88829565e-01  7.02793598e-01  1.73229709e-01]]])\n",
      "device     = cpu()\n",
      "embedding_size = 34\n",
      "h0         = needle.Tensor([[[-0.20868427 -1.7273272  -0.6194198   1.0151792  -0.46514824\n",
      "   -0.6620914   0.43577257  0.34805533  1...66  -0.67873317  0.7412183\n",
      "    0.66679466  0.27562737  0.815284   -1.2450371   2.1619318\n",
      "    1.4063256  -0.04737167]]])\n",
      "hidden_size = 12\n",
      "init_hidden = True\n",
      "num_layers = 2\n",
      "output_size = 1000\n",
      "seq_length = 1\n",
      "seq_model  = 'rnn'\n",
      "x          = array([[896., 971., 617., 639., 797., 103., 752.,  30., 691., 233., 264.,\n",
      "        376.,  15.,  28., 931.]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:201: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "self = <models.LanguageModel object at 0x1577ac260>, embedding_size = 34\n",
      "output_size = 1000, hidden_size = 12, num_layers = 2, seq_model = 'rnn'\n",
      "device = cpu(), dtype = 'float32'\n",
      "\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92m__init__\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, embedding_size, output_size, hidden_size, num_layers=\u001b[94m1\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                 seq_model=\u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, device=\u001b[94mNone\u001b[39;49;00m, dtype=\u001b[33m\"\u001b[39;49;00m\u001b[33mfloat32\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"\u001b[39;49;00m\n",
      "    \u001b[33m    Consists of an embedding layer, a sequence model (either RNN or LSTM), and a\u001b[39;49;00m\n",
      "    \u001b[33m    linear layer.\u001b[39;49;00m\n",
      "    \u001b[33m    Parameters:\u001b[39;49;00m\n",
      "    \u001b[33m    output_size: Size of dictionary\u001b[39;49;00m\n",
      "    \u001b[33m    embedding_size: Size of embeddings\u001b[39;49;00m\n",
      "    \u001b[33m    hidden_size: The number of features in the hidden state of LSTM or RNN\u001b[39;49;00m\n",
      "    \u001b[33m    seq_model: 'rnn' or 'lstm', whether to use RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    num_layers: Number of layers in RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    \"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[96msuper\u001b[39;49;00m(LanguageModel, \u001b[96mself\u001b[39;49;00m).\u001b[92m__init__\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m### BEGIN YOUR SOLUTION\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94mraise\u001b[39;49;00m \u001b[96mNotImplementedError\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       NotImplementedError\u001b[0m\n",
      "\n",
      "__class__  = <class 'models.LanguageModel'>\n",
      "device     = cpu()\n",
      "dtype      = 'float32'\n",
      "embedding_size = 34\n",
      "hidden_size = 12\n",
      "num_layers = 2\n",
      "output_size = 1000\n",
      "self       = <models.LanguageModel object at 0x1577ac260>\n",
      "seq_model  = 'rnn'\n",
      "\n",
      "\u001b[1m\u001b[31mapps/models.py\u001b[0m:38: NotImplementedError\n",
      "\u001b[31m\u001b[1m_____ test_language_model_implementation[cpu-rnn-1000-True-12-34-15-2-13] ______\u001b[0m\n",
      "\n",
      "seq_length = 13, num_layers = 2, batch_size = 15, embedding_size = 34\n",
      "hidden_size = 12, init_hidden = True, output_size = 1000, seq_model = 'rnn'\n",
      "device = cpu()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\u001b[90m\u001b[39;49;00m\n",
      "                            init_hidden, output_size, seq_model, device):\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      ">       model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "batch_size = 15\n",
      "c0         = needle.Tensor([[[ 2.14384347e-01  6.45353973e-01  7.57944226e-01  3.68721008e-01\n",
      "   -1.84506965e+00 -1.56253904e-01 -2... -6.80297732e-01 -6.89615667e-01 -1.36137879e+00\n",
      "    1.69051898e-04  7.93277681e-01  1.33365309e+00 -8.30131829e-01]]])\n",
      "device     = cpu()\n",
      "embedding_size = 34\n",
      "h0         = needle.Tensor([[[ 6.58601403e-01  3.20333451e-01 -1.64255095e+00  1.06786358e+00\n",
      "   -6.86810613e-01  6.46132529e-01  7... -1.28275967e+00 -7.70027936e-02 -8.69572014e-02\n",
      "   -3.90890628e-01 -1.37862158e+00  1.69570959e+00  6.43248916e-01]]])\n",
      "hidden_size = 12\n",
      "init_hidden = True\n",
      "num_layers = 2\n",
      "output_size = 1000\n",
      "seq_length = 13\n",
      "seq_model  = 'rnn'\n",
      "x          = array([[605., 522., 864., 282., 916., 406., 932., 231., 481., 354., 855.,\n",
      "        521., 292., 201.,  47.],\n",
      "       [744...    [ 55., 594., 208., 956., 389., 284., 466., 477., 126., 742., 563.,\n",
      "        746., 667.,  94., 521.]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:201: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "self = <models.LanguageModel object at 0x15753ae40>, embedding_size = 34\n",
      "output_size = 1000, hidden_size = 12, num_layers = 2, seq_model = 'rnn'\n",
      "device = cpu(), dtype = 'float32'\n",
      "\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92m__init__\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, embedding_size, output_size, hidden_size, num_layers=\u001b[94m1\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                 seq_model=\u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, device=\u001b[94mNone\u001b[39;49;00m, dtype=\u001b[33m\"\u001b[39;49;00m\u001b[33mfloat32\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"\u001b[39;49;00m\n",
      "    \u001b[33m    Consists of an embedding layer, a sequence model (either RNN or LSTM), and a\u001b[39;49;00m\n",
      "    \u001b[33m    linear layer.\u001b[39;49;00m\n",
      "    \u001b[33m    Parameters:\u001b[39;49;00m\n",
      "    \u001b[33m    output_size: Size of dictionary\u001b[39;49;00m\n",
      "    \u001b[33m    embedding_size: Size of embeddings\u001b[39;49;00m\n",
      "    \u001b[33m    hidden_size: The number of features in the hidden state of LSTM or RNN\u001b[39;49;00m\n",
      "    \u001b[33m    seq_model: 'rnn' or 'lstm', whether to use RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    num_layers: Number of layers in RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    \"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[96msuper\u001b[39;49;00m(LanguageModel, \u001b[96mself\u001b[39;49;00m).\u001b[92m__init__\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m### BEGIN YOUR SOLUTION\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94mraise\u001b[39;49;00m \u001b[96mNotImplementedError\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       NotImplementedError\u001b[0m\n",
      "\n",
      "__class__  = <class 'models.LanguageModel'>\n",
      "device     = cpu()\n",
      "dtype      = 'float32'\n",
      "embedding_size = 34\n",
      "hidden_size = 12\n",
      "num_layers = 2\n",
      "output_size = 1000\n",
      "self       = <models.LanguageModel object at 0x15753ae40>\n",
      "seq_model  = 'rnn'\n",
      "\n",
      "\u001b[1m\u001b[31mapps/models.py\u001b[0m:38: NotImplementedError\n",
      "\u001b[31m\u001b[1m_______ test_language_model_implementation[cpu-rnn-1000-False-1-1-1-1-1] _______\u001b[0m\n",
      "\n",
      "seq_length = 1, num_layers = 1, batch_size = 1, embedding_size = 1\n",
      "hidden_size = 1, init_hidden = False, output_size = 1000, seq_model = 'rnn'\n",
      "device = cpu()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\u001b[90m\u001b[39;49;00m\n",
      "                            init_hidden, output_size, seq_model, device):\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      ">       model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "batch_size = 1\n",
      "c0         = needle.Tensor([[[1.1680617]]])\n",
      "device     = cpu()\n",
      "embedding_size = 1\n",
      "h0         = needle.Tensor([[[0.6960531]]])\n",
      "hidden_size = 1\n",
      "init_hidden = False\n",
      "num_layers = 1\n",
      "output_size = 1000\n",
      "seq_length = 1\n",
      "seq_model  = 'rnn'\n",
      "x          = array([[725.]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:201: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "self = <models.LanguageModel object at 0x157794740>, embedding_size = 1\n",
      "output_size = 1000, hidden_size = 1, num_layers = 1, seq_model = 'rnn'\n",
      "device = cpu(), dtype = 'float32'\n",
      "\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92m__init__\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, embedding_size, output_size, hidden_size, num_layers=\u001b[94m1\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                 seq_model=\u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, device=\u001b[94mNone\u001b[39;49;00m, dtype=\u001b[33m\"\u001b[39;49;00m\u001b[33mfloat32\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"\u001b[39;49;00m\n",
      "    \u001b[33m    Consists of an embedding layer, a sequence model (either RNN or LSTM), and a\u001b[39;49;00m\n",
      "    \u001b[33m    linear layer.\u001b[39;49;00m\n",
      "    \u001b[33m    Parameters:\u001b[39;49;00m\n",
      "    \u001b[33m    output_size: Size of dictionary\u001b[39;49;00m\n",
      "    \u001b[33m    embedding_size: Size of embeddings\u001b[39;49;00m\n",
      "    \u001b[33m    hidden_size: The number of features in the hidden state of LSTM or RNN\u001b[39;49;00m\n",
      "    \u001b[33m    seq_model: 'rnn' or 'lstm', whether to use RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    num_layers: Number of layers in RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    \"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[96msuper\u001b[39;49;00m(LanguageModel, \u001b[96mself\u001b[39;49;00m).\u001b[92m__init__\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m### BEGIN YOUR SOLUTION\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94mraise\u001b[39;49;00m \u001b[96mNotImplementedError\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       NotImplementedError\u001b[0m\n",
      "\n",
      "__class__  = <class 'models.LanguageModel'>\n",
      "device     = cpu()\n",
      "dtype      = 'float32'\n",
      "embedding_size = 1\n",
      "hidden_size = 1\n",
      "num_layers = 1\n",
      "output_size = 1000\n",
      "self       = <models.LanguageModel object at 0x157794740>\n",
      "seq_model  = 'rnn'\n",
      "\n",
      "\u001b[1m\u001b[31mapps/models.py\u001b[0m:38: NotImplementedError\n",
      "\u001b[31m\u001b[1m______ test_language_model_implementation[cpu-rnn-1000-False-1-1-1-1-13] _______\u001b[0m\n",
      "\n",
      "seq_length = 13, num_layers = 1, batch_size = 1, embedding_size = 1\n",
      "hidden_size = 1, init_hidden = False, output_size = 1000, seq_model = 'rnn'\n",
      "device = cpu()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\u001b[90m\u001b[39;49;00m\n",
      "                            init_hidden, output_size, seq_model, device):\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      ">       model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "batch_size = 1\n",
      "c0         = needle.Tensor([[[-1.0633867]]])\n",
      "device     = cpu()\n",
      "embedding_size = 1\n",
      "h0         = needle.Tensor([[[-0.35160843]]])\n",
      "hidden_size = 1\n",
      "init_hidden = False\n",
      "num_layers = 1\n",
      "output_size = 1000\n",
      "seq_length = 13\n",
      "seq_model  = 'rnn'\n",
      "x          = array([[306.],\n",
      "       [810.],\n",
      "       [955.],\n",
      "       [572.],\n",
      "       [277.],\n",
      "       [206.],\n",
      "       [965.],\n",
      "       [ 74.],\n",
      "       [ 84.],\n",
      "       [955.],\n",
      "       [458.],\n",
      "       [ 66.],\n",
      "       [326.]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:201: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "self = <models.LanguageModel object at 0x157797530>, embedding_size = 1\n",
      "output_size = 1000, hidden_size = 1, num_layers = 1, seq_model = 'rnn'\n",
      "device = cpu(), dtype = 'float32'\n",
      "\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92m__init__\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, embedding_size, output_size, hidden_size, num_layers=\u001b[94m1\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                 seq_model=\u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, device=\u001b[94mNone\u001b[39;49;00m, dtype=\u001b[33m\"\u001b[39;49;00m\u001b[33mfloat32\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"\u001b[39;49;00m\n",
      "    \u001b[33m    Consists of an embedding layer, a sequence model (either RNN or LSTM), and a\u001b[39;49;00m\n",
      "    \u001b[33m    linear layer.\u001b[39;49;00m\n",
      "    \u001b[33m    Parameters:\u001b[39;49;00m\n",
      "    \u001b[33m    output_size: Size of dictionary\u001b[39;49;00m\n",
      "    \u001b[33m    embedding_size: Size of embeddings\u001b[39;49;00m\n",
      "    \u001b[33m    hidden_size: The number of features in the hidden state of LSTM or RNN\u001b[39;49;00m\n",
      "    \u001b[33m    seq_model: 'rnn' or 'lstm', whether to use RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    num_layers: Number of layers in RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    \"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[96msuper\u001b[39;49;00m(LanguageModel, \u001b[96mself\u001b[39;49;00m).\u001b[92m__init__\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m### BEGIN YOUR SOLUTION\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94mraise\u001b[39;49;00m \u001b[96mNotImplementedError\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       NotImplementedError\u001b[0m\n",
      "\n",
      "__class__  = <class 'models.LanguageModel'>\n",
      "device     = cpu()\n",
      "dtype      = 'float32'\n",
      "embedding_size = 1\n",
      "hidden_size = 1\n",
      "num_layers = 1\n",
      "output_size = 1000\n",
      "self       = <models.LanguageModel object at 0x157797530>\n",
      "seq_model  = 'rnn'\n",
      "\n",
      "\u001b[1m\u001b[31mapps/models.py\u001b[0m:38: NotImplementedError\n",
      "\u001b[31m\u001b[1m_______ test_language_model_implementation[cpu-rnn-1000-False-1-1-1-2-1] _______\u001b[0m\n",
      "\n",
      "seq_length = 1, num_layers = 2, batch_size = 1, embedding_size = 1\n",
      "hidden_size = 1, init_hidden = False, output_size = 1000, seq_model = 'rnn'\n",
      "device = cpu()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\u001b[90m\u001b[39;49;00m\n",
      "                            init_hidden, output_size, seq_model, device):\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      ">       model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "batch_size = 1\n",
      "c0         = needle.Tensor([[[-0.6836024 ]]\n",
      "\n",
      " [[-0.30054682]]])\n",
      "device     = cpu()\n",
      "embedding_size = 1\n",
      "h0         = needle.Tensor([[[-0.24303754]]\n",
      "\n",
      " [[ 0.52405655]]])\n",
      "hidden_size = 1\n",
      "init_hidden = False\n",
      "num_layers = 2\n",
      "output_size = 1000\n",
      "seq_length = 1\n",
      "seq_model  = 'rnn'\n",
      "x          = array([[6.]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:201: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "self = <models.LanguageModel object at 0x157795a30>, embedding_size = 1\n",
      "output_size = 1000, hidden_size = 1, num_layers = 2, seq_model = 'rnn'\n",
      "device = cpu(), dtype = 'float32'\n",
      "\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92m__init__\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, embedding_size, output_size, hidden_size, num_layers=\u001b[94m1\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                 seq_model=\u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, device=\u001b[94mNone\u001b[39;49;00m, dtype=\u001b[33m\"\u001b[39;49;00m\u001b[33mfloat32\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"\u001b[39;49;00m\n",
      "    \u001b[33m    Consists of an embedding layer, a sequence model (either RNN or LSTM), and a\u001b[39;49;00m\n",
      "    \u001b[33m    linear layer.\u001b[39;49;00m\n",
      "    \u001b[33m    Parameters:\u001b[39;49;00m\n",
      "    \u001b[33m    output_size: Size of dictionary\u001b[39;49;00m\n",
      "    \u001b[33m    embedding_size: Size of embeddings\u001b[39;49;00m\n",
      "    \u001b[33m    hidden_size: The number of features in the hidden state of LSTM or RNN\u001b[39;49;00m\n",
      "    \u001b[33m    seq_model: 'rnn' or 'lstm', whether to use RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    num_layers: Number of layers in RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    \"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[96msuper\u001b[39;49;00m(LanguageModel, \u001b[96mself\u001b[39;49;00m).\u001b[92m__init__\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m### BEGIN YOUR SOLUTION\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94mraise\u001b[39;49;00m \u001b[96mNotImplementedError\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       NotImplementedError\u001b[0m\n",
      "\n",
      "__class__  = <class 'models.LanguageModel'>\n",
      "device     = cpu()\n",
      "dtype      = 'float32'\n",
      "embedding_size = 1\n",
      "hidden_size = 1\n",
      "num_layers = 2\n",
      "output_size = 1000\n",
      "self       = <models.LanguageModel object at 0x157795a30>\n",
      "seq_model  = 'rnn'\n",
      "\n",
      "\u001b[1m\u001b[31mapps/models.py\u001b[0m:38: NotImplementedError\n",
      "\u001b[31m\u001b[1m______ test_language_model_implementation[cpu-rnn-1000-False-1-1-1-2-13] _______\u001b[0m\n",
      "\n",
      "seq_length = 13, num_layers = 2, batch_size = 1, embedding_size = 1\n",
      "hidden_size = 1, init_hidden = False, output_size = 1000, seq_model = 'rnn'\n",
      "device = cpu()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\u001b[90m\u001b[39;49;00m\n",
      "                            init_hidden, output_size, seq_model, device):\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      ">       model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "batch_size = 1\n",
      "c0         = needle.Tensor([[[0.8872479]]\n",
      "\n",
      " [[1.0917978]]])\n",
      "device     = cpu()\n",
      "embedding_size = 1\n",
      "h0         = needle.Tensor([[[0.79333705]]\n",
      "\n",
      " [[0.75522655]]])\n",
      "hidden_size = 1\n",
      "init_hidden = False\n",
      "num_layers = 2\n",
      "output_size = 1000\n",
      "seq_length = 13\n",
      "seq_model  = 'rnn'\n",
      "x          = array([[485.],\n",
      "       [311.],\n",
      "       [868.],\n",
      "       [184.],\n",
      "       [970.],\n",
      "       [404.],\n",
      "       [314.],\n",
      "       [ 59.],\n",
      "       [887.],\n",
      "       [684.],\n",
      "       [829.],\n",
      "       [914.],\n",
      "       [126.]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:201: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "self = <models.LanguageModel object at 0x157794aa0>, embedding_size = 1\n",
      "output_size = 1000, hidden_size = 1, num_layers = 2, seq_model = 'rnn'\n",
      "device = cpu(), dtype = 'float32'\n",
      "\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92m__init__\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, embedding_size, output_size, hidden_size, num_layers=\u001b[94m1\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                 seq_model=\u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, device=\u001b[94mNone\u001b[39;49;00m, dtype=\u001b[33m\"\u001b[39;49;00m\u001b[33mfloat32\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"\u001b[39;49;00m\n",
      "    \u001b[33m    Consists of an embedding layer, a sequence model (either RNN or LSTM), and a\u001b[39;49;00m\n",
      "    \u001b[33m    linear layer.\u001b[39;49;00m\n",
      "    \u001b[33m    Parameters:\u001b[39;49;00m\n",
      "    \u001b[33m    output_size: Size of dictionary\u001b[39;49;00m\n",
      "    \u001b[33m    embedding_size: Size of embeddings\u001b[39;49;00m\n",
      "    \u001b[33m    hidden_size: The number of features in the hidden state of LSTM or RNN\u001b[39;49;00m\n",
      "    \u001b[33m    seq_model: 'rnn' or 'lstm', whether to use RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    num_layers: Number of layers in RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    \"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[96msuper\u001b[39;49;00m(LanguageModel, \u001b[96mself\u001b[39;49;00m).\u001b[92m__init__\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m### BEGIN YOUR SOLUTION\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94mraise\u001b[39;49;00m \u001b[96mNotImplementedError\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       NotImplementedError\u001b[0m\n",
      "\n",
      "__class__  = <class 'models.LanguageModel'>\n",
      "device     = cpu()\n",
      "dtype      = 'float32'\n",
      "embedding_size = 1\n",
      "hidden_size = 1\n",
      "num_layers = 2\n",
      "output_size = 1000\n",
      "self       = <models.LanguageModel object at 0x157794aa0>\n",
      "seq_model  = 'rnn'\n",
      "\n",
      "\u001b[1m\u001b[31mapps/models.py\u001b[0m:38: NotImplementedError\n",
      "\u001b[31m\u001b[1m______ test_language_model_implementation[cpu-rnn-1000-False-1-1-15-1-1] _______\u001b[0m\n",
      "\n",
      "seq_length = 1, num_layers = 1, batch_size = 15, embedding_size = 1\n",
      "hidden_size = 1, init_hidden = False, output_size = 1000, seq_model = 'rnn'\n",
      "device = cpu()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\u001b[90m\u001b[39;49;00m\n",
      "                            init_hidden, output_size, seq_model, device):\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      ">       model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "batch_size = 15\n",
      "c0         = needle.Tensor([[[-0.6236546 ]\n",
      "  [ 0.7880341 ]\n",
      "  [ 0.65113425]\n",
      "  [ 0.6806424 ]\n",
      "  [ 0.8177094 ]\n",
      "  [ 0.26251557]\n",
      "  [-0.30...776]\n",
      "  [-1.2490757 ]\n",
      "  [ 0.43040118]\n",
      "  [ 0.40795785]\n",
      "  [-0.92235106]\n",
      "  [ 0.7926343 ]\n",
      "  [-1.1212124 ]\n",
      "  [-1.2838346 ]]])\n",
      "device     = cpu()\n",
      "embedding_size = 1\n",
      "h0         = needle.Tensor([[[ 9.2841184e-01]\n",
      "  [ 7.0889562e-01]\n",
      "  [ 6.7614508e-01]\n",
      "  [ 9.8111647e-01]\n",
      "  [-8.6902559e-01]\n",
      "  [-6.557...1]\n",
      "  [-1.4937779e+00]\n",
      "  [-8.6438352e-01]\n",
      "  [ 3.7797588e-01]\n",
      "  [-1.1259352e+00]\n",
      "  [ 1.1077291e+00]\n",
      "  [ 1.4409327e-03]]])\n",
      "hidden_size = 1\n",
      "init_hidden = False\n",
      "num_layers = 1\n",
      "output_size = 1000\n",
      "seq_length = 1\n",
      "seq_model  = 'rnn'\n",
      "x          = array([[808., 124., 475., 109., 782., 547., 836., 960., 438., 651.,  18.,\n",
      "        688., 323., 638., 724.]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:201: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "self = <models.LanguageModel object at 0x15748e390>, embedding_size = 1\n",
      "output_size = 1000, hidden_size = 1, num_layers = 1, seq_model = 'rnn'\n",
      "device = cpu(), dtype = 'float32'\n",
      "\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92m__init__\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, embedding_size, output_size, hidden_size, num_layers=\u001b[94m1\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                 seq_model=\u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, device=\u001b[94mNone\u001b[39;49;00m, dtype=\u001b[33m\"\u001b[39;49;00m\u001b[33mfloat32\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"\u001b[39;49;00m\n",
      "    \u001b[33m    Consists of an embedding layer, a sequence model (either RNN or LSTM), and a\u001b[39;49;00m\n",
      "    \u001b[33m    linear layer.\u001b[39;49;00m\n",
      "    \u001b[33m    Parameters:\u001b[39;49;00m\n",
      "    \u001b[33m    output_size: Size of dictionary\u001b[39;49;00m\n",
      "    \u001b[33m    embedding_size: Size of embeddings\u001b[39;49;00m\n",
      "    \u001b[33m    hidden_size: The number of features in the hidden state of LSTM or RNN\u001b[39;49;00m\n",
      "    \u001b[33m    seq_model: 'rnn' or 'lstm', whether to use RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    num_layers: Number of layers in RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    \"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[96msuper\u001b[39;49;00m(LanguageModel, \u001b[96mself\u001b[39;49;00m).\u001b[92m__init__\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m### BEGIN YOUR SOLUTION\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94mraise\u001b[39;49;00m \u001b[96mNotImplementedError\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       NotImplementedError\u001b[0m\n",
      "\n",
      "__class__  = <class 'models.LanguageModel'>\n",
      "device     = cpu()\n",
      "dtype      = 'float32'\n",
      "embedding_size = 1\n",
      "hidden_size = 1\n",
      "num_layers = 1\n",
      "output_size = 1000\n",
      "self       = <models.LanguageModel object at 0x15748e390>\n",
      "seq_model  = 'rnn'\n",
      "\n",
      "\u001b[1m\u001b[31mapps/models.py\u001b[0m:38: NotImplementedError\n",
      "\u001b[31m\u001b[1m______ test_language_model_implementation[cpu-rnn-1000-False-1-1-15-1-13] ______\u001b[0m\n",
      "\n",
      "seq_length = 13, num_layers = 1, batch_size = 15, embedding_size = 1\n",
      "hidden_size = 1, init_hidden = False, output_size = 1000, seq_model = 'rnn'\n",
      "device = cpu()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\u001b[90m\u001b[39;49;00m\n",
      "                            init_hidden, output_size, seq_model, device):\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      ">       model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "batch_size = 15\n",
      "c0         = needle.Tensor([[[ 0.49415305]\n",
      "  [ 2.238403  ]\n",
      "  [ 1.6075245 ]\n",
      "  [-1.124388  ]\n",
      "  [-0.88373065]\n",
      "  [-0.04995747]\n",
      "  [ 0.54...64 ]\n",
      "  [-1.5099478 ]\n",
      "  [-1.430878  ]\n",
      "  [ 0.997536  ]\n",
      "  [ 0.2839232 ]\n",
      "  [ 0.23791064]\n",
      "  [-0.47679907]\n",
      "  [ 1.0777504 ]]])\n",
      "device     = cpu()\n",
      "embedding_size = 1\n",
      "h0         = needle.Tensor([[[-0.04826349]\n",
      "  [ 0.04868641]\n",
      "  [-1.2210668 ]\n",
      "  [-0.90682495]\n",
      "  [ 0.6277182 ]\n",
      "  [ 0.07255696]\n",
      "  [-0.61...413]\n",
      "  [-0.4405659 ]\n",
      "  [ 1.6595286 ]\n",
      "  [ 1.4594893 ]\n",
      "  [ 0.22392654]\n",
      "  [ 1.3423492 ]\n",
      "  [ 0.17316298]\n",
      "  [-0.06892478]]])\n",
      "hidden_size = 1\n",
      "init_hidden = False\n",
      "num_layers = 1\n",
      "output_size = 1000\n",
      "seq_length = 13\n",
      "seq_model  = 'rnn'\n",
      "x          = array([[322., 387., 397., 586., 274., 709., 303., 296., 211., 587., 392.,\n",
      "         84., 106., 161., 905.],\n",
      "       [481...    [839.,  98., 104., 210.,  34., 179., 662., 353., 639.,  85., 242.,\n",
      "        721., 335., 216.,  74.]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:201: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "self = <models.LanguageModel object at 0x15778ce30>, embedding_size = 1\n",
      "output_size = 1000, hidden_size = 1, num_layers = 1, seq_model = 'rnn'\n",
      "device = cpu(), dtype = 'float32'\n",
      "\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92m__init__\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, embedding_size, output_size, hidden_size, num_layers=\u001b[94m1\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                 seq_model=\u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, device=\u001b[94mNone\u001b[39;49;00m, dtype=\u001b[33m\"\u001b[39;49;00m\u001b[33mfloat32\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"\u001b[39;49;00m\n",
      "    \u001b[33m    Consists of an embedding layer, a sequence model (either RNN or LSTM), and a\u001b[39;49;00m\n",
      "    \u001b[33m    linear layer.\u001b[39;49;00m\n",
      "    \u001b[33m    Parameters:\u001b[39;49;00m\n",
      "    \u001b[33m    output_size: Size of dictionary\u001b[39;49;00m\n",
      "    \u001b[33m    embedding_size: Size of embeddings\u001b[39;49;00m\n",
      "    \u001b[33m    hidden_size: The number of features in the hidden state of LSTM or RNN\u001b[39;49;00m\n",
      "    \u001b[33m    seq_model: 'rnn' or 'lstm', whether to use RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    num_layers: Number of layers in RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    \"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[96msuper\u001b[39;49;00m(LanguageModel, \u001b[96mself\u001b[39;49;00m).\u001b[92m__init__\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m### BEGIN YOUR SOLUTION\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94mraise\u001b[39;49;00m \u001b[96mNotImplementedError\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       NotImplementedError\u001b[0m\n",
      "\n",
      "__class__  = <class 'models.LanguageModel'>\n",
      "device     = cpu()\n",
      "dtype      = 'float32'\n",
      "embedding_size = 1\n",
      "hidden_size = 1\n",
      "num_layers = 1\n",
      "output_size = 1000\n",
      "self       = <models.LanguageModel object at 0x15778ce30>\n",
      "seq_model  = 'rnn'\n",
      "\n",
      "\u001b[1m\u001b[31mapps/models.py\u001b[0m:38: NotImplementedError\n",
      "\u001b[31m\u001b[1m______ test_language_model_implementation[cpu-rnn-1000-False-1-1-15-2-1] _______\u001b[0m\n",
      "\n",
      "seq_length = 1, num_layers = 2, batch_size = 15, embedding_size = 1\n",
      "hidden_size = 1, init_hidden = False, output_size = 1000, seq_model = 'rnn'\n",
      "device = cpu()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\u001b[90m\u001b[39;49;00m\n",
      "                            init_hidden, output_size, seq_model, device):\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      ">       model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "batch_size = 15\n",
      "c0         = needle.Tensor([[[ 0.24436864]\n",
      "  [ 0.5797666 ]\n",
      "  [ 0.14269745]\n",
      "  [-0.65758836]\n",
      "  [ 0.9730822 ]\n",
      "  [-1.507747  ]\n",
      "  [-0.37...54 ]\n",
      "  [-1.576842  ]\n",
      "  [ 0.76991916]\n",
      "  [-3.1137888 ]\n",
      "  [-1.1898954 ]\n",
      "  [ 0.15258081]\n",
      "  [ 0.5540616 ]\n",
      "  [ 0.05262964]]])\n",
      "device     = cpu()\n",
      "embedding_size = 1\n",
      "h0         = needle.Tensor([[[ 1.5723801 ]\n",
      "  [-1.3546324 ]\n",
      "  [-0.4279044 ]\n",
      "  [ 0.64917076]\n",
      "  [-1.4834466 ]\n",
      "  [ 1.1453232 ]\n",
      "  [ 0.91...85 ]\n",
      "  [-0.37224853]\n",
      "  [ 0.37398237]\n",
      "  [-1.9070762 ]\n",
      "  [ 0.04732922]\n",
      "  [ 0.57048506]\n",
      "  [-0.7882144 ]\n",
      "  [-0.77311605]]])\n",
      "hidden_size = 1\n",
      "init_hidden = False\n",
      "num_layers = 2\n",
      "output_size = 1000\n",
      "seq_length = 1\n",
      "seq_model  = 'rnn'\n",
      "x          = array([[312.,  43., 848., 239., 532., 710., 403., 423., 685., 676., 211.,\n",
      "        361.,  54., 875., 630.]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:201: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "self = <models.LanguageModel object at 0x157507980>, embedding_size = 1\n",
      "output_size = 1000, hidden_size = 1, num_layers = 2, seq_model = 'rnn'\n",
      "device = cpu(), dtype = 'float32'\n",
      "\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92m__init__\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, embedding_size, output_size, hidden_size, num_layers=\u001b[94m1\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                 seq_model=\u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, device=\u001b[94mNone\u001b[39;49;00m, dtype=\u001b[33m\"\u001b[39;49;00m\u001b[33mfloat32\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"\u001b[39;49;00m\n",
      "    \u001b[33m    Consists of an embedding layer, a sequence model (either RNN or LSTM), and a\u001b[39;49;00m\n",
      "    \u001b[33m    linear layer.\u001b[39;49;00m\n",
      "    \u001b[33m    Parameters:\u001b[39;49;00m\n",
      "    \u001b[33m    output_size: Size of dictionary\u001b[39;49;00m\n",
      "    \u001b[33m    embedding_size: Size of embeddings\u001b[39;49;00m\n",
      "    \u001b[33m    hidden_size: The number of features in the hidden state of LSTM or RNN\u001b[39;49;00m\n",
      "    \u001b[33m    seq_model: 'rnn' or 'lstm', whether to use RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    num_layers: Number of layers in RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    \"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[96msuper\u001b[39;49;00m(LanguageModel, \u001b[96mself\u001b[39;49;00m).\u001b[92m__init__\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m### BEGIN YOUR SOLUTION\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94mraise\u001b[39;49;00m \u001b[96mNotImplementedError\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       NotImplementedError\u001b[0m\n",
      "\n",
      "__class__  = <class 'models.LanguageModel'>\n",
      "device     = cpu()\n",
      "dtype      = 'float32'\n",
      "embedding_size = 1\n",
      "hidden_size = 1\n",
      "num_layers = 2\n",
      "output_size = 1000\n",
      "self       = <models.LanguageModel object at 0x157507980>\n",
      "seq_model  = 'rnn'\n",
      "\n",
      "\u001b[1m\u001b[31mapps/models.py\u001b[0m:38: NotImplementedError\n",
      "\u001b[31m\u001b[1m______ test_language_model_implementation[cpu-rnn-1000-False-1-1-15-2-13] ______\u001b[0m\n",
      "\n",
      "seq_length = 13, num_layers = 2, batch_size = 15, embedding_size = 1\n",
      "hidden_size = 1, init_hidden = False, output_size = 1000, seq_model = 'rnn'\n",
      "device = cpu()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\u001b[90m\u001b[39;49;00m\n",
      "                            init_hidden, output_size, seq_model, device):\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      ">       model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "batch_size = 15\n",
      "c0         = needle.Tensor([[[-0.8266245 ]\n",
      "  [ 0.36876568]\n",
      "  [ 0.24916063]\n",
      "  [ 1.3141892 ]\n",
      "  [ 1.0376288 ]\n",
      "  [-1.8333158 ]\n",
      "  [ 0.66...58 ]\n",
      "  [-0.5743481 ]\n",
      "  [ 0.93767446]\n",
      "  [ 0.27291003]\n",
      "  [ 0.80001646]\n",
      "  [-2.1379728 ]\n",
      "  [-0.5978344 ]\n",
      "  [ 1.1429259 ]]])\n",
      "device     = cpu()\n",
      "embedding_size = 1\n",
      "h0         = needle.Tensor([[[ 0.2930729 ]\n",
      "  [-0.8356589 ]\n",
      "  [ 1.3117673 ]\n",
      "  [-1.7440324 ]\n",
      "  [-1.9924343 ]\n",
      "  [-0.8354798 ]\n",
      "  [ 1.12...147]\n",
      "  [-1.106448  ]\n",
      "  [ 0.6789466 ]\n",
      "  [-1.0712416 ]\n",
      "  [ 0.14647906]\n",
      "  [-0.20233965]\n",
      "  [ 0.7859948 ]\n",
      "  [-0.2944264 ]]])\n",
      "hidden_size = 1\n",
      "init_hidden = False\n",
      "num_layers = 2\n",
      "output_size = 1000\n",
      "seq_length = 13\n",
      "seq_model  = 'rnn'\n",
      "x          = array([[731., 930.,  34., 808., 512., 990., 794., 546., 952., 949., 943.,\n",
      "         77., 257.,  76., 482.],\n",
      "       [918...    [488., 404., 839., 994.,  65., 934., 750.,  22., 906., 356., 766.,\n",
      "        874., 448., 676., 578.]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:201: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "self = <models.LanguageModel object at 0x1577aefc0>, embedding_size = 1\n",
      "output_size = 1000, hidden_size = 1, num_layers = 2, seq_model = 'rnn'\n",
      "device = cpu(), dtype = 'float32'\n",
      "\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92m__init__\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, embedding_size, output_size, hidden_size, num_layers=\u001b[94m1\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                 seq_model=\u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, device=\u001b[94mNone\u001b[39;49;00m, dtype=\u001b[33m\"\u001b[39;49;00m\u001b[33mfloat32\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"\u001b[39;49;00m\n",
      "    \u001b[33m    Consists of an embedding layer, a sequence model (either RNN or LSTM), and a\u001b[39;49;00m\n",
      "    \u001b[33m    linear layer.\u001b[39;49;00m\n",
      "    \u001b[33m    Parameters:\u001b[39;49;00m\n",
      "    \u001b[33m    output_size: Size of dictionary\u001b[39;49;00m\n",
      "    \u001b[33m    embedding_size: Size of embeddings\u001b[39;49;00m\n",
      "    \u001b[33m    hidden_size: The number of features in the hidden state of LSTM or RNN\u001b[39;49;00m\n",
      "    \u001b[33m    seq_model: 'rnn' or 'lstm', whether to use RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    num_layers: Number of layers in RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    \"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[96msuper\u001b[39;49;00m(LanguageModel, \u001b[96mself\u001b[39;49;00m).\u001b[92m__init__\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m### BEGIN YOUR SOLUTION\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94mraise\u001b[39;49;00m \u001b[96mNotImplementedError\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       NotImplementedError\u001b[0m\n",
      "\n",
      "__class__  = <class 'models.LanguageModel'>\n",
      "device     = cpu()\n",
      "dtype      = 'float32'\n",
      "embedding_size = 1\n",
      "hidden_size = 1\n",
      "num_layers = 2\n",
      "output_size = 1000\n",
      "self       = <models.LanguageModel object at 0x1577aefc0>\n",
      "seq_model  = 'rnn'\n",
      "\n",
      "\u001b[1m\u001b[31mapps/models.py\u001b[0m:38: NotImplementedError\n",
      "\u001b[31m\u001b[1m______ test_language_model_implementation[cpu-rnn-1000-False-1-34-1-1-1] _______\u001b[0m\n",
      "\n",
      "seq_length = 1, num_layers = 1, batch_size = 1, embedding_size = 34\n",
      "hidden_size = 1, init_hidden = False, output_size = 1000, seq_model = 'rnn'\n",
      "device = cpu()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\u001b[90m\u001b[39;49;00m\n",
      "                            init_hidden, output_size, seq_model, device):\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      ">       model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "batch_size = 1\n",
      "c0         = needle.Tensor([[[0.20127814]]])\n",
      "device     = cpu()\n",
      "embedding_size = 34\n",
      "h0         = needle.Tensor([[[-0.8800172]]])\n",
      "hidden_size = 1\n",
      "init_hidden = False\n",
      "num_layers = 1\n",
      "output_size = 1000\n",
      "seq_length = 1\n",
      "seq_model  = 'rnn'\n",
      "x          = array([[744.]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:201: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "self = <models.LanguageModel object at 0x157795eb0>, embedding_size = 34\n",
      "output_size = 1000, hidden_size = 1, num_layers = 1, seq_model = 'rnn'\n",
      "device = cpu(), dtype = 'float32'\n",
      "\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92m__init__\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, embedding_size, output_size, hidden_size, num_layers=\u001b[94m1\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                 seq_model=\u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, device=\u001b[94mNone\u001b[39;49;00m, dtype=\u001b[33m\"\u001b[39;49;00m\u001b[33mfloat32\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"\u001b[39;49;00m\n",
      "    \u001b[33m    Consists of an embedding layer, a sequence model (either RNN or LSTM), and a\u001b[39;49;00m\n",
      "    \u001b[33m    linear layer.\u001b[39;49;00m\n",
      "    \u001b[33m    Parameters:\u001b[39;49;00m\n",
      "    \u001b[33m    output_size: Size of dictionary\u001b[39;49;00m\n",
      "    \u001b[33m    embedding_size: Size of embeddings\u001b[39;49;00m\n",
      "    \u001b[33m    hidden_size: The number of features in the hidden state of LSTM or RNN\u001b[39;49;00m\n",
      "    \u001b[33m    seq_model: 'rnn' or 'lstm', whether to use RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    num_layers: Number of layers in RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    \"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[96msuper\u001b[39;49;00m(LanguageModel, \u001b[96mself\u001b[39;49;00m).\u001b[92m__init__\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m### BEGIN YOUR SOLUTION\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94mraise\u001b[39;49;00m \u001b[96mNotImplementedError\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       NotImplementedError\u001b[0m\n",
      "\n",
      "__class__  = <class 'models.LanguageModel'>\n",
      "device     = cpu()\n",
      "dtype      = 'float32'\n",
      "embedding_size = 34\n",
      "hidden_size = 1\n",
      "num_layers = 1\n",
      "output_size = 1000\n",
      "self       = <models.LanguageModel object at 0x157795eb0>\n",
      "seq_model  = 'rnn'\n",
      "\n",
      "\u001b[1m\u001b[31mapps/models.py\u001b[0m:38: NotImplementedError\n",
      "\u001b[31m\u001b[1m______ test_language_model_implementation[cpu-rnn-1000-False-1-34-1-1-13] ______\u001b[0m\n",
      "\n",
      "seq_length = 13, num_layers = 1, batch_size = 1, embedding_size = 34\n",
      "hidden_size = 1, init_hidden = False, output_size = 1000, seq_model = 'rnn'\n",
      "device = cpu()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\u001b[90m\u001b[39;49;00m\n",
      "                            init_hidden, output_size, seq_model, device):\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      ">       model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "batch_size = 1\n",
      "c0         = needle.Tensor([[[-0.99019814]]])\n",
      "device     = cpu()\n",
      "embedding_size = 34\n",
      "h0         = needle.Tensor([[[-1.0732931]]])\n",
      "hidden_size = 1\n",
      "init_hidden = False\n",
      "num_layers = 1\n",
      "output_size = 1000\n",
      "seq_length = 13\n",
      "seq_model  = 'rnn'\n",
      "x          = array([[325.],\n",
      "       [827.],\n",
      "       [456.],\n",
      "       [197.],\n",
      "       [  7.],\n",
      "       [486.],\n",
      "       [911.],\n",
      "       [379.],\n",
      "       [533.],\n",
      "       [ 52.],\n",
      "       [794.],\n",
      "       [923.],\n",
      "       [915.]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:201: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "self = <models.LanguageModel object at 0x157796030>, embedding_size = 34\n",
      "output_size = 1000, hidden_size = 1, num_layers = 1, seq_model = 'rnn'\n",
      "device = cpu(), dtype = 'float32'\n",
      "\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92m__init__\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, embedding_size, output_size, hidden_size, num_layers=\u001b[94m1\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                 seq_model=\u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, device=\u001b[94mNone\u001b[39;49;00m, dtype=\u001b[33m\"\u001b[39;49;00m\u001b[33mfloat32\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"\u001b[39;49;00m\n",
      "    \u001b[33m    Consists of an embedding layer, a sequence model (either RNN or LSTM), and a\u001b[39;49;00m\n",
      "    \u001b[33m    linear layer.\u001b[39;49;00m\n",
      "    \u001b[33m    Parameters:\u001b[39;49;00m\n",
      "    \u001b[33m    output_size: Size of dictionary\u001b[39;49;00m\n",
      "    \u001b[33m    embedding_size: Size of embeddings\u001b[39;49;00m\n",
      "    \u001b[33m    hidden_size: The number of features in the hidden state of LSTM or RNN\u001b[39;49;00m\n",
      "    \u001b[33m    seq_model: 'rnn' or 'lstm', whether to use RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    num_layers: Number of layers in RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    \"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[96msuper\u001b[39;49;00m(LanguageModel, \u001b[96mself\u001b[39;49;00m).\u001b[92m__init__\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m### BEGIN YOUR SOLUTION\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94mraise\u001b[39;49;00m \u001b[96mNotImplementedError\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       NotImplementedError\u001b[0m\n",
      "\n",
      "__class__  = <class 'models.LanguageModel'>\n",
      "device     = cpu()\n",
      "dtype      = 'float32'\n",
      "embedding_size = 34\n",
      "hidden_size = 1\n",
      "num_layers = 1\n",
      "output_size = 1000\n",
      "self       = <models.LanguageModel object at 0x157796030>\n",
      "seq_model  = 'rnn'\n",
      "\n",
      "\u001b[1m\u001b[31mapps/models.py\u001b[0m:38: NotImplementedError\n",
      "\u001b[31m\u001b[1m______ test_language_model_implementation[cpu-rnn-1000-False-1-34-1-2-1] _______\u001b[0m\n",
      "\n",
      "seq_length = 1, num_layers = 2, batch_size = 1, embedding_size = 34\n",
      "hidden_size = 1, init_hidden = False, output_size = 1000, seq_model = 'rnn'\n",
      "device = cpu()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\u001b[90m\u001b[39;49;00m\n",
      "                            init_hidden, output_size, seq_model, device):\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      ">       model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "batch_size = 1\n",
      "c0         = needle.Tensor([[[ 2.1255555 ]]\n",
      "\n",
      " [[-0.32469758]]])\n",
      "device     = cpu()\n",
      "embedding_size = 34\n",
      "h0         = needle.Tensor([[[1.6458716]]\n",
      "\n",
      " [[0.6587371]]])\n",
      "hidden_size = 1\n",
      "init_hidden = False\n",
      "num_layers = 2\n",
      "output_size = 1000\n",
      "seq_length = 1\n",
      "seq_model  = 'rnn'\n",
      "x          = array([[498.]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:201: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "self = <models.LanguageModel object at 0x157796cf0>, embedding_size = 34\n",
      "output_size = 1000, hidden_size = 1, num_layers = 2, seq_model = 'rnn'\n",
      "device = cpu(), dtype = 'float32'\n",
      "\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92m__init__\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, embedding_size, output_size, hidden_size, num_layers=\u001b[94m1\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                 seq_model=\u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, device=\u001b[94mNone\u001b[39;49;00m, dtype=\u001b[33m\"\u001b[39;49;00m\u001b[33mfloat32\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"\u001b[39;49;00m\n",
      "    \u001b[33m    Consists of an embedding layer, a sequence model (either RNN or LSTM), and a\u001b[39;49;00m\n",
      "    \u001b[33m    linear layer.\u001b[39;49;00m\n",
      "    \u001b[33m    Parameters:\u001b[39;49;00m\n",
      "    \u001b[33m    output_size: Size of dictionary\u001b[39;49;00m\n",
      "    \u001b[33m    embedding_size: Size of embeddings\u001b[39;49;00m\n",
      "    \u001b[33m    hidden_size: The number of features in the hidden state of LSTM or RNN\u001b[39;49;00m\n",
      "    \u001b[33m    seq_model: 'rnn' or 'lstm', whether to use RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    num_layers: Number of layers in RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    \"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[96msuper\u001b[39;49;00m(LanguageModel, \u001b[96mself\u001b[39;49;00m).\u001b[92m__init__\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m### BEGIN YOUR SOLUTION\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94mraise\u001b[39;49;00m \u001b[96mNotImplementedError\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       NotImplementedError\u001b[0m\n",
      "\n",
      "__class__  = <class 'models.LanguageModel'>\n",
      "device     = cpu()\n",
      "dtype      = 'float32'\n",
      "embedding_size = 34\n",
      "hidden_size = 1\n",
      "num_layers = 2\n",
      "output_size = 1000\n",
      "self       = <models.LanguageModel object at 0x157796cf0>\n",
      "seq_model  = 'rnn'\n",
      "\n",
      "\u001b[1m\u001b[31mapps/models.py\u001b[0m:38: NotImplementedError\n",
      "\u001b[31m\u001b[1m______ test_language_model_implementation[cpu-rnn-1000-False-1-34-1-2-13] ______\u001b[0m\n",
      "\n",
      "seq_length = 13, num_layers = 2, batch_size = 1, embedding_size = 34\n",
      "hidden_size = 1, init_hidden = False, output_size = 1000, seq_model = 'rnn'\n",
      "device = cpu()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\u001b[90m\u001b[39;49;00m\n",
      "                            init_hidden, output_size, seq_model, device):\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      ">       model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "batch_size = 1\n",
      "c0         = needle.Tensor([[[-0.42726076]]\n",
      "\n",
      " [[-0.5661576 ]]])\n",
      "device     = cpu()\n",
      "embedding_size = 34\n",
      "h0         = needle.Tensor([[[ 0.89005864]]\n",
      "\n",
      " [[-1.8271905 ]]])\n",
      "hidden_size = 1\n",
      "init_hidden = False\n",
      "num_layers = 2\n",
      "output_size = 1000\n",
      "seq_length = 13\n",
      "seq_model  = 'rnn'\n",
      "x          = array([[217.],\n",
      "       [951.],\n",
      "       [730.],\n",
      "       [678.],\n",
      "       [609.],\n",
      "       [457.],\n",
      "       [213.],\n",
      "       [276.],\n",
      "       [813.],\n",
      "       [408.],\n",
      "       [ 33.],\n",
      "       [798.],\n",
      "       [309.]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:201: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "self = <models.LanguageModel object at 0x1577affb0>, embedding_size = 34\n",
      "output_size = 1000, hidden_size = 1, num_layers = 2, seq_model = 'rnn'\n",
      "device = cpu(), dtype = 'float32'\n",
      "\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92m__init__\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, embedding_size, output_size, hidden_size, num_layers=\u001b[94m1\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                 seq_model=\u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, device=\u001b[94mNone\u001b[39;49;00m, dtype=\u001b[33m\"\u001b[39;49;00m\u001b[33mfloat32\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"\u001b[39;49;00m\n",
      "    \u001b[33m    Consists of an embedding layer, a sequence model (either RNN or LSTM), and a\u001b[39;49;00m\n",
      "    \u001b[33m    linear layer.\u001b[39;49;00m\n",
      "    \u001b[33m    Parameters:\u001b[39;49;00m\n",
      "    \u001b[33m    output_size: Size of dictionary\u001b[39;49;00m\n",
      "    \u001b[33m    embedding_size: Size of embeddings\u001b[39;49;00m\n",
      "    \u001b[33m    hidden_size: The number of features in the hidden state of LSTM or RNN\u001b[39;49;00m\n",
      "    \u001b[33m    seq_model: 'rnn' or 'lstm', whether to use RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    num_layers: Number of layers in RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    \"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[96msuper\u001b[39;49;00m(LanguageModel, \u001b[96mself\u001b[39;49;00m).\u001b[92m__init__\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m### BEGIN YOUR SOLUTION\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94mraise\u001b[39;49;00m \u001b[96mNotImplementedError\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       NotImplementedError\u001b[0m\n",
      "\n",
      "__class__  = <class 'models.LanguageModel'>\n",
      "device     = cpu()\n",
      "dtype      = 'float32'\n",
      "embedding_size = 34\n",
      "hidden_size = 1\n",
      "num_layers = 2\n",
      "output_size = 1000\n",
      "self       = <models.LanguageModel object at 0x1577affb0>\n",
      "seq_model  = 'rnn'\n",
      "\n",
      "\u001b[1m\u001b[31mapps/models.py\u001b[0m:38: NotImplementedError\n",
      "\u001b[31m\u001b[1m______ test_language_model_implementation[cpu-rnn-1000-False-1-34-15-1-1] ______\u001b[0m\n",
      "\n",
      "seq_length = 1, num_layers = 1, batch_size = 15, embedding_size = 34\n",
      "hidden_size = 1, init_hidden = False, output_size = 1000, seq_model = 'rnn'\n",
      "device = cpu()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\u001b[90m\u001b[39;49;00m\n",
      "                            init_hidden, output_size, seq_model, device):\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      ">       model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "batch_size = 15\n",
      "c0         = needle.Tensor([[[-0.20518854]\n",
      "  [-1.523568  ]\n",
      "  [ 0.2836439 ]\n",
      "  [-0.01511224]\n",
      "  [-0.53124195]\n",
      "  [ 0.720182  ]\n",
      "  [-2.01...946]\n",
      "  [ 1.6785052 ]\n",
      "  [-0.38760266]\n",
      "  [-0.48344064]\n",
      "  [ 0.7478805 ]\n",
      "  [-1.359201  ]\n",
      "  [ 0.4876875 ]\n",
      "  [ 2.2125938 ]]])\n",
      "device     = cpu()\n",
      "embedding_size = 34\n",
      "h0         = needle.Tensor([[[ 0.58019346]\n",
      "  [-0.8074996 ]\n",
      "  [ 0.35870585]\n",
      "  [-1.4406121 ]\n",
      "  [ 0.55815095]\n",
      "  [-0.89145243]\n",
      "  [ 0.82...18 ]\n",
      "  [ 0.6960633 ]\n",
      "  [-0.01175008]\n",
      "  [-0.33685708]\n",
      "  [-1.3864312 ]\n",
      "  [-1.7133985 ]\n",
      "  [-0.954887  ]\n",
      "  [-2.2418938 ]]])\n",
      "hidden_size = 1\n",
      "init_hidden = False\n",
      "num_layers = 1\n",
      "output_size = 1000\n",
      "seq_length = 1\n",
      "seq_model  = 'rnn'\n",
      "x          = array([[175., 235., 852., 782., 702., 490., 309., 360., 713., 221., 266.,\n",
      "        924., 593., 276., 460.]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:201: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "self = <models.LanguageModel object at 0x1577af230>, embedding_size = 34\n",
      "output_size = 1000, hidden_size = 1, num_layers = 1, seq_model = 'rnn'\n",
      "device = cpu(), dtype = 'float32'\n",
      "\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92m__init__\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, embedding_size, output_size, hidden_size, num_layers=\u001b[94m1\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                 seq_model=\u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, device=\u001b[94mNone\u001b[39;49;00m, dtype=\u001b[33m\"\u001b[39;49;00m\u001b[33mfloat32\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"\u001b[39;49;00m\n",
      "    \u001b[33m    Consists of an embedding layer, a sequence model (either RNN or LSTM), and a\u001b[39;49;00m\n",
      "    \u001b[33m    linear layer.\u001b[39;49;00m\n",
      "    \u001b[33m    Parameters:\u001b[39;49;00m\n",
      "    \u001b[33m    output_size: Size of dictionary\u001b[39;49;00m\n",
      "    \u001b[33m    embedding_size: Size of embeddings\u001b[39;49;00m\n",
      "    \u001b[33m    hidden_size: The number of features in the hidden state of LSTM or RNN\u001b[39;49;00m\n",
      "    \u001b[33m    seq_model: 'rnn' or 'lstm', whether to use RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    num_layers: Number of layers in RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    \"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[96msuper\u001b[39;49;00m(LanguageModel, \u001b[96mself\u001b[39;49;00m).\u001b[92m__init__\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m### BEGIN YOUR SOLUTION\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94mraise\u001b[39;49;00m \u001b[96mNotImplementedError\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       NotImplementedError\u001b[0m\n",
      "\n",
      "__class__  = <class 'models.LanguageModel'>\n",
      "device     = cpu()\n",
      "dtype      = 'float32'\n",
      "embedding_size = 34\n",
      "hidden_size = 1\n",
      "num_layers = 1\n",
      "output_size = 1000\n",
      "self       = <models.LanguageModel object at 0x1577af230>\n",
      "seq_model  = 'rnn'\n",
      "\n",
      "\u001b[1m\u001b[31mapps/models.py\u001b[0m:38: NotImplementedError\n",
      "\u001b[31m\u001b[1m_____ test_language_model_implementation[cpu-rnn-1000-False-1-34-15-1-13] ______\u001b[0m\n",
      "\n",
      "seq_length = 13, num_layers = 1, batch_size = 15, embedding_size = 34\n",
      "hidden_size = 1, init_hidden = False, output_size = 1000, seq_model = 'rnn'\n",
      "device = cpu()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\u001b[90m\u001b[39;49;00m\n",
      "                            init_hidden, output_size, seq_model, device):\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      ">       model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "batch_size = 15\n",
      "c0         = needle.Tensor([[[ 0.17976387]\n",
      "  [ 0.7145726 ]\n",
      "  [ 0.00252514]\n",
      "  [ 0.0276069 ]\n",
      "  [ 1.2182897 ]\n",
      "  [-0.191832  ]\n",
      "  [ 0.44...775]\n",
      "  [ 1.7068615 ]\n",
      "  [-0.85022515]\n",
      "  [ 0.41208908]\n",
      "  [-0.8591717 ]\n",
      "  [ 0.53880376]\n",
      "  [ 0.79676014]\n",
      "  [-0.74079597]]])\n",
      "device     = cpu()\n",
      "embedding_size = 34\n",
      "h0         = needle.Tensor([[[ 0.96132153]\n",
      "  [ 1.5443645 ]\n",
      "  [ 2.334404  ]\n",
      "  [-1.3486387 ]\n",
      "  [ 1.6001631 ]\n",
      "  [-0.83067995]\n",
      "  [-0.14...609]\n",
      "  [-0.90007997]\n",
      "  [-0.02277305]\n",
      "  [ 0.17792827]\n",
      "  [ 1.1970717 ]\n",
      "  [-1.0898658 ]\n",
      "  [-1.4383991 ]\n",
      "  [-1.0570047 ]]])\n",
      "hidden_size = 1\n",
      "init_hidden = False\n",
      "num_layers = 1\n",
      "output_size = 1000\n",
      "seq_length = 13\n",
      "seq_model  = 'rnn'\n",
      "x          = array([[705., 600., 296., 995., 651., 847., 921., 265., 861., 462., 190.,\n",
      "        641.,  47.,  62., 967.],\n",
      "       [ 53...    [610., 910., 450., 963.,  55.,  89., 357., 846., 276., 497., 168.,\n",
      "        895., 862., 352.,  97.]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:201: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "self = <models.LanguageModel object at 0x1577ae420>, embedding_size = 34\n",
      "output_size = 1000, hidden_size = 1, num_layers = 1, seq_model = 'rnn'\n",
      "device = cpu(), dtype = 'float32'\n",
      "\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92m__init__\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, embedding_size, output_size, hidden_size, num_layers=\u001b[94m1\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                 seq_model=\u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, device=\u001b[94mNone\u001b[39;49;00m, dtype=\u001b[33m\"\u001b[39;49;00m\u001b[33mfloat32\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"\u001b[39;49;00m\n",
      "    \u001b[33m    Consists of an embedding layer, a sequence model (either RNN or LSTM), and a\u001b[39;49;00m\n",
      "    \u001b[33m    linear layer.\u001b[39;49;00m\n",
      "    \u001b[33m    Parameters:\u001b[39;49;00m\n",
      "    \u001b[33m    output_size: Size of dictionary\u001b[39;49;00m\n",
      "    \u001b[33m    embedding_size: Size of embeddings\u001b[39;49;00m\n",
      "    \u001b[33m    hidden_size: The number of features in the hidden state of LSTM or RNN\u001b[39;49;00m\n",
      "    \u001b[33m    seq_model: 'rnn' or 'lstm', whether to use RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    num_layers: Number of layers in RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    \"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[96msuper\u001b[39;49;00m(LanguageModel, \u001b[96mself\u001b[39;49;00m).\u001b[92m__init__\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m### BEGIN YOUR SOLUTION\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94mraise\u001b[39;49;00m \u001b[96mNotImplementedError\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       NotImplementedError\u001b[0m\n",
      "\n",
      "__class__  = <class 'models.LanguageModel'>\n",
      "device     = cpu()\n",
      "dtype      = 'float32'\n",
      "embedding_size = 34\n",
      "hidden_size = 1\n",
      "num_layers = 1\n",
      "output_size = 1000\n",
      "self       = <models.LanguageModel object at 0x1577ae420>\n",
      "seq_model  = 'rnn'\n",
      "\n",
      "\u001b[1m\u001b[31mapps/models.py\u001b[0m:38: NotImplementedError\n",
      "\u001b[31m\u001b[1m______ test_language_model_implementation[cpu-rnn-1000-False-1-34-15-2-1] ______\u001b[0m\n",
      "\n",
      "seq_length = 1, num_layers = 2, batch_size = 15, embedding_size = 34\n",
      "hidden_size = 1, init_hidden = False, output_size = 1000, seq_model = 'rnn'\n",
      "device = cpu()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\u001b[90m\u001b[39;49;00m\n",
      "                            init_hidden, output_size, seq_model, device):\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      ">       model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "batch_size = 15\n",
      "c0         = needle.Tensor([[[ 0.5920006 ]\n",
      "  [-0.4832251 ]\n",
      "  [-1.8087608 ]\n",
      "  [-0.36746252]\n",
      "  [-0.61919916]\n",
      "  [-0.65916216]\n",
      "  [-0.12...78 ]\n",
      "  [-0.16666983]\n",
      "  [ 0.19384083]\n",
      "  [ 0.65750504]\n",
      "  [-0.94329464]\n",
      "  [-0.9588121 ]\n",
      "  [ 0.00868028]\n",
      "  [ 0.07868288]]])\n",
      "device     = cpu()\n",
      "embedding_size = 34\n",
      "h0         = needle.Tensor([[[-0.79560256]\n",
      "  [ 0.23177412]\n",
      "  [-1.9788244 ]\n",
      "  [-1.2289561 ]\n",
      "  [-1.2945567 ]\n",
      "  [-1.1679134 ]\n",
      "  [ 1.38...735]\n",
      "  [ 0.10385609]\n",
      "  [ 0.5909692 ]\n",
      "  [-1.7315277 ]\n",
      "  [ 0.16570303]\n",
      "  [ 0.23936126]\n",
      "  [ 0.7958265 ]\n",
      "  [-0.24956098]]])\n",
      "hidden_size = 1\n",
      "init_hidden = False\n",
      "num_layers = 2\n",
      "output_size = 1000\n",
      "seq_length = 1\n",
      "seq_model  = 'rnn'\n",
      "x          = array([[737., 862., 271., 529., 837., 868., 859., 352., 572., 876., 195.,\n",
      "        201., 863., 584., 660.]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:201: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "self = <models.LanguageModel object at 0x1577bd2e0>, embedding_size = 34\n",
      "output_size = 1000, hidden_size = 1, num_layers = 2, seq_model = 'rnn'\n",
      "device = cpu(), dtype = 'float32'\n",
      "\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92m__init__\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, embedding_size, output_size, hidden_size, num_layers=\u001b[94m1\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                 seq_model=\u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, device=\u001b[94mNone\u001b[39;49;00m, dtype=\u001b[33m\"\u001b[39;49;00m\u001b[33mfloat32\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"\u001b[39;49;00m\n",
      "    \u001b[33m    Consists of an embedding layer, a sequence model (either RNN or LSTM), and a\u001b[39;49;00m\n",
      "    \u001b[33m    linear layer.\u001b[39;49;00m\n",
      "    \u001b[33m    Parameters:\u001b[39;49;00m\n",
      "    \u001b[33m    output_size: Size of dictionary\u001b[39;49;00m\n",
      "    \u001b[33m    embedding_size: Size of embeddings\u001b[39;49;00m\n",
      "    \u001b[33m    hidden_size: The number of features in the hidden state of LSTM or RNN\u001b[39;49;00m\n",
      "    \u001b[33m    seq_model: 'rnn' or 'lstm', whether to use RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    num_layers: Number of layers in RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    \"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[96msuper\u001b[39;49;00m(LanguageModel, \u001b[96mself\u001b[39;49;00m).\u001b[92m__init__\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m### BEGIN YOUR SOLUTION\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94mraise\u001b[39;49;00m \u001b[96mNotImplementedError\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       NotImplementedError\u001b[0m\n",
      "\n",
      "__class__  = <class 'models.LanguageModel'>\n",
      "device     = cpu()\n",
      "dtype      = 'float32'\n",
      "embedding_size = 34\n",
      "hidden_size = 1\n",
      "num_layers = 2\n",
      "output_size = 1000\n",
      "self       = <models.LanguageModel object at 0x1577bd2e0>\n",
      "seq_model  = 'rnn'\n",
      "\n",
      "\u001b[1m\u001b[31mapps/models.py\u001b[0m:38: NotImplementedError\n",
      "\u001b[31m\u001b[1m_____ test_language_model_implementation[cpu-rnn-1000-False-1-34-15-2-13] ______\u001b[0m\n",
      "\n",
      "seq_length = 13, num_layers = 2, batch_size = 15, embedding_size = 34\n",
      "hidden_size = 1, init_hidden = False, output_size = 1000, seq_model = 'rnn'\n",
      "device = cpu()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\u001b[90m\u001b[39;49;00m\n",
      "                            init_hidden, output_size, seq_model, device):\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      ">       model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "batch_size = 15\n",
      "c0         = needle.Tensor([[[-0.3440236 ]\n",
      "  [ 1.2461624 ]\n",
      "  [ 0.20689239]\n",
      "  [-2.7379308 ]\n",
      "  [-0.49235943]\n",
      "  [-0.01762371]\n",
      "  [ 0.98...383]\n",
      "  [-0.05405315]\n",
      "  [ 0.5208647 ]\n",
      "  [-0.8521625 ]\n",
      "  [-0.63889956]\n",
      "  [-0.9497852 ]\n",
      "  [-0.09743008]\n",
      "  [-1.1381925 ]]])\n",
      "device     = cpu()\n",
      "embedding_size = 34\n",
      "h0         = needle.Tensor([[[-0.31763205]\n",
      "  [-0.98921686]\n",
      "  [ 1.4031475 ]\n",
      "  [-0.64366394]\n",
      "  [ 1.6358114 ]\n",
      "  [-1.8883256 ]\n",
      "  [ 1.30...378]\n",
      "  [-0.03543316]\n",
      "  [-0.27300537]\n",
      "  [-0.85724735]\n",
      "  [ 0.5962357 ]\n",
      "  [-0.1078399 ]\n",
      "  [-0.442016  ]\n",
      "  [ 1.2818594 ]]])\n",
      "hidden_size = 1\n",
      "init_hidden = False\n",
      "num_layers = 2\n",
      "output_size = 1000\n",
      "seq_length = 13\n",
      "seq_model  = 'rnn'\n",
      "x          = array([[464., 378.,  77., 765., 301., 622., 299., 918., 508., 784., 531.,\n",
      "        554., 612., 115., 306.],\n",
      "       [882...    [986., 519., 667., 820.,  33., 868., 387., 686., 656., 910., 665.,\n",
      "        576., 642.,  63., 530.]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:201: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "self = <models.LanguageModel object at 0x1577be480>, embedding_size = 34\n",
      "output_size = 1000, hidden_size = 1, num_layers = 2, seq_model = 'rnn'\n",
      "device = cpu(), dtype = 'float32'\n",
      "\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92m__init__\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, embedding_size, output_size, hidden_size, num_layers=\u001b[94m1\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                 seq_model=\u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, device=\u001b[94mNone\u001b[39;49;00m, dtype=\u001b[33m\"\u001b[39;49;00m\u001b[33mfloat32\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"\u001b[39;49;00m\n",
      "    \u001b[33m    Consists of an embedding layer, a sequence model (either RNN or LSTM), and a\u001b[39;49;00m\n",
      "    \u001b[33m    linear layer.\u001b[39;49;00m\n",
      "    \u001b[33m    Parameters:\u001b[39;49;00m\n",
      "    \u001b[33m    output_size: Size of dictionary\u001b[39;49;00m\n",
      "    \u001b[33m    embedding_size: Size of embeddings\u001b[39;49;00m\n",
      "    \u001b[33m    hidden_size: The number of features in the hidden state of LSTM or RNN\u001b[39;49;00m\n",
      "    \u001b[33m    seq_model: 'rnn' or 'lstm', whether to use RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    num_layers: Number of layers in RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    \"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[96msuper\u001b[39;49;00m(LanguageModel, \u001b[96mself\u001b[39;49;00m).\u001b[92m__init__\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m### BEGIN YOUR SOLUTION\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94mraise\u001b[39;49;00m \u001b[96mNotImplementedError\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       NotImplementedError\u001b[0m\n",
      "\n",
      "__class__  = <class 'models.LanguageModel'>\n",
      "device     = cpu()\n",
      "dtype      = 'float32'\n",
      "embedding_size = 34\n",
      "hidden_size = 1\n",
      "num_layers = 2\n",
      "output_size = 1000\n",
      "self       = <models.LanguageModel object at 0x1577be480>\n",
      "seq_model  = 'rnn'\n",
      "\n",
      "\u001b[1m\u001b[31mapps/models.py\u001b[0m:38: NotImplementedError\n",
      "\u001b[31m\u001b[1m______ test_language_model_implementation[cpu-rnn-1000-False-12-1-1-1-1] _______\u001b[0m\n",
      "\n",
      "seq_length = 1, num_layers = 1, batch_size = 1, embedding_size = 1\n",
      "hidden_size = 12, init_hidden = False, output_size = 1000, seq_model = 'rnn'\n",
      "device = cpu()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\u001b[90m\u001b[39;49;00m\n",
      "                            init_hidden, output_size, seq_model, device):\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      ">       model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "batch_size = 1\n",
      "c0         = needle.Tensor([[[ 0.53968     0.30826166  0.3618807  -0.11758347 -2.2718406\n",
      "   -0.8124206  -0.99383944  0.8659819   0.7650577  -0.4024327\n",
      "   -0.47558948  0.0134029 ]]])\n",
      "device     = cpu()\n",
      "embedding_size = 1\n",
      "h0         = needle.Tensor([[[ 0.49510273  0.26646522  0.5007615  -0.10760855  0.03339789\n",
      "   -0.74342006 -0.7433173   0.07053147  0.23555699  1.3162107\n",
      "    0.78019553 -0.25049967]]])\n",
      "hidden_size = 12\n",
      "init_hidden = False\n",
      "num_layers = 1\n",
      "output_size = 1000\n",
      "seq_length = 1\n",
      "seq_model  = 'rnn'\n",
      "x          = array([[543.]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:201: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "self = <models.LanguageModel object at 0x1572bb7a0>, embedding_size = 1\n",
      "output_size = 1000, hidden_size = 12, num_layers = 1, seq_model = 'rnn'\n",
      "device = cpu(), dtype = 'float32'\n",
      "\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92m__init__\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, embedding_size, output_size, hidden_size, num_layers=\u001b[94m1\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                 seq_model=\u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, device=\u001b[94mNone\u001b[39;49;00m, dtype=\u001b[33m\"\u001b[39;49;00m\u001b[33mfloat32\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"\u001b[39;49;00m\n",
      "    \u001b[33m    Consists of an embedding layer, a sequence model (either RNN or LSTM), and a\u001b[39;49;00m\n",
      "    \u001b[33m    linear layer.\u001b[39;49;00m\n",
      "    \u001b[33m    Parameters:\u001b[39;49;00m\n",
      "    \u001b[33m    output_size: Size of dictionary\u001b[39;49;00m\n",
      "    \u001b[33m    embedding_size: Size of embeddings\u001b[39;49;00m\n",
      "    \u001b[33m    hidden_size: The number of features in the hidden state of LSTM or RNN\u001b[39;49;00m\n",
      "    \u001b[33m    seq_model: 'rnn' or 'lstm', whether to use RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    num_layers: Number of layers in RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    \"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[96msuper\u001b[39;49;00m(LanguageModel, \u001b[96mself\u001b[39;49;00m).\u001b[92m__init__\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m### BEGIN YOUR SOLUTION\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94mraise\u001b[39;49;00m \u001b[96mNotImplementedError\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       NotImplementedError\u001b[0m\n",
      "\n",
      "__class__  = <class 'models.LanguageModel'>\n",
      "device     = cpu()\n",
      "dtype      = 'float32'\n",
      "embedding_size = 1\n",
      "hidden_size = 12\n",
      "num_layers = 1\n",
      "output_size = 1000\n",
      "self       = <models.LanguageModel object at 0x1572bb7a0>\n",
      "seq_model  = 'rnn'\n",
      "\n",
      "\u001b[1m\u001b[31mapps/models.py\u001b[0m:38: NotImplementedError\n",
      "\u001b[31m\u001b[1m______ test_language_model_implementation[cpu-rnn-1000-False-12-1-1-1-13] ______\u001b[0m\n",
      "\n",
      "seq_length = 13, num_layers = 1, batch_size = 1, embedding_size = 1\n",
      "hidden_size = 12, init_hidden = False, output_size = 1000, seq_model = 'rnn'\n",
      "device = cpu()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\u001b[90m\u001b[39;49;00m\n",
      "                            init_hidden, output_size, seq_model, device):\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      ">       model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "batch_size = 1\n",
      "c0         = needle.Tensor([[[-0.33201066  0.69169    -1.0030758  -0.2708697   1.2723095\n",
      "    3.4826956   0.8728058   0.68920654 -0.2765199   0.11851941\n",
      "   -0.34999025 -1.6362319 ]]])\n",
      "device     = cpu()\n",
      "embedding_size = 1\n",
      "h0         = needle.Tensor([[[-0.9456591  -0.15516295  1.2871897   0.6347165  -1.7157187\n",
      "    1.7525297  -0.24772093  0.23418894  0.5837673  -1.0326177\n",
      "   -0.6552545   0.76760906]]])\n",
      "hidden_size = 12\n",
      "init_hidden = False\n",
      "num_layers = 1\n",
      "output_size = 1000\n",
      "seq_length = 13\n",
      "seq_model  = 'rnn'\n",
      "x          = array([[252.],\n",
      "       [532.],\n",
      "       [257.],\n",
      "       [667.],\n",
      "       [564.],\n",
      "       [255.],\n",
      "       [735.],\n",
      "       [678.],\n",
      "       [ 53.],\n",
      "       [907.],\n",
      "       [174.],\n",
      "       [552.],\n",
      "       [267.]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:201: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "self = <models.LanguageModel object at 0x1577be090>, embedding_size = 1\n",
      "output_size = 1000, hidden_size = 12, num_layers = 1, seq_model = 'rnn'\n",
      "device = cpu(), dtype = 'float32'\n",
      "\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92m__init__\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, embedding_size, output_size, hidden_size, num_layers=\u001b[94m1\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                 seq_model=\u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, device=\u001b[94mNone\u001b[39;49;00m, dtype=\u001b[33m\"\u001b[39;49;00m\u001b[33mfloat32\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"\u001b[39;49;00m\n",
      "    \u001b[33m    Consists of an embedding layer, a sequence model (either RNN or LSTM), and a\u001b[39;49;00m\n",
      "    \u001b[33m    linear layer.\u001b[39;49;00m\n",
      "    \u001b[33m    Parameters:\u001b[39;49;00m\n",
      "    \u001b[33m    output_size: Size of dictionary\u001b[39;49;00m\n",
      "    \u001b[33m    embedding_size: Size of embeddings\u001b[39;49;00m\n",
      "    \u001b[33m    hidden_size: The number of features in the hidden state of LSTM or RNN\u001b[39;49;00m\n",
      "    \u001b[33m    seq_model: 'rnn' or 'lstm', whether to use RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    num_layers: Number of layers in RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    \"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[96msuper\u001b[39;49;00m(LanguageModel, \u001b[96mself\u001b[39;49;00m).\u001b[92m__init__\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m### BEGIN YOUR SOLUTION\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94mraise\u001b[39;49;00m \u001b[96mNotImplementedError\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       NotImplementedError\u001b[0m\n",
      "\n",
      "__class__  = <class 'models.LanguageModel'>\n",
      "device     = cpu()\n",
      "dtype      = 'float32'\n",
      "embedding_size = 1\n",
      "hidden_size = 12\n",
      "num_layers = 1\n",
      "output_size = 1000\n",
      "self       = <models.LanguageModel object at 0x1577be090>\n",
      "seq_model  = 'rnn'\n",
      "\n",
      "\u001b[1m\u001b[31mapps/models.py\u001b[0m:38: NotImplementedError\n",
      "\u001b[31m\u001b[1m______ test_language_model_implementation[cpu-rnn-1000-False-12-1-1-2-1] _______\u001b[0m\n",
      "\n",
      "seq_length = 1, num_layers = 2, batch_size = 1, embedding_size = 1\n",
      "hidden_size = 12, init_hidden = False, output_size = 1000, seq_model = 'rnn'\n",
      "device = cpu()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\u001b[90m\u001b[39;49;00m\n",
      "                            init_hidden, output_size, seq_model, device):\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      ">       model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "batch_size = 1\n",
      "c0         = needle.Tensor([[[ 0.07512562  0.4642248  -0.54980505 -0.33572134  1.4924816\n",
      "    1.496803    1.328473    0.12125894  0....925  1.8023609  -1.4830097\n",
      "    1.635449   -0.5976572  -0.0712148  -0.7172896  -0.6667621\n",
      "    1.3503255   0.08618083]]])\n",
      "device     = cpu()\n",
      "embedding_size = 1\n",
      "h0         = needle.Tensor([[[ 1.2592512e+00 -9.3137980e-01 -1.5964971e+00 -6.3102514e-01\n",
      "   -9.4822717e-01 -2.0300023e-01  8.77407...019e+00 -6.8562794e-01  5.7269484e-01  6.3933287e-04\n",
      "   -8.0734909e-02 -5.8600444e-01  6.3184309e-01 -3.3685747e-01]]])\n",
      "hidden_size = 12\n",
      "init_hidden = False\n",
      "num_layers = 2\n",
      "output_size = 1000\n",
      "seq_length = 1\n",
      "seq_model  = 'rnn'\n",
      "x          = array([[143.]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:201: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "self = <models.LanguageModel object at 0x1577bff20>, embedding_size = 1\n",
      "output_size = 1000, hidden_size = 12, num_layers = 2, seq_model = 'rnn'\n",
      "device = cpu(), dtype = 'float32'\n",
      "\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92m__init__\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, embedding_size, output_size, hidden_size, num_layers=\u001b[94m1\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                 seq_model=\u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, device=\u001b[94mNone\u001b[39;49;00m, dtype=\u001b[33m\"\u001b[39;49;00m\u001b[33mfloat32\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"\u001b[39;49;00m\n",
      "    \u001b[33m    Consists of an embedding layer, a sequence model (either RNN or LSTM), and a\u001b[39;49;00m\n",
      "    \u001b[33m    linear layer.\u001b[39;49;00m\n",
      "    \u001b[33m    Parameters:\u001b[39;49;00m\n",
      "    \u001b[33m    output_size: Size of dictionary\u001b[39;49;00m\n",
      "    \u001b[33m    embedding_size: Size of embeddings\u001b[39;49;00m\n",
      "    \u001b[33m    hidden_size: The number of features in the hidden state of LSTM or RNN\u001b[39;49;00m\n",
      "    \u001b[33m    seq_model: 'rnn' or 'lstm', whether to use RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    num_layers: Number of layers in RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    \"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[96msuper\u001b[39;49;00m(LanguageModel, \u001b[96mself\u001b[39;49;00m).\u001b[92m__init__\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m### BEGIN YOUR SOLUTION\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94mraise\u001b[39;49;00m \u001b[96mNotImplementedError\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       NotImplementedError\u001b[0m\n",
      "\n",
      "__class__  = <class 'models.LanguageModel'>\n",
      "device     = cpu()\n",
      "dtype      = 'float32'\n",
      "embedding_size = 1\n",
      "hidden_size = 12\n",
      "num_layers = 2\n",
      "output_size = 1000\n",
      "self       = <models.LanguageModel object at 0x1577bff20>\n",
      "seq_model  = 'rnn'\n",
      "\n",
      "\u001b[1m\u001b[31mapps/models.py\u001b[0m:38: NotImplementedError\n",
      "\u001b[31m\u001b[1m______ test_language_model_implementation[cpu-rnn-1000-False-12-1-1-2-13] ______\u001b[0m\n",
      "\n",
      "seq_length = 13, num_layers = 2, batch_size = 1, embedding_size = 1\n",
      "hidden_size = 12, init_hidden = False, output_size = 1000, seq_model = 'rnn'\n",
      "device = cpu()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\u001b[90m\u001b[39;49;00m\n",
      "                            init_hidden, output_size, seq_model, device):\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      ">       model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "batch_size = 1\n",
      "c0         = needle.Tensor([[[ 0.09830094  0.6003347  -0.63365006 -0.6527349  -3.0592248\n",
      "   -0.14758874  0.69376683  0.78111845  0....   1.3893424  -0.59500647\n",
      "   -0.5955456  -1.9841937   0.5465143   0.04086787  0.75143343\n",
      "    0.5031794   1.5547745 ]]])\n",
      "device     = cpu()\n",
      "embedding_size = 1\n",
      "h0         = needle.Tensor([[[-0.47333497 -2.9109333  -1.1819088   0.11660681  0.04943356\n",
      "    0.64908963 -0.6178561  -0.8256395  -0...85   0.57759213  1.0604538\n",
      "   -0.52773184 -1.6886828  -0.94088656 -0.54610443 -2.2328837\n",
      "    0.276447   -0.5987482 ]]])\n",
      "hidden_size = 12\n",
      "init_hidden = False\n",
      "num_layers = 2\n",
      "output_size = 1000\n",
      "seq_length = 13\n",
      "seq_model  = 'rnn'\n",
      "x          = array([[422.],\n",
      "       [101.],\n",
      "       [930.],\n",
      "       [732.],\n",
      "       [234.],\n",
      "       [798.],\n",
      "       [994.],\n",
      "       [ 35.],\n",
      "       [606.],\n",
      "       [431.],\n",
      "       [819.],\n",
      "       [698.],\n",
      "       [909.]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:201: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "self = <models.LanguageModel object at 0x1577bf4d0>, embedding_size = 1\n",
      "output_size = 1000, hidden_size = 12, num_layers = 2, seq_model = 'rnn'\n",
      "device = cpu(), dtype = 'float32'\n",
      "\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92m__init__\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, embedding_size, output_size, hidden_size, num_layers=\u001b[94m1\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                 seq_model=\u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, device=\u001b[94mNone\u001b[39;49;00m, dtype=\u001b[33m\"\u001b[39;49;00m\u001b[33mfloat32\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"\u001b[39;49;00m\n",
      "    \u001b[33m    Consists of an embedding layer, a sequence model (either RNN or LSTM), and a\u001b[39;49;00m\n",
      "    \u001b[33m    linear layer.\u001b[39;49;00m\n",
      "    \u001b[33m    Parameters:\u001b[39;49;00m\n",
      "    \u001b[33m    output_size: Size of dictionary\u001b[39;49;00m\n",
      "    \u001b[33m    embedding_size: Size of embeddings\u001b[39;49;00m\n",
      "    \u001b[33m    hidden_size: The number of features in the hidden state of LSTM or RNN\u001b[39;49;00m\n",
      "    \u001b[33m    seq_model: 'rnn' or 'lstm', whether to use RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    num_layers: Number of layers in RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    \"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[96msuper\u001b[39;49;00m(LanguageModel, \u001b[96mself\u001b[39;49;00m).\u001b[92m__init__\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m### BEGIN YOUR SOLUTION\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94mraise\u001b[39;49;00m \u001b[96mNotImplementedError\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       NotImplementedError\u001b[0m\n",
      "\n",
      "__class__  = <class 'models.LanguageModel'>\n",
      "device     = cpu()\n",
      "dtype      = 'float32'\n",
      "embedding_size = 1\n",
      "hidden_size = 12\n",
      "num_layers = 2\n",
      "output_size = 1000\n",
      "self       = <models.LanguageModel object at 0x1577bf4d0>\n",
      "seq_model  = 'rnn'\n",
      "\n",
      "\u001b[1m\u001b[31mapps/models.py\u001b[0m:38: NotImplementedError\n",
      "\u001b[31m\u001b[1m______ test_language_model_implementation[cpu-rnn-1000-False-12-1-15-1-1] ______\u001b[0m\n",
      "\n",
      "seq_length = 1, num_layers = 1, batch_size = 15, embedding_size = 1\n",
      "hidden_size = 12, init_hidden = False, output_size = 1000, seq_model = 'rnn'\n",
      "device = cpu()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\u001b[90m\u001b[39;49;00m\n",
      "                            init_hidden, output_size, seq_model, device):\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      ">       model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "batch_size = 15\n",
      "c0         = needle.Tensor([[[ 0.6112623  -0.06499932 -0.23215897  0.8968919   0.20463695\n",
      "    0.54821956 -0.40105954 -0.26781988 -1...67 -0.27227727  0.10222401\n",
      "    0.6359367   0.01683965  0.5905518   0.47004667 -0.6267227\n",
      "    0.0608821  -0.28551975]]])\n",
      "device     = cpu()\n",
      "embedding_size = 1\n",
      "h0         = needle.Tensor([[[-0.7748922  -0.54670036  0.6758969  -0.61877316 -0.17425214\n",
      "   -0.5315769  -3.016942    0.04967602 -1...7 -0.6564448   0.16144575\n",
      "   -1.0645423   0.34295598  0.32295483  0.9428852  -0.15336362\n",
      "    0.2739717   0.20443597]]])\n",
      "hidden_size = 12\n",
      "init_hidden = False\n",
      "num_layers = 1\n",
      "output_size = 1000\n",
      "seq_length = 1\n",
      "seq_model  = 'rnn'\n",
      "x          = array([[406., 969., 308., 854., 182., 530., 923.,   0., 446., 363., 701.,\n",
      "        753., 866., 596., 697.]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:201: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "self = <models.LanguageModel object at 0x1577be4b0>, embedding_size = 1\n",
      "output_size = 1000, hidden_size = 12, num_layers = 1, seq_model = 'rnn'\n",
      "device = cpu(), dtype = 'float32'\n",
      "\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92m__init__\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, embedding_size, output_size, hidden_size, num_layers=\u001b[94m1\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                 seq_model=\u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, device=\u001b[94mNone\u001b[39;49;00m, dtype=\u001b[33m\"\u001b[39;49;00m\u001b[33mfloat32\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"\u001b[39;49;00m\n",
      "    \u001b[33m    Consists of an embedding layer, a sequence model (either RNN or LSTM), and a\u001b[39;49;00m\n",
      "    \u001b[33m    linear layer.\u001b[39;49;00m\n",
      "    \u001b[33m    Parameters:\u001b[39;49;00m\n",
      "    \u001b[33m    output_size: Size of dictionary\u001b[39;49;00m\n",
      "    \u001b[33m    embedding_size: Size of embeddings\u001b[39;49;00m\n",
      "    \u001b[33m    hidden_size: The number of features in the hidden state of LSTM or RNN\u001b[39;49;00m\n",
      "    \u001b[33m    seq_model: 'rnn' or 'lstm', whether to use RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    num_layers: Number of layers in RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    \"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[96msuper\u001b[39;49;00m(LanguageModel, \u001b[96mself\u001b[39;49;00m).\u001b[92m__init__\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m### BEGIN YOUR SOLUTION\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94mraise\u001b[39;49;00m \u001b[96mNotImplementedError\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       NotImplementedError\u001b[0m\n",
      "\n",
      "__class__  = <class 'models.LanguageModel'>\n",
      "device     = cpu()\n",
      "dtype      = 'float32'\n",
      "embedding_size = 1\n",
      "hidden_size = 12\n",
      "num_layers = 1\n",
      "output_size = 1000\n",
      "self       = <models.LanguageModel object at 0x1577be4b0>\n",
      "seq_model  = 'rnn'\n",
      "\n",
      "\u001b[1m\u001b[31mapps/models.py\u001b[0m:38: NotImplementedError\n",
      "\u001b[31m\u001b[1m_____ test_language_model_implementation[cpu-rnn-1000-False-12-1-15-1-13] ______\u001b[0m\n",
      "\n",
      "seq_length = 13, num_layers = 1, batch_size = 15, embedding_size = 1\n",
      "hidden_size = 12, init_hidden = False, output_size = 1000, seq_model = 'rnn'\n",
      "device = cpu()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\u001b[90m\u001b[39;49;00m\n",
      "                            init_hidden, output_size, seq_model, device):\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      ">       model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "batch_size = 15\n",
      "c0         = needle.Tensor([[[-1.4614305  -0.6602228  -0.1943014  -1.0772555  -1.488242\n",
      "   -1.0875067  -0.6334625   0.36236656 -0.6...6 -0.21450178 -0.05187454\n",
      "    0.30920416  0.62781     0.5346222  -1.4179544   0.80650836\n",
      "    0.10981355 -0.70319456]]])\n",
      "device     = cpu()\n",
      "embedding_size = 1\n",
      "h0         = needle.Tensor([[[ 0.47160292  0.1611544  -1.3538183  -1.9486355   0.6796598\n",
      "   -0.6811762   0.08690875 -1.4813987   0....4 -0.21759264  0.07799965\n",
      "    2.955156    0.19715042 -0.3671788   0.37532327  0.30484247\n",
      "   -0.58692116 -0.9212689 ]]])\n",
      "hidden_size = 12\n",
      "init_hidden = False\n",
      "num_layers = 1\n",
      "output_size = 1000\n",
      "seq_length = 13\n",
      "seq_model  = 'rnn'\n",
      "x          = array([[560., 324., 640., 742., 737., 608., 200., 749., 808., 716., 273.,\n",
      "        229., 524., 380., 185.],\n",
      "       [707...    [ 33., 533., 469., 365., 150., 677., 925., 789., 442., 910., 340.,\n",
      "        988., 394., 575., 833.]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:201: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "self = <models.LanguageModel object at 0x1577ac530>, embedding_size = 1\n",
      "output_size = 1000, hidden_size = 12, num_layers = 1, seq_model = 'rnn'\n",
      "device = cpu(), dtype = 'float32'\n",
      "\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92m__init__\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, embedding_size, output_size, hidden_size, num_layers=\u001b[94m1\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                 seq_model=\u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, device=\u001b[94mNone\u001b[39;49;00m, dtype=\u001b[33m\"\u001b[39;49;00m\u001b[33mfloat32\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"\u001b[39;49;00m\n",
      "    \u001b[33m    Consists of an embedding layer, a sequence model (either RNN or LSTM), and a\u001b[39;49;00m\n",
      "    \u001b[33m    linear layer.\u001b[39;49;00m\n",
      "    \u001b[33m    Parameters:\u001b[39;49;00m\n",
      "    \u001b[33m    output_size: Size of dictionary\u001b[39;49;00m\n",
      "    \u001b[33m    embedding_size: Size of embeddings\u001b[39;49;00m\n",
      "    \u001b[33m    hidden_size: The number of features in the hidden state of LSTM or RNN\u001b[39;49;00m\n",
      "    \u001b[33m    seq_model: 'rnn' or 'lstm', whether to use RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    num_layers: Number of layers in RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    \"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[96msuper\u001b[39;49;00m(LanguageModel, \u001b[96mself\u001b[39;49;00m).\u001b[92m__init__\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m### BEGIN YOUR SOLUTION\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94mraise\u001b[39;49;00m \u001b[96mNotImplementedError\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       NotImplementedError\u001b[0m\n",
      "\n",
      "__class__  = <class 'models.LanguageModel'>\n",
      "device     = cpu()\n",
      "dtype      = 'float32'\n",
      "embedding_size = 1\n",
      "hidden_size = 12\n",
      "num_layers = 1\n",
      "output_size = 1000\n",
      "self       = <models.LanguageModel object at 0x1577ac530>\n",
      "seq_model  = 'rnn'\n",
      "\n",
      "\u001b[1m\u001b[31mapps/models.py\u001b[0m:38: NotImplementedError\n",
      "\u001b[31m\u001b[1m______ test_language_model_implementation[cpu-rnn-1000-False-12-1-15-2-1] ______\u001b[0m\n",
      "\n",
      "seq_length = 1, num_layers = 2, batch_size = 15, embedding_size = 1\n",
      "hidden_size = 12, init_hidden = False, output_size = 1000, seq_model = 'rnn'\n",
      "device = cpu()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\u001b[90m\u001b[39;49;00m\n",
      "                            init_hidden, output_size, seq_model, device):\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      ">       model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "batch_size = 15\n",
      "c0         = needle.Tensor([[[-9.76052046e-01  1.11838245e+00 -7.74746574e-03  4.91843581e-01\n",
      "    1.18800819e+00 -3.03860366e-01  2... -1.20515311e+00  1.65689743e+00  7.54169583e-01\n",
      "   -4.78480339e-01 -3.58671904e-01 -1.14848375e+00 -8.90172541e-01]]])\n",
      "device     = cpu()\n",
      "embedding_size = 1\n",
      "h0         = needle.Tensor([[[ 0.6646814   0.20386958 -0.59178686 -0.7199801  -0.847418\n",
      "    0.07443945  0.6739138   0.47454372 -0.6...78 -0.6333422  -1.9634583\n",
      "    1.7440631   0.35598963 -0.17774554  0.41165426  0.18089913\n",
      "   -1.4950179  -1.3936584 ]]])\n",
      "hidden_size = 12\n",
      "init_hidden = False\n",
      "num_layers = 2\n",
      "output_size = 1000\n",
      "seq_length = 1\n",
      "seq_model  = 'rnn'\n",
      "x          = array([[452., 808., 224., 895., 737., 632.,  79., 308.,  57., 689., 927.,\n",
      "        564., 765., 128., 896.]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:201: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "self = <models.LanguageModel object at 0x1577af020>, embedding_size = 1\n",
      "output_size = 1000, hidden_size = 12, num_layers = 2, seq_model = 'rnn'\n",
      "device = cpu(), dtype = 'float32'\n",
      "\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92m__init__\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, embedding_size, output_size, hidden_size, num_layers=\u001b[94m1\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                 seq_model=\u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, device=\u001b[94mNone\u001b[39;49;00m, dtype=\u001b[33m\"\u001b[39;49;00m\u001b[33mfloat32\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"\u001b[39;49;00m\n",
      "    \u001b[33m    Consists of an embedding layer, a sequence model (either RNN or LSTM), and a\u001b[39;49;00m\n",
      "    \u001b[33m    linear layer.\u001b[39;49;00m\n",
      "    \u001b[33m    Parameters:\u001b[39;49;00m\n",
      "    \u001b[33m    output_size: Size of dictionary\u001b[39;49;00m\n",
      "    \u001b[33m    embedding_size: Size of embeddings\u001b[39;49;00m\n",
      "    \u001b[33m    hidden_size: The number of features in the hidden state of LSTM or RNN\u001b[39;49;00m\n",
      "    \u001b[33m    seq_model: 'rnn' or 'lstm', whether to use RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    num_layers: Number of layers in RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    \"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[96msuper\u001b[39;49;00m(LanguageModel, \u001b[96mself\u001b[39;49;00m).\u001b[92m__init__\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m### BEGIN YOUR SOLUTION\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94mraise\u001b[39;49;00m \u001b[96mNotImplementedError\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       NotImplementedError\u001b[0m\n",
      "\n",
      "__class__  = <class 'models.LanguageModel'>\n",
      "device     = cpu()\n",
      "dtype      = 'float32'\n",
      "embedding_size = 1\n",
      "hidden_size = 12\n",
      "num_layers = 2\n",
      "output_size = 1000\n",
      "self       = <models.LanguageModel object at 0x1577af020>\n",
      "seq_model  = 'rnn'\n",
      "\n",
      "\u001b[1m\u001b[31mapps/models.py\u001b[0m:38: NotImplementedError\n",
      "\u001b[31m\u001b[1m_____ test_language_model_implementation[cpu-rnn-1000-False-12-1-15-2-13] ______\u001b[0m\n",
      "\n",
      "seq_length = 13, num_layers = 2, batch_size = 15, embedding_size = 1\n",
      "hidden_size = 12, init_hidden = False, output_size = 1000, seq_model = 'rnn'\n",
      "device = cpu()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\u001b[90m\u001b[39;49;00m\n",
      "                            init_hidden, output_size, seq_model, device):\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      ">       model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "batch_size = 15\n",
      "c0         = needle.Tensor([[[-0.27614257 -0.10911596  2.774444   -0.02586606  0.5097465\n",
      "   -0.45485374  1.1634055   1.3733858   0....2   0.8727171   0.7536729\n",
      "    0.71216786 -1.8491147   0.2704255   1.1334894   0.78636676\n",
      "   -0.6516751   0.7123644 ]]])\n",
      "device     = cpu()\n",
      "embedding_size = 1\n",
      "h0         = needle.Tensor([[[ 1.4321884  -0.1682304  -0.3357856   0.59947777 -1.2372406\n",
      "   -0.12888099  0.34640276 -0.4276056  -1....52   0.9884056  -1.0561517\n",
      "    0.16480176  1.7388878   1.2407556   1.0360929  -0.9671709\n",
      "   -0.2656315  -0.22662559]]])\n",
      "hidden_size = 12\n",
      "init_hidden = False\n",
      "num_layers = 2\n",
      "output_size = 1000\n",
      "seq_length = 13\n",
      "seq_model  = 'rnn'\n",
      "x          = array([[391., 202., 492., 844.,  66., 188., 311., 991., 744., 171., 281.,\n",
      "        850., 238., 792., 208.],\n",
      "       [188...    [370., 858., 593.,  54., 753., 524., 648., 964., 167., 730., 208.,\n",
      "         83.,  31., 696., 368.]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:201: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "self = <models.LanguageModel object at 0x1577c4920>, embedding_size = 1\n",
      "output_size = 1000, hidden_size = 12, num_layers = 2, seq_model = 'rnn'\n",
      "device = cpu(), dtype = 'float32'\n",
      "\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92m__init__\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, embedding_size, output_size, hidden_size, num_layers=\u001b[94m1\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                 seq_model=\u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, device=\u001b[94mNone\u001b[39;49;00m, dtype=\u001b[33m\"\u001b[39;49;00m\u001b[33mfloat32\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"\u001b[39;49;00m\n",
      "    \u001b[33m    Consists of an embedding layer, a sequence model (either RNN or LSTM), and a\u001b[39;49;00m\n",
      "    \u001b[33m    linear layer.\u001b[39;49;00m\n",
      "    \u001b[33m    Parameters:\u001b[39;49;00m\n",
      "    \u001b[33m    output_size: Size of dictionary\u001b[39;49;00m\n",
      "    \u001b[33m    embedding_size: Size of embeddings\u001b[39;49;00m\n",
      "    \u001b[33m    hidden_size: The number of features in the hidden state of LSTM or RNN\u001b[39;49;00m\n",
      "    \u001b[33m    seq_model: 'rnn' or 'lstm', whether to use RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    num_layers: Number of layers in RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    \"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[96msuper\u001b[39;49;00m(LanguageModel, \u001b[96mself\u001b[39;49;00m).\u001b[92m__init__\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m### BEGIN YOUR SOLUTION\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94mraise\u001b[39;49;00m \u001b[96mNotImplementedError\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       NotImplementedError\u001b[0m\n",
      "\n",
      "__class__  = <class 'models.LanguageModel'>\n",
      "device     = cpu()\n",
      "dtype      = 'float32'\n",
      "embedding_size = 1\n",
      "hidden_size = 12\n",
      "num_layers = 2\n",
      "output_size = 1000\n",
      "self       = <models.LanguageModel object at 0x1577c4920>\n",
      "seq_model  = 'rnn'\n",
      "\n",
      "\u001b[1m\u001b[31mapps/models.py\u001b[0m:38: NotImplementedError\n",
      "\u001b[31m\u001b[1m______ test_language_model_implementation[cpu-rnn-1000-False-12-34-1-1-1] ______\u001b[0m\n",
      "\n",
      "seq_length = 1, num_layers = 1, batch_size = 1, embedding_size = 34\n",
      "hidden_size = 12, init_hidden = False, output_size = 1000, seq_model = 'rnn'\n",
      "device = cpu()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\u001b[90m\u001b[39;49;00m\n",
      "                            init_hidden, output_size, seq_model, device):\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      ">       model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "batch_size = 1\n",
      "c0         = needle.Tensor([[[-0.31421563 -0.82486093  0.13844275  0.5930581   0.58118826\n",
      "    0.01056353  0.4345397   0.18458247 -0.49405965  0.52360576\n",
      "   -0.3481225  -0.2438188 ]]])\n",
      "device     = cpu()\n",
      "embedding_size = 34\n",
      "h0         = needle.Tensor([[[-0.4182695  -0.73981863  1.1586789  -0.40364125  0.6126975\n",
      "   -2.0838575   0.52194744  1.1898311  -1.5671934   0.02220138\n",
      "   -1.1609591  -0.25075072]]])\n",
      "hidden_size = 12\n",
      "init_hidden = False\n",
      "num_layers = 1\n",
      "output_size = 1000\n",
      "seq_length = 1\n",
      "seq_model  = 'rnn'\n",
      "x          = array([[596.]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:201: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "self = <models.LanguageModel object at 0x1577973e0>, embedding_size = 34\n",
      "output_size = 1000, hidden_size = 12, num_layers = 1, seq_model = 'rnn'\n",
      "device = cpu(), dtype = 'float32'\n",
      "\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92m__init__\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, embedding_size, output_size, hidden_size, num_layers=\u001b[94m1\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                 seq_model=\u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, device=\u001b[94mNone\u001b[39;49;00m, dtype=\u001b[33m\"\u001b[39;49;00m\u001b[33mfloat32\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"\u001b[39;49;00m\n",
      "    \u001b[33m    Consists of an embedding layer, a sequence model (either RNN or LSTM), and a\u001b[39;49;00m\n",
      "    \u001b[33m    linear layer.\u001b[39;49;00m\n",
      "    \u001b[33m    Parameters:\u001b[39;49;00m\n",
      "    \u001b[33m    output_size: Size of dictionary\u001b[39;49;00m\n",
      "    \u001b[33m    embedding_size: Size of embeddings\u001b[39;49;00m\n",
      "    \u001b[33m    hidden_size: The number of features in the hidden state of LSTM or RNN\u001b[39;49;00m\n",
      "    \u001b[33m    seq_model: 'rnn' or 'lstm', whether to use RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    num_layers: Number of layers in RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    \"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[96msuper\u001b[39;49;00m(LanguageModel, \u001b[96mself\u001b[39;49;00m).\u001b[92m__init__\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m### BEGIN YOUR SOLUTION\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94mraise\u001b[39;49;00m \u001b[96mNotImplementedError\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       NotImplementedError\u001b[0m\n",
      "\n",
      "__class__  = <class 'models.LanguageModel'>\n",
      "device     = cpu()\n",
      "dtype      = 'float32'\n",
      "embedding_size = 34\n",
      "hidden_size = 12\n",
      "num_layers = 1\n",
      "output_size = 1000\n",
      "self       = <models.LanguageModel object at 0x1577973e0>\n",
      "seq_model  = 'rnn'\n",
      "\n",
      "\u001b[1m\u001b[31mapps/models.py\u001b[0m:38: NotImplementedError\n",
      "\u001b[31m\u001b[1m_____ test_language_model_implementation[cpu-rnn-1000-False-12-34-1-1-13] ______\u001b[0m\n",
      "\n",
      "seq_length = 13, num_layers = 1, batch_size = 1, embedding_size = 34\n",
      "hidden_size = 12, init_hidden = False, output_size = 1000, seq_model = 'rnn'\n",
      "device = cpu()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\u001b[90m\u001b[39;49;00m\n",
      "                            init_hidden, output_size, seq_model, device):\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      ">       model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "batch_size = 1\n",
      "c0         = needle.Tensor([[[ 0.73904914 -1.0228035   0.15202145  0.8459022  -0.43772244\n",
      "    1.2041534   0.41324446 -1.6617289   0.8315088   0.36961478\n",
      "    0.8318004   0.05239945]]])\n",
      "device     = cpu()\n",
      "embedding_size = 34\n",
      "h0         = needle.Tensor([[[-0.4777482  -0.31636903  1.0705284  -1.2008591  -0.4716289\n",
      "    0.15981887 -1.4269572  -0.10360131  1.3181996   1.5207582\n",
      "   -0.52706    -0.76375246]]])\n",
      "hidden_size = 12\n",
      "init_hidden = False\n",
      "num_layers = 1\n",
      "output_size = 1000\n",
      "seq_length = 13\n",
      "seq_model  = 'rnn'\n",
      "x          = array([[334.],\n",
      "       [117.],\n",
      "       [103.],\n",
      "       [872.],\n",
      "       [959.],\n",
      "       [473.],\n",
      "       [115.],\n",
      "       [676.],\n",
      "       [913.],\n",
      "       [606.],\n",
      "       [999.],\n",
      "       [455.],\n",
      "       [806.]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:201: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "self = <models.LanguageModel object at 0x1577c60c0>, embedding_size = 34\n",
      "output_size = 1000, hidden_size = 12, num_layers = 1, seq_model = 'rnn'\n",
      "device = cpu(), dtype = 'float32'\n",
      "\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92m__init__\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, embedding_size, output_size, hidden_size, num_layers=\u001b[94m1\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                 seq_model=\u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, device=\u001b[94mNone\u001b[39;49;00m, dtype=\u001b[33m\"\u001b[39;49;00m\u001b[33mfloat32\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"\u001b[39;49;00m\n",
      "    \u001b[33m    Consists of an embedding layer, a sequence model (either RNN or LSTM), and a\u001b[39;49;00m\n",
      "    \u001b[33m    linear layer.\u001b[39;49;00m\n",
      "    \u001b[33m    Parameters:\u001b[39;49;00m\n",
      "    \u001b[33m    output_size: Size of dictionary\u001b[39;49;00m\n",
      "    \u001b[33m    embedding_size: Size of embeddings\u001b[39;49;00m\n",
      "    \u001b[33m    hidden_size: The number of features in the hidden state of LSTM or RNN\u001b[39;49;00m\n",
      "    \u001b[33m    seq_model: 'rnn' or 'lstm', whether to use RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    num_layers: Number of layers in RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    \"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[96msuper\u001b[39;49;00m(LanguageModel, \u001b[96mself\u001b[39;49;00m).\u001b[92m__init__\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m### BEGIN YOUR SOLUTION\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94mraise\u001b[39;49;00m \u001b[96mNotImplementedError\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       NotImplementedError\u001b[0m\n",
      "\n",
      "__class__  = <class 'models.LanguageModel'>\n",
      "device     = cpu()\n",
      "dtype      = 'float32'\n",
      "embedding_size = 34\n",
      "hidden_size = 12\n",
      "num_layers = 1\n",
      "output_size = 1000\n",
      "self       = <models.LanguageModel object at 0x1577c60c0>\n",
      "seq_model  = 'rnn'\n",
      "\n",
      "\u001b[1m\u001b[31mapps/models.py\u001b[0m:38: NotImplementedError\n",
      "\u001b[31m\u001b[1m______ test_language_model_implementation[cpu-rnn-1000-False-12-34-1-2-1] ______\u001b[0m\n",
      "\n",
      "seq_length = 1, num_layers = 2, batch_size = 1, embedding_size = 34\n",
      "hidden_size = 12, init_hidden = False, output_size = 1000, seq_model = 'rnn'\n",
      "device = cpu()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\u001b[90m\u001b[39;49;00m\n",
      "                            init_hidden, output_size, seq_model, device):\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      ">       model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "batch_size = 1\n",
      "c0         = needle.Tensor([[[ 0.3882204   1.6018724   0.46443185  0.72503823  3.2702682\n",
      "    0.97097695 -1.2654183  -0.5742382  -0....4  -1.8039796  -0.02425601\n",
      "   -0.07141578 -0.33209     1.3638883  -0.2465643  -1.0431635\n",
      "    0.31673738  2.2828536 ]]])\n",
      "device     = cpu()\n",
      "embedding_size = 34\n",
      "h0         = needle.Tensor([[[-0.67116845  0.73041236 -1.261713    0.4249643  -0.14218277\n",
      "   -1.1166985   0.72945774  1.4675986   0...9   0.65401614 -0.3661444\n",
      "   -0.570586   -0.6110015  -1.0540798   0.60696083  0.41645968\n",
      "    0.8403947  -2.1120887 ]]])\n",
      "hidden_size = 12\n",
      "init_hidden = False\n",
      "num_layers = 2\n",
      "output_size = 1000\n",
      "seq_length = 1\n",
      "seq_model  = 'rnn'\n",
      "x          = array([[454.]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:201: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "self = <models.LanguageModel object at 0x1577bc560>, embedding_size = 34\n",
      "output_size = 1000, hidden_size = 12, num_layers = 2, seq_model = 'rnn'\n",
      "device = cpu(), dtype = 'float32'\n",
      "\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92m__init__\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, embedding_size, output_size, hidden_size, num_layers=\u001b[94m1\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                 seq_model=\u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, device=\u001b[94mNone\u001b[39;49;00m, dtype=\u001b[33m\"\u001b[39;49;00m\u001b[33mfloat32\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"\u001b[39;49;00m\n",
      "    \u001b[33m    Consists of an embedding layer, a sequence model (either RNN or LSTM), and a\u001b[39;49;00m\n",
      "    \u001b[33m    linear layer.\u001b[39;49;00m\n",
      "    \u001b[33m    Parameters:\u001b[39;49;00m\n",
      "    \u001b[33m    output_size: Size of dictionary\u001b[39;49;00m\n",
      "    \u001b[33m    embedding_size: Size of embeddings\u001b[39;49;00m\n",
      "    \u001b[33m    hidden_size: The number of features in the hidden state of LSTM or RNN\u001b[39;49;00m\n",
      "    \u001b[33m    seq_model: 'rnn' or 'lstm', whether to use RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    num_layers: Number of layers in RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    \"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[96msuper\u001b[39;49;00m(LanguageModel, \u001b[96mself\u001b[39;49;00m).\u001b[92m__init__\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m### BEGIN YOUR SOLUTION\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94mraise\u001b[39;49;00m \u001b[96mNotImplementedError\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       NotImplementedError\u001b[0m\n",
      "\n",
      "__class__  = <class 'models.LanguageModel'>\n",
      "device     = cpu()\n",
      "dtype      = 'float32'\n",
      "embedding_size = 34\n",
      "hidden_size = 12\n",
      "num_layers = 2\n",
      "output_size = 1000\n",
      "self       = <models.LanguageModel object at 0x1577bc560>\n",
      "seq_model  = 'rnn'\n",
      "\n",
      "\u001b[1m\u001b[31mapps/models.py\u001b[0m:38: NotImplementedError\n",
      "\u001b[31m\u001b[1m_____ test_language_model_implementation[cpu-rnn-1000-False-12-34-1-2-13] ______\u001b[0m\n",
      "\n",
      "seq_length = 13, num_layers = 2, batch_size = 1, embedding_size = 34\n",
      "hidden_size = 12, init_hidden = False, output_size = 1000, seq_model = 'rnn'\n",
      "device = cpu()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\u001b[90m\u001b[39;49;00m\n",
      "                            init_hidden, output_size, seq_model, device):\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      ">       model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "batch_size = 1\n",
      "c0         = needle.Tensor([[[ 0.4276577  -2.542088   -1.0637829   0.12124714 -0.76674795\n",
      "   -0.5464066  -1.5238312  -1.4729105   2...2    0.6299588  -3.2900667\n",
      "    0.54889965 -0.8084792   0.73038715 -1.9136454   0.4799007\n",
      "    0.18326108  0.11081011]]])\n",
      "device     = cpu()\n",
      "embedding_size = 34\n",
      "h0         = needle.Tensor([[[-0.38386917 -0.32119375 -1.1163464  -1.6010107   1.1746011\n",
      "    0.7372695  -0.1752646   0.82135516  0....638  0.5139861   1.1145746\n",
      "    0.82330436  0.9797174  -1.2854254   0.33723778  1.3131056\n",
      "   -1.840066   -0.03365133]]])\n",
      "hidden_size = 12\n",
      "init_hidden = False\n",
      "num_layers = 2\n",
      "output_size = 1000\n",
      "seq_length = 13\n",
      "seq_model  = 'rnn'\n",
      "x          = array([[201.],\n",
      "       [619.],\n",
      "       [495.],\n",
      "       [802.],\n",
      "       [344.],\n",
      "       [258.],\n",
      "       [ 54.],\n",
      "       [856.],\n",
      "       [822.],\n",
      "       [803.],\n",
      "       [645.],\n",
      "       [524.],\n",
      "       [352.]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:201: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "self = <models.LanguageModel object at 0x1577be9c0>, embedding_size = 34\n",
      "output_size = 1000, hidden_size = 12, num_layers = 2, seq_model = 'rnn'\n",
      "device = cpu(), dtype = 'float32'\n",
      "\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92m__init__\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, embedding_size, output_size, hidden_size, num_layers=\u001b[94m1\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                 seq_model=\u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, device=\u001b[94mNone\u001b[39;49;00m, dtype=\u001b[33m\"\u001b[39;49;00m\u001b[33mfloat32\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"\u001b[39;49;00m\n",
      "    \u001b[33m    Consists of an embedding layer, a sequence model (either RNN or LSTM), and a\u001b[39;49;00m\n",
      "    \u001b[33m    linear layer.\u001b[39;49;00m\n",
      "    \u001b[33m    Parameters:\u001b[39;49;00m\n",
      "    \u001b[33m    output_size: Size of dictionary\u001b[39;49;00m\n",
      "    \u001b[33m    embedding_size: Size of embeddings\u001b[39;49;00m\n",
      "    \u001b[33m    hidden_size: The number of features in the hidden state of LSTM or RNN\u001b[39;49;00m\n",
      "    \u001b[33m    seq_model: 'rnn' or 'lstm', whether to use RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    num_layers: Number of layers in RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    \"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[96msuper\u001b[39;49;00m(LanguageModel, \u001b[96mself\u001b[39;49;00m).\u001b[92m__init__\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m### BEGIN YOUR SOLUTION\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94mraise\u001b[39;49;00m \u001b[96mNotImplementedError\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       NotImplementedError\u001b[0m\n",
      "\n",
      "__class__  = <class 'models.LanguageModel'>\n",
      "device     = cpu()\n",
      "dtype      = 'float32'\n",
      "embedding_size = 34\n",
      "hidden_size = 12\n",
      "num_layers = 2\n",
      "output_size = 1000\n",
      "self       = <models.LanguageModel object at 0x1577be9c0>\n",
      "seq_model  = 'rnn'\n",
      "\n",
      "\u001b[1m\u001b[31mapps/models.py\u001b[0m:38: NotImplementedError\n",
      "\u001b[31m\u001b[1m_____ test_language_model_implementation[cpu-rnn-1000-False-12-34-15-1-1] ______\u001b[0m\n",
      "\n",
      "seq_length = 1, num_layers = 1, batch_size = 15, embedding_size = 34\n",
      "hidden_size = 12, init_hidden = False, output_size = 1000, seq_model = 'rnn'\n",
      "device = cpu()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\u001b[90m\u001b[39;49;00m\n",
      "                            init_hidden, output_size, seq_model, device):\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      ">       model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "batch_size = 15\n",
      "c0         = needle.Tensor([[[ 0.7222005   0.8439547   0.09135951  1.6386403   0.7148929\n",
      "   -1.5166053  -0.29378757  0.9351976   0....3  -0.8606113  -0.5146548\n",
      "   -3.530014    1.4882369   0.47297317  0.5725905  -0.29232085\n",
      "   -0.28270924 -0.373239  ]]])\n",
      "device     = cpu()\n",
      "embedding_size = 34\n",
      "h0         = needle.Tensor([[[-0.93757546 -1.248031    1.244592   -1.347431    0.3147687\n",
      "    1.3358008   0.5365211  -0.05352529 -0....38  -0.27772668  1.2656966\n",
      "   -0.85071546  0.14327167 -0.14451027  1.9055003  -1.5013353\n",
      "    0.45773622 -0.9591771 ]]])\n",
      "hidden_size = 12\n",
      "init_hidden = False\n",
      "num_layers = 1\n",
      "output_size = 1000\n",
      "seq_length = 1\n",
      "seq_model  = 'rnn'\n",
      "x          = array([[186., 319., 109., 779., 988., 704., 183., 244., 915., 200., 452.,\n",
      "        380., 504., 910., 189.]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:201: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "self = <models.LanguageModel object at 0x1572bb740>, embedding_size = 34\n",
      "output_size = 1000, hidden_size = 12, num_layers = 1, seq_model = 'rnn'\n",
      "device = cpu(), dtype = 'float32'\n",
      "\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92m__init__\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, embedding_size, output_size, hidden_size, num_layers=\u001b[94m1\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                 seq_model=\u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, device=\u001b[94mNone\u001b[39;49;00m, dtype=\u001b[33m\"\u001b[39;49;00m\u001b[33mfloat32\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"\u001b[39;49;00m\n",
      "    \u001b[33m    Consists of an embedding layer, a sequence model (either RNN or LSTM), and a\u001b[39;49;00m\n",
      "    \u001b[33m    linear layer.\u001b[39;49;00m\n",
      "    \u001b[33m    Parameters:\u001b[39;49;00m\n",
      "    \u001b[33m    output_size: Size of dictionary\u001b[39;49;00m\n",
      "    \u001b[33m    embedding_size: Size of embeddings\u001b[39;49;00m\n",
      "    \u001b[33m    hidden_size: The number of features in the hidden state of LSTM or RNN\u001b[39;49;00m\n",
      "    \u001b[33m    seq_model: 'rnn' or 'lstm', whether to use RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    num_layers: Number of layers in RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    \"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[96msuper\u001b[39;49;00m(LanguageModel, \u001b[96mself\u001b[39;49;00m).\u001b[92m__init__\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m### BEGIN YOUR SOLUTION\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94mraise\u001b[39;49;00m \u001b[96mNotImplementedError\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       NotImplementedError\u001b[0m\n",
      "\n",
      "__class__  = <class 'models.LanguageModel'>\n",
      "device     = cpu()\n",
      "dtype      = 'float32'\n",
      "embedding_size = 34\n",
      "hidden_size = 12\n",
      "num_layers = 1\n",
      "output_size = 1000\n",
      "self       = <models.LanguageModel object at 0x1572bb740>\n",
      "seq_model  = 'rnn'\n",
      "\n",
      "\u001b[1m\u001b[31mapps/models.py\u001b[0m:38: NotImplementedError\n",
      "\u001b[31m\u001b[1m_____ test_language_model_implementation[cpu-rnn-1000-False-12-34-15-1-13] _____\u001b[0m\n",
      "\n",
      "seq_length = 13, num_layers = 1, batch_size = 15, embedding_size = 34\n",
      "hidden_size = 12, init_hidden = False, output_size = 1000, seq_model = 'rnn'\n",
      "device = cpu()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\u001b[90m\u001b[39;49;00m\n",
      "                            init_hidden, output_size, seq_model, device):\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      ">       model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "batch_size = 15\n",
      "c0         = needle.Tensor([[[ 0.70526737  0.0498686   0.02842683  1.0713533   2.2501147\n",
      "    0.63286227  0.69873744 -0.44858542 -1....74 -0.8650594  -0.28300905\n",
      "   -0.8516819   0.1685032  -0.3151978   0.5692341   0.4629592\n",
      "    1.6515453   0.21489069]]])\n",
      "device     = cpu()\n",
      "embedding_size = 34\n",
      "h0         = needle.Tensor([[[ 1.3350478   0.0328417   0.47221863  0.90703046  1.4696283\n",
      "    1.1016388  -0.76887137  0.07103134  0....63 -0.42227736 -0.15671173\n",
      "   -0.14680547 -1.1317664  -0.47033352  0.18984999  1.3391293\n",
      "   -0.75690335 -0.50977916]]])\n",
      "hidden_size = 12\n",
      "init_hidden = False\n",
      "num_layers = 1\n",
      "output_size = 1000\n",
      "seq_length = 13\n",
      "seq_model  = 'rnn'\n",
      "x          = array([[206., 368., 973., 131., 239., 846., 360., 402., 745.,  11., 600.,\n",
      "        966., 131., 809., 248.],\n",
      "       [923...    [125., 247., 413., 822., 299., 320., 874., 517., 700., 473., 399.,\n",
      "        763., 790., 172., 554.]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:201: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "self = <models.LanguageModel object at 0x1577c5f70>, embedding_size = 34\n",
      "output_size = 1000, hidden_size = 12, num_layers = 1, seq_model = 'rnn'\n",
      "device = cpu(), dtype = 'float32'\n",
      "\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92m__init__\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, embedding_size, output_size, hidden_size, num_layers=\u001b[94m1\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                 seq_model=\u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, device=\u001b[94mNone\u001b[39;49;00m, dtype=\u001b[33m\"\u001b[39;49;00m\u001b[33mfloat32\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"\u001b[39;49;00m\n",
      "    \u001b[33m    Consists of an embedding layer, a sequence model (either RNN or LSTM), and a\u001b[39;49;00m\n",
      "    \u001b[33m    linear layer.\u001b[39;49;00m\n",
      "    \u001b[33m    Parameters:\u001b[39;49;00m\n",
      "    \u001b[33m    output_size: Size of dictionary\u001b[39;49;00m\n",
      "    \u001b[33m    embedding_size: Size of embeddings\u001b[39;49;00m\n",
      "    \u001b[33m    hidden_size: The number of features in the hidden state of LSTM or RNN\u001b[39;49;00m\n",
      "    \u001b[33m    seq_model: 'rnn' or 'lstm', whether to use RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    num_layers: Number of layers in RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    \"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[96msuper\u001b[39;49;00m(LanguageModel, \u001b[96mself\u001b[39;49;00m).\u001b[92m__init__\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m### BEGIN YOUR SOLUTION\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94mraise\u001b[39;49;00m \u001b[96mNotImplementedError\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       NotImplementedError\u001b[0m\n",
      "\n",
      "__class__  = <class 'models.LanguageModel'>\n",
      "device     = cpu()\n",
      "dtype      = 'float32'\n",
      "embedding_size = 34\n",
      "hidden_size = 12\n",
      "num_layers = 1\n",
      "output_size = 1000\n",
      "self       = <models.LanguageModel object at 0x1577c5f70>\n",
      "seq_model  = 'rnn'\n",
      "\n",
      "\u001b[1m\u001b[31mapps/models.py\u001b[0m:38: NotImplementedError\n",
      "\u001b[31m\u001b[1m_____ test_language_model_implementation[cpu-rnn-1000-False-12-34-15-2-1] ______\u001b[0m\n",
      "\n",
      "seq_length = 1, num_layers = 2, batch_size = 15, embedding_size = 34\n",
      "hidden_size = 12, init_hidden = False, output_size = 1000, seq_model = 'rnn'\n",
      "device = cpu()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\u001b[90m\u001b[39;49;00m\n",
      "                            init_hidden, output_size, seq_model, device):\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      ">       model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "batch_size = 15\n",
      "c0         = needle.Tensor([[[-5.24348736e-01  8.33912373e-01  2.70481445e-02  3.46149713e-01\n",
      "   -4.52263087e-01 -4.55515474e-01 -7...  3.25031906e-01  2.88871396e-02 -1.62051129e+00\n",
      "   -2.04952717e-01  3.71753931e-01  3.57560158e-01  7.24879026e-01]]])\n",
      "device     = cpu()\n",
      "embedding_size = 34\n",
      "h0         = needle.Tensor([[[ 7.34997988e-02  9.04186547e-01 -2.48205736e-01  1.06545091e+00\n",
      "    5.08969545e-01  1.27237618e+00 -5...  6.90504789e-01  1.27937362e-01  5.71482539e-01\n",
      "    1.09798265e+00  2.34199494e-01  1.07492805e+00  1.36718929e+00]]])\n",
      "hidden_size = 12\n",
      "init_hidden = False\n",
      "num_layers = 2\n",
      "output_size = 1000\n",
      "seq_length = 1\n",
      "seq_model  = 'rnn'\n",
      "x          = array([[204.,   7., 476., 569., 460., 368., 852., 551., 222., 859., 625.,\n",
      "        271., 319.,  65., 310.]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:201: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "self = <models.LanguageModel object at 0x1577ac5f0>, embedding_size = 34\n",
      "output_size = 1000, hidden_size = 12, num_layers = 2, seq_model = 'rnn'\n",
      "device = cpu(), dtype = 'float32'\n",
      "\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92m__init__\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, embedding_size, output_size, hidden_size, num_layers=\u001b[94m1\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                 seq_model=\u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, device=\u001b[94mNone\u001b[39;49;00m, dtype=\u001b[33m\"\u001b[39;49;00m\u001b[33mfloat32\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"\u001b[39;49;00m\n",
      "    \u001b[33m    Consists of an embedding layer, a sequence model (either RNN or LSTM), and a\u001b[39;49;00m\n",
      "    \u001b[33m    linear layer.\u001b[39;49;00m\n",
      "    \u001b[33m    Parameters:\u001b[39;49;00m\n",
      "    \u001b[33m    output_size: Size of dictionary\u001b[39;49;00m\n",
      "    \u001b[33m    embedding_size: Size of embeddings\u001b[39;49;00m\n",
      "    \u001b[33m    hidden_size: The number of features in the hidden state of LSTM or RNN\u001b[39;49;00m\n",
      "    \u001b[33m    seq_model: 'rnn' or 'lstm', whether to use RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    num_layers: Number of layers in RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    \"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[96msuper\u001b[39;49;00m(LanguageModel, \u001b[96mself\u001b[39;49;00m).\u001b[92m__init__\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m### BEGIN YOUR SOLUTION\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94mraise\u001b[39;49;00m \u001b[96mNotImplementedError\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       NotImplementedError\u001b[0m\n",
      "\n",
      "__class__  = <class 'models.LanguageModel'>\n",
      "device     = cpu()\n",
      "dtype      = 'float32'\n",
      "embedding_size = 34\n",
      "hidden_size = 12\n",
      "num_layers = 2\n",
      "output_size = 1000\n",
      "self       = <models.LanguageModel object at 0x1577ac5f0>\n",
      "seq_model  = 'rnn'\n",
      "\n",
      "\u001b[1m\u001b[31mapps/models.py\u001b[0m:38: NotImplementedError\n",
      "\u001b[31m\u001b[1m_____ test_language_model_implementation[cpu-rnn-1000-False-12-34-15-2-13] _____\u001b[0m\n",
      "\n",
      "seq_length = 13, num_layers = 2, batch_size = 15, embedding_size = 34\n",
      "hidden_size = 12, init_hidden = False, output_size = 1000, seq_model = 'rnn'\n",
      "device = cpu()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\u001b[90m\u001b[39;49;00m\n",
      "                            init_hidden, output_size, seq_model, device):\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      ">       model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "batch_size = 15\n",
      "c0         = needle.Tensor([[[-1.557764   -0.38256207  0.3022451  -0.0479818  -1.8346229\n",
      "    0.6527162   0.6733368   0.5925657  -1....4   -0.6994073   1.7954184\n",
      "   -1.9103132   1.4846008  -0.18195651 -0.7345489  -0.4432021\n",
      "   -1.8711681  -0.01526214]]])\n",
      "device     = cpu()\n",
      "embedding_size = 34\n",
      "h0         = needle.Tensor([[[ 1.05222833e+00  1.31504869e+00  3.67534637e-01 -1.15249884e+00\n",
      "    4.70129728e-01  5.12120903e-01  1...  4.97044533e-01  2.13893604e+00 -1.25493693e+00\n",
      "    2.28809214e+00 -1.70011485e+00  9.91378725e-01 -1.20594060e+00]]])\n",
      "hidden_size = 12\n",
      "init_hidden = False\n",
      "num_layers = 2\n",
      "output_size = 1000\n",
      "seq_length = 13\n",
      "seq_model  = 'rnn'\n",
      "x          = array([[497., 941.,  72., 427., 148., 817., 187., 924., 647., 166., 759.,\n",
      "        135.,  35., 425.,  42.],\n",
      "       [816...    [948.,  35., 380., 260., 310., 227., 826., 833., 354., 510., 113.,\n",
      "        571., 231., 563., 338.]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:201: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "self = <models.LanguageModel object at 0x1577af440>, embedding_size = 34\n",
      "output_size = 1000, hidden_size = 12, num_layers = 2, seq_model = 'rnn'\n",
      "device = cpu(), dtype = 'float32'\n",
      "\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92m__init__\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, embedding_size, output_size, hidden_size, num_layers=\u001b[94m1\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                 seq_model=\u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, device=\u001b[94mNone\u001b[39;49;00m, dtype=\u001b[33m\"\u001b[39;49;00m\u001b[33mfloat32\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"\u001b[39;49;00m\n",
      "    \u001b[33m    Consists of an embedding layer, a sequence model (either RNN or LSTM), and a\u001b[39;49;00m\n",
      "    \u001b[33m    linear layer.\u001b[39;49;00m\n",
      "    \u001b[33m    Parameters:\u001b[39;49;00m\n",
      "    \u001b[33m    output_size: Size of dictionary\u001b[39;49;00m\n",
      "    \u001b[33m    embedding_size: Size of embeddings\u001b[39;49;00m\n",
      "    \u001b[33m    hidden_size: The number of features in the hidden state of LSTM or RNN\u001b[39;49;00m\n",
      "    \u001b[33m    seq_model: 'rnn' or 'lstm', whether to use RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    num_layers: Number of layers in RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    \"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[96msuper\u001b[39;49;00m(LanguageModel, \u001b[96mself\u001b[39;49;00m).\u001b[92m__init__\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m### BEGIN YOUR SOLUTION\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94mraise\u001b[39;49;00m \u001b[96mNotImplementedError\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       NotImplementedError\u001b[0m\n",
      "\n",
      "__class__  = <class 'models.LanguageModel'>\n",
      "device     = cpu()\n",
      "dtype      = 'float32'\n",
      "embedding_size = 34\n",
      "hidden_size = 12\n",
      "num_layers = 2\n",
      "output_size = 1000\n",
      "self       = <models.LanguageModel object at 0x1577af440>\n",
      "seq_model  = 'rnn'\n",
      "\n",
      "\u001b[1m\u001b[31mapps/models.py\u001b[0m:38: NotImplementedError\n",
      "\u001b[31m\u001b[1m________ test_language_model_implementation[cpu-lstm-1-True-1-1-1-1-1] _________\u001b[0m\n",
      "\n",
      "seq_length = 1, num_layers = 1, batch_size = 1, embedding_size = 1\n",
      "hidden_size = 1, init_hidden = True, output_size = 1, seq_model = 'lstm'\n",
      "device = cpu()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\u001b[90m\u001b[39;49;00m\n",
      "                            init_hidden, output_size, seq_model, device):\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      ">       model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "batch_size = 1\n",
      "c0         = needle.Tensor([[[-0.75635624]]])\n",
      "device     = cpu()\n",
      "embedding_size = 1\n",
      "h0         = needle.Tensor([[[0.42774025]]])\n",
      "hidden_size = 1\n",
      "init_hidden = True\n",
      "num_layers = 1\n",
      "output_size = 1\n",
      "seq_length = 1\n",
      "seq_model  = 'lstm'\n",
      "x          = array([[0.]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:201: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "self = <models.LanguageModel object at 0x1577f3050>, embedding_size = 1\n",
      "output_size = 1, hidden_size = 1, num_layers = 1, seq_model = 'lstm'\n",
      "device = cpu(), dtype = 'float32'\n",
      "\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92m__init__\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, embedding_size, output_size, hidden_size, num_layers=\u001b[94m1\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                 seq_model=\u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, device=\u001b[94mNone\u001b[39;49;00m, dtype=\u001b[33m\"\u001b[39;49;00m\u001b[33mfloat32\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"\u001b[39;49;00m\n",
      "    \u001b[33m    Consists of an embedding layer, a sequence model (either RNN or LSTM), and a\u001b[39;49;00m\n",
      "    \u001b[33m    linear layer.\u001b[39;49;00m\n",
      "    \u001b[33m    Parameters:\u001b[39;49;00m\n",
      "    \u001b[33m    output_size: Size of dictionary\u001b[39;49;00m\n",
      "    \u001b[33m    embedding_size: Size of embeddings\u001b[39;49;00m\n",
      "    \u001b[33m    hidden_size: The number of features in the hidden state of LSTM or RNN\u001b[39;49;00m\n",
      "    \u001b[33m    seq_model: 'rnn' or 'lstm', whether to use RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    num_layers: Number of layers in RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    \"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[96msuper\u001b[39;49;00m(LanguageModel, \u001b[96mself\u001b[39;49;00m).\u001b[92m__init__\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m### BEGIN YOUR SOLUTION\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94mraise\u001b[39;49;00m \u001b[96mNotImplementedError\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       NotImplementedError\u001b[0m\n",
      "\n",
      "__class__  = <class 'models.LanguageModel'>\n",
      "device     = cpu()\n",
      "dtype      = 'float32'\n",
      "embedding_size = 1\n",
      "hidden_size = 1\n",
      "num_layers = 1\n",
      "output_size = 1\n",
      "self       = <models.LanguageModel object at 0x1577f3050>\n",
      "seq_model  = 'lstm'\n",
      "\n",
      "\u001b[1m\u001b[31mapps/models.py\u001b[0m:38: NotImplementedError\n",
      "\u001b[31m\u001b[1m________ test_language_model_implementation[cpu-lstm-1-True-1-1-1-1-13] ________\u001b[0m\n",
      "\n",
      "seq_length = 13, num_layers = 1, batch_size = 1, embedding_size = 1\n",
      "hidden_size = 1, init_hidden = True, output_size = 1, seq_model = 'lstm'\n",
      "device = cpu()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\u001b[90m\u001b[39;49;00m\n",
      "                            init_hidden, output_size, seq_model, device):\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      ">       model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "batch_size = 1\n",
      "c0         = needle.Tensor([[[0.37445816]]])\n",
      "device     = cpu()\n",
      "embedding_size = 1\n",
      "h0         = needle.Tensor([[[1.4834875]]])\n",
      "hidden_size = 1\n",
      "init_hidden = True\n",
      "num_layers = 1\n",
      "output_size = 1\n",
      "seq_length = 13\n",
      "seq_model  = 'lstm'\n",
      "x          = array([[0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:201: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "self = <models.LanguageModel object at 0x1577f3e30>, embedding_size = 1\n",
      "output_size = 1, hidden_size = 1, num_layers = 1, seq_model = 'lstm'\n",
      "device = cpu(), dtype = 'float32'\n",
      "\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92m__init__\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, embedding_size, output_size, hidden_size, num_layers=\u001b[94m1\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                 seq_model=\u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, device=\u001b[94mNone\u001b[39;49;00m, dtype=\u001b[33m\"\u001b[39;49;00m\u001b[33mfloat32\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"\u001b[39;49;00m\n",
      "    \u001b[33m    Consists of an embedding layer, a sequence model (either RNN or LSTM), and a\u001b[39;49;00m\n",
      "    \u001b[33m    linear layer.\u001b[39;49;00m\n",
      "    \u001b[33m    Parameters:\u001b[39;49;00m\n",
      "    \u001b[33m    output_size: Size of dictionary\u001b[39;49;00m\n",
      "    \u001b[33m    embedding_size: Size of embeddings\u001b[39;49;00m\n",
      "    \u001b[33m    hidden_size: The number of features in the hidden state of LSTM or RNN\u001b[39;49;00m\n",
      "    \u001b[33m    seq_model: 'rnn' or 'lstm', whether to use RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    num_layers: Number of layers in RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    \"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[96msuper\u001b[39;49;00m(LanguageModel, \u001b[96mself\u001b[39;49;00m).\u001b[92m__init__\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m### BEGIN YOUR SOLUTION\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94mraise\u001b[39;49;00m \u001b[96mNotImplementedError\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       NotImplementedError\u001b[0m\n",
      "\n",
      "__class__  = <class 'models.LanguageModel'>\n",
      "device     = cpu()\n",
      "dtype      = 'float32'\n",
      "embedding_size = 1\n",
      "hidden_size = 1\n",
      "num_layers = 1\n",
      "output_size = 1\n",
      "self       = <models.LanguageModel object at 0x1577f3e30>\n",
      "seq_model  = 'lstm'\n",
      "\n",
      "\u001b[1m\u001b[31mapps/models.py\u001b[0m:38: NotImplementedError\n",
      "\u001b[31m\u001b[1m________ test_language_model_implementation[cpu-lstm-1-True-1-1-1-2-1] _________\u001b[0m\n",
      "\n",
      "seq_length = 1, num_layers = 2, batch_size = 1, embedding_size = 1\n",
      "hidden_size = 1, init_hidden = True, output_size = 1, seq_model = 'lstm'\n",
      "device = cpu()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\u001b[90m\u001b[39;49;00m\n",
      "                            init_hidden, output_size, seq_model, device):\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      ">       model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "batch_size = 1\n",
      "c0         = needle.Tensor([[[0.20875385]]\n",
      "\n",
      " [[0.32988632]]])\n",
      "device     = cpu()\n",
      "embedding_size = 1\n",
      "h0         = needle.Tensor([[[-0.21699813]]\n",
      "\n",
      " [[-1.4276239 ]]])\n",
      "hidden_size = 1\n",
      "init_hidden = True\n",
      "num_layers = 2\n",
      "output_size = 1\n",
      "seq_length = 1\n",
      "seq_model  = 'lstm'\n",
      "x          = array([[0.]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:201: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "self = <models.LanguageModel object at 0x1577f2720>, embedding_size = 1\n",
      "output_size = 1, hidden_size = 1, num_layers = 2, seq_model = 'lstm'\n",
      "device = cpu(), dtype = 'float32'\n",
      "\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92m__init__\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, embedding_size, output_size, hidden_size, num_layers=\u001b[94m1\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                 seq_model=\u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, device=\u001b[94mNone\u001b[39;49;00m, dtype=\u001b[33m\"\u001b[39;49;00m\u001b[33mfloat32\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"\u001b[39;49;00m\n",
      "    \u001b[33m    Consists of an embedding layer, a sequence model (either RNN or LSTM), and a\u001b[39;49;00m\n",
      "    \u001b[33m    linear layer.\u001b[39;49;00m\n",
      "    \u001b[33m    Parameters:\u001b[39;49;00m\n",
      "    \u001b[33m    output_size: Size of dictionary\u001b[39;49;00m\n",
      "    \u001b[33m    embedding_size: Size of embeddings\u001b[39;49;00m\n",
      "    \u001b[33m    hidden_size: The number of features in the hidden state of LSTM or RNN\u001b[39;49;00m\n",
      "    \u001b[33m    seq_model: 'rnn' or 'lstm', whether to use RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    num_layers: Number of layers in RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    \"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[96msuper\u001b[39;49;00m(LanguageModel, \u001b[96mself\u001b[39;49;00m).\u001b[92m__init__\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m### BEGIN YOUR SOLUTION\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94mraise\u001b[39;49;00m \u001b[96mNotImplementedError\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       NotImplementedError\u001b[0m\n",
      "\n",
      "__class__  = <class 'models.LanguageModel'>\n",
      "device     = cpu()\n",
      "dtype      = 'float32'\n",
      "embedding_size = 1\n",
      "hidden_size = 1\n",
      "num_layers = 2\n",
      "output_size = 1\n",
      "self       = <models.LanguageModel object at 0x1577f2720>\n",
      "seq_model  = 'lstm'\n",
      "\n",
      "\u001b[1m\u001b[31mapps/models.py\u001b[0m:38: NotImplementedError\n",
      "\u001b[31m\u001b[1m________ test_language_model_implementation[cpu-lstm-1-True-1-1-1-2-13] ________\u001b[0m\n",
      "\n",
      "seq_length = 13, num_layers = 2, batch_size = 1, embedding_size = 1\n",
      "hidden_size = 1, init_hidden = True, output_size = 1, seq_model = 'lstm'\n",
      "device = cpu()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\u001b[90m\u001b[39;49;00m\n",
      "                            init_hidden, output_size, seq_model, device):\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      ">       model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "batch_size = 1\n",
      "c0         = needle.Tensor([[[ 0.234583 ]]\n",
      "\n",
      " [[-1.0241327]]])\n",
      "device     = cpu()\n",
      "embedding_size = 1\n",
      "h0         = needle.Tensor([[[-1.0254366 ]]\n",
      "\n",
      " [[-0.10997374]]])\n",
      "hidden_size = 1\n",
      "init_hidden = True\n",
      "num_layers = 2\n",
      "output_size = 1\n",
      "seq_length = 13\n",
      "seq_model  = 'lstm'\n",
      "x          = array([[0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:201: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "self = <models.LanguageModel object at 0x1577f1b20>, embedding_size = 1\n",
      "output_size = 1, hidden_size = 1, num_layers = 2, seq_model = 'lstm'\n",
      "device = cpu(), dtype = 'float32'\n",
      "\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92m__init__\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, embedding_size, output_size, hidden_size, num_layers=\u001b[94m1\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                 seq_model=\u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, device=\u001b[94mNone\u001b[39;49;00m, dtype=\u001b[33m\"\u001b[39;49;00m\u001b[33mfloat32\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"\u001b[39;49;00m\n",
      "    \u001b[33m    Consists of an embedding layer, a sequence model (either RNN or LSTM), and a\u001b[39;49;00m\n",
      "    \u001b[33m    linear layer.\u001b[39;49;00m\n",
      "    \u001b[33m    Parameters:\u001b[39;49;00m\n",
      "    \u001b[33m    output_size: Size of dictionary\u001b[39;49;00m\n",
      "    \u001b[33m    embedding_size: Size of embeddings\u001b[39;49;00m\n",
      "    \u001b[33m    hidden_size: The number of features in the hidden state of LSTM or RNN\u001b[39;49;00m\n",
      "    \u001b[33m    seq_model: 'rnn' or 'lstm', whether to use RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    num_layers: Number of layers in RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    \"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[96msuper\u001b[39;49;00m(LanguageModel, \u001b[96mself\u001b[39;49;00m).\u001b[92m__init__\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m### BEGIN YOUR SOLUTION\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94mraise\u001b[39;49;00m \u001b[96mNotImplementedError\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       NotImplementedError\u001b[0m\n",
      "\n",
      "__class__  = <class 'models.LanguageModel'>\n",
      "device     = cpu()\n",
      "dtype      = 'float32'\n",
      "embedding_size = 1\n",
      "hidden_size = 1\n",
      "num_layers = 2\n",
      "output_size = 1\n",
      "self       = <models.LanguageModel object at 0x1577f1b20>\n",
      "seq_model  = 'lstm'\n",
      "\n",
      "\u001b[1m\u001b[31mapps/models.py\u001b[0m:38: NotImplementedError\n",
      "\u001b[31m\u001b[1m________ test_language_model_implementation[cpu-lstm-1-True-1-1-15-1-1] ________\u001b[0m\n",
      "\n",
      "seq_length = 1, num_layers = 1, batch_size = 15, embedding_size = 1\n",
      "hidden_size = 1, init_hidden = True, output_size = 1, seq_model = 'lstm'\n",
      "device = cpu()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\u001b[90m\u001b[39;49;00m\n",
      "                            init_hidden, output_size, seq_model, device):\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      ">       model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "batch_size = 15\n",
      "c0         = needle.Tensor([[[-0.650399  ]\n",
      "  [ 0.6099873 ]\n",
      "  [-1.4842865 ]\n",
      "  [ 1.6696743 ]\n",
      "  [-2.7244644 ]\n",
      "  [-0.9185192 ]\n",
      "  [ 0.42...78 ]\n",
      "  [-0.8133901 ]\n",
      "  [-0.812739  ]\n",
      "  [-0.7334457 ]\n",
      "  [-0.15034488]\n",
      "  [ 0.49231866]\n",
      "  [-0.952257  ]\n",
      "  [ 2.8514426 ]]])\n",
      "device     = cpu()\n",
      "embedding_size = 1\n",
      "h0         = needle.Tensor([[[ 0.321765  ]\n",
      "  [-0.04636998]\n",
      "  [-0.09160823]\n",
      "  [-1.2950191 ]\n",
      "  [-1.4266856 ]\n",
      "  [ 0.23477261]\n",
      "  [ 0.22...53 ]\n",
      "  [ 1.2573292 ]\n",
      "  [ 0.9237499 ]\n",
      "  [ 1.4397583 ]\n",
      "  [ 0.3067581 ]\n",
      "  [ 0.3636619 ]\n",
      "  [-0.5021253 ]\n",
      "  [-0.40469345]]])\n",
      "hidden_size = 1\n",
      "init_hidden = True\n",
      "num_layers = 1\n",
      "output_size = 1\n",
      "seq_length = 1\n",
      "seq_model  = 'lstm'\n",
      "x          = array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "      dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:201: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "self = <models.LanguageModel object at 0x1572bb980>, embedding_size = 1\n",
      "output_size = 1, hidden_size = 1, num_layers = 1, seq_model = 'lstm'\n",
      "device = cpu(), dtype = 'float32'\n",
      "\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92m__init__\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, embedding_size, output_size, hidden_size, num_layers=\u001b[94m1\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                 seq_model=\u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, device=\u001b[94mNone\u001b[39;49;00m, dtype=\u001b[33m\"\u001b[39;49;00m\u001b[33mfloat32\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"\u001b[39;49;00m\n",
      "    \u001b[33m    Consists of an embedding layer, a sequence model (either RNN or LSTM), and a\u001b[39;49;00m\n",
      "    \u001b[33m    linear layer.\u001b[39;49;00m\n",
      "    \u001b[33m    Parameters:\u001b[39;49;00m\n",
      "    \u001b[33m    output_size: Size of dictionary\u001b[39;49;00m\n",
      "    \u001b[33m    embedding_size: Size of embeddings\u001b[39;49;00m\n",
      "    \u001b[33m    hidden_size: The number of features in the hidden state of LSTM or RNN\u001b[39;49;00m\n",
      "    \u001b[33m    seq_model: 'rnn' or 'lstm', whether to use RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    num_layers: Number of layers in RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    \"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[96msuper\u001b[39;49;00m(LanguageModel, \u001b[96mself\u001b[39;49;00m).\u001b[92m__init__\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m### BEGIN YOUR SOLUTION\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94mraise\u001b[39;49;00m \u001b[96mNotImplementedError\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       NotImplementedError\u001b[0m\n",
      "\n",
      "__class__  = <class 'models.LanguageModel'>\n",
      "device     = cpu()\n",
      "dtype      = 'float32'\n",
      "embedding_size = 1\n",
      "hidden_size = 1\n",
      "num_layers = 1\n",
      "output_size = 1\n",
      "self       = <models.LanguageModel object at 0x1572bb980>\n",
      "seq_model  = 'lstm'\n",
      "\n",
      "\u001b[1m\u001b[31mapps/models.py\u001b[0m:38: NotImplementedError\n",
      "\u001b[31m\u001b[1m_______ test_language_model_implementation[cpu-lstm-1-True-1-1-15-1-13] ________\u001b[0m\n",
      "\n",
      "seq_length = 13, num_layers = 1, batch_size = 15, embedding_size = 1\n",
      "hidden_size = 1, init_hidden = True, output_size = 1, seq_model = 'lstm'\n",
      "device = cpu()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\u001b[90m\u001b[39;49;00m\n",
      "                            init_hidden, output_size, seq_model, device):\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      ">       model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "batch_size = 15\n",
      "c0         = needle.Tensor([[[-0.66746086]\n",
      "  [-0.8652473 ]\n",
      "  [-0.27452636]\n",
      "  [-0.502844  ]\n",
      "  [-0.18561533]\n",
      "  [-0.6449421 ]\n",
      "  [ 2.16...834]\n",
      "  [ 0.15374215]\n",
      "  [-2.0603976 ]\n",
      "  [ 0.10247674]\n",
      "  [-1.6059668 ]\n",
      "  [-0.55308396]\n",
      "  [-0.11563512]\n",
      "  [-0.6708046 ]]])\n",
      "device     = cpu()\n",
      "embedding_size = 1\n",
      "h0         = needle.Tensor([[[ 2.383424  ]\n",
      "  [ 1.3337418 ]\n",
      "  [-0.17766929]\n",
      "  [-0.8105111 ]\n",
      "  [-0.5173427 ]\n",
      "  [-0.4190178 ]\n",
      "  [-0.29...095]\n",
      "  [-0.16640896]\n",
      "  [ 0.6389982 ]\n",
      "  [-1.0622602 ]\n",
      "  [ 0.42625582]\n",
      "  [ 0.31684244]\n",
      "  [-0.10616443]\n",
      "  [-1.0540929 ]]])\n",
      "hidden_size = 1\n",
      "init_hidden = True\n",
      "num_layers = 1\n",
      "output_size = 1\n",
      "seq_length = 13\n",
      "seq_model  = 'lstm'\n",
      "x          = array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0...0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "      dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:201: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "self = <models.LanguageModel object at 0x1577bea50>, embedding_size = 1\n",
      "output_size = 1, hidden_size = 1, num_layers = 1, seq_model = 'lstm'\n",
      "device = cpu(), dtype = 'float32'\n",
      "\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92m__init__\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, embedding_size, output_size, hidden_size, num_layers=\u001b[94m1\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                 seq_model=\u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, device=\u001b[94mNone\u001b[39;49;00m, dtype=\u001b[33m\"\u001b[39;49;00m\u001b[33mfloat32\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"\u001b[39;49;00m\n",
      "    \u001b[33m    Consists of an embedding layer, a sequence model (either RNN or LSTM), and a\u001b[39;49;00m\n",
      "    \u001b[33m    linear layer.\u001b[39;49;00m\n",
      "    \u001b[33m    Parameters:\u001b[39;49;00m\n",
      "    \u001b[33m    output_size: Size of dictionary\u001b[39;49;00m\n",
      "    \u001b[33m    embedding_size: Size of embeddings\u001b[39;49;00m\n",
      "    \u001b[33m    hidden_size: The number of features in the hidden state of LSTM or RNN\u001b[39;49;00m\n",
      "    \u001b[33m    seq_model: 'rnn' or 'lstm', whether to use RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    num_layers: Number of layers in RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    \"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[96msuper\u001b[39;49;00m(LanguageModel, \u001b[96mself\u001b[39;49;00m).\u001b[92m__init__\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m### BEGIN YOUR SOLUTION\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94mraise\u001b[39;49;00m \u001b[96mNotImplementedError\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       NotImplementedError\u001b[0m\n",
      "\n",
      "__class__  = <class 'models.LanguageModel'>\n",
      "device     = cpu()\n",
      "dtype      = 'float32'\n",
      "embedding_size = 1\n",
      "hidden_size = 1\n",
      "num_layers = 1\n",
      "output_size = 1\n",
      "self       = <models.LanguageModel object at 0x1577bea50>\n",
      "seq_model  = 'lstm'\n",
      "\n",
      "\u001b[1m\u001b[31mapps/models.py\u001b[0m:38: NotImplementedError\n",
      "\u001b[31m\u001b[1m________ test_language_model_implementation[cpu-lstm-1-True-1-1-15-2-1] ________\u001b[0m\n",
      "\n",
      "seq_length = 1, num_layers = 2, batch_size = 15, embedding_size = 1\n",
      "hidden_size = 1, init_hidden = True, output_size = 1, seq_model = 'lstm'\n",
      "device = cpu()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\u001b[90m\u001b[39;49;00m\n",
      "                            init_hidden, output_size, seq_model, device):\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      ">       model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "batch_size = 15\n",
      "c0         = needle.Tensor([[[ 0.35355297]\n",
      "  [ 0.11478067]\n",
      "  [ 0.7538369 ]\n",
      "  [ 0.26692453]\n",
      "  [ 1.9353931 ]\n",
      "  [ 0.5205154 ]\n",
      "  [-0.72...86 ]\n",
      "  [-0.32569292]\n",
      "  [ 0.8205647 ]\n",
      "  [-1.2602124 ]\n",
      "  [ 1.2537831 ]\n",
      "  [-0.08979519]\n",
      "  [-1.2389779 ]\n",
      "  [ 0.04863897]]])\n",
      "device     = cpu()\n",
      "embedding_size = 1\n",
      "h0         = needle.Tensor([[[-0.19799599]\n",
      "  [ 0.5509112 ]\n",
      "  [ 0.22474214]\n",
      "  [ 1.9075794 ]\n",
      "  [ 1.5356704 ]\n",
      "  [-1.4074093 ]\n",
      "  [-0.20...116]\n",
      "  [-0.10021229]\n",
      "  [ 0.01096684]\n",
      "  [-0.4963788 ]\n",
      "  [ 0.9925114 ]\n",
      "  [ 0.43442985]\n",
      "  [-0.7604489 ]\n",
      "  [-0.42010605]]])\n",
      "hidden_size = 1\n",
      "init_hidden = True\n",
      "num_layers = 2\n",
      "output_size = 1\n",
      "seq_length = 1\n",
      "seq_model  = 'lstm'\n",
      "x          = array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "      dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:201: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "self = <models.LanguageModel object at 0x1577f0260>, embedding_size = 1\n",
      "output_size = 1, hidden_size = 1, num_layers = 2, seq_model = 'lstm'\n",
      "device = cpu(), dtype = 'float32'\n",
      "\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92m__init__\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, embedding_size, output_size, hidden_size, num_layers=\u001b[94m1\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                 seq_model=\u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, device=\u001b[94mNone\u001b[39;49;00m, dtype=\u001b[33m\"\u001b[39;49;00m\u001b[33mfloat32\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"\u001b[39;49;00m\n",
      "    \u001b[33m    Consists of an embedding layer, a sequence model (either RNN or LSTM), and a\u001b[39;49;00m\n",
      "    \u001b[33m    linear layer.\u001b[39;49;00m\n",
      "    \u001b[33m    Parameters:\u001b[39;49;00m\n",
      "    \u001b[33m    output_size: Size of dictionary\u001b[39;49;00m\n",
      "    \u001b[33m    embedding_size: Size of embeddings\u001b[39;49;00m\n",
      "    \u001b[33m    hidden_size: The number of features in the hidden state of LSTM or RNN\u001b[39;49;00m\n",
      "    \u001b[33m    seq_model: 'rnn' or 'lstm', whether to use RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    num_layers: Number of layers in RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    \"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[96msuper\u001b[39;49;00m(LanguageModel, \u001b[96mself\u001b[39;49;00m).\u001b[92m__init__\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m### BEGIN YOUR SOLUTION\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94mraise\u001b[39;49;00m \u001b[96mNotImplementedError\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       NotImplementedError\u001b[0m\n",
      "\n",
      "__class__  = <class 'models.LanguageModel'>\n",
      "device     = cpu()\n",
      "dtype      = 'float32'\n",
      "embedding_size = 1\n",
      "hidden_size = 1\n",
      "num_layers = 2\n",
      "output_size = 1\n",
      "self       = <models.LanguageModel object at 0x1577f0260>\n",
      "seq_model  = 'lstm'\n",
      "\n",
      "\u001b[1m\u001b[31mapps/models.py\u001b[0m:38: NotImplementedError\n",
      "\u001b[31m\u001b[1m_______ test_language_model_implementation[cpu-lstm-1-True-1-1-15-2-13] ________\u001b[0m\n",
      "\n",
      "seq_length = 13, num_layers = 2, batch_size = 15, embedding_size = 1\n",
      "hidden_size = 1, init_hidden = True, output_size = 1, seq_model = 'lstm'\n",
      "device = cpu()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\u001b[90m\u001b[39;49;00m\n",
      "                            init_hidden, output_size, seq_model, device):\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      ">       model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "batch_size = 15\n",
      "c0         = needle.Tensor([[[-1.4209797 ]\n",
      "  [-1.025819  ]\n",
      "  [ 0.26506677]\n",
      "  [ 0.25898007]\n",
      "  [ 1.733452  ]\n",
      "  [ 0.3418382 ]\n",
      "  [ 0.74...273]\n",
      "  [ 1.9836423 ]\n",
      "  [-0.04655279]\n",
      "  [ 0.44795737]\n",
      "  [ 0.19797873]\n",
      "  [-0.41372573]\n",
      "  [ 0.9527996 ]\n",
      "  [-0.5896589 ]]])\n",
      "device     = cpu()\n",
      "embedding_size = 1\n",
      "h0         = needle.Tensor([[[-1.3057013 ]\n",
      "  [ 0.25334892]\n",
      "  [-0.15033828]\n",
      "  [-0.1833147 ]\n",
      "  [-0.7435434 ]\n",
      "  [-0.5772761 ]\n",
      "  [ 1.00...693]\n",
      "  [ 0.13704534]\n",
      "  [ 0.3829966 ]\n",
      "  [ 3.0702107 ]\n",
      "  [ 0.68051386]\n",
      "  [-1.6717085 ]\n",
      "  [ 0.4720237 ]\n",
      "  [-0.8097844 ]]])\n",
      "hidden_size = 1\n",
      "init_hidden = True\n",
      "num_layers = 2\n",
      "output_size = 1\n",
      "seq_length = 13\n",
      "seq_model  = 'lstm'\n",
      "x          = array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0...0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "      dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:201: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "self = <models.LanguageModel object at 0x1577f1610>, embedding_size = 1\n",
      "output_size = 1, hidden_size = 1, num_layers = 2, seq_model = 'lstm'\n",
      "device = cpu(), dtype = 'float32'\n",
      "\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92m__init__\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, embedding_size, output_size, hidden_size, num_layers=\u001b[94m1\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                 seq_model=\u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, device=\u001b[94mNone\u001b[39;49;00m, dtype=\u001b[33m\"\u001b[39;49;00m\u001b[33mfloat32\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"\u001b[39;49;00m\n",
      "    \u001b[33m    Consists of an embedding layer, a sequence model (either RNN or LSTM), and a\u001b[39;49;00m\n",
      "    \u001b[33m    linear layer.\u001b[39;49;00m\n",
      "    \u001b[33m    Parameters:\u001b[39;49;00m\n",
      "    \u001b[33m    output_size: Size of dictionary\u001b[39;49;00m\n",
      "    \u001b[33m    embedding_size: Size of embeddings\u001b[39;49;00m\n",
      "    \u001b[33m    hidden_size: The number of features in the hidden state of LSTM or RNN\u001b[39;49;00m\n",
      "    \u001b[33m    seq_model: 'rnn' or 'lstm', whether to use RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    num_layers: Number of layers in RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    \"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[96msuper\u001b[39;49;00m(LanguageModel, \u001b[96mself\u001b[39;49;00m).\u001b[92m__init__\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m### BEGIN YOUR SOLUTION\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94mraise\u001b[39;49;00m \u001b[96mNotImplementedError\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       NotImplementedError\u001b[0m\n",
      "\n",
      "__class__  = <class 'models.LanguageModel'>\n",
      "device     = cpu()\n",
      "dtype      = 'float32'\n",
      "embedding_size = 1\n",
      "hidden_size = 1\n",
      "num_layers = 2\n",
      "output_size = 1\n",
      "self       = <models.LanguageModel object at 0x1577f1610>\n",
      "seq_model  = 'lstm'\n",
      "\n",
      "\u001b[1m\u001b[31mapps/models.py\u001b[0m:38: NotImplementedError\n",
      "\u001b[31m\u001b[1m________ test_language_model_implementation[cpu-lstm-1-True-1-34-1-1-1] ________\u001b[0m\n",
      "\n",
      "seq_length = 1, num_layers = 1, batch_size = 1, embedding_size = 34\n",
      "hidden_size = 1, init_hidden = True, output_size = 1, seq_model = 'lstm'\n",
      "device = cpu()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\u001b[90m\u001b[39;49;00m\n",
      "                            init_hidden, output_size, seq_model, device):\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      ">       model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "batch_size = 1\n",
      "c0         = needle.Tensor([[[1.7715733]]])\n",
      "device     = cpu()\n",
      "embedding_size = 34\n",
      "h0         = needle.Tensor([[[-0.52723414]]])\n",
      "hidden_size = 1\n",
      "init_hidden = True\n",
      "num_layers = 1\n",
      "output_size = 1\n",
      "seq_length = 1\n",
      "seq_model  = 'lstm'\n",
      "x          = array([[0.]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:201: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "self = <models.LanguageModel object at 0x1577f29c0>, embedding_size = 34\n",
      "output_size = 1, hidden_size = 1, num_layers = 1, seq_model = 'lstm'\n",
      "device = cpu(), dtype = 'float32'\n",
      "\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92m__init__\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, embedding_size, output_size, hidden_size, num_layers=\u001b[94m1\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                 seq_model=\u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, device=\u001b[94mNone\u001b[39;49;00m, dtype=\u001b[33m\"\u001b[39;49;00m\u001b[33mfloat32\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"\u001b[39;49;00m\n",
      "    \u001b[33m    Consists of an embedding layer, a sequence model (either RNN or LSTM), and a\u001b[39;49;00m\n",
      "    \u001b[33m    linear layer.\u001b[39;49;00m\n",
      "    \u001b[33m    Parameters:\u001b[39;49;00m\n",
      "    \u001b[33m    output_size: Size of dictionary\u001b[39;49;00m\n",
      "    \u001b[33m    embedding_size: Size of embeddings\u001b[39;49;00m\n",
      "    \u001b[33m    hidden_size: The number of features in the hidden state of LSTM or RNN\u001b[39;49;00m\n",
      "    \u001b[33m    seq_model: 'rnn' or 'lstm', whether to use RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    num_layers: Number of layers in RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    \"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[96msuper\u001b[39;49;00m(LanguageModel, \u001b[96mself\u001b[39;49;00m).\u001b[92m__init__\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m### BEGIN YOUR SOLUTION\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94mraise\u001b[39;49;00m \u001b[96mNotImplementedError\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       NotImplementedError\u001b[0m\n",
      "\n",
      "__class__  = <class 'models.LanguageModel'>\n",
      "device     = cpu()\n",
      "dtype      = 'float32'\n",
      "embedding_size = 34\n",
      "hidden_size = 1\n",
      "num_layers = 1\n",
      "output_size = 1\n",
      "self       = <models.LanguageModel object at 0x1577f29c0>\n",
      "seq_model  = 'lstm'\n",
      "\n",
      "\u001b[1m\u001b[31mapps/models.py\u001b[0m:38: NotImplementedError\n",
      "\u001b[31m\u001b[1m_______ test_language_model_implementation[cpu-lstm-1-True-1-34-1-1-13] ________\u001b[0m\n",
      "\n",
      "seq_length = 13, num_layers = 1, batch_size = 1, embedding_size = 34\n",
      "hidden_size = 1, init_hidden = True, output_size = 1, seq_model = 'lstm'\n",
      "device = cpu()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\u001b[90m\u001b[39;49;00m\n",
      "                            init_hidden, output_size, seq_model, device):\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      ">       model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "batch_size = 1\n",
      "c0         = needle.Tensor([[[-0.9181309]]])\n",
      "device     = cpu()\n",
      "embedding_size = 34\n",
      "h0         = needle.Tensor([[[-0.4499642]]])\n",
      "hidden_size = 1\n",
      "init_hidden = True\n",
      "num_layers = 1\n",
      "output_size = 1\n",
      "seq_length = 13\n",
      "seq_model  = 'lstm'\n",
      "x          = array([[0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:201: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "self = <models.LanguageModel object at 0x1577c7470>, embedding_size = 34\n",
      "output_size = 1, hidden_size = 1, num_layers = 1, seq_model = 'lstm'\n",
      "device = cpu(), dtype = 'float32'\n",
      "\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92m__init__\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, embedding_size, output_size, hidden_size, num_layers=\u001b[94m1\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                 seq_model=\u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, device=\u001b[94mNone\u001b[39;49;00m, dtype=\u001b[33m\"\u001b[39;49;00m\u001b[33mfloat32\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"\u001b[39;49;00m\n",
      "    \u001b[33m    Consists of an embedding layer, a sequence model (either RNN or LSTM), and a\u001b[39;49;00m\n",
      "    \u001b[33m    linear layer.\u001b[39;49;00m\n",
      "    \u001b[33m    Parameters:\u001b[39;49;00m\n",
      "    \u001b[33m    output_size: Size of dictionary\u001b[39;49;00m\n",
      "    \u001b[33m    embedding_size: Size of embeddings\u001b[39;49;00m\n",
      "    \u001b[33m    hidden_size: The number of features in the hidden state of LSTM or RNN\u001b[39;49;00m\n",
      "    \u001b[33m    seq_model: 'rnn' or 'lstm', whether to use RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    num_layers: Number of layers in RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    \"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[96msuper\u001b[39;49;00m(LanguageModel, \u001b[96mself\u001b[39;49;00m).\u001b[92m__init__\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m### BEGIN YOUR SOLUTION\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94mraise\u001b[39;49;00m \u001b[96mNotImplementedError\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       NotImplementedError\u001b[0m\n",
      "\n",
      "__class__  = <class 'models.LanguageModel'>\n",
      "device     = cpu()\n",
      "dtype      = 'float32'\n",
      "embedding_size = 34\n",
      "hidden_size = 1\n",
      "num_layers = 1\n",
      "output_size = 1\n",
      "self       = <models.LanguageModel object at 0x1577c7470>\n",
      "seq_model  = 'lstm'\n",
      "\n",
      "\u001b[1m\u001b[31mapps/models.py\u001b[0m:38: NotImplementedError\n",
      "\u001b[31m\u001b[1m________ test_language_model_implementation[cpu-lstm-1-True-1-34-1-2-1] ________\u001b[0m\n",
      "\n",
      "seq_length = 1, num_layers = 2, batch_size = 1, embedding_size = 34\n",
      "hidden_size = 1, init_hidden = True, output_size = 1, seq_model = 'lstm'\n",
      "device = cpu()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\u001b[90m\u001b[39;49;00m\n",
      "                            init_hidden, output_size, seq_model, device):\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      ">       model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "batch_size = 1\n",
      "c0         = needle.Tensor([[[ 0.3200255]]\n",
      "\n",
      " [[-0.7448148]]])\n",
      "device     = cpu()\n",
      "embedding_size = 34\n",
      "h0         = needle.Tensor([[[-0.7031709 ]]\n",
      "\n",
      " [[ 0.39181334]]])\n",
      "hidden_size = 1\n",
      "init_hidden = True\n",
      "num_layers = 2\n",
      "output_size = 1\n",
      "seq_length = 1\n",
      "seq_model  = 'lstm'\n",
      "x          = array([[0.]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:201: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "self = <models.LanguageModel object at 0x1577c6840>, embedding_size = 34\n",
      "output_size = 1, hidden_size = 1, num_layers = 2, seq_model = 'lstm'\n",
      "device = cpu(), dtype = 'float32'\n",
      "\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92m__init__\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, embedding_size, output_size, hidden_size, num_layers=\u001b[94m1\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                 seq_model=\u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, device=\u001b[94mNone\u001b[39;49;00m, dtype=\u001b[33m\"\u001b[39;49;00m\u001b[33mfloat32\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"\u001b[39;49;00m\n",
      "    \u001b[33m    Consists of an embedding layer, a sequence model (either RNN or LSTM), and a\u001b[39;49;00m\n",
      "    \u001b[33m    linear layer.\u001b[39;49;00m\n",
      "    \u001b[33m    Parameters:\u001b[39;49;00m\n",
      "    \u001b[33m    output_size: Size of dictionary\u001b[39;49;00m\n",
      "    \u001b[33m    embedding_size: Size of embeddings\u001b[39;49;00m\n",
      "    \u001b[33m    hidden_size: The number of features in the hidden state of LSTM or RNN\u001b[39;49;00m\n",
      "    \u001b[33m    seq_model: 'rnn' or 'lstm', whether to use RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    num_layers: Number of layers in RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    \"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[96msuper\u001b[39;49;00m(LanguageModel, \u001b[96mself\u001b[39;49;00m).\u001b[92m__init__\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m### BEGIN YOUR SOLUTION\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94mraise\u001b[39;49;00m \u001b[96mNotImplementedError\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       NotImplementedError\u001b[0m\n",
      "\n",
      "__class__  = <class 'models.LanguageModel'>\n",
      "device     = cpu()\n",
      "dtype      = 'float32'\n",
      "embedding_size = 34\n",
      "hidden_size = 1\n",
      "num_layers = 2\n",
      "output_size = 1\n",
      "self       = <models.LanguageModel object at 0x1577c6840>\n",
      "seq_model  = 'lstm'\n",
      "\n",
      "\u001b[1m\u001b[31mapps/models.py\u001b[0m:38: NotImplementedError\n",
      "\u001b[31m\u001b[1m_______ test_language_model_implementation[cpu-lstm-1-True-1-34-1-2-13] ________\u001b[0m\n",
      "\n",
      "seq_length = 13, num_layers = 2, batch_size = 1, embedding_size = 34\n",
      "hidden_size = 1, init_hidden = True, output_size = 1, seq_model = 'lstm'\n",
      "device = cpu()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\u001b[90m\u001b[39;49;00m\n",
      "                            init_hidden, output_size, seq_model, device):\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      ">       model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "batch_size = 1\n",
      "c0         = needle.Tensor([[[-0.8784076 ]]\n",
      "\n",
      " [[-0.01241007]]])\n",
      "device     = cpu()\n",
      "embedding_size = 34\n",
      "h0         = needle.Tensor([[[-0.04734183]]\n",
      "\n",
      " [[-0.4056347 ]]])\n",
      "hidden_size = 1\n",
      "init_hidden = True\n",
      "num_layers = 2\n",
      "output_size = 1\n",
      "seq_length = 13\n",
      "seq_model  = 'lstm'\n",
      "x          = array([[0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:201: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "self = <models.LanguageModel object at 0x1577c4b60>, embedding_size = 34\n",
      "output_size = 1, hidden_size = 1, num_layers = 2, seq_model = 'lstm'\n",
      "device = cpu(), dtype = 'float32'\n",
      "\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92m__init__\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, embedding_size, output_size, hidden_size, num_layers=\u001b[94m1\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                 seq_model=\u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, device=\u001b[94mNone\u001b[39;49;00m, dtype=\u001b[33m\"\u001b[39;49;00m\u001b[33mfloat32\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"\u001b[39;49;00m\n",
      "    \u001b[33m    Consists of an embedding layer, a sequence model (either RNN or LSTM), and a\u001b[39;49;00m\n",
      "    \u001b[33m    linear layer.\u001b[39;49;00m\n",
      "    \u001b[33m    Parameters:\u001b[39;49;00m\n",
      "    \u001b[33m    output_size: Size of dictionary\u001b[39;49;00m\n",
      "    \u001b[33m    embedding_size: Size of embeddings\u001b[39;49;00m\n",
      "    \u001b[33m    hidden_size: The number of features in the hidden state of LSTM or RNN\u001b[39;49;00m\n",
      "    \u001b[33m    seq_model: 'rnn' or 'lstm', whether to use RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    num_layers: Number of layers in RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    \"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[96msuper\u001b[39;49;00m(LanguageModel, \u001b[96mself\u001b[39;49;00m).\u001b[92m__init__\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m### BEGIN YOUR SOLUTION\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94mraise\u001b[39;49;00m \u001b[96mNotImplementedError\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       NotImplementedError\u001b[0m\n",
      "\n",
      "__class__  = <class 'models.LanguageModel'>\n",
      "device     = cpu()\n",
      "dtype      = 'float32'\n",
      "embedding_size = 34\n",
      "hidden_size = 1\n",
      "num_layers = 2\n",
      "output_size = 1\n",
      "self       = <models.LanguageModel object at 0x1577c4b60>\n",
      "seq_model  = 'lstm'\n",
      "\n",
      "\u001b[1m\u001b[31mapps/models.py\u001b[0m:38: NotImplementedError\n",
      "\u001b[31m\u001b[1m_______ test_language_model_implementation[cpu-lstm-1-True-1-34-15-1-1] ________\u001b[0m\n",
      "\n",
      "seq_length = 1, num_layers = 1, batch_size = 15, embedding_size = 34\n",
      "hidden_size = 1, init_hidden = True, output_size = 1, seq_model = 'lstm'\n",
      "device = cpu()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\u001b[90m\u001b[39;49;00m\n",
      "                            init_hidden, output_size, seq_model, device):\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      ">       model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "batch_size = 15\n",
      "c0         = needle.Tensor([[[-2.001679  ]\n",
      "  [ 0.6341642 ]\n",
      "  [ 0.69307864]\n",
      "  [-0.8998378 ]\n",
      "  [ 1.7863024 ]\n",
      "  [ 1.0140572 ]\n",
      "  [ 1.09...3  ]\n",
      "  [ 0.6088145 ]\n",
      "  [ 0.7934392 ]\n",
      "  [-0.97987425]\n",
      "  [ 0.01361816]\n",
      "  [ 1.1524037 ]\n",
      "  [-1.1168656 ]\n",
      "  [ 1.372289  ]]])\n",
      "device     = cpu()\n",
      "embedding_size = 34\n",
      "h0         = needle.Tensor([[[ 0.6490037 ]\n",
      "  [ 2.2106745 ]\n",
      "  [-0.72866815]\n",
      "  [ 0.3614907 ]\n",
      "  [ 1.2664557 ]\n",
      "  [ 0.7240338 ]\n",
      "  [ 0.81...882]\n",
      "  [-1.9091717 ]\n",
      "  [ 0.3899248 ]\n",
      "  [ 0.39257148]\n",
      "  [ 0.2572277 ]\n",
      "  [-0.6914739 ]\n",
      "  [-2.4211662 ]\n",
      "  [-1.1235783 ]]])\n",
      "hidden_size = 1\n",
      "init_hidden = True\n",
      "num_layers = 1\n",
      "output_size = 1\n",
      "seq_length = 1\n",
      "seq_model  = 'lstm'\n",
      "x          = array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "      dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:201: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "self = <models.LanguageModel object at 0x1577c78c0>, embedding_size = 34\n",
      "output_size = 1, hidden_size = 1, num_layers = 1, seq_model = 'lstm'\n",
      "device = cpu(), dtype = 'float32'\n",
      "\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92m__init__\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, embedding_size, output_size, hidden_size, num_layers=\u001b[94m1\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                 seq_model=\u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, device=\u001b[94mNone\u001b[39;49;00m, dtype=\u001b[33m\"\u001b[39;49;00m\u001b[33mfloat32\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"\u001b[39;49;00m\n",
      "    \u001b[33m    Consists of an embedding layer, a sequence model (either RNN or LSTM), and a\u001b[39;49;00m\n",
      "    \u001b[33m    linear layer.\u001b[39;49;00m\n",
      "    \u001b[33m    Parameters:\u001b[39;49;00m\n",
      "    \u001b[33m    output_size: Size of dictionary\u001b[39;49;00m\n",
      "    \u001b[33m    embedding_size: Size of embeddings\u001b[39;49;00m\n",
      "    \u001b[33m    hidden_size: The number of features in the hidden state of LSTM or RNN\u001b[39;49;00m\n",
      "    \u001b[33m    seq_model: 'rnn' or 'lstm', whether to use RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    num_layers: Number of layers in RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    \"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[96msuper\u001b[39;49;00m(LanguageModel, \u001b[96mself\u001b[39;49;00m).\u001b[92m__init__\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m### BEGIN YOUR SOLUTION\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94mraise\u001b[39;49;00m \u001b[96mNotImplementedError\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       NotImplementedError\u001b[0m\n",
      "\n",
      "__class__  = <class 'models.LanguageModel'>\n",
      "device     = cpu()\n",
      "dtype      = 'float32'\n",
      "embedding_size = 34\n",
      "hidden_size = 1\n",
      "num_layers = 1\n",
      "output_size = 1\n",
      "self       = <models.LanguageModel object at 0x1577c78c0>\n",
      "seq_model  = 'lstm'\n",
      "\n",
      "\u001b[1m\u001b[31mapps/models.py\u001b[0m:38: NotImplementedError\n",
      "\u001b[31m\u001b[1m_______ test_language_model_implementation[cpu-lstm-1-True-1-34-15-1-13] _______\u001b[0m\n",
      "\n",
      "seq_length = 13, num_layers = 1, batch_size = 15, embedding_size = 34\n",
      "hidden_size = 1, init_hidden = True, output_size = 1, seq_model = 'lstm'\n",
      "device = cpu()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\u001b[90m\u001b[39;49;00m\n",
      "                            init_hidden, output_size, seq_model, device):\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      ">       model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "batch_size = 15\n",
      "c0         = needle.Tensor([[[-0.5119451 ]\n",
      "  [ 0.3600955 ]\n",
      "  [ 0.05158272]\n",
      "  [ 0.91145104]\n",
      "  [ 1.4518164 ]\n",
      "  [ 0.93691844]\n",
      "  [-1.36...68 ]\n",
      "  [ 0.6847876 ]\n",
      "  [ 1.4570041 ]\n",
      "  [ 0.45146298]\n",
      "  [ 0.9632558 ]\n",
      "  [ 0.3737286 ]\n",
      "  [ 1.1524447 ]\n",
      "  [-2.258943  ]]])\n",
      "device     = cpu()\n",
      "embedding_size = 34\n",
      "h0         = needle.Tensor([[[-1.0565836 ]\n",
      "  [-0.32727453]\n",
      "  [ 0.20435974]\n",
      "  [ 0.00805486]\n",
      "  [-0.76070887]\n",
      "  [ 0.3769586 ]\n",
      "  [ 0.26...12 ]\n",
      "  [ 0.37907615]\n",
      "  [ 0.23753093]\n",
      "  [-1.5880064 ]\n",
      "  [ 0.58087164]\n",
      "  [ 2.1771264 ]\n",
      "  [-0.00579447]\n",
      "  [ 1.9458811 ]]])\n",
      "hidden_size = 1\n",
      "init_hidden = True\n",
      "num_layers = 1\n",
      "output_size = 1\n",
      "seq_length = 13\n",
      "seq_model  = 'lstm'\n",
      "x          = array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0...0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "      dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:201: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "self = <models.LanguageModel object at 0x1577995b0>, embedding_size = 34\n",
      "output_size = 1, hidden_size = 1, num_layers = 1, seq_model = 'lstm'\n",
      "device = cpu(), dtype = 'float32'\n",
      "\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92m__init__\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, embedding_size, output_size, hidden_size, num_layers=\u001b[94m1\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                 seq_model=\u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, device=\u001b[94mNone\u001b[39;49;00m, dtype=\u001b[33m\"\u001b[39;49;00m\u001b[33mfloat32\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"\u001b[39;49;00m\n",
      "    \u001b[33m    Consists of an embedding layer, a sequence model (either RNN or LSTM), and a\u001b[39;49;00m\n",
      "    \u001b[33m    linear layer.\u001b[39;49;00m\n",
      "    \u001b[33m    Parameters:\u001b[39;49;00m\n",
      "    \u001b[33m    output_size: Size of dictionary\u001b[39;49;00m\n",
      "    \u001b[33m    embedding_size: Size of embeddings\u001b[39;49;00m\n",
      "    \u001b[33m    hidden_size: The number of features in the hidden state of LSTM or RNN\u001b[39;49;00m\n",
      "    \u001b[33m    seq_model: 'rnn' or 'lstm', whether to use RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    num_layers: Number of layers in RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    \"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[96msuper\u001b[39;49;00m(LanguageModel, \u001b[96mself\u001b[39;49;00m).\u001b[92m__init__\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m### BEGIN YOUR SOLUTION\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94mraise\u001b[39;49;00m \u001b[96mNotImplementedError\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       NotImplementedError\u001b[0m\n",
      "\n",
      "__class__  = <class 'models.LanguageModel'>\n",
      "device     = cpu()\n",
      "dtype      = 'float32'\n",
      "embedding_size = 34\n",
      "hidden_size = 1\n",
      "num_layers = 1\n",
      "output_size = 1\n",
      "self       = <models.LanguageModel object at 0x1577995b0>\n",
      "seq_model  = 'lstm'\n",
      "\n",
      "\u001b[1m\u001b[31mapps/models.py\u001b[0m:38: NotImplementedError\n",
      "\u001b[31m\u001b[1m_______ test_language_model_implementation[cpu-lstm-1-True-1-34-15-2-1] ________\u001b[0m\n",
      "\n",
      "seq_length = 1, num_layers = 2, batch_size = 15, embedding_size = 34\n",
      "hidden_size = 1, init_hidden = True, output_size = 1, seq_model = 'lstm'\n",
      "device = cpu()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\u001b[90m\u001b[39;49;00m\n",
      "                            init_hidden, output_size, seq_model, device):\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      ">       model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "batch_size = 15\n",
      "c0         = needle.Tensor([[[ 1.313269  ]\n",
      "  [ 0.27452967]\n",
      "  [-0.90180033]\n",
      "  [ 0.775645  ]\n",
      "  [ 0.9506361 ]\n",
      "  [ 0.79276204]\n",
      "  [-0.99...75 ]\n",
      "  [-1.0995646 ]\n",
      "  [ 0.92395806]\n",
      "  [ 1.5274264 ]\n",
      "  [ 0.54226565]\n",
      "  [-2.1004815 ]\n",
      "  [-0.56590086]\n",
      "  [ 0.05395194]]])\n",
      "device     = cpu()\n",
      "embedding_size = 34\n",
      "h0         = needle.Tensor([[[ 0.04671483]\n",
      "  [ 1.4775933 ]\n",
      "  [-0.16244255]\n",
      "  [ 1.1760072 ]\n",
      "  [-0.8848886 ]\n",
      "  [-1.1118332 ]\n",
      "  [-0.61...468]\n",
      "  [-1.3510879 ]\n",
      "  [ 0.86677945]\n",
      "  [-1.2442977 ]\n",
      "  [ 0.9642595 ]\n",
      "  [-1.6372626 ]\n",
      "  [-1.5223931 ]\n",
      "  [ 0.39724055]]])\n",
      "hidden_size = 1\n",
      "init_hidden = True\n",
      "num_layers = 2\n",
      "output_size = 1\n",
      "seq_length = 1\n",
      "seq_model  = 'lstm'\n",
      "x          = array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "      dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:201: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "self = <models.LanguageModel object at 0x157798710>, embedding_size = 34\n",
      "output_size = 1, hidden_size = 1, num_layers = 2, seq_model = 'lstm'\n",
      "device = cpu(), dtype = 'float32'\n",
      "\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92m__init__\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, embedding_size, output_size, hidden_size, num_layers=\u001b[94m1\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                 seq_model=\u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, device=\u001b[94mNone\u001b[39;49;00m, dtype=\u001b[33m\"\u001b[39;49;00m\u001b[33mfloat32\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"\u001b[39;49;00m\n",
      "    \u001b[33m    Consists of an embedding layer, a sequence model (either RNN or LSTM), and a\u001b[39;49;00m\n",
      "    \u001b[33m    linear layer.\u001b[39;49;00m\n",
      "    \u001b[33m    Parameters:\u001b[39;49;00m\n",
      "    \u001b[33m    output_size: Size of dictionary\u001b[39;49;00m\n",
      "    \u001b[33m    embedding_size: Size of embeddings\u001b[39;49;00m\n",
      "    \u001b[33m    hidden_size: The number of features in the hidden state of LSTM or RNN\u001b[39;49;00m\n",
      "    \u001b[33m    seq_model: 'rnn' or 'lstm', whether to use RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    num_layers: Number of layers in RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    \"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[96msuper\u001b[39;49;00m(LanguageModel, \u001b[96mself\u001b[39;49;00m).\u001b[92m__init__\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m### BEGIN YOUR SOLUTION\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94mraise\u001b[39;49;00m \u001b[96mNotImplementedError\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       NotImplementedError\u001b[0m\n",
      "\n",
      "__class__  = <class 'models.LanguageModel'>\n",
      "device     = cpu()\n",
      "dtype      = 'float32'\n",
      "embedding_size = 34\n",
      "hidden_size = 1\n",
      "num_layers = 2\n",
      "output_size = 1\n",
      "self       = <models.LanguageModel object at 0x157798710>\n",
      "seq_model  = 'lstm'\n",
      "\n",
      "\u001b[1m\u001b[31mapps/models.py\u001b[0m:38: NotImplementedError\n",
      "\u001b[31m\u001b[1m_______ test_language_model_implementation[cpu-lstm-1-True-1-34-15-2-13] _______\u001b[0m\n",
      "\n",
      "seq_length = 13, num_layers = 2, batch_size = 15, embedding_size = 34\n",
      "hidden_size = 1, init_hidden = True, output_size = 1, seq_model = 'lstm'\n",
      "device = cpu()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\u001b[90m\u001b[39;49;00m\n",
      "                            init_hidden, output_size, seq_model, device):\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      ">       model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "batch_size = 15\n",
      "c0         = needle.Tensor([[[-1.0324192 ]\n",
      "  [-1.4430592 ]\n",
      "  [ 0.1415362 ]\n",
      "  [ 0.50014955]\n",
      "  [ 0.19033009]\n",
      "  [-1.2942547 ]\n",
      "  [ 1.46...373]\n",
      "  [-0.6984993 ]\n",
      "  [-0.6567399 ]\n",
      "  [-0.84686434]\n",
      "  [ 0.40873343]\n",
      "  [-1.3481154 ]\n",
      "  [ 0.51866084]\n",
      "  [-1.9298062 ]]])\n",
      "device     = cpu()\n",
      "embedding_size = 34\n",
      "h0         = needle.Tensor([[[ 0.6107933 ]\n",
      "  [ 1.4127787 ]\n",
      "  [-0.5551528 ]\n",
      "  [ 1.4166704 ]\n",
      "  [ 1.0123292 ]\n",
      "  [-0.41724643]\n",
      "  [ 0.98...035]\n",
      "  [-0.2886063 ]\n",
      "  [ 0.5854636 ]\n",
      "  [-0.08088673]\n",
      "  [ 0.08049309]\n",
      "  [ 1.2918261 ]\n",
      "  [ 0.0436465 ]\n",
      "  [ 0.26352784]]])\n",
      "hidden_size = 1\n",
      "init_hidden = True\n",
      "num_layers = 2\n",
      "output_size = 1\n",
      "seq_length = 13\n",
      "seq_model  = 'lstm'\n",
      "x          = array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0...0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "      dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:201: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "self = <models.LanguageModel object at 0x1577997f0>, embedding_size = 34\n",
      "output_size = 1, hidden_size = 1, num_layers = 2, seq_model = 'lstm'\n",
      "device = cpu(), dtype = 'float32'\n",
      "\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92m__init__\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, embedding_size, output_size, hidden_size, num_layers=\u001b[94m1\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                 seq_model=\u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, device=\u001b[94mNone\u001b[39;49;00m, dtype=\u001b[33m\"\u001b[39;49;00m\u001b[33mfloat32\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"\u001b[39;49;00m\n",
      "    \u001b[33m    Consists of an embedding layer, a sequence model (either RNN or LSTM), and a\u001b[39;49;00m\n",
      "    \u001b[33m    linear layer.\u001b[39;49;00m\n",
      "    \u001b[33m    Parameters:\u001b[39;49;00m\n",
      "    \u001b[33m    output_size: Size of dictionary\u001b[39;49;00m\n",
      "    \u001b[33m    embedding_size: Size of embeddings\u001b[39;49;00m\n",
      "    \u001b[33m    hidden_size: The number of features in the hidden state of LSTM or RNN\u001b[39;49;00m\n",
      "    \u001b[33m    seq_model: 'rnn' or 'lstm', whether to use RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    num_layers: Number of layers in RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    \"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[96msuper\u001b[39;49;00m(LanguageModel, \u001b[96mself\u001b[39;49;00m).\u001b[92m__init__\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m### BEGIN YOUR SOLUTION\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94mraise\u001b[39;49;00m \u001b[96mNotImplementedError\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       NotImplementedError\u001b[0m\n",
      "\n",
      "__class__  = <class 'models.LanguageModel'>\n",
      "device     = cpu()\n",
      "dtype      = 'float32'\n",
      "embedding_size = 34\n",
      "hidden_size = 1\n",
      "num_layers = 2\n",
      "output_size = 1\n",
      "self       = <models.LanguageModel object at 0x1577997f0>\n",
      "seq_model  = 'lstm'\n",
      "\n",
      "\u001b[1m\u001b[31mapps/models.py\u001b[0m:38: NotImplementedError\n",
      "\u001b[31m\u001b[1m________ test_language_model_implementation[cpu-lstm-1-True-12-1-1-1-1] ________\u001b[0m\n",
      "\n",
      "seq_length = 1, num_layers = 1, batch_size = 1, embedding_size = 1\n",
      "hidden_size = 12, init_hidden = True, output_size = 1, seq_model = 'lstm'\n",
      "device = cpu()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\u001b[90m\u001b[39;49;00m\n",
      "                            init_hidden, output_size, seq_model, device):\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      ">       model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "batch_size = 1\n",
      "c0         = needle.Tensor([[[-1.1266227   1.1148582   0.2521779  -1.4031652   0.32436788\n",
      "   -0.19966456  0.32343864 -0.89023083 -0.0302078   1.3325676\n",
      "   -0.02386215  0.4379525 ]]])\n",
      "device     = cpu()\n",
      "embedding_size = 1\n",
      "h0         = needle.Tensor([[[-0.8144044  -0.21782966 -0.7744056   1.1352228  -0.29405323\n",
      "   -1.5728154   0.7281912  -1.4144185   1.6421664   1.6666448\n",
      "    2.0950272  -0.38138694]]])\n",
      "hidden_size = 12\n",
      "init_hidden = True\n",
      "num_layers = 1\n",
      "output_size = 1\n",
      "seq_length = 1\n",
      "seq_model  = 'lstm'\n",
      "x          = array([[0.]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:201: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "self = <models.LanguageModel object at 0x1577c4350>, embedding_size = 1\n",
      "output_size = 1, hidden_size = 12, num_layers = 1, seq_model = 'lstm'\n",
      "device = cpu(), dtype = 'float32'\n",
      "\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92m__init__\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, embedding_size, output_size, hidden_size, num_layers=\u001b[94m1\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                 seq_model=\u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, device=\u001b[94mNone\u001b[39;49;00m, dtype=\u001b[33m\"\u001b[39;49;00m\u001b[33mfloat32\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"\u001b[39;49;00m\n",
      "    \u001b[33m    Consists of an embedding layer, a sequence model (either RNN or LSTM), and a\u001b[39;49;00m\n",
      "    \u001b[33m    linear layer.\u001b[39;49;00m\n",
      "    \u001b[33m    Parameters:\u001b[39;49;00m\n",
      "    \u001b[33m    output_size: Size of dictionary\u001b[39;49;00m\n",
      "    \u001b[33m    embedding_size: Size of embeddings\u001b[39;49;00m\n",
      "    \u001b[33m    hidden_size: The number of features in the hidden state of LSTM or RNN\u001b[39;49;00m\n",
      "    \u001b[33m    seq_model: 'rnn' or 'lstm', whether to use RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    num_layers: Number of layers in RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    \"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[96msuper\u001b[39;49;00m(LanguageModel, \u001b[96mself\u001b[39;49;00m).\u001b[92m__init__\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m### BEGIN YOUR SOLUTION\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94mraise\u001b[39;49;00m \u001b[96mNotImplementedError\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       NotImplementedError\u001b[0m\n",
      "\n",
      "__class__  = <class 'models.LanguageModel'>\n",
      "device     = cpu()\n",
      "dtype      = 'float32'\n",
      "embedding_size = 1\n",
      "hidden_size = 12\n",
      "num_layers = 1\n",
      "output_size = 1\n",
      "self       = <models.LanguageModel object at 0x1577c4350>\n",
      "seq_model  = 'lstm'\n",
      "\n",
      "\u001b[1m\u001b[31mapps/models.py\u001b[0m:38: NotImplementedError\n",
      "\u001b[31m\u001b[1m_______ test_language_model_implementation[cpu-lstm-1-True-12-1-1-1-13] ________\u001b[0m\n",
      "\n",
      "seq_length = 13, num_layers = 1, batch_size = 1, embedding_size = 1\n",
      "hidden_size = 12, init_hidden = True, output_size = 1, seq_model = 'lstm'\n",
      "device = cpu()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\u001b[90m\u001b[39;49;00m\n",
      "                            init_hidden, output_size, seq_model, device):\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      ">       model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "batch_size = 1\n",
      "c0         = needle.Tensor([[[-0.4259905  -0.6057215   1.0762855  -0.4112458  -0.3856339\n",
      "   -0.7687718   0.6450598   0.91398513 -1.4721977   2.007904\n",
      "   -0.581909   -1.3173361 ]]])\n",
      "device     = cpu()\n",
      "embedding_size = 1\n",
      "h0         = needle.Tensor([[[ 1.119288   -1.0534431  -0.22092417 -0.95607495  0.78942585\n",
      "    0.96443945 -0.89171296 -0.28417888  0.5777632  -0.19294325\n",
      "   -1.2138333  -1.9715472 ]]])\n",
      "hidden_size = 12\n",
      "init_hidden = True\n",
      "num_layers = 1\n",
      "output_size = 1\n",
      "seq_length = 13\n",
      "seq_model  = 'lstm'\n",
      "x          = array([[0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:201: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "self = <models.LanguageModel object at 0x1577f0230>, embedding_size = 1\n",
      "output_size = 1, hidden_size = 12, num_layers = 1, seq_model = 'lstm'\n",
      "device = cpu(), dtype = 'float32'\n",
      "\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92m__init__\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, embedding_size, output_size, hidden_size, num_layers=\u001b[94m1\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                 seq_model=\u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, device=\u001b[94mNone\u001b[39;49;00m, dtype=\u001b[33m\"\u001b[39;49;00m\u001b[33mfloat32\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"\u001b[39;49;00m\n",
      "    \u001b[33m    Consists of an embedding layer, a sequence model (either RNN or LSTM), and a\u001b[39;49;00m\n",
      "    \u001b[33m    linear layer.\u001b[39;49;00m\n",
      "    \u001b[33m    Parameters:\u001b[39;49;00m\n",
      "    \u001b[33m    output_size: Size of dictionary\u001b[39;49;00m\n",
      "    \u001b[33m    embedding_size: Size of embeddings\u001b[39;49;00m\n",
      "    \u001b[33m    hidden_size: The number of features in the hidden state of LSTM or RNN\u001b[39;49;00m\n",
      "    \u001b[33m    seq_model: 'rnn' or 'lstm', whether to use RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    num_layers: Number of layers in RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    \"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[96msuper\u001b[39;49;00m(LanguageModel, \u001b[96mself\u001b[39;49;00m).\u001b[92m__init__\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m### BEGIN YOUR SOLUTION\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94mraise\u001b[39;49;00m \u001b[96mNotImplementedError\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       NotImplementedError\u001b[0m\n",
      "\n",
      "__class__  = <class 'models.LanguageModel'>\n",
      "device     = cpu()\n",
      "dtype      = 'float32'\n",
      "embedding_size = 1\n",
      "hidden_size = 12\n",
      "num_layers = 1\n",
      "output_size = 1\n",
      "self       = <models.LanguageModel object at 0x1577f0230>\n",
      "seq_model  = 'lstm'\n",
      "\n",
      "\u001b[1m\u001b[31mapps/models.py\u001b[0m:38: NotImplementedError\n",
      "\u001b[31m\u001b[1m________ test_language_model_implementation[cpu-lstm-1-True-12-1-1-2-1] ________\u001b[0m\n",
      "\n",
      "seq_length = 1, num_layers = 2, batch_size = 1, embedding_size = 1\n",
      "hidden_size = 12, init_hidden = True, output_size = 1, seq_model = 'lstm'\n",
      "device = cpu()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\u001b[90m\u001b[39;49;00m\n",
      "                            init_hidden, output_size, seq_model, device):\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      ">       model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "batch_size = 1\n",
      "c0         = needle.Tensor([[[-2.320584    1.2984148   0.95981824  1.7614911   0.13900776\n",
      "    0.97923315 -0.66864     0.42330226 -1...457  0.10935805 -1.7582005\n",
      "    0.5826005   1.030479    0.02082051  1.3995316  -1.3278273\n",
      "   -0.10532229 -1.3789144 ]]])\n",
      "device     = cpu()\n",
      "embedding_size = 1\n",
      "h0         = needle.Tensor([[[ 0.05295874  0.43408948 -0.66639996 -0.4135641   0.17513731\n",
      "   -1.646816   -0.0754398   0.02262559 -0...7  -0.15691137 -1.2558684\n",
      "    0.92376864 -1.8126332  -1.1314267  -0.08963787 -0.22794782\n",
      "   -0.83334684  0.3951848 ]]])\n",
      "hidden_size = 12\n",
      "init_hidden = True\n",
      "num_layers = 2\n",
      "output_size = 1\n",
      "seq_length = 1\n",
      "seq_model  = 'lstm'\n",
      "x          = array([[0.]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:201: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "self = <models.LanguageModel object at 0x1577bf800>, embedding_size = 1\n",
      "output_size = 1, hidden_size = 12, num_layers = 2, seq_model = 'lstm'\n",
      "device = cpu(), dtype = 'float32'\n",
      "\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92m__init__\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, embedding_size, output_size, hidden_size, num_layers=\u001b[94m1\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                 seq_model=\u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, device=\u001b[94mNone\u001b[39;49;00m, dtype=\u001b[33m\"\u001b[39;49;00m\u001b[33mfloat32\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"\u001b[39;49;00m\n",
      "    \u001b[33m    Consists of an embedding layer, a sequence model (either RNN or LSTM), and a\u001b[39;49;00m\n",
      "    \u001b[33m    linear layer.\u001b[39;49;00m\n",
      "    \u001b[33m    Parameters:\u001b[39;49;00m\n",
      "    \u001b[33m    output_size: Size of dictionary\u001b[39;49;00m\n",
      "    \u001b[33m    embedding_size: Size of embeddings\u001b[39;49;00m\n",
      "    \u001b[33m    hidden_size: The number of features in the hidden state of LSTM or RNN\u001b[39;49;00m\n",
      "    \u001b[33m    seq_model: 'rnn' or 'lstm', whether to use RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    num_layers: Number of layers in RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    \"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[96msuper\u001b[39;49;00m(LanguageModel, \u001b[96mself\u001b[39;49;00m).\u001b[92m__init__\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m### BEGIN YOUR SOLUTION\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94mraise\u001b[39;49;00m \u001b[96mNotImplementedError\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       NotImplementedError\u001b[0m\n",
      "\n",
      "__class__  = <class 'models.LanguageModel'>\n",
      "device     = cpu()\n",
      "dtype      = 'float32'\n",
      "embedding_size = 1\n",
      "hidden_size = 12\n",
      "num_layers = 2\n",
      "output_size = 1\n",
      "self       = <models.LanguageModel object at 0x1577bf800>\n",
      "seq_model  = 'lstm'\n",
      "\n",
      "\u001b[1m\u001b[31mapps/models.py\u001b[0m:38: NotImplementedError\n",
      "\u001b[31m\u001b[1m_______ test_language_model_implementation[cpu-lstm-1-True-12-1-1-2-13] ________\u001b[0m\n",
      "\n",
      "seq_length = 13, num_layers = 2, batch_size = 1, embedding_size = 1\n",
      "hidden_size = 12, init_hidden = True, output_size = 1, seq_model = 'lstm'\n",
      "device = cpu()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\u001b[90m\u001b[39;49;00m\n",
      "                            init_hidden, output_size, seq_model, device):\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      ">       model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "batch_size = 1\n",
      "c0         = needle.Tensor([[[-1.9459807  -0.39835012  0.5659812  -0.6628399  -0.5337312\n",
      "    0.3684486  -1.2042384   2.0427036   1....89   1.2862755   0.24181587\n",
      "   -0.6093073   1.0698433   0.09225911  0.32076684  1.601773\n",
      "    1.3469322  -0.8049667 ]]])\n",
      "device     = cpu()\n",
      "embedding_size = 1\n",
      "h0         = needle.Tensor([[[ 0.87650615 -0.05053032 -1.9808997   0.22683817  0.15389259\n",
      "    0.5270427   0.32257456 -0.19580625 -0...7   0.9063535  -0.19559363\n",
      "    0.45796728 -0.09456202 -0.85594136  1.2052611  -1.2546995\n",
      "    0.02828394 -0.9808863 ]]])\n",
      "hidden_size = 12\n",
      "init_hidden = True\n",
      "num_layers = 2\n",
      "output_size = 1\n",
      "seq_length = 13\n",
      "seq_model  = 'lstm'\n",
      "x          = array([[0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:201: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "self = <models.LanguageModel object at 0x15737ba10>, embedding_size = 1\n",
      "output_size = 1, hidden_size = 12, num_layers = 2, seq_model = 'lstm'\n",
      "device = cpu(), dtype = 'float32'\n",
      "\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92m__init__\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, embedding_size, output_size, hidden_size, num_layers=\u001b[94m1\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                 seq_model=\u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, device=\u001b[94mNone\u001b[39;49;00m, dtype=\u001b[33m\"\u001b[39;49;00m\u001b[33mfloat32\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"\u001b[39;49;00m\n",
      "    \u001b[33m    Consists of an embedding layer, a sequence model (either RNN or LSTM), and a\u001b[39;49;00m\n",
      "    \u001b[33m    linear layer.\u001b[39;49;00m\n",
      "    \u001b[33m    Parameters:\u001b[39;49;00m\n",
      "    \u001b[33m    output_size: Size of dictionary\u001b[39;49;00m\n",
      "    \u001b[33m    embedding_size: Size of embeddings\u001b[39;49;00m\n",
      "    \u001b[33m    hidden_size: The number of features in the hidden state of LSTM or RNN\u001b[39;49;00m\n",
      "    \u001b[33m    seq_model: 'rnn' or 'lstm', whether to use RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    num_layers: Number of layers in RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    \"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[96msuper\u001b[39;49;00m(LanguageModel, \u001b[96mself\u001b[39;49;00m).\u001b[92m__init__\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m### BEGIN YOUR SOLUTION\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94mraise\u001b[39;49;00m \u001b[96mNotImplementedError\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       NotImplementedError\u001b[0m\n",
      "\n",
      "__class__  = <class 'models.LanguageModel'>\n",
      "device     = cpu()\n",
      "dtype      = 'float32'\n",
      "embedding_size = 1\n",
      "hidden_size = 12\n",
      "num_layers = 2\n",
      "output_size = 1\n",
      "self       = <models.LanguageModel object at 0x15737ba10>\n",
      "seq_model  = 'lstm'\n",
      "\n",
      "\u001b[1m\u001b[31mapps/models.py\u001b[0m:38: NotImplementedError\n",
      "\u001b[31m\u001b[1m_______ test_language_model_implementation[cpu-lstm-1-True-12-1-15-1-1] ________\u001b[0m\n",
      "\n",
      "seq_length = 1, num_layers = 1, batch_size = 15, embedding_size = 1\n",
      "hidden_size = 12, init_hidden = True, output_size = 1, seq_model = 'lstm'\n",
      "device = cpu()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\u001b[90m\u001b[39;49;00m\n",
      "                            init_hidden, output_size, seq_model, device):\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      ">       model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "batch_size = 15\n",
      "c0         = needle.Tensor([[[ 1.5797377   0.14905515 -0.22360936  0.96034074  0.32226133\n",
      "    1.4615498  -0.09045645 -0.72645634 -1...95   2.1780121   0.5965754\n",
      "   -1.2805046   0.03928215 -0.5477989   1.9189744  -0.1723003\n",
      "   -1.3228157   1.6492313 ]]])\n",
      "device     = cpu()\n",
      "embedding_size = 1\n",
      "h0         = needle.Tensor([[[ 2.2794445e+00  2.8004473e-01  6.1667764e-01  3.7674594e-01\n",
      "   -6.5093130e-01 -8.0794084e-01  8.06511...065e-01  4.9804860e-01 -1.8310626e+00 -2.9823208e-01\n",
      "    5.3892523e-01  7.9260212e-01  5.0881189e-01  5.3300858e-01]]])\n",
      "hidden_size = 12\n",
      "init_hidden = True\n",
      "num_layers = 1\n",
      "output_size = 1\n",
      "seq_length = 1\n",
      "seq_model  = 'lstm'\n",
      "x          = array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "      dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:201: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "self = <models.LanguageModel object at 0x15779a6c0>, embedding_size = 1\n",
      "output_size = 1, hidden_size = 12, num_layers = 1, seq_model = 'lstm'\n",
      "device = cpu(), dtype = 'float32'\n",
      "\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92m__init__\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, embedding_size, output_size, hidden_size, num_layers=\u001b[94m1\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                 seq_model=\u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, device=\u001b[94mNone\u001b[39;49;00m, dtype=\u001b[33m\"\u001b[39;49;00m\u001b[33mfloat32\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"\u001b[39;49;00m\n",
      "    \u001b[33m    Consists of an embedding layer, a sequence model (either RNN or LSTM), and a\u001b[39;49;00m\n",
      "    \u001b[33m    linear layer.\u001b[39;49;00m\n",
      "    \u001b[33m    Parameters:\u001b[39;49;00m\n",
      "    \u001b[33m    output_size: Size of dictionary\u001b[39;49;00m\n",
      "    \u001b[33m    embedding_size: Size of embeddings\u001b[39;49;00m\n",
      "    \u001b[33m    hidden_size: The number of features in the hidden state of LSTM or RNN\u001b[39;49;00m\n",
      "    \u001b[33m    seq_model: 'rnn' or 'lstm', whether to use RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    num_layers: Number of layers in RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    \"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[96msuper\u001b[39;49;00m(LanguageModel, \u001b[96mself\u001b[39;49;00m).\u001b[92m__init__\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m### BEGIN YOUR SOLUTION\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94mraise\u001b[39;49;00m \u001b[96mNotImplementedError\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       NotImplementedError\u001b[0m\n",
      "\n",
      "__class__  = <class 'models.LanguageModel'>\n",
      "device     = cpu()\n",
      "dtype      = 'float32'\n",
      "embedding_size = 1\n",
      "hidden_size = 12\n",
      "num_layers = 1\n",
      "output_size = 1\n",
      "self       = <models.LanguageModel object at 0x15779a6c0>\n",
      "seq_model  = 'lstm'\n",
      "\n",
      "\u001b[1m\u001b[31mapps/models.py\u001b[0m:38: NotImplementedError\n",
      "\u001b[31m\u001b[1m_______ test_language_model_implementation[cpu-lstm-1-True-12-1-15-1-13] _______\u001b[0m\n",
      "\n",
      "seq_length = 13, num_layers = 1, batch_size = 15, embedding_size = 1\n",
      "hidden_size = 12, init_hidden = True, output_size = 1, seq_model = 'lstm'\n",
      "device = cpu()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\u001b[90m\u001b[39;49;00m\n",
      "                            init_hidden, output_size, seq_model, device):\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      ">       model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "batch_size = 15\n",
      "c0         = needle.Tensor([[[-0.80527526 -3.0929923   0.3917616  -0.6599268  -0.28034636\n",
      "    1.530996   -1.1778853   0.11369905  0...343 -2.08291     0.88112426\n",
      "    0.34268144  0.1769815   0.24851929 -1.210327   -1.023335\n",
      "    0.45164773 -0.3782335 ]]])\n",
      "device     = cpu()\n",
      "embedding_size = 1\n",
      "h0         = needle.Tensor([[[ 0.68937105 -0.7558497  -0.74715275 -0.06753924 -0.69649976\n",
      "    0.07921001  1.0042547  -1.1528022  -0...84  1.5928069   1.0548463\n",
      "    0.38822347  0.7742213  -1.9466946   0.5685017  -0.05315084\n",
      "    0.8698795  -1.3610693 ]]])\n",
      "hidden_size = 12\n",
      "init_hidden = True\n",
      "num_layers = 1\n",
      "output_size = 1\n",
      "seq_length = 13\n",
      "seq_model  = 'lstm'\n",
      "x          = array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0...0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "      dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:201: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "self = <models.LanguageModel object at 0x1694a54c0>, embedding_size = 1\n",
      "output_size = 1, hidden_size = 12, num_layers = 1, seq_model = 'lstm'\n",
      "device = cpu(), dtype = 'float32'\n",
      "\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92m__init__\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, embedding_size, output_size, hidden_size, num_layers=\u001b[94m1\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                 seq_model=\u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, device=\u001b[94mNone\u001b[39;49;00m, dtype=\u001b[33m\"\u001b[39;49;00m\u001b[33mfloat32\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"\u001b[39;49;00m\n",
      "    \u001b[33m    Consists of an embedding layer, a sequence model (either RNN or LSTM), and a\u001b[39;49;00m\n",
      "    \u001b[33m    linear layer.\u001b[39;49;00m\n",
      "    \u001b[33m    Parameters:\u001b[39;49;00m\n",
      "    \u001b[33m    output_size: Size of dictionary\u001b[39;49;00m\n",
      "    \u001b[33m    embedding_size: Size of embeddings\u001b[39;49;00m\n",
      "    \u001b[33m    hidden_size: The number of features in the hidden state of LSTM or RNN\u001b[39;49;00m\n",
      "    \u001b[33m    seq_model: 'rnn' or 'lstm', whether to use RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    num_layers: Number of layers in RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    \"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[96msuper\u001b[39;49;00m(LanguageModel, \u001b[96mself\u001b[39;49;00m).\u001b[92m__init__\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m### BEGIN YOUR SOLUTION\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94mraise\u001b[39;49;00m \u001b[96mNotImplementedError\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       NotImplementedError\u001b[0m\n",
      "\n",
      "__class__  = <class 'models.LanguageModel'>\n",
      "device     = cpu()\n",
      "dtype      = 'float32'\n",
      "embedding_size = 1\n",
      "hidden_size = 12\n",
      "num_layers = 1\n",
      "output_size = 1\n",
      "self       = <models.LanguageModel object at 0x1694a54c0>\n",
      "seq_model  = 'lstm'\n",
      "\n",
      "\u001b[1m\u001b[31mapps/models.py\u001b[0m:38: NotImplementedError\n",
      "\u001b[31m\u001b[1m_______ test_language_model_implementation[cpu-lstm-1-True-12-1-15-2-1] ________\u001b[0m\n",
      "\n",
      "seq_length = 1, num_layers = 2, batch_size = 15, embedding_size = 1\n",
      "hidden_size = 12, init_hidden = True, output_size = 1, seq_model = 'lstm'\n",
      "device = cpu()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\u001b[90m\u001b[39;49;00m\n",
      "                            init_hidden, output_size, seq_model, device):\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      ">       model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "batch_size = 15\n",
      "c0         = needle.Tensor([[[-1.63035214e+00 -9.27499890e-01  3.81848276e-01  1.86633885e+00\n",
      "   -9.32452977e-02  4.67329144e-01 -1...  1.04887509e+00  5.16717613e-01 -1.73737860e+00\n",
      "    1.47306427e-01  2.10151821e-02  5.95158994e-01 -1.45346010e+00]]])\n",
      "device     = cpu()\n",
      "embedding_size = 1\n",
      "h0         = needle.Tensor([[[ 0.27083278 -0.1458491   0.47190893  1.2195473   0.4206706\n",
      "    0.29021943 -0.2782378  -0.26540902 -0....24  -1.687889    0.46268034\n",
      "   -1.4388868  -0.47222555  0.89698946  2.203945   -1.472248\n",
      "   -0.01973496 -1.1641628 ]]])\n",
      "hidden_size = 12\n",
      "init_hidden = True\n",
      "num_layers = 2\n",
      "output_size = 1\n",
      "seq_length = 1\n",
      "seq_model  = 'lstm'\n",
      "x          = array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "      dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:201: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "self = <models.LanguageModel object at 0x1694a4c50>, embedding_size = 1\n",
      "output_size = 1, hidden_size = 12, num_layers = 2, seq_model = 'lstm'\n",
      "device = cpu(), dtype = 'float32'\n",
      "\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92m__init__\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, embedding_size, output_size, hidden_size, num_layers=\u001b[94m1\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                 seq_model=\u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, device=\u001b[94mNone\u001b[39;49;00m, dtype=\u001b[33m\"\u001b[39;49;00m\u001b[33mfloat32\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"\u001b[39;49;00m\n",
      "    \u001b[33m    Consists of an embedding layer, a sequence model (either RNN or LSTM), and a\u001b[39;49;00m\n",
      "    \u001b[33m    linear layer.\u001b[39;49;00m\n",
      "    \u001b[33m    Parameters:\u001b[39;49;00m\n",
      "    \u001b[33m    output_size: Size of dictionary\u001b[39;49;00m\n",
      "    \u001b[33m    embedding_size: Size of embeddings\u001b[39;49;00m\n",
      "    \u001b[33m    hidden_size: The number of features in the hidden state of LSTM or RNN\u001b[39;49;00m\n",
      "    \u001b[33m    seq_model: 'rnn' or 'lstm', whether to use RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    num_layers: Number of layers in RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    \"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[96msuper\u001b[39;49;00m(LanguageModel, \u001b[96mself\u001b[39;49;00m).\u001b[92m__init__\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m### BEGIN YOUR SOLUTION\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94mraise\u001b[39;49;00m \u001b[96mNotImplementedError\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       NotImplementedError\u001b[0m\n",
      "\n",
      "__class__  = <class 'models.LanguageModel'>\n",
      "device     = cpu()\n",
      "dtype      = 'float32'\n",
      "embedding_size = 1\n",
      "hidden_size = 12\n",
      "num_layers = 2\n",
      "output_size = 1\n",
      "self       = <models.LanguageModel object at 0x1694a4c50>\n",
      "seq_model  = 'lstm'\n",
      "\n",
      "\u001b[1m\u001b[31mapps/models.py\u001b[0m:38: NotImplementedError\n",
      "\u001b[31m\u001b[1m_______ test_language_model_implementation[cpu-lstm-1-True-12-1-15-2-13] _______\u001b[0m\n",
      "\n",
      "seq_length = 13, num_layers = 2, batch_size = 15, embedding_size = 1\n",
      "hidden_size = 12, init_hidden = True, output_size = 1, seq_model = 'lstm'\n",
      "device = cpu()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\u001b[90m\u001b[39;49;00m\n",
      "                            init_hidden, output_size, seq_model, device):\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      ">       model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "batch_size = 15\n",
      "c0         = needle.Tensor([[[-1.5431339e+00  7.5740886e-01 -8.3210170e-01 -7.0028967e-01\n",
      "    5.0747967e-01 -1.5204078e+00  3.49878...855e-01  4.5081779e-01 -1.2028799e+00  8.9936626e-01\n",
      "    8.6659020e-01 -8.0713654e-01 -6.3820082e-01  1.1175934e-01]]])\n",
      "device     = cpu()\n",
      "embedding_size = 1\n",
      "h0         = needle.Tensor([[[ 5.06517887e-01 -2.15496469e+00  9.36780691e-01 -1.49776554e+00\n",
      "    2.01729953e-01 -2.09001851e+00 -2...  1.69636023e+00  1.76437914e+00 -1.77214837e+00\n",
      "    6.90865219e-01  1.63106394e+00  3.83995175e-02 -2.38711286e+00]]])\n",
      "hidden_size = 12\n",
      "init_hidden = True\n",
      "num_layers = 2\n",
      "output_size = 1\n",
      "seq_length = 13\n",
      "seq_model  = 'lstm'\n",
      "x          = array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0...0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "      dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:201: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "self = <models.LanguageModel object at 0x15779b740>, embedding_size = 1\n",
      "output_size = 1, hidden_size = 12, num_layers = 2, seq_model = 'lstm'\n",
      "device = cpu(), dtype = 'float32'\n",
      "\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92m__init__\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, embedding_size, output_size, hidden_size, num_layers=\u001b[94m1\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                 seq_model=\u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, device=\u001b[94mNone\u001b[39;49;00m, dtype=\u001b[33m\"\u001b[39;49;00m\u001b[33mfloat32\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"\u001b[39;49;00m\n",
      "    \u001b[33m    Consists of an embedding layer, a sequence model (either RNN or LSTM), and a\u001b[39;49;00m\n",
      "    \u001b[33m    linear layer.\u001b[39;49;00m\n",
      "    \u001b[33m    Parameters:\u001b[39;49;00m\n",
      "    \u001b[33m    output_size: Size of dictionary\u001b[39;49;00m\n",
      "    \u001b[33m    embedding_size: Size of embeddings\u001b[39;49;00m\n",
      "    \u001b[33m    hidden_size: The number of features in the hidden state of LSTM or RNN\u001b[39;49;00m\n",
      "    \u001b[33m    seq_model: 'rnn' or 'lstm', whether to use RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    num_layers: Number of layers in RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    \"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[96msuper\u001b[39;49;00m(LanguageModel, \u001b[96mself\u001b[39;49;00m).\u001b[92m__init__\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m### BEGIN YOUR SOLUTION\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94mraise\u001b[39;49;00m \u001b[96mNotImplementedError\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       NotImplementedError\u001b[0m\n",
      "\n",
      "__class__  = <class 'models.LanguageModel'>\n",
      "device     = cpu()\n",
      "dtype      = 'float32'\n",
      "embedding_size = 1\n",
      "hidden_size = 12\n",
      "num_layers = 2\n",
      "output_size = 1\n",
      "self       = <models.LanguageModel object at 0x15779b740>\n",
      "seq_model  = 'lstm'\n",
      "\n",
      "\u001b[1m\u001b[31mapps/models.py\u001b[0m:38: NotImplementedError\n",
      "\u001b[31m\u001b[1m_______ test_language_model_implementation[cpu-lstm-1-True-12-34-1-1-1] ________\u001b[0m\n",
      "\n",
      "seq_length = 1, num_layers = 1, batch_size = 1, embedding_size = 34\n",
      "hidden_size = 12, init_hidden = True, output_size = 1, seq_model = 'lstm'\n",
      "device = cpu()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\u001b[90m\u001b[39;49;00m\n",
      "                            init_hidden, output_size, seq_model, device):\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      ">       model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "batch_size = 1\n",
      "c0         = needle.Tensor([[[ 1.3632236   0.1783894   0.14946346  2.1091712   2.2756722\n",
      "    1.4189138  -0.03045183 -0.5826926  -0.2084915  -0.89080906\n",
      "    0.5399559  -1.3278983 ]]])\n",
      "device     = cpu()\n",
      "embedding_size = 34\n",
      "h0         = needle.Tensor([[[-1.1009331  -0.02026029 -1.5327361  -0.866585    0.19248095\n",
      "    0.59633833  0.6914937   0.26915762 -1.3427837   1.3044333\n",
      "   -0.46362028  0.7016813 ]]])\n",
      "hidden_size = 12\n",
      "init_hidden = True\n",
      "num_layers = 1\n",
      "output_size = 1\n",
      "seq_length = 1\n",
      "seq_model  = 'lstm'\n",
      "x          = array([[0.]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:201: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "self = <models.LanguageModel object at 0x157798200>, embedding_size = 34\n",
      "output_size = 1, hidden_size = 12, num_layers = 1, seq_model = 'lstm'\n",
      "device = cpu(), dtype = 'float32'\n",
      "\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92m__init__\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, embedding_size, output_size, hidden_size, num_layers=\u001b[94m1\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                 seq_model=\u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, device=\u001b[94mNone\u001b[39;49;00m, dtype=\u001b[33m\"\u001b[39;49;00m\u001b[33mfloat32\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"\u001b[39;49;00m\n",
      "    \u001b[33m    Consists of an embedding layer, a sequence model (either RNN or LSTM), and a\u001b[39;49;00m\n",
      "    \u001b[33m    linear layer.\u001b[39;49;00m\n",
      "    \u001b[33m    Parameters:\u001b[39;49;00m\n",
      "    \u001b[33m    output_size: Size of dictionary\u001b[39;49;00m\n",
      "    \u001b[33m    embedding_size: Size of embeddings\u001b[39;49;00m\n",
      "    \u001b[33m    hidden_size: The number of features in the hidden state of LSTM or RNN\u001b[39;49;00m\n",
      "    \u001b[33m    seq_model: 'rnn' or 'lstm', whether to use RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    num_layers: Number of layers in RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    \"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[96msuper\u001b[39;49;00m(LanguageModel, \u001b[96mself\u001b[39;49;00m).\u001b[92m__init__\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m### BEGIN YOUR SOLUTION\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94mraise\u001b[39;49;00m \u001b[96mNotImplementedError\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       NotImplementedError\u001b[0m\n",
      "\n",
      "__class__  = <class 'models.LanguageModel'>\n",
      "device     = cpu()\n",
      "dtype      = 'float32'\n",
      "embedding_size = 34\n",
      "hidden_size = 12\n",
      "num_layers = 1\n",
      "output_size = 1\n",
      "self       = <models.LanguageModel object at 0x157798200>\n",
      "seq_model  = 'lstm'\n",
      "\n",
      "\u001b[1m\u001b[31mapps/models.py\u001b[0m:38: NotImplementedError\n",
      "\u001b[31m\u001b[1m_______ test_language_model_implementation[cpu-lstm-1-True-12-34-1-1-13] _______\u001b[0m\n",
      "\n",
      "seq_length = 13, num_layers = 1, batch_size = 1, embedding_size = 34\n",
      "hidden_size = 12, init_hidden = True, output_size = 1, seq_model = 'lstm'\n",
      "device = cpu()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\u001b[90m\u001b[39;49;00m\n",
      "                            init_hidden, output_size, seq_model, device):\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      ">       model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "batch_size = 1\n",
      "c0         = needle.Tensor([[[ 0.9440376   0.23012656 -0.7369753   0.71567124 -1.804392\n",
      "    0.0241302  -1.2245212  -0.78555906  1.208483    1.4602294\n",
      "    0.69859487 -1.3603808 ]]])\n",
      "device     = cpu()\n",
      "embedding_size = 34\n",
      "h0         = needle.Tensor([[[-0.8832185  -0.8958795  -0.82941604  1.7584567   0.10196433\n",
      "   -0.32661328 -0.5418693   1.0800079   0.09104811 -0.8930489\n",
      "    0.42543012 -1.480704  ]]])\n",
      "hidden_size = 12\n",
      "init_hidden = True\n",
      "num_layers = 1\n",
      "output_size = 1\n",
      "seq_length = 13\n",
      "seq_model  = 'lstm'\n",
      "x          = array([[0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:201: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "self = <models.LanguageModel object at 0x1694a4290>, embedding_size = 34\n",
      "output_size = 1, hidden_size = 12, num_layers = 1, seq_model = 'lstm'\n",
      "device = cpu(), dtype = 'float32'\n",
      "\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92m__init__\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, embedding_size, output_size, hidden_size, num_layers=\u001b[94m1\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                 seq_model=\u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, device=\u001b[94mNone\u001b[39;49;00m, dtype=\u001b[33m\"\u001b[39;49;00m\u001b[33mfloat32\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"\u001b[39;49;00m\n",
      "    \u001b[33m    Consists of an embedding layer, a sequence model (either RNN or LSTM), and a\u001b[39;49;00m\n",
      "    \u001b[33m    linear layer.\u001b[39;49;00m\n",
      "    \u001b[33m    Parameters:\u001b[39;49;00m\n",
      "    \u001b[33m    output_size: Size of dictionary\u001b[39;49;00m\n",
      "    \u001b[33m    embedding_size: Size of embeddings\u001b[39;49;00m\n",
      "    \u001b[33m    hidden_size: The number of features in the hidden state of LSTM or RNN\u001b[39;49;00m\n",
      "    \u001b[33m    seq_model: 'rnn' or 'lstm', whether to use RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    num_layers: Number of layers in RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    \"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[96msuper\u001b[39;49;00m(LanguageModel, \u001b[96mself\u001b[39;49;00m).\u001b[92m__init__\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m### BEGIN YOUR SOLUTION\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94mraise\u001b[39;49;00m \u001b[96mNotImplementedError\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       NotImplementedError\u001b[0m\n",
      "\n",
      "__class__  = <class 'models.LanguageModel'>\n",
      "device     = cpu()\n",
      "dtype      = 'float32'\n",
      "embedding_size = 34\n",
      "hidden_size = 12\n",
      "num_layers = 1\n",
      "output_size = 1\n",
      "self       = <models.LanguageModel object at 0x1694a4290>\n",
      "seq_model  = 'lstm'\n",
      "\n",
      "\u001b[1m\u001b[31mapps/models.py\u001b[0m:38: NotImplementedError\n",
      "\u001b[31m\u001b[1m_______ test_language_model_implementation[cpu-lstm-1-True-12-34-1-2-1] ________\u001b[0m\n",
      "\n",
      "seq_length = 1, num_layers = 2, batch_size = 1, embedding_size = 34\n",
      "hidden_size = 12, init_hidden = True, output_size = 1, seq_model = 'lstm'\n",
      "device = cpu()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\u001b[90m\u001b[39;49;00m\n",
      "                            init_hidden, output_size, seq_model, device):\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      ">       model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "batch_size = 1\n",
      "c0         = needle.Tensor([[[ 0.5187269   0.18468061  0.3123348  -0.24774651 -1.2404852\n",
      "   -1.7793541   0.16061534 -0.5891415   0....2 -1.0528965   0.09857754\n",
      "    0.14473085 -0.3108506  -0.85358757 -0.812919   -0.98226386\n",
      "   -2.334936   -0.5492478 ]]])\n",
      "device     = cpu()\n",
      "embedding_size = 34\n",
      "h0         = needle.Tensor([[[-2.11012     0.7654833  -0.26576477  0.6141451   0.61064273\n",
      "   -0.11433357 -1.314155   -0.28514177  0...66   0.8890959  -1.1213374\n",
      "    0.9057736  -0.80094755 -0.85922295 -0.8684062   1.1528255\n",
      "    0.9604365   0.07215489]]])\n",
      "hidden_size = 12\n",
      "init_hidden = True\n",
      "num_layers = 2\n",
      "output_size = 1\n",
      "seq_length = 1\n",
      "seq_model  = 'lstm'\n",
      "x          = array([[0.]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:201: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "self = <models.LanguageModel object at 0x15779ab40>, embedding_size = 34\n",
      "output_size = 1, hidden_size = 12, num_layers = 2, seq_model = 'lstm'\n",
      "device = cpu(), dtype = 'float32'\n",
      "\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92m__init__\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, embedding_size, output_size, hidden_size, num_layers=\u001b[94m1\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                 seq_model=\u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, device=\u001b[94mNone\u001b[39;49;00m, dtype=\u001b[33m\"\u001b[39;49;00m\u001b[33mfloat32\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"\u001b[39;49;00m\n",
      "    \u001b[33m    Consists of an embedding layer, a sequence model (either RNN or LSTM), and a\u001b[39;49;00m\n",
      "    \u001b[33m    linear layer.\u001b[39;49;00m\n",
      "    \u001b[33m    Parameters:\u001b[39;49;00m\n",
      "    \u001b[33m    output_size: Size of dictionary\u001b[39;49;00m\n",
      "    \u001b[33m    embedding_size: Size of embeddings\u001b[39;49;00m\n",
      "    \u001b[33m    hidden_size: The number of features in the hidden state of LSTM or RNN\u001b[39;49;00m\n",
      "    \u001b[33m    seq_model: 'rnn' or 'lstm', whether to use RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    num_layers: Number of layers in RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    \"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[96msuper\u001b[39;49;00m(LanguageModel, \u001b[96mself\u001b[39;49;00m).\u001b[92m__init__\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m### BEGIN YOUR SOLUTION\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94mraise\u001b[39;49;00m \u001b[96mNotImplementedError\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       NotImplementedError\u001b[0m\n",
      "\n",
      "__class__  = <class 'models.LanguageModel'>\n",
      "device     = cpu()\n",
      "dtype      = 'float32'\n",
      "embedding_size = 34\n",
      "hidden_size = 12\n",
      "num_layers = 2\n",
      "output_size = 1\n",
      "self       = <models.LanguageModel object at 0x15779ab40>\n",
      "seq_model  = 'lstm'\n",
      "\n",
      "\u001b[1m\u001b[31mapps/models.py\u001b[0m:38: NotImplementedError\n",
      "\u001b[31m\u001b[1m_______ test_language_model_implementation[cpu-lstm-1-True-12-34-1-2-13] _______\u001b[0m\n",
      "\n",
      "seq_length = 13, num_layers = 2, batch_size = 1, embedding_size = 34\n",
      "hidden_size = 12, init_hidden = True, output_size = 1, seq_model = 'lstm'\n",
      "device = cpu()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\u001b[90m\u001b[39;49;00m\n",
      "                            init_hidden, output_size, seq_model, device):\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      ">       model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "batch_size = 1\n",
      "c0         = needle.Tensor([[[-0.77705127  1.0691147   1.3556452  -0.60284823 -0.29686904\n",
      "   -0.41306442 -0.8409194  -0.47646257  1...3   0.65677476  1.3540509\n",
      "   -2.5412703  -0.3220558  -0.3899751   0.08163554  0.71064055\n",
      "    1.344466   -0.46746582]]])\n",
      "device     = cpu()\n",
      "embedding_size = 34\n",
      "h0         = needle.Tensor([[[ 0.20795786 -2.03577    -0.7122538  -1.7122992   0.6189592\n",
      "    0.6569383   1.1217506   1.1933169  -2....045  0.26220033  1.2075295\n",
      "   -2.2857223   1.5061355   0.22103952 -2.1501915   1.2910101\n",
      "    1.4568751  -0.03140808]]])\n",
      "hidden_size = 12\n",
      "init_hidden = True\n",
      "num_layers = 2\n",
      "output_size = 1\n",
      "seq_length = 13\n",
      "seq_model  = 'lstm'\n",
      "x          = array([[0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:201: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "self = <models.LanguageModel object at 0x1577bff20>, embedding_size = 34\n",
      "output_size = 1, hidden_size = 12, num_layers = 2, seq_model = 'lstm'\n",
      "device = cpu(), dtype = 'float32'\n",
      "\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92m__init__\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, embedding_size, output_size, hidden_size, num_layers=\u001b[94m1\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                 seq_model=\u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, device=\u001b[94mNone\u001b[39;49;00m, dtype=\u001b[33m\"\u001b[39;49;00m\u001b[33mfloat32\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"\u001b[39;49;00m\n",
      "    \u001b[33m    Consists of an embedding layer, a sequence model (either RNN or LSTM), and a\u001b[39;49;00m\n",
      "    \u001b[33m    linear layer.\u001b[39;49;00m\n",
      "    \u001b[33m    Parameters:\u001b[39;49;00m\n",
      "    \u001b[33m    output_size: Size of dictionary\u001b[39;49;00m\n",
      "    \u001b[33m    embedding_size: Size of embeddings\u001b[39;49;00m\n",
      "    \u001b[33m    hidden_size: The number of features in the hidden state of LSTM or RNN\u001b[39;49;00m\n",
      "    \u001b[33m    seq_model: 'rnn' or 'lstm', whether to use RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    num_layers: Number of layers in RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    \"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[96msuper\u001b[39;49;00m(LanguageModel, \u001b[96mself\u001b[39;49;00m).\u001b[92m__init__\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m### BEGIN YOUR SOLUTION\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94mraise\u001b[39;49;00m \u001b[96mNotImplementedError\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       NotImplementedError\u001b[0m\n",
      "\n",
      "__class__  = <class 'models.LanguageModel'>\n",
      "device     = cpu()\n",
      "dtype      = 'float32'\n",
      "embedding_size = 34\n",
      "hidden_size = 12\n",
      "num_layers = 2\n",
      "output_size = 1\n",
      "self       = <models.LanguageModel object at 0x1577bff20>\n",
      "seq_model  = 'lstm'\n",
      "\n",
      "\u001b[1m\u001b[31mapps/models.py\u001b[0m:38: NotImplementedError\n",
      "\u001b[31m\u001b[1m_______ test_language_model_implementation[cpu-lstm-1-True-12-34-15-1-1] _______\u001b[0m\n",
      "\n",
      "seq_length = 1, num_layers = 1, batch_size = 15, embedding_size = 34\n",
      "hidden_size = 12, init_hidden = True, output_size = 1, seq_model = 'lstm'\n",
      "device = cpu()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\u001b[90m\u001b[39;49;00m\n",
      "                            init_hidden, output_size, seq_model, device):\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      ">       model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "batch_size = 15\n",
      "c0         = needle.Tensor([[[-2.502255    0.00804737  0.59058315 -1.1893854   0.03168301\n",
      "   -2.1636035   1.2057823   0.5691967  -0...7   1.4643862  -0.81806886\n",
      "    1.818502   -0.3929956  -0.5903174   0.29812506  1.9489812\n",
      "    2.2965965   0.09906952]]])\n",
      "device     = cpu()\n",
      "embedding_size = 34\n",
      "h0         = needle.Tensor([[[ 0.6843043  -0.11422619 -0.07436816  0.3729417   0.31126326\n",
      "   -0.74956024 -0.4241048  -0.22828087 -0...25   2.0787184   0.7010707\n",
      "   -0.69102037 -0.17285495 -2.422026    0.6646391   1.9642885\n",
      "    0.5147796   1.2108684 ]]])\n",
      "hidden_size = 12\n",
      "init_hidden = True\n",
      "num_layers = 1\n",
      "output_size = 1\n",
      "seq_length = 1\n",
      "seq_model  = 'lstm'\n",
      "x          = array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "      dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:201: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "self = <models.LanguageModel object at 0x1577c5100>, embedding_size = 34\n",
      "output_size = 1, hidden_size = 12, num_layers = 1, seq_model = 'lstm'\n",
      "device = cpu(), dtype = 'float32'\n",
      "\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92m__init__\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, embedding_size, output_size, hidden_size, num_layers=\u001b[94m1\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                 seq_model=\u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, device=\u001b[94mNone\u001b[39;49;00m, dtype=\u001b[33m\"\u001b[39;49;00m\u001b[33mfloat32\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"\u001b[39;49;00m\n",
      "    \u001b[33m    Consists of an embedding layer, a sequence model (either RNN or LSTM), and a\u001b[39;49;00m\n",
      "    \u001b[33m    linear layer.\u001b[39;49;00m\n",
      "    \u001b[33m    Parameters:\u001b[39;49;00m\n",
      "    \u001b[33m    output_size: Size of dictionary\u001b[39;49;00m\n",
      "    \u001b[33m    embedding_size: Size of embeddings\u001b[39;49;00m\n",
      "    \u001b[33m    hidden_size: The number of features in the hidden state of LSTM or RNN\u001b[39;49;00m\n",
      "    \u001b[33m    seq_model: 'rnn' or 'lstm', whether to use RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    num_layers: Number of layers in RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    \"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[96msuper\u001b[39;49;00m(LanguageModel, \u001b[96mself\u001b[39;49;00m).\u001b[92m__init__\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m### BEGIN YOUR SOLUTION\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94mraise\u001b[39;49;00m \u001b[96mNotImplementedError\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       NotImplementedError\u001b[0m\n",
      "\n",
      "__class__  = <class 'models.LanguageModel'>\n",
      "device     = cpu()\n",
      "dtype      = 'float32'\n",
      "embedding_size = 34\n",
      "hidden_size = 12\n",
      "num_layers = 1\n",
      "output_size = 1\n",
      "self       = <models.LanguageModel object at 0x1577c5100>\n",
      "seq_model  = 'lstm'\n",
      "\n",
      "\u001b[1m\u001b[31mapps/models.py\u001b[0m:38: NotImplementedError\n",
      "\u001b[31m\u001b[1m______ test_language_model_implementation[cpu-lstm-1-True-12-34-15-1-13] _______\u001b[0m\n",
      "\n",
      "seq_length = 13, num_layers = 1, batch_size = 15, embedding_size = 34\n",
      "hidden_size = 12, init_hidden = True, output_size = 1, seq_model = 'lstm'\n",
      "device = cpu()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\u001b[90m\u001b[39;49;00m\n",
      "                            init_hidden, output_size, seq_model, device):\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      ">       model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "batch_size = 15\n",
      "c0         = needle.Tensor([[[ 6.0175504e-03  1.6282173e+00 -1.0048324e+00  5.0828463e-01\n",
      "    4.1643956e-01  8.8332099e-01 -1.30011...347e-01  9.6692169e-01 -8.1092966e-01  1.5849549e-01\n",
      "   -3.5863012e-02 -7.4737489e-01 -1.3792711e-01 -7.6227409e-01]]])\n",
      "device     = cpu()\n",
      "embedding_size = 34\n",
      "h0         = needle.Tensor([[[-3.04287642e-01  6.64591670e-01  9.90928710e-01 -2.51116395e-01\n",
      "    1.25922203e+00 -5.72272658e-01  5... -6.13491774e-01 -5.86696386e-01  7.47473359e-01\n",
      "   -5.75143754e-01 -1.92501158e-01  1.97734821e+00 -1.21244943e+00]]])\n",
      "hidden_size = 12\n",
      "init_hidden = True\n",
      "num_layers = 1\n",
      "output_size = 1\n",
      "seq_length = 13\n",
      "seq_model  = 'lstm'\n",
      "x          = array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0...0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "      dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:201: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "self = <models.LanguageModel object at 0x1694a6570>, embedding_size = 34\n",
      "output_size = 1, hidden_size = 12, num_layers = 1, seq_model = 'lstm'\n",
      "device = cpu(), dtype = 'float32'\n",
      "\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92m__init__\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, embedding_size, output_size, hidden_size, num_layers=\u001b[94m1\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                 seq_model=\u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, device=\u001b[94mNone\u001b[39;49;00m, dtype=\u001b[33m\"\u001b[39;49;00m\u001b[33mfloat32\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"\u001b[39;49;00m\n",
      "    \u001b[33m    Consists of an embedding layer, a sequence model (either RNN or LSTM), and a\u001b[39;49;00m\n",
      "    \u001b[33m    linear layer.\u001b[39;49;00m\n",
      "    \u001b[33m    Parameters:\u001b[39;49;00m\n",
      "    \u001b[33m    output_size: Size of dictionary\u001b[39;49;00m\n",
      "    \u001b[33m    embedding_size: Size of embeddings\u001b[39;49;00m\n",
      "    \u001b[33m    hidden_size: The number of features in the hidden state of LSTM or RNN\u001b[39;49;00m\n",
      "    \u001b[33m    seq_model: 'rnn' or 'lstm', whether to use RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    num_layers: Number of layers in RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    \"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[96msuper\u001b[39;49;00m(LanguageModel, \u001b[96mself\u001b[39;49;00m).\u001b[92m__init__\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m### BEGIN YOUR SOLUTION\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94mraise\u001b[39;49;00m \u001b[96mNotImplementedError\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       NotImplementedError\u001b[0m\n",
      "\n",
      "__class__  = <class 'models.LanguageModel'>\n",
      "device     = cpu()\n",
      "dtype      = 'float32'\n",
      "embedding_size = 34\n",
      "hidden_size = 12\n",
      "num_layers = 1\n",
      "output_size = 1\n",
      "self       = <models.LanguageModel object at 0x1694a6570>\n",
      "seq_model  = 'lstm'\n",
      "\n",
      "\u001b[1m\u001b[31mapps/models.py\u001b[0m:38: NotImplementedError\n",
      "\u001b[31m\u001b[1m_______ test_language_model_implementation[cpu-lstm-1-True-12-34-15-2-1] _______\u001b[0m\n",
      "\n",
      "seq_length = 1, num_layers = 2, batch_size = 15, embedding_size = 34\n",
      "hidden_size = 12, init_hidden = True, output_size = 1, seq_model = 'lstm'\n",
      "device = cpu()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\u001b[90m\u001b[39;49;00m\n",
      "                            init_hidden, output_size, seq_model, device):\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      ">       model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "batch_size = 15\n",
      "c0         = needle.Tensor([[[-0.21137092  1.4028239   1.1214492  -0.65373456  1.2734163\n",
      "   -2.0262764  -1.290521    0.4508663  -1....82255  0.15939595 -1.2706766\n",
      "    0.52588475 -0.38213864 -1.2392925   0.3677479  -1.00748\n",
      "    0.16847302 -0.58411384]]])\n",
      "device     = cpu()\n",
      "embedding_size = 34\n",
      "h0         = needle.Tensor([[[-0.6747427  -0.612678    0.6801615   0.05178329 -0.73506445\n",
      "   -1.1032908  -0.16791952  1.5549576   0...65 -0.30617446  0.2336247\n",
      "   -0.899277    0.01165633  1.0970708   0.68003476  0.20047516\n",
      "    0.78740364 -0.70622534]]])\n",
      "hidden_size = 12\n",
      "init_hidden = True\n",
      "num_layers = 2\n",
      "output_size = 1\n",
      "seq_length = 1\n",
      "seq_model  = 'lstm'\n",
      "x          = array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "      dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:201: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "self = <models.LanguageModel object at 0x1694a4890>, embedding_size = 34\n",
      "output_size = 1, hidden_size = 12, num_layers = 2, seq_model = 'lstm'\n",
      "device = cpu(), dtype = 'float32'\n",
      "\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92m__init__\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, embedding_size, output_size, hidden_size, num_layers=\u001b[94m1\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                 seq_model=\u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, device=\u001b[94mNone\u001b[39;49;00m, dtype=\u001b[33m\"\u001b[39;49;00m\u001b[33mfloat32\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"\u001b[39;49;00m\n",
      "    \u001b[33m    Consists of an embedding layer, a sequence model (either RNN or LSTM), and a\u001b[39;49;00m\n",
      "    \u001b[33m    linear layer.\u001b[39;49;00m\n",
      "    \u001b[33m    Parameters:\u001b[39;49;00m\n",
      "    \u001b[33m    output_size: Size of dictionary\u001b[39;49;00m\n",
      "    \u001b[33m    embedding_size: Size of embeddings\u001b[39;49;00m\n",
      "    \u001b[33m    hidden_size: The number of features in the hidden state of LSTM or RNN\u001b[39;49;00m\n",
      "    \u001b[33m    seq_model: 'rnn' or 'lstm', whether to use RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    num_layers: Number of layers in RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    \"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[96msuper\u001b[39;49;00m(LanguageModel, \u001b[96mself\u001b[39;49;00m).\u001b[92m__init__\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m### BEGIN YOUR SOLUTION\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94mraise\u001b[39;49;00m \u001b[96mNotImplementedError\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       NotImplementedError\u001b[0m\n",
      "\n",
      "__class__  = <class 'models.LanguageModel'>\n",
      "device     = cpu()\n",
      "dtype      = 'float32'\n",
      "embedding_size = 34\n",
      "hidden_size = 12\n",
      "num_layers = 2\n",
      "output_size = 1\n",
      "self       = <models.LanguageModel object at 0x1694a4890>\n",
      "seq_model  = 'lstm'\n",
      "\n",
      "\u001b[1m\u001b[31mapps/models.py\u001b[0m:38: NotImplementedError\n",
      "\u001b[31m\u001b[1m______ test_language_model_implementation[cpu-lstm-1-True-12-34-15-2-13] _______\u001b[0m\n",
      "\n",
      "seq_length = 13, num_layers = 2, batch_size = 15, embedding_size = 34\n",
      "hidden_size = 12, init_hidden = True, output_size = 1, seq_model = 'lstm'\n",
      "device = cpu()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\u001b[90m\u001b[39;49;00m\n",
      "                            init_hidden, output_size, seq_model, device):\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      ">       model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "batch_size = 15\n",
      "c0         = needle.Tensor([[[-1.37535322e+00  8.09105158e-01 -1.70849347e+00 -1.39102733e+00\n",
      "    8.44143271e-01 -3.19747597e-01  1... -6.33585870e-01  1.28395963e+00  1.55108273e-01\n",
      "   -7.83173621e-01  9.47560906e-01  1.51320410e+00 -3.34997326e-01]]])\n",
      "device     = cpu()\n",
      "embedding_size = 34\n",
      "h0         = needle.Tensor([[[-0.40750635  0.462513   -1.0720109  -1.0617002  -0.47395307\n",
      "   -1.0247663  -1.2626292   1.9067403  -0...62  0.38011503 -0.9601334\n",
      "    0.8344752  -0.8578844  -2.306139   -0.1123995   0.16374893\n",
      "   -1.8868963   0.92222095]]])\n",
      "hidden_size = 12\n",
      "init_hidden = True\n",
      "num_layers = 2\n",
      "output_size = 1\n",
      "seq_length = 13\n",
      "seq_model  = 'lstm'\n",
      "x          = array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0...0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "      dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:201: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "self = <models.LanguageModel object at 0x1694a6b40>, embedding_size = 34\n",
      "output_size = 1, hidden_size = 12, num_layers = 2, seq_model = 'lstm'\n",
      "device = cpu(), dtype = 'float32'\n",
      "\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92m__init__\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, embedding_size, output_size, hidden_size, num_layers=\u001b[94m1\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                 seq_model=\u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, device=\u001b[94mNone\u001b[39;49;00m, dtype=\u001b[33m\"\u001b[39;49;00m\u001b[33mfloat32\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"\u001b[39;49;00m\n",
      "    \u001b[33m    Consists of an embedding layer, a sequence model (either RNN or LSTM), and a\u001b[39;49;00m\n",
      "    \u001b[33m    linear layer.\u001b[39;49;00m\n",
      "    \u001b[33m    Parameters:\u001b[39;49;00m\n",
      "    \u001b[33m    output_size: Size of dictionary\u001b[39;49;00m\n",
      "    \u001b[33m    embedding_size: Size of embeddings\u001b[39;49;00m\n",
      "    \u001b[33m    hidden_size: The number of features in the hidden state of LSTM or RNN\u001b[39;49;00m\n",
      "    \u001b[33m    seq_model: 'rnn' or 'lstm', whether to use RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    num_layers: Number of layers in RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    \"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[96msuper\u001b[39;49;00m(LanguageModel, \u001b[96mself\u001b[39;49;00m).\u001b[92m__init__\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m### BEGIN YOUR SOLUTION\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94mraise\u001b[39;49;00m \u001b[96mNotImplementedError\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       NotImplementedError\u001b[0m\n",
      "\n",
      "__class__  = <class 'models.LanguageModel'>\n",
      "device     = cpu()\n",
      "dtype      = 'float32'\n",
      "embedding_size = 34\n",
      "hidden_size = 12\n",
      "num_layers = 2\n",
      "output_size = 1\n",
      "self       = <models.LanguageModel object at 0x1694a6b40>\n",
      "seq_model  = 'lstm'\n",
      "\n",
      "\u001b[1m\u001b[31mapps/models.py\u001b[0m:38: NotImplementedError\n",
      "\u001b[31m\u001b[1m________ test_language_model_implementation[cpu-lstm-1-False-1-1-1-1-1] ________\u001b[0m\n",
      "\n",
      "seq_length = 1, num_layers = 1, batch_size = 1, embedding_size = 1\n",
      "hidden_size = 1, init_hidden = False, output_size = 1, seq_model = 'lstm'\n",
      "device = cpu()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\u001b[90m\u001b[39;49;00m\n",
      "                            init_hidden, output_size, seq_model, device):\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      ">       model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "batch_size = 1\n",
      "c0         = needle.Tensor([[[0.6045185]]])\n",
      "device     = cpu()\n",
      "embedding_size = 1\n",
      "h0         = needle.Tensor([[[-0.2190452]]])\n",
      "hidden_size = 1\n",
      "init_hidden = False\n",
      "num_layers = 1\n",
      "output_size = 1\n",
      "seq_length = 1\n",
      "seq_model  = 'lstm'\n",
      "x          = array([[0.]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:201: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "self = <models.LanguageModel object at 0x1694a99a0>, embedding_size = 1\n",
      "output_size = 1, hidden_size = 1, num_layers = 1, seq_model = 'lstm'\n",
      "device = cpu(), dtype = 'float32'\n",
      "\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92m__init__\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, embedding_size, output_size, hidden_size, num_layers=\u001b[94m1\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                 seq_model=\u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, device=\u001b[94mNone\u001b[39;49;00m, dtype=\u001b[33m\"\u001b[39;49;00m\u001b[33mfloat32\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"\u001b[39;49;00m\n",
      "    \u001b[33m    Consists of an embedding layer, a sequence model (either RNN or LSTM), and a\u001b[39;49;00m\n",
      "    \u001b[33m    linear layer.\u001b[39;49;00m\n",
      "    \u001b[33m    Parameters:\u001b[39;49;00m\n",
      "    \u001b[33m    output_size: Size of dictionary\u001b[39;49;00m\n",
      "    \u001b[33m    embedding_size: Size of embeddings\u001b[39;49;00m\n",
      "    \u001b[33m    hidden_size: The number of features in the hidden state of LSTM or RNN\u001b[39;49;00m\n",
      "    \u001b[33m    seq_model: 'rnn' or 'lstm', whether to use RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    num_layers: Number of layers in RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    \"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[96msuper\u001b[39;49;00m(LanguageModel, \u001b[96mself\u001b[39;49;00m).\u001b[92m__init__\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m### BEGIN YOUR SOLUTION\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94mraise\u001b[39;49;00m \u001b[96mNotImplementedError\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       NotImplementedError\u001b[0m\n",
      "\n",
      "__class__  = <class 'models.LanguageModel'>\n",
      "device     = cpu()\n",
      "dtype      = 'float32'\n",
      "embedding_size = 1\n",
      "hidden_size = 1\n",
      "num_layers = 1\n",
      "output_size = 1\n",
      "self       = <models.LanguageModel object at 0x1694a99a0>\n",
      "seq_model  = 'lstm'\n",
      "\n",
      "\u001b[1m\u001b[31mapps/models.py\u001b[0m:38: NotImplementedError\n",
      "\u001b[31m\u001b[1m_______ test_language_model_implementation[cpu-lstm-1-False-1-1-1-1-13] ________\u001b[0m\n",
      "\n",
      "seq_length = 13, num_layers = 1, batch_size = 1, embedding_size = 1\n",
      "hidden_size = 1, init_hidden = False, output_size = 1, seq_model = 'lstm'\n",
      "device = cpu()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\u001b[90m\u001b[39;49;00m\n",
      "                            init_hidden, output_size, seq_model, device):\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      ">       model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "batch_size = 1\n",
      "c0         = needle.Tensor([[[-1.4327993]]])\n",
      "device     = cpu()\n",
      "embedding_size = 1\n",
      "h0         = needle.Tensor([[[0.83866465]]])\n",
      "hidden_size = 1\n",
      "init_hidden = False\n",
      "num_layers = 1\n",
      "output_size = 1\n",
      "seq_length = 13\n",
      "seq_model  = 'lstm'\n",
      "x          = array([[0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:201: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "self = <models.LanguageModel object at 0x1694a8f50>, embedding_size = 1\n",
      "output_size = 1, hidden_size = 1, num_layers = 1, seq_model = 'lstm'\n",
      "device = cpu(), dtype = 'float32'\n",
      "\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92m__init__\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, embedding_size, output_size, hidden_size, num_layers=\u001b[94m1\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                 seq_model=\u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, device=\u001b[94mNone\u001b[39;49;00m, dtype=\u001b[33m\"\u001b[39;49;00m\u001b[33mfloat32\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"\u001b[39;49;00m\n",
      "    \u001b[33m    Consists of an embedding layer, a sequence model (either RNN or LSTM), and a\u001b[39;49;00m\n",
      "    \u001b[33m    linear layer.\u001b[39;49;00m\n",
      "    \u001b[33m    Parameters:\u001b[39;49;00m\n",
      "    \u001b[33m    output_size: Size of dictionary\u001b[39;49;00m\n",
      "    \u001b[33m    embedding_size: Size of embeddings\u001b[39;49;00m\n",
      "    \u001b[33m    hidden_size: The number of features in the hidden state of LSTM or RNN\u001b[39;49;00m\n",
      "    \u001b[33m    seq_model: 'rnn' or 'lstm', whether to use RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    num_layers: Number of layers in RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    \"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[96msuper\u001b[39;49;00m(LanguageModel, \u001b[96mself\u001b[39;49;00m).\u001b[92m__init__\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m### BEGIN YOUR SOLUTION\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94mraise\u001b[39;49;00m \u001b[96mNotImplementedError\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       NotImplementedError\u001b[0m\n",
      "\n",
      "__class__  = <class 'models.LanguageModel'>\n",
      "device     = cpu()\n",
      "dtype      = 'float32'\n",
      "embedding_size = 1\n",
      "hidden_size = 1\n",
      "num_layers = 1\n",
      "output_size = 1\n",
      "self       = <models.LanguageModel object at 0x1694a8f50>\n",
      "seq_model  = 'lstm'\n",
      "\n",
      "\u001b[1m\u001b[31mapps/models.py\u001b[0m:38: NotImplementedError\n",
      "\u001b[31m\u001b[1m________ test_language_model_implementation[cpu-lstm-1-False-1-1-1-2-1] ________\u001b[0m\n",
      "\n",
      "seq_length = 1, num_layers = 2, batch_size = 1, embedding_size = 1\n",
      "hidden_size = 1, init_hidden = False, output_size = 1, seq_model = 'lstm'\n",
      "device = cpu()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\u001b[90m\u001b[39;49;00m\n",
      "                            init_hidden, output_size, seq_model, device):\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      ">       model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "batch_size = 1\n",
      "c0         = needle.Tensor([[[-0.68218714]]\n",
      "\n",
      " [[ 1.7054567 ]]])\n",
      "device     = cpu()\n",
      "embedding_size = 1\n",
      "h0         = needle.Tensor([[[-1.2195272]]\n",
      "\n",
      " [[-1.0664761]]])\n",
      "hidden_size = 1\n",
      "init_hidden = False\n",
      "num_layers = 2\n",
      "output_size = 1\n",
      "seq_length = 1\n",
      "seq_model  = 'lstm'\n",
      "x          = array([[0.]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:201: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "self = <models.LanguageModel object at 0x1694ab680>, embedding_size = 1\n",
      "output_size = 1, hidden_size = 1, num_layers = 2, seq_model = 'lstm'\n",
      "device = cpu(), dtype = 'float32'\n",
      "\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92m__init__\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, embedding_size, output_size, hidden_size, num_layers=\u001b[94m1\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                 seq_model=\u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, device=\u001b[94mNone\u001b[39;49;00m, dtype=\u001b[33m\"\u001b[39;49;00m\u001b[33mfloat32\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"\u001b[39;49;00m\n",
      "    \u001b[33m    Consists of an embedding layer, a sequence model (either RNN or LSTM), and a\u001b[39;49;00m\n",
      "    \u001b[33m    linear layer.\u001b[39;49;00m\n",
      "    \u001b[33m    Parameters:\u001b[39;49;00m\n",
      "    \u001b[33m    output_size: Size of dictionary\u001b[39;49;00m\n",
      "    \u001b[33m    embedding_size: Size of embeddings\u001b[39;49;00m\n",
      "    \u001b[33m    hidden_size: The number of features in the hidden state of LSTM or RNN\u001b[39;49;00m\n",
      "    \u001b[33m    seq_model: 'rnn' or 'lstm', whether to use RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    num_layers: Number of layers in RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    \"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[96msuper\u001b[39;49;00m(LanguageModel, \u001b[96mself\u001b[39;49;00m).\u001b[92m__init__\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m### BEGIN YOUR SOLUTION\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94mraise\u001b[39;49;00m \u001b[96mNotImplementedError\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       NotImplementedError\u001b[0m\n",
      "\n",
      "__class__  = <class 'models.LanguageModel'>\n",
      "device     = cpu()\n",
      "dtype      = 'float32'\n",
      "embedding_size = 1\n",
      "hidden_size = 1\n",
      "num_layers = 2\n",
      "output_size = 1\n",
      "self       = <models.LanguageModel object at 0x1694ab680>\n",
      "seq_model  = 'lstm'\n",
      "\n",
      "\u001b[1m\u001b[31mapps/models.py\u001b[0m:38: NotImplementedError\n",
      "\u001b[31m\u001b[1m_______ test_language_model_implementation[cpu-lstm-1-False-1-1-1-2-13] ________\u001b[0m\n",
      "\n",
      "seq_length = 13, num_layers = 2, batch_size = 1, embedding_size = 1\n",
      "hidden_size = 1, init_hidden = False, output_size = 1, seq_model = 'lstm'\n",
      "device = cpu()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\u001b[90m\u001b[39;49;00m\n",
      "                            init_hidden, output_size, seq_model, device):\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      ">       model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "batch_size = 1\n",
      "c0         = needle.Tensor([[[2.0871277]]\n",
      "\n",
      " [[1.0460345]]])\n",
      "device     = cpu()\n",
      "embedding_size = 1\n",
      "h0         = needle.Tensor([[[0.83954024]]\n",
      "\n",
      " [[0.87630004]]])\n",
      "hidden_size = 1\n",
      "init_hidden = False\n",
      "num_layers = 2\n",
      "output_size = 1\n",
      "seq_length = 13\n",
      "seq_model  = 'lstm'\n",
      "x          = array([[0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:201: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "self = <models.LanguageModel object at 0x1694ab200>, embedding_size = 1\n",
      "output_size = 1, hidden_size = 1, num_layers = 2, seq_model = 'lstm'\n",
      "device = cpu(), dtype = 'float32'\n",
      "\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92m__init__\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, embedding_size, output_size, hidden_size, num_layers=\u001b[94m1\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                 seq_model=\u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, device=\u001b[94mNone\u001b[39;49;00m, dtype=\u001b[33m\"\u001b[39;49;00m\u001b[33mfloat32\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"\u001b[39;49;00m\n",
      "    \u001b[33m    Consists of an embedding layer, a sequence model (either RNN or LSTM), and a\u001b[39;49;00m\n",
      "    \u001b[33m    linear layer.\u001b[39;49;00m\n",
      "    \u001b[33m    Parameters:\u001b[39;49;00m\n",
      "    \u001b[33m    output_size: Size of dictionary\u001b[39;49;00m\n",
      "    \u001b[33m    embedding_size: Size of embeddings\u001b[39;49;00m\n",
      "    \u001b[33m    hidden_size: The number of features in the hidden state of LSTM or RNN\u001b[39;49;00m\n",
      "    \u001b[33m    seq_model: 'rnn' or 'lstm', whether to use RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    num_layers: Number of layers in RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    \"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[96msuper\u001b[39;49;00m(LanguageModel, \u001b[96mself\u001b[39;49;00m).\u001b[92m__init__\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m### BEGIN YOUR SOLUTION\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94mraise\u001b[39;49;00m \u001b[96mNotImplementedError\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       NotImplementedError\u001b[0m\n",
      "\n",
      "__class__  = <class 'models.LanguageModel'>\n",
      "device     = cpu()\n",
      "dtype      = 'float32'\n",
      "embedding_size = 1\n",
      "hidden_size = 1\n",
      "num_layers = 2\n",
      "output_size = 1\n",
      "self       = <models.LanguageModel object at 0x1694ab200>\n",
      "seq_model  = 'lstm'\n",
      "\n",
      "\u001b[1m\u001b[31mapps/models.py\u001b[0m:38: NotImplementedError\n",
      "\u001b[31m\u001b[1m_______ test_language_model_implementation[cpu-lstm-1-False-1-1-15-1-1] ________\u001b[0m\n",
      "\n",
      "seq_length = 1, num_layers = 1, batch_size = 15, embedding_size = 1\n",
      "hidden_size = 1, init_hidden = False, output_size = 1, seq_model = 'lstm'\n",
      "device = cpu()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\u001b[90m\u001b[39;49;00m\n",
      "                            init_hidden, output_size, seq_model, device):\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      ">       model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "batch_size = 15\n",
      "c0         = needle.Tensor([[[-0.2935338 ]\n",
      "  [-0.43532792]\n",
      "  [-1.0421945 ]\n",
      "  [ 0.7407265 ]\n",
      "  [-0.39036146]\n",
      "  [ 1.1360364 ]\n",
      "  [-0.24...774]\n",
      "  [ 1.176359  ]\n",
      "  [-0.98463833]\n",
      "  [ 0.45512527]\n",
      "  [ 0.32096165]\n",
      "  [ 0.19810812]\n",
      "  [ 2.0758927 ]\n",
      "  [ 0.21168837]]])\n",
      "device     = cpu()\n",
      "embedding_size = 1\n",
      "h0         = needle.Tensor([[[-0.27128288]\n",
      "  [-0.7265106 ]\n",
      "  [ 0.6789018 ]\n",
      "  [-1.4311665 ]\n",
      "  [ 0.91850996]\n",
      "  [ 0.43618277]\n",
      "  [ 0.52...94 ]\n",
      "  [ 1.0057656 ]\n",
      "  [-0.970623  ]\n",
      "  [ 0.1938316 ]\n",
      "  [ 0.05702265]\n",
      "  [ 1.106193  ]\n",
      "  [-0.10693821]\n",
      "  [ 0.6413473 ]]])\n",
      "hidden_size = 1\n",
      "init_hidden = False\n",
      "num_layers = 1\n",
      "output_size = 1\n",
      "seq_length = 1\n",
      "seq_model  = 'lstm'\n",
      "x          = array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "      dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:201: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "self = <models.LanguageModel object at 0x1577982f0>, embedding_size = 1\n",
      "output_size = 1, hidden_size = 1, num_layers = 1, seq_model = 'lstm'\n",
      "device = cpu(), dtype = 'float32'\n",
      "\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92m__init__\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, embedding_size, output_size, hidden_size, num_layers=\u001b[94m1\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                 seq_model=\u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, device=\u001b[94mNone\u001b[39;49;00m, dtype=\u001b[33m\"\u001b[39;49;00m\u001b[33mfloat32\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"\u001b[39;49;00m\n",
      "    \u001b[33m    Consists of an embedding layer, a sequence model (either RNN or LSTM), and a\u001b[39;49;00m\n",
      "    \u001b[33m    linear layer.\u001b[39;49;00m\n",
      "    \u001b[33m    Parameters:\u001b[39;49;00m\n",
      "    \u001b[33m    output_size: Size of dictionary\u001b[39;49;00m\n",
      "    \u001b[33m    embedding_size: Size of embeddings\u001b[39;49;00m\n",
      "    \u001b[33m    hidden_size: The number of features in the hidden state of LSTM or RNN\u001b[39;49;00m\n",
      "    \u001b[33m    seq_model: 'rnn' or 'lstm', whether to use RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    num_layers: Number of layers in RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    \"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[96msuper\u001b[39;49;00m(LanguageModel, \u001b[96mself\u001b[39;49;00m).\u001b[92m__init__\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m### BEGIN YOUR SOLUTION\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94mraise\u001b[39;49;00m \u001b[96mNotImplementedError\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       NotImplementedError\u001b[0m\n",
      "\n",
      "__class__  = <class 'models.LanguageModel'>\n",
      "device     = cpu()\n",
      "dtype      = 'float32'\n",
      "embedding_size = 1\n",
      "hidden_size = 1\n",
      "num_layers = 1\n",
      "output_size = 1\n",
      "self       = <models.LanguageModel object at 0x1577982f0>\n",
      "seq_model  = 'lstm'\n",
      "\n",
      "\u001b[1m\u001b[31mapps/models.py\u001b[0m:38: NotImplementedError\n",
      "\u001b[31m\u001b[1m_______ test_language_model_implementation[cpu-lstm-1-False-1-1-15-1-13] _______\u001b[0m\n",
      "\n",
      "seq_length = 13, num_layers = 1, batch_size = 15, embedding_size = 1\n",
      "hidden_size = 1, init_hidden = False, output_size = 1, seq_model = 'lstm'\n",
      "device = cpu()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\u001b[90m\u001b[39;49;00m\n",
      "                            init_hidden, output_size, seq_model, device):\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      ">       model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "batch_size = 15\n",
      "c0         = needle.Tensor([[[ 1.19113   ]\n",
      "  [ 0.45101815]\n",
      "  [ 0.3972802 ]\n",
      "  [ 0.24539034]\n",
      "  [ 0.51266944]\n",
      "  [-1.0885059 ]\n",
      "  [-0.59...785]\n",
      "  [ 0.7043383 ]\n",
      "  [-0.9119342 ]\n",
      "  [-0.48810652]\n",
      "  [ 1.1227341 ]\n",
      "  [-0.22493987]\n",
      "  [ 0.36897996]\n",
      "  [ 1.0523448 ]]])\n",
      "device     = cpu()\n",
      "embedding_size = 1\n",
      "h0         = needle.Tensor([[[ 1.2070574 ]\n",
      "  [-1.056365  ]\n",
      "  [-0.08675723]\n",
      "  [-2.4521673 ]\n",
      "  [-0.12165473]\n",
      "  [-0.96788484]\n",
      "  [-1.32...232]\n",
      "  [-0.5032976 ]\n",
      "  [-0.05235546]\n",
      "  [ 0.15410507]\n",
      "  [ 0.5270355 ]\n",
      "  [-1.0466981 ]\n",
      "  [ 0.24339683]\n",
      "  [-0.5362572 ]]])\n",
      "hidden_size = 1\n",
      "init_hidden = False\n",
      "num_layers = 1\n",
      "output_size = 1\n",
      "seq_length = 13\n",
      "seq_model  = 'lstm'\n",
      "x          = array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0...0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "      dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:201: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "self = <models.LanguageModel object at 0x1694a8380>, embedding_size = 1\n",
      "output_size = 1, hidden_size = 1, num_layers = 1, seq_model = 'lstm'\n",
      "device = cpu(), dtype = 'float32'\n",
      "\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92m__init__\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, embedding_size, output_size, hidden_size, num_layers=\u001b[94m1\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                 seq_model=\u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, device=\u001b[94mNone\u001b[39;49;00m, dtype=\u001b[33m\"\u001b[39;49;00m\u001b[33mfloat32\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"\u001b[39;49;00m\n",
      "    \u001b[33m    Consists of an embedding layer, a sequence model (either RNN or LSTM), and a\u001b[39;49;00m\n",
      "    \u001b[33m    linear layer.\u001b[39;49;00m\n",
      "    \u001b[33m    Parameters:\u001b[39;49;00m\n",
      "    \u001b[33m    output_size: Size of dictionary\u001b[39;49;00m\n",
      "    \u001b[33m    embedding_size: Size of embeddings\u001b[39;49;00m\n",
      "    \u001b[33m    hidden_size: The number of features in the hidden state of LSTM or RNN\u001b[39;49;00m\n",
      "    \u001b[33m    seq_model: 'rnn' or 'lstm', whether to use RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    num_layers: Number of layers in RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    \"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[96msuper\u001b[39;49;00m(LanguageModel, \u001b[96mself\u001b[39;49;00m).\u001b[92m__init__\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m### BEGIN YOUR SOLUTION\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94mraise\u001b[39;49;00m \u001b[96mNotImplementedError\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       NotImplementedError\u001b[0m\n",
      "\n",
      "__class__  = <class 'models.LanguageModel'>\n",
      "device     = cpu()\n",
      "dtype      = 'float32'\n",
      "embedding_size = 1\n",
      "hidden_size = 1\n",
      "num_layers = 1\n",
      "output_size = 1\n",
      "self       = <models.LanguageModel object at 0x1694a8380>\n",
      "seq_model  = 'lstm'\n",
      "\n",
      "\u001b[1m\u001b[31mapps/models.py\u001b[0m:38: NotImplementedError\n",
      "\u001b[31m\u001b[1m_______ test_language_model_implementation[cpu-lstm-1-False-1-1-15-2-1] ________\u001b[0m\n",
      "\n",
      "seq_length = 1, num_layers = 2, batch_size = 15, embedding_size = 1\n",
      "hidden_size = 1, init_hidden = False, output_size = 1, seq_model = 'lstm'\n",
      "device = cpu()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\u001b[90m\u001b[39;49;00m\n",
      "                            init_hidden, output_size, seq_model, device):\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      ">       model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "batch_size = 15\n",
      "c0         = needle.Tensor([[[ 1.4695245 ]\n",
      "  [-1.1740825 ]\n",
      "  [-0.95199686]\n",
      "  [ 0.89645827]\n",
      "  [-1.1942843 ]\n",
      "  [-1.3832672 ]\n",
      "  [ 0.23...02 ]\n",
      "  [-0.34479162]\n",
      "  [ 0.5374779 ]\n",
      "  [-1.2608831 ]\n",
      "  [ 1.8602155 ]\n",
      "  [-0.21827547]\n",
      "  [ 0.893405  ]\n",
      "  [-0.56007403]]])\n",
      "device     = cpu()\n",
      "embedding_size = 1\n",
      "h0         = needle.Tensor([[[ 0.16721717]\n",
      "  [ 0.52209675]\n",
      "  [ 1.9601623 ]\n",
      "  [-0.35460597]\n",
      "  [-0.73914343]\n",
      "  [ 0.23425975]\n",
      "  [-0.09...394]\n",
      "  [ 1.7710178 ]\n",
      "  [-0.11955672]\n",
      "  [ 0.19572611]\n",
      "  [ 1.2127963 ]\n",
      "  [ 0.31791553]\n",
      "  [-1.0087414 ]\n",
      "  [-2.2934506 ]]])\n",
      "hidden_size = 1\n",
      "init_hidden = False\n",
      "num_layers = 2\n",
      "output_size = 1\n",
      "seq_length = 1\n",
      "seq_model  = 'lstm'\n",
      "x          = array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "      dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:201: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "self = <models.LanguageModel object at 0x1694aa360>, embedding_size = 1\n",
      "output_size = 1, hidden_size = 1, num_layers = 2, seq_model = 'lstm'\n",
      "device = cpu(), dtype = 'float32'\n",
      "\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92m__init__\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, embedding_size, output_size, hidden_size, num_layers=\u001b[94m1\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                 seq_model=\u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, device=\u001b[94mNone\u001b[39;49;00m, dtype=\u001b[33m\"\u001b[39;49;00m\u001b[33mfloat32\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"\u001b[39;49;00m\n",
      "    \u001b[33m    Consists of an embedding layer, a sequence model (either RNN or LSTM), and a\u001b[39;49;00m\n",
      "    \u001b[33m    linear layer.\u001b[39;49;00m\n",
      "    \u001b[33m    Parameters:\u001b[39;49;00m\n",
      "    \u001b[33m    output_size: Size of dictionary\u001b[39;49;00m\n",
      "    \u001b[33m    embedding_size: Size of embeddings\u001b[39;49;00m\n",
      "    \u001b[33m    hidden_size: The number of features in the hidden state of LSTM or RNN\u001b[39;49;00m\n",
      "    \u001b[33m    seq_model: 'rnn' or 'lstm', whether to use RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    num_layers: Number of layers in RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    \"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[96msuper\u001b[39;49;00m(LanguageModel, \u001b[96mself\u001b[39;49;00m).\u001b[92m__init__\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m### BEGIN YOUR SOLUTION\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94mraise\u001b[39;49;00m \u001b[96mNotImplementedError\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       NotImplementedError\u001b[0m\n",
      "\n",
      "__class__  = <class 'models.LanguageModel'>\n",
      "device     = cpu()\n",
      "dtype      = 'float32'\n",
      "embedding_size = 1\n",
      "hidden_size = 1\n",
      "num_layers = 2\n",
      "output_size = 1\n",
      "self       = <models.LanguageModel object at 0x1694aa360>\n",
      "seq_model  = 'lstm'\n",
      "\n",
      "\u001b[1m\u001b[31mapps/models.py\u001b[0m:38: NotImplementedError\n",
      "\u001b[31m\u001b[1m_______ test_language_model_implementation[cpu-lstm-1-False-1-1-15-2-13] _______\u001b[0m\n",
      "\n",
      "seq_length = 13, num_layers = 2, batch_size = 15, embedding_size = 1\n",
      "hidden_size = 1, init_hidden = False, output_size = 1, seq_model = 'lstm'\n",
      "device = cpu()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\u001b[90m\u001b[39;49;00m\n",
      "                            init_hidden, output_size, seq_model, device):\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      ">       model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "batch_size = 15\n",
      "c0         = needle.Tensor([[[-0.6500041 ]\n",
      "  [ 0.5764097 ]\n",
      "  [-1.0865347 ]\n",
      "  [ 0.50892425]\n",
      "  [-1.0292517 ]\n",
      "  [-2.1909025 ]\n",
      "  [-0.69...84 ]\n",
      "  [ 0.66678095]\n",
      "  [ 0.329735  ]\n",
      "  [ 1.0612559 ]\n",
      "  [-1.141556  ]\n",
      "  [ 0.7133607 ]\n",
      "  [ 0.45515114]\n",
      "  [ 0.09093864]]])\n",
      "device     = cpu()\n",
      "embedding_size = 1\n",
      "h0         = needle.Tensor([[[-0.18687499]\n",
      "  [-0.23637824]\n",
      "  [ 1.0663592 ]\n",
      "  [-0.6085279 ]\n",
      "  [ 0.74193335]\n",
      "  [ 1.1293823 ]\n",
      "  [ 0.02...68 ]\n",
      "  [-1.6034945 ]\n",
      "  [ 0.34659368]\n",
      "  [-1.1934887 ]\n",
      "  [ 0.9780672 ]\n",
      "  [-1.0097225 ]\n",
      "  [-0.35687658]\n",
      "  [-0.63657707]]])\n",
      "hidden_size = 1\n",
      "init_hidden = False\n",
      "num_layers = 2\n",
      "output_size = 1\n",
      "seq_length = 13\n",
      "seq_model  = 'lstm'\n",
      "x          = array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0...0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "      dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:201: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "self = <models.LanguageModel object at 0x1694aa1b0>, embedding_size = 1\n",
      "output_size = 1, hidden_size = 1, num_layers = 2, seq_model = 'lstm'\n",
      "device = cpu(), dtype = 'float32'\n",
      "\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92m__init__\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, embedding_size, output_size, hidden_size, num_layers=\u001b[94m1\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                 seq_model=\u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, device=\u001b[94mNone\u001b[39;49;00m, dtype=\u001b[33m\"\u001b[39;49;00m\u001b[33mfloat32\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"\u001b[39;49;00m\n",
      "    \u001b[33m    Consists of an embedding layer, a sequence model (either RNN or LSTM), and a\u001b[39;49;00m\n",
      "    \u001b[33m    linear layer.\u001b[39;49;00m\n",
      "    \u001b[33m    Parameters:\u001b[39;49;00m\n",
      "    \u001b[33m    output_size: Size of dictionary\u001b[39;49;00m\n",
      "    \u001b[33m    embedding_size: Size of embeddings\u001b[39;49;00m\n",
      "    \u001b[33m    hidden_size: The number of features in the hidden state of LSTM or RNN\u001b[39;49;00m\n",
      "    \u001b[33m    seq_model: 'rnn' or 'lstm', whether to use RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    num_layers: Number of layers in RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    \"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[96msuper\u001b[39;49;00m(LanguageModel, \u001b[96mself\u001b[39;49;00m).\u001b[92m__init__\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m### BEGIN YOUR SOLUTION\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94mraise\u001b[39;49;00m \u001b[96mNotImplementedError\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       NotImplementedError\u001b[0m\n",
      "\n",
      "__class__  = <class 'models.LanguageModel'>\n",
      "device     = cpu()\n",
      "dtype      = 'float32'\n",
      "embedding_size = 1\n",
      "hidden_size = 1\n",
      "num_layers = 2\n",
      "output_size = 1\n",
      "self       = <models.LanguageModel object at 0x1694aa1b0>\n",
      "seq_model  = 'lstm'\n",
      "\n",
      "\u001b[1m\u001b[31mapps/models.py\u001b[0m:38: NotImplementedError\n",
      "\u001b[31m\u001b[1m_______ test_language_model_implementation[cpu-lstm-1-False-1-34-1-1-1] ________\u001b[0m\n",
      "\n",
      "seq_length = 1, num_layers = 1, batch_size = 1, embedding_size = 34\n",
      "hidden_size = 1, init_hidden = False, output_size = 1, seq_model = 'lstm'\n",
      "device = cpu()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\u001b[90m\u001b[39;49;00m\n",
      "                            init_hidden, output_size, seq_model, device):\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      ">       model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "batch_size = 1\n",
      "c0         = needle.Tensor([[[1.313429]]])\n",
      "device     = cpu()\n",
      "embedding_size = 34\n",
      "h0         = needle.Tensor([[[1.520656]]])\n",
      "hidden_size = 1\n",
      "init_hidden = False\n",
      "num_layers = 1\n",
      "output_size = 1\n",
      "seq_length = 1\n",
      "seq_model  = 'lstm'\n",
      "x          = array([[0.]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:201: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "self = <models.LanguageModel object at 0x1694a6d50>, embedding_size = 34\n",
      "output_size = 1, hidden_size = 1, num_layers = 1, seq_model = 'lstm'\n",
      "device = cpu(), dtype = 'float32'\n",
      "\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92m__init__\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, embedding_size, output_size, hidden_size, num_layers=\u001b[94m1\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                 seq_model=\u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, device=\u001b[94mNone\u001b[39;49;00m, dtype=\u001b[33m\"\u001b[39;49;00m\u001b[33mfloat32\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"\u001b[39;49;00m\n",
      "    \u001b[33m    Consists of an embedding layer, a sequence model (either RNN or LSTM), and a\u001b[39;49;00m\n",
      "    \u001b[33m    linear layer.\u001b[39;49;00m\n",
      "    \u001b[33m    Parameters:\u001b[39;49;00m\n",
      "    \u001b[33m    output_size: Size of dictionary\u001b[39;49;00m\n",
      "    \u001b[33m    embedding_size: Size of embeddings\u001b[39;49;00m\n",
      "    \u001b[33m    hidden_size: The number of features in the hidden state of LSTM or RNN\u001b[39;49;00m\n",
      "    \u001b[33m    seq_model: 'rnn' or 'lstm', whether to use RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    num_layers: Number of layers in RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    \"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[96msuper\u001b[39;49;00m(LanguageModel, \u001b[96mself\u001b[39;49;00m).\u001b[92m__init__\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m### BEGIN YOUR SOLUTION\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94mraise\u001b[39;49;00m \u001b[96mNotImplementedError\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       NotImplementedError\u001b[0m\n",
      "\n",
      "__class__  = <class 'models.LanguageModel'>\n",
      "device     = cpu()\n",
      "dtype      = 'float32'\n",
      "embedding_size = 34\n",
      "hidden_size = 1\n",
      "num_layers = 1\n",
      "output_size = 1\n",
      "self       = <models.LanguageModel object at 0x1694a6d50>\n",
      "seq_model  = 'lstm'\n",
      "\n",
      "\u001b[1m\u001b[31mapps/models.py\u001b[0m:38: NotImplementedError\n",
      "\u001b[31m\u001b[1m_______ test_language_model_implementation[cpu-lstm-1-False-1-34-1-1-13] _______\u001b[0m\n",
      "\n",
      "seq_length = 13, num_layers = 1, batch_size = 1, embedding_size = 34\n",
      "hidden_size = 1, init_hidden = False, output_size = 1, seq_model = 'lstm'\n",
      "device = cpu()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\u001b[90m\u001b[39;49;00m\n",
      "                            init_hidden, output_size, seq_model, device):\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      ">       model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "batch_size = 1\n",
      "c0         = needle.Tensor([[[-0.7108814]]])\n",
      "device     = cpu()\n",
      "embedding_size = 34\n",
      "h0         = needle.Tensor([[[-0.51008326]]])\n",
      "hidden_size = 1\n",
      "init_hidden = False\n",
      "num_layers = 1\n",
      "output_size = 1\n",
      "seq_length = 13\n",
      "seq_model  = 'lstm'\n",
      "x          = array([[0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:201: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "self = <models.LanguageModel object at 0x1694a6510>, embedding_size = 34\n",
      "output_size = 1, hidden_size = 1, num_layers = 1, seq_model = 'lstm'\n",
      "device = cpu(), dtype = 'float32'\n",
      "\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92m__init__\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, embedding_size, output_size, hidden_size, num_layers=\u001b[94m1\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                 seq_model=\u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, device=\u001b[94mNone\u001b[39;49;00m, dtype=\u001b[33m\"\u001b[39;49;00m\u001b[33mfloat32\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"\u001b[39;49;00m\n",
      "    \u001b[33m    Consists of an embedding layer, a sequence model (either RNN or LSTM), and a\u001b[39;49;00m\n",
      "    \u001b[33m    linear layer.\u001b[39;49;00m\n",
      "    \u001b[33m    Parameters:\u001b[39;49;00m\n",
      "    \u001b[33m    output_size: Size of dictionary\u001b[39;49;00m\n",
      "    \u001b[33m    embedding_size: Size of embeddings\u001b[39;49;00m\n",
      "    \u001b[33m    hidden_size: The number of features in the hidden state of LSTM or RNN\u001b[39;49;00m\n",
      "    \u001b[33m    seq_model: 'rnn' or 'lstm', whether to use RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    num_layers: Number of layers in RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    \"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[96msuper\u001b[39;49;00m(LanguageModel, \u001b[96mself\u001b[39;49;00m).\u001b[92m__init__\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m### BEGIN YOUR SOLUTION\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94mraise\u001b[39;49;00m \u001b[96mNotImplementedError\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       NotImplementedError\u001b[0m\n",
      "\n",
      "__class__  = <class 'models.LanguageModel'>\n",
      "device     = cpu()\n",
      "dtype      = 'float32'\n",
      "embedding_size = 34\n",
      "hidden_size = 1\n",
      "num_layers = 1\n",
      "output_size = 1\n",
      "self       = <models.LanguageModel object at 0x1694a6510>\n",
      "seq_model  = 'lstm'\n",
      "\n",
      "\u001b[1m\u001b[31mapps/models.py\u001b[0m:38: NotImplementedError\n",
      "\u001b[31m\u001b[1m_______ test_language_model_implementation[cpu-lstm-1-False-1-34-1-2-1] ________\u001b[0m\n",
      "\n",
      "seq_length = 1, num_layers = 2, batch_size = 1, embedding_size = 34\n",
      "hidden_size = 1, init_hidden = False, output_size = 1, seq_model = 'lstm'\n",
      "device = cpu()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\u001b[90m\u001b[39;49;00m\n",
      "                            init_hidden, output_size, seq_model, device):\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      ">       model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "batch_size = 1\n",
      "c0         = needle.Tensor([[[0.25001708]]\n",
      "\n",
      " [[0.66004235]]])\n",
      "device     = cpu()\n",
      "embedding_size = 34\n",
      "h0         = needle.Tensor([[[0.57607967]]\n",
      "\n",
      " [[0.24521975]]])\n",
      "hidden_size = 1\n",
      "init_hidden = False\n",
      "num_layers = 2\n",
      "output_size = 1\n",
      "seq_length = 1\n",
      "seq_model  = 'lstm'\n",
      "x          = array([[0.]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:201: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "self = <models.LanguageModel object at 0x1694a5f70>, embedding_size = 34\n",
      "output_size = 1, hidden_size = 1, num_layers = 2, seq_model = 'lstm'\n",
      "device = cpu(), dtype = 'float32'\n",
      "\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92m__init__\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, embedding_size, output_size, hidden_size, num_layers=\u001b[94m1\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                 seq_model=\u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, device=\u001b[94mNone\u001b[39;49;00m, dtype=\u001b[33m\"\u001b[39;49;00m\u001b[33mfloat32\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"\u001b[39;49;00m\n",
      "    \u001b[33m    Consists of an embedding layer, a sequence model (either RNN or LSTM), and a\u001b[39;49;00m\n",
      "    \u001b[33m    linear layer.\u001b[39;49;00m\n",
      "    \u001b[33m    Parameters:\u001b[39;49;00m\n",
      "    \u001b[33m    output_size: Size of dictionary\u001b[39;49;00m\n",
      "    \u001b[33m    embedding_size: Size of embeddings\u001b[39;49;00m\n",
      "    \u001b[33m    hidden_size: The number of features in the hidden state of LSTM or RNN\u001b[39;49;00m\n",
      "    \u001b[33m    seq_model: 'rnn' or 'lstm', whether to use RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    num_layers: Number of layers in RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    \"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[96msuper\u001b[39;49;00m(LanguageModel, \u001b[96mself\u001b[39;49;00m).\u001b[92m__init__\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m### BEGIN YOUR SOLUTION\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94mraise\u001b[39;49;00m \u001b[96mNotImplementedError\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       NotImplementedError\u001b[0m\n",
      "\n",
      "__class__  = <class 'models.LanguageModel'>\n",
      "device     = cpu()\n",
      "dtype      = 'float32'\n",
      "embedding_size = 34\n",
      "hidden_size = 1\n",
      "num_layers = 2\n",
      "output_size = 1\n",
      "self       = <models.LanguageModel object at 0x1694a5f70>\n",
      "seq_model  = 'lstm'\n",
      "\n",
      "\u001b[1m\u001b[31mapps/models.py\u001b[0m:38: NotImplementedError\n",
      "\u001b[31m\u001b[1m_______ test_language_model_implementation[cpu-lstm-1-False-1-34-1-2-13] _______\u001b[0m\n",
      "\n",
      "seq_length = 13, num_layers = 2, batch_size = 1, embedding_size = 34\n",
      "hidden_size = 1, init_hidden = False, output_size = 1, seq_model = 'lstm'\n",
      "device = cpu()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\u001b[90m\u001b[39;49;00m\n",
      "                            init_hidden, output_size, seq_model, device):\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      ">       model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "batch_size = 1\n",
      "c0         = needle.Tensor([[[-1.049606 ]]\n",
      "\n",
      " [[-0.9830766]]])\n",
      "device     = cpu()\n",
      "embedding_size = 34\n",
      "h0         = needle.Tensor([[[ 0.1317245 ]]\n",
      "\n",
      " [[-0.39293113]]])\n",
      "hidden_size = 1\n",
      "init_hidden = False\n",
      "num_layers = 2\n",
      "output_size = 1\n",
      "seq_length = 13\n",
      "seq_model  = 'lstm'\n",
      "x          = array([[0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:201: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "self = <models.LanguageModel object at 0x1694e5790>, embedding_size = 34\n",
      "output_size = 1, hidden_size = 1, num_layers = 2, seq_model = 'lstm'\n",
      "device = cpu(), dtype = 'float32'\n",
      "\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92m__init__\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, embedding_size, output_size, hidden_size, num_layers=\u001b[94m1\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                 seq_model=\u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, device=\u001b[94mNone\u001b[39;49;00m, dtype=\u001b[33m\"\u001b[39;49;00m\u001b[33mfloat32\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"\u001b[39;49;00m\n",
      "    \u001b[33m    Consists of an embedding layer, a sequence model (either RNN or LSTM), and a\u001b[39;49;00m\n",
      "    \u001b[33m    linear layer.\u001b[39;49;00m\n",
      "    \u001b[33m    Parameters:\u001b[39;49;00m\n",
      "    \u001b[33m    output_size: Size of dictionary\u001b[39;49;00m\n",
      "    \u001b[33m    embedding_size: Size of embeddings\u001b[39;49;00m\n",
      "    \u001b[33m    hidden_size: The number of features in the hidden state of LSTM or RNN\u001b[39;49;00m\n",
      "    \u001b[33m    seq_model: 'rnn' or 'lstm', whether to use RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    num_layers: Number of layers in RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    \"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[96msuper\u001b[39;49;00m(LanguageModel, \u001b[96mself\u001b[39;49;00m).\u001b[92m__init__\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m### BEGIN YOUR SOLUTION\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94mraise\u001b[39;49;00m \u001b[96mNotImplementedError\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       NotImplementedError\u001b[0m\n",
      "\n",
      "__class__  = <class 'models.LanguageModel'>\n",
      "device     = cpu()\n",
      "dtype      = 'float32'\n",
      "embedding_size = 34\n",
      "hidden_size = 1\n",
      "num_layers = 2\n",
      "output_size = 1\n",
      "self       = <models.LanguageModel object at 0x1694e5790>\n",
      "seq_model  = 'lstm'\n",
      "\n",
      "\u001b[1m\u001b[31mapps/models.py\u001b[0m:38: NotImplementedError\n",
      "\u001b[31m\u001b[1m_______ test_language_model_implementation[cpu-lstm-1-False-1-34-15-1-1] _______\u001b[0m\n",
      "\n",
      "seq_length = 1, num_layers = 1, batch_size = 15, embedding_size = 34\n",
      "hidden_size = 1, init_hidden = False, output_size = 1, seq_model = 'lstm'\n",
      "device = cpu()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\u001b[90m\u001b[39;49;00m\n",
      "                            init_hidden, output_size, seq_model, device):\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      ">       model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "batch_size = 15\n",
      "c0         = needle.Tensor([[[ 0.5045223 ]\n",
      "  [-0.66991323]\n",
      "  [ 0.18445835]\n",
      "  [ 0.36284095]\n",
      "  [ 0.58707654]\n",
      "  [ 0.21203573]\n",
      "  [ 2.04...91 ]\n",
      "  [ 0.21095572]\n",
      "  [-0.2477046 ]\n",
      "  [ 1.2857105 ]\n",
      "  [-1.1265033 ]\n",
      "  [ 0.44672054]\n",
      "  [-1.1120943 ]\n",
      "  [-0.8502508 ]]])\n",
      "device     = cpu()\n",
      "embedding_size = 34\n",
      "h0         = needle.Tensor([[[ 1.7495235 ]\n",
      "  [ 0.5454027 ]\n",
      "  [ 0.31862608]\n",
      "  [-0.2437197 ]\n",
      "  [-1.8433019 ]\n",
      "  [-0.968781  ]\n",
      "  [-2.00...15 ]\n",
      "  [ 0.5474627 ]\n",
      "  [ 0.5022563 ]\n",
      "  [-0.7853454 ]\n",
      "  [-1.3820103 ]\n",
      "  [ 1.316165  ]\n",
      "  [ 0.27811125]\n",
      "  [ 1.6395884 ]]])\n",
      "hidden_size = 1\n",
      "init_hidden = False\n",
      "num_layers = 1\n",
      "output_size = 1\n",
      "seq_length = 1\n",
      "seq_model  = 'lstm'\n",
      "x          = array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "      dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:201: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "self = <models.LanguageModel object at 0x1694e62a0>, embedding_size = 34\n",
      "output_size = 1, hidden_size = 1, num_layers = 1, seq_model = 'lstm'\n",
      "device = cpu(), dtype = 'float32'\n",
      "\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92m__init__\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, embedding_size, output_size, hidden_size, num_layers=\u001b[94m1\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                 seq_model=\u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, device=\u001b[94mNone\u001b[39;49;00m, dtype=\u001b[33m\"\u001b[39;49;00m\u001b[33mfloat32\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"\u001b[39;49;00m\n",
      "    \u001b[33m    Consists of an embedding layer, a sequence model (either RNN or LSTM), and a\u001b[39;49;00m\n",
      "    \u001b[33m    linear layer.\u001b[39;49;00m\n",
      "    \u001b[33m    Parameters:\u001b[39;49;00m\n",
      "    \u001b[33m    output_size: Size of dictionary\u001b[39;49;00m\n",
      "    \u001b[33m    embedding_size: Size of embeddings\u001b[39;49;00m\n",
      "    \u001b[33m    hidden_size: The number of features in the hidden state of LSTM or RNN\u001b[39;49;00m\n",
      "    \u001b[33m    seq_model: 'rnn' or 'lstm', whether to use RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    num_layers: Number of layers in RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    \"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[96msuper\u001b[39;49;00m(LanguageModel, \u001b[96mself\u001b[39;49;00m).\u001b[92m__init__\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m### BEGIN YOUR SOLUTION\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94mraise\u001b[39;49;00m \u001b[96mNotImplementedError\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       NotImplementedError\u001b[0m\n",
      "\n",
      "__class__  = <class 'models.LanguageModel'>\n",
      "device     = cpu()\n",
      "dtype      = 'float32'\n",
      "embedding_size = 34\n",
      "hidden_size = 1\n",
      "num_layers = 1\n",
      "output_size = 1\n",
      "self       = <models.LanguageModel object at 0x1694e62a0>\n",
      "seq_model  = 'lstm'\n",
      "\n",
      "\u001b[1m\u001b[31mapps/models.py\u001b[0m:38: NotImplementedError\n",
      "\u001b[31m\u001b[1m______ test_language_model_implementation[cpu-lstm-1-False-1-34-15-1-13] _______\u001b[0m\n",
      "\n",
      "seq_length = 13, num_layers = 1, batch_size = 15, embedding_size = 34\n",
      "hidden_size = 1, init_hidden = False, output_size = 1, seq_model = 'lstm'\n",
      "device = cpu()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\u001b[90m\u001b[39;49;00m\n",
      "                            init_hidden, output_size, seq_model, device):\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      ">       model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "batch_size = 15\n",
      "c0         = needle.Tensor([[[-1.6393527 ]\n",
      "  [ 1.2861757 ]\n",
      "  [ 0.6851822 ]\n",
      "  [ 0.7179895 ]\n",
      "  [ 2.3137343 ]\n",
      "  [-1.6814734 ]\n",
      "  [-1.39...91 ]\n",
      "  [ 0.53504217]\n",
      "  [-0.7842242 ]\n",
      "  [-1.1266952 ]\n",
      "  [ 0.4035856 ]\n",
      "  [ 1.2814323 ]\n",
      "  [-0.7713179 ]\n",
      "  [-0.65862995]]])\n",
      "device     = cpu()\n",
      "embedding_size = 34\n",
      "h0         = needle.Tensor([[[-1.7551023 ]\n",
      "  [ 0.97222346]\n",
      "  [ 1.5104048 ]\n",
      "  [-2.1634064 ]\n",
      "  [ 0.8736412 ]\n",
      "  [ 1.8663247 ]\n",
      "  [ 0.39...005]\n",
      "  [ 2.905238  ]\n",
      "  [-0.21697804]\n",
      "  [-0.30269983]\n",
      "  [ 0.1604677 ]\n",
      "  [ 0.52347064]\n",
      "  [ 1.1175965 ]\n",
      "  [ 0.31610963]]])\n",
      "hidden_size = 1\n",
      "init_hidden = False\n",
      "num_layers = 1\n",
      "output_size = 1\n",
      "seq_length = 13\n",
      "seq_model  = 'lstm'\n",
      "x          = array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0...0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "      dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:201: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "self = <models.LanguageModel object at 0x1694e6e40>, embedding_size = 34\n",
      "output_size = 1, hidden_size = 1, num_layers = 1, seq_model = 'lstm'\n",
      "device = cpu(), dtype = 'float32'\n",
      "\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92m__init__\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, embedding_size, output_size, hidden_size, num_layers=\u001b[94m1\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                 seq_model=\u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, device=\u001b[94mNone\u001b[39;49;00m, dtype=\u001b[33m\"\u001b[39;49;00m\u001b[33mfloat32\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"\u001b[39;49;00m\n",
      "    \u001b[33m    Consists of an embedding layer, a sequence model (either RNN or LSTM), and a\u001b[39;49;00m\n",
      "    \u001b[33m    linear layer.\u001b[39;49;00m\n",
      "    \u001b[33m    Parameters:\u001b[39;49;00m\n",
      "    \u001b[33m    output_size: Size of dictionary\u001b[39;49;00m\n",
      "    \u001b[33m    embedding_size: Size of embeddings\u001b[39;49;00m\n",
      "    \u001b[33m    hidden_size: The number of features in the hidden state of LSTM or RNN\u001b[39;49;00m\n",
      "    \u001b[33m    seq_model: 'rnn' or 'lstm', whether to use RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    num_layers: Number of layers in RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    \"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[96msuper\u001b[39;49;00m(LanguageModel, \u001b[96mself\u001b[39;49;00m).\u001b[92m__init__\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m### BEGIN YOUR SOLUTION\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94mraise\u001b[39;49;00m \u001b[96mNotImplementedError\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       NotImplementedError\u001b[0m\n",
      "\n",
      "__class__  = <class 'models.LanguageModel'>\n",
      "device     = cpu()\n",
      "dtype      = 'float32'\n",
      "embedding_size = 34\n",
      "hidden_size = 1\n",
      "num_layers = 1\n",
      "output_size = 1\n",
      "self       = <models.LanguageModel object at 0x1694e6e40>\n",
      "seq_model  = 'lstm'\n",
      "\n",
      "\u001b[1m\u001b[31mapps/models.py\u001b[0m:38: NotImplementedError\n",
      "\u001b[31m\u001b[1m_______ test_language_model_implementation[cpu-lstm-1-False-1-34-15-2-1] _______\u001b[0m\n",
      "\n",
      "seq_length = 1, num_layers = 2, batch_size = 15, embedding_size = 34\n",
      "hidden_size = 1, init_hidden = False, output_size = 1, seq_model = 'lstm'\n",
      "device = cpu()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\u001b[90m\u001b[39;49;00m\n",
      "                            init_hidden, output_size, seq_model, device):\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      ">       model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "batch_size = 15\n",
      "c0         = needle.Tensor([[[-1.0379467 ]\n",
      "  [ 1.6299253 ]\n",
      "  [ 0.5947726 ]\n",
      "  [ 2.6422267 ]\n",
      "  [-1.0775532 ]\n",
      "  [-0.17948298]\n",
      "  [-0.81...877]\n",
      "  [ 1.7799618 ]\n",
      "  [-0.24292369]\n",
      "  [-0.04436355]\n",
      "  [ 0.5234736 ]\n",
      "  [-0.7940397 ]\n",
      "  [-0.24962877]\n",
      "  [ 0.07462344]]])\n",
      "device     = cpu()\n",
      "embedding_size = 34\n",
      "h0         = needle.Tensor([[[ 6.2074482e-01]\n",
      "  [ 1.4819878e-01]\n",
      "  [ 7.4814091e-04]\n",
      "  [ 2.4532757e+00]\n",
      "  [-1.7309052e-01]\n",
      "  [ 2.793...1]\n",
      "  [-8.2223642e-01]\n",
      "  [ 1.1148509e-01]\n",
      "  [ 1.1942184e-01]\n",
      "  [-4.0646496e-01]\n",
      "  [-1.0657108e+00]\n",
      "  [-1.0003483e+00]]])\n",
      "hidden_size = 1\n",
      "init_hidden = False\n",
      "num_layers = 2\n",
      "output_size = 1\n",
      "seq_length = 1\n",
      "seq_model  = 'lstm'\n",
      "x          = array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "      dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:201: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "self = <models.LanguageModel object at 0x1694e6150>, embedding_size = 34\n",
      "output_size = 1, hidden_size = 1, num_layers = 2, seq_model = 'lstm'\n",
      "device = cpu(), dtype = 'float32'\n",
      "\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92m__init__\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, embedding_size, output_size, hidden_size, num_layers=\u001b[94m1\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                 seq_model=\u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, device=\u001b[94mNone\u001b[39;49;00m, dtype=\u001b[33m\"\u001b[39;49;00m\u001b[33mfloat32\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"\u001b[39;49;00m\n",
      "    \u001b[33m    Consists of an embedding layer, a sequence model (either RNN or LSTM), and a\u001b[39;49;00m\n",
      "    \u001b[33m    linear layer.\u001b[39;49;00m\n",
      "    \u001b[33m    Parameters:\u001b[39;49;00m\n",
      "    \u001b[33m    output_size: Size of dictionary\u001b[39;49;00m\n",
      "    \u001b[33m    embedding_size: Size of embeddings\u001b[39;49;00m\n",
      "    \u001b[33m    hidden_size: The number of features in the hidden state of LSTM or RNN\u001b[39;49;00m\n",
      "    \u001b[33m    seq_model: 'rnn' or 'lstm', whether to use RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    num_layers: Number of layers in RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    \"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[96msuper\u001b[39;49;00m(LanguageModel, \u001b[96mself\u001b[39;49;00m).\u001b[92m__init__\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m### BEGIN YOUR SOLUTION\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94mraise\u001b[39;49;00m \u001b[96mNotImplementedError\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       NotImplementedError\u001b[0m\n",
      "\n",
      "__class__  = <class 'models.LanguageModel'>\n",
      "device     = cpu()\n",
      "dtype      = 'float32'\n",
      "embedding_size = 34\n",
      "hidden_size = 1\n",
      "num_layers = 2\n",
      "output_size = 1\n",
      "self       = <models.LanguageModel object at 0x1694e6150>\n",
      "seq_model  = 'lstm'\n",
      "\n",
      "\u001b[1m\u001b[31mapps/models.py\u001b[0m:38: NotImplementedError\n",
      "\u001b[31m\u001b[1m______ test_language_model_implementation[cpu-lstm-1-False-1-34-15-2-13] _______\u001b[0m\n",
      "\n",
      "seq_length = 13, num_layers = 2, batch_size = 15, embedding_size = 34\n",
      "hidden_size = 1, init_hidden = False, output_size = 1, seq_model = 'lstm'\n",
      "device = cpu()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\u001b[90m\u001b[39;49;00m\n",
      "                            init_hidden, output_size, seq_model, device):\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      ">       model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "batch_size = 15\n",
      "c0         = needle.Tensor([[[-1.2711339 ]\n",
      "  [-1.3731313 ]\n",
      "  [ 0.1578723 ]\n",
      "  [-0.42424014]\n",
      "  [-0.24350815]\n",
      "  [-1.1561563 ]\n",
      "  [-1.85...85 ]\n",
      "  [ 0.25846136]\n",
      "  [-0.08756304]\n",
      "  [-0.981103  ]\n",
      "  [-0.06278399]\n",
      "  [-0.49639696]\n",
      "  [ 0.59871274]\n",
      "  [-0.08937646]]])\n",
      "device     = cpu()\n",
      "embedding_size = 34\n",
      "h0         = needle.Tensor([[[ 0.9376705 ]\n",
      "  [ 0.8217742 ]\n",
      "  [-0.21701208]\n",
      "  [-0.05013791]\n",
      "  [ 0.7628268 ]\n",
      "  [-0.34542233]\n",
      "  [ 0.70...47 ]\n",
      "  [ 1.254985  ]\n",
      "  [ 1.5171462 ]\n",
      "  [ 0.9954709 ]\n",
      "  [-0.09044258]\n",
      "  [-1.8260703 ]\n",
      "  [-0.4876924 ]\n",
      "  [-1.3321034 ]]])\n",
      "hidden_size = 1\n",
      "init_hidden = False\n",
      "num_layers = 2\n",
      "output_size = 1\n",
      "seq_length = 13\n",
      "seq_model  = 'lstm'\n",
      "x          = array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0...0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "      dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:201: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "self = <models.LanguageModel object at 0x1694e7f80>, embedding_size = 34\n",
      "output_size = 1, hidden_size = 1, num_layers = 2, seq_model = 'lstm'\n",
      "device = cpu(), dtype = 'float32'\n",
      "\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92m__init__\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, embedding_size, output_size, hidden_size, num_layers=\u001b[94m1\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                 seq_model=\u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, device=\u001b[94mNone\u001b[39;49;00m, dtype=\u001b[33m\"\u001b[39;49;00m\u001b[33mfloat32\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"\u001b[39;49;00m\n",
      "    \u001b[33m    Consists of an embedding layer, a sequence model (either RNN or LSTM), and a\u001b[39;49;00m\n",
      "    \u001b[33m    linear layer.\u001b[39;49;00m\n",
      "    \u001b[33m    Parameters:\u001b[39;49;00m\n",
      "    \u001b[33m    output_size: Size of dictionary\u001b[39;49;00m\n",
      "    \u001b[33m    embedding_size: Size of embeddings\u001b[39;49;00m\n",
      "    \u001b[33m    hidden_size: The number of features in the hidden state of LSTM or RNN\u001b[39;49;00m\n",
      "    \u001b[33m    seq_model: 'rnn' or 'lstm', whether to use RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    num_layers: Number of layers in RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    \"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[96msuper\u001b[39;49;00m(LanguageModel, \u001b[96mself\u001b[39;49;00m).\u001b[92m__init__\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m### BEGIN YOUR SOLUTION\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94mraise\u001b[39;49;00m \u001b[96mNotImplementedError\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       NotImplementedError\u001b[0m\n",
      "\n",
      "__class__  = <class 'models.LanguageModel'>\n",
      "device     = cpu()\n",
      "dtype      = 'float32'\n",
      "embedding_size = 34\n",
      "hidden_size = 1\n",
      "num_layers = 2\n",
      "output_size = 1\n",
      "self       = <models.LanguageModel object at 0x1694e7f80>\n",
      "seq_model  = 'lstm'\n",
      "\n",
      "\u001b[1m\u001b[31mapps/models.py\u001b[0m:38: NotImplementedError\n",
      "\u001b[31m\u001b[1m_______ test_language_model_implementation[cpu-lstm-1-False-12-1-1-1-1] ________\u001b[0m\n",
      "\n",
      "seq_length = 1, num_layers = 1, batch_size = 1, embedding_size = 1\n",
      "hidden_size = 12, init_hidden = False, output_size = 1, seq_model = 'lstm'\n",
      "device = cpu()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\u001b[90m\u001b[39;49;00m\n",
      "                            init_hidden, output_size, seq_model, device):\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      ">       model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "batch_size = 1\n",
      "c0         = needle.Tensor([[[ 2.68324     0.4270546  -0.33412233  1.5480554  -0.00944412\n",
      "   -0.85356367 -0.29085597 -0.4039103  -1.8470156  -0.7654468\n",
      "    0.18418774  1.2655073 ]]])\n",
      "device     = cpu()\n",
      "embedding_size = 1\n",
      "h0         = needle.Tensor([[[-2.1420476   1.7251563  -0.5296711  -0.25006348  0.63696206\n",
      "    0.67764425  0.0831638   1.4520724   1.0095745  -0.04556229\n",
      "    0.08562503 -1.610764  ]]])\n",
      "hidden_size = 12\n",
      "init_hidden = False\n",
      "num_layers = 1\n",
      "output_size = 1\n",
      "seq_length = 1\n",
      "seq_model  = 'lstm'\n",
      "x          = array([[0.]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:201: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "self = <models.LanguageModel object at 0x1694a5970>, embedding_size = 1\n",
      "output_size = 1, hidden_size = 12, num_layers = 1, seq_model = 'lstm'\n",
      "device = cpu(), dtype = 'float32'\n",
      "\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92m__init__\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, embedding_size, output_size, hidden_size, num_layers=\u001b[94m1\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                 seq_model=\u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, device=\u001b[94mNone\u001b[39;49;00m, dtype=\u001b[33m\"\u001b[39;49;00m\u001b[33mfloat32\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"\u001b[39;49;00m\n",
      "    \u001b[33m    Consists of an embedding layer, a sequence model (either RNN or LSTM), and a\u001b[39;49;00m\n",
      "    \u001b[33m    linear layer.\u001b[39;49;00m\n",
      "    \u001b[33m    Parameters:\u001b[39;49;00m\n",
      "    \u001b[33m    output_size: Size of dictionary\u001b[39;49;00m\n",
      "    \u001b[33m    embedding_size: Size of embeddings\u001b[39;49;00m\n",
      "    \u001b[33m    hidden_size: The number of features in the hidden state of LSTM or RNN\u001b[39;49;00m\n",
      "    \u001b[33m    seq_model: 'rnn' or 'lstm', whether to use RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    num_layers: Number of layers in RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    \"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[96msuper\u001b[39;49;00m(LanguageModel, \u001b[96mself\u001b[39;49;00m).\u001b[92m__init__\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m### BEGIN YOUR SOLUTION\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94mraise\u001b[39;49;00m \u001b[96mNotImplementedError\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       NotImplementedError\u001b[0m\n",
      "\n",
      "__class__  = <class 'models.LanguageModel'>\n",
      "device     = cpu()\n",
      "dtype      = 'float32'\n",
      "embedding_size = 1\n",
      "hidden_size = 12\n",
      "num_layers = 1\n",
      "output_size = 1\n",
      "self       = <models.LanguageModel object at 0x1694a5970>\n",
      "seq_model  = 'lstm'\n",
      "\n",
      "\u001b[1m\u001b[31mapps/models.py\u001b[0m:38: NotImplementedError\n",
      "\u001b[31m\u001b[1m_______ test_language_model_implementation[cpu-lstm-1-False-12-1-1-1-13] _______\u001b[0m\n",
      "\n",
      "seq_length = 13, num_layers = 1, batch_size = 1, embedding_size = 1\n",
      "hidden_size = 12, init_hidden = False, output_size = 1, seq_model = 'lstm'\n",
      "device = cpu()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\u001b[90m\u001b[39;49;00m\n",
      "                            init_hidden, output_size, seq_model, device):\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      ">       model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "batch_size = 1\n",
      "c0         = needle.Tensor([[[-1.9461304  -0.8277874   0.8550149  -0.68380105 -0.5349686\n",
      "   -1.5371269  -1.7116593  -0.32875246  1.366224   -1.5697978\n",
      "    1.0182828   0.9405398 ]]])\n",
      "device     = cpu()\n",
      "embedding_size = 1\n",
      "h0         = needle.Tensor([[[ 0.424263    0.8435918  -1.8791559  -0.6340467  -0.35086805\n",
      "    0.6329341   0.5552571  -0.36445317 -1.0976251   0.5658724\n",
      "   -0.12791479 -0.02144402]]])\n",
      "hidden_size = 12\n",
      "init_hidden = False\n",
      "num_layers = 1\n",
      "output_size = 1\n",
      "seq_length = 13\n",
      "seq_model  = 'lstm'\n",
      "x          = array([[0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:201: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "self = <models.LanguageModel object at 0x1694a6ab0>, embedding_size = 1\n",
      "output_size = 1, hidden_size = 12, num_layers = 1, seq_model = 'lstm'\n",
      "device = cpu(), dtype = 'float32'\n",
      "\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92m__init__\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, embedding_size, output_size, hidden_size, num_layers=\u001b[94m1\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                 seq_model=\u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, device=\u001b[94mNone\u001b[39;49;00m, dtype=\u001b[33m\"\u001b[39;49;00m\u001b[33mfloat32\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"\u001b[39;49;00m\n",
      "    \u001b[33m    Consists of an embedding layer, a sequence model (either RNN or LSTM), and a\u001b[39;49;00m\n",
      "    \u001b[33m    linear layer.\u001b[39;49;00m\n",
      "    \u001b[33m    Parameters:\u001b[39;49;00m\n",
      "    \u001b[33m    output_size: Size of dictionary\u001b[39;49;00m\n",
      "    \u001b[33m    embedding_size: Size of embeddings\u001b[39;49;00m\n",
      "    \u001b[33m    hidden_size: The number of features in the hidden state of LSTM or RNN\u001b[39;49;00m\n",
      "    \u001b[33m    seq_model: 'rnn' or 'lstm', whether to use RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    num_layers: Number of layers in RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    \"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[96msuper\u001b[39;49;00m(LanguageModel, \u001b[96mself\u001b[39;49;00m).\u001b[92m__init__\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m### BEGIN YOUR SOLUTION\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94mraise\u001b[39;49;00m \u001b[96mNotImplementedError\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       NotImplementedError\u001b[0m\n",
      "\n",
      "__class__  = <class 'models.LanguageModel'>\n",
      "device     = cpu()\n",
      "dtype      = 'float32'\n",
      "embedding_size = 1\n",
      "hidden_size = 12\n",
      "num_layers = 1\n",
      "output_size = 1\n",
      "self       = <models.LanguageModel object at 0x1694a6ab0>\n",
      "seq_model  = 'lstm'\n",
      "\n",
      "\u001b[1m\u001b[31mapps/models.py\u001b[0m:38: NotImplementedError\n",
      "\u001b[31m\u001b[1m_______ test_language_model_implementation[cpu-lstm-1-False-12-1-1-2-1] ________\u001b[0m\n",
      "\n",
      "seq_length = 1, num_layers = 2, batch_size = 1, embedding_size = 1\n",
      "hidden_size = 12, init_hidden = False, output_size = 1, seq_model = 'lstm'\n",
      "device = cpu()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\u001b[90m\u001b[39;49;00m\n",
      "                            init_hidden, output_size, seq_model, device):\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      ">       model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "batch_size = 1\n",
      "c0         = needle.Tensor([[[ 0.40598652 -1.5315827  -0.671845   -0.81762916 -0.0778113\n",
      "   -0.6114656   0.20698957  0.13124801 -0....61 -0.27686608  0.88440853\n",
      "   -0.88564634 -1.0898553  -0.05380245 -0.16103216  1.0991879\n",
      "    0.58233315  0.16037647]]])\n",
      "device     = cpu()\n",
      "embedding_size = 1\n",
      "h0         = needle.Tensor([[[-1.3863026   1.9301107   0.4852037   0.01529308  0.69040704\n",
      "    0.05293633 -0.56457335  0.52455854  0...9  0.5140881  -0.63533515\n",
      "    0.77154815 -1.7017959  -0.2942097  -0.6480822   0.21713585\n",
      "   -1.9600505  -0.61986834]]])\n",
      "hidden_size = 12\n",
      "init_hidden = False\n",
      "num_layers = 2\n",
      "output_size = 1\n",
      "seq_length = 1\n",
      "seq_model  = 'lstm'\n",
      "x          = array([[0.]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:201: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "self = <models.LanguageModel object at 0x1577974a0>, embedding_size = 1\n",
      "output_size = 1, hidden_size = 12, num_layers = 2, seq_model = 'lstm'\n",
      "device = cpu(), dtype = 'float32'\n",
      "\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92m__init__\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, embedding_size, output_size, hidden_size, num_layers=\u001b[94m1\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                 seq_model=\u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, device=\u001b[94mNone\u001b[39;49;00m, dtype=\u001b[33m\"\u001b[39;49;00m\u001b[33mfloat32\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"\u001b[39;49;00m\n",
      "    \u001b[33m    Consists of an embedding layer, a sequence model (either RNN or LSTM), and a\u001b[39;49;00m\n",
      "    \u001b[33m    linear layer.\u001b[39;49;00m\n",
      "    \u001b[33m    Parameters:\u001b[39;49;00m\n",
      "    \u001b[33m    output_size: Size of dictionary\u001b[39;49;00m\n",
      "    \u001b[33m    embedding_size: Size of embeddings\u001b[39;49;00m\n",
      "    \u001b[33m    hidden_size: The number of features in the hidden state of LSTM or RNN\u001b[39;49;00m\n",
      "    \u001b[33m    seq_model: 'rnn' or 'lstm', whether to use RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    num_layers: Number of layers in RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    \"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[96msuper\u001b[39;49;00m(LanguageModel, \u001b[96mself\u001b[39;49;00m).\u001b[92m__init__\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m### BEGIN YOUR SOLUTION\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94mraise\u001b[39;49;00m \u001b[96mNotImplementedError\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       NotImplementedError\u001b[0m\n",
      "\n",
      "__class__  = <class 'models.LanguageModel'>\n",
      "device     = cpu()\n",
      "dtype      = 'float32'\n",
      "embedding_size = 1\n",
      "hidden_size = 12\n",
      "num_layers = 2\n",
      "output_size = 1\n",
      "self       = <models.LanguageModel object at 0x1577974a0>\n",
      "seq_model  = 'lstm'\n",
      "\n",
      "\u001b[1m\u001b[31mapps/models.py\u001b[0m:38: NotImplementedError\n",
      "\u001b[31m\u001b[1m_______ test_language_model_implementation[cpu-lstm-1-False-12-1-1-2-13] _______\u001b[0m\n",
      "\n",
      "seq_length = 13, num_layers = 2, batch_size = 1, embedding_size = 1\n",
      "hidden_size = 12, init_hidden = False, output_size = 1, seq_model = 'lstm'\n",
      "device = cpu()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\u001b[90m\u001b[39;49;00m\n",
      "                            init_hidden, output_size, seq_model, device):\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      ">       model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "batch_size = 1\n",
      "c0         = needle.Tensor([[[ 1.0770249  -0.5523047  -1.378113    0.1026803  -1.0506142\n",
      "    0.3306516  -0.5567479  -0.49457723  0....24576  1.5287185  -2.90389\n",
      "    0.8298716  -0.33845317 -0.44702765  2.8454595   0.3720017\n",
      "   -0.92486906  1.298105  ]]])\n",
      "device     = cpu()\n",
      "embedding_size = 1\n",
      "h0         = needle.Tensor([[[-5.2871114e-01  2.0604115e+00 -5.9128869e-01  7.6710379e-01\n",
      "   -4.2142060e-01 -7.5223112e-01 -9.76225...900e-01  5.5237973e-01 -9.4707601e-02  3.2200405e-01\n",
      "    1.3732827e+00 -1.6572320e+00 -1.7654736e+00  6.1170238e-01]]])\n",
      "hidden_size = 12\n",
      "init_hidden = False\n",
      "num_layers = 2\n",
      "output_size = 1\n",
      "seq_length = 13\n",
      "seq_model  = 'lstm'\n",
      "x          = array([[0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:201: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "self = <models.LanguageModel object at 0x157538aa0>, embedding_size = 1\n",
      "output_size = 1, hidden_size = 12, num_layers = 2, seq_model = 'lstm'\n",
      "device = cpu(), dtype = 'float32'\n",
      "\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92m__init__\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, embedding_size, output_size, hidden_size, num_layers=\u001b[94m1\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                 seq_model=\u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, device=\u001b[94mNone\u001b[39;49;00m, dtype=\u001b[33m\"\u001b[39;49;00m\u001b[33mfloat32\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"\u001b[39;49;00m\n",
      "    \u001b[33m    Consists of an embedding layer, a sequence model (either RNN or LSTM), and a\u001b[39;49;00m\n",
      "    \u001b[33m    linear layer.\u001b[39;49;00m\n",
      "    \u001b[33m    Parameters:\u001b[39;49;00m\n",
      "    \u001b[33m    output_size: Size of dictionary\u001b[39;49;00m\n",
      "    \u001b[33m    embedding_size: Size of embeddings\u001b[39;49;00m\n",
      "    \u001b[33m    hidden_size: The number of features in the hidden state of LSTM or RNN\u001b[39;49;00m\n",
      "    \u001b[33m    seq_model: 'rnn' or 'lstm', whether to use RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    num_layers: Number of layers in RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    \"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[96msuper\u001b[39;49;00m(LanguageModel, \u001b[96mself\u001b[39;49;00m).\u001b[92m__init__\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m### BEGIN YOUR SOLUTION\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94mraise\u001b[39;49;00m \u001b[96mNotImplementedError\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       NotImplementedError\u001b[0m\n",
      "\n",
      "__class__  = <class 'models.LanguageModel'>\n",
      "device     = cpu()\n",
      "dtype      = 'float32'\n",
      "embedding_size = 1\n",
      "hidden_size = 12\n",
      "num_layers = 2\n",
      "output_size = 1\n",
      "self       = <models.LanguageModel object at 0x157538aa0>\n",
      "seq_model  = 'lstm'\n",
      "\n",
      "\u001b[1m\u001b[31mapps/models.py\u001b[0m:38: NotImplementedError\n",
      "\u001b[31m\u001b[1m_______ test_language_model_implementation[cpu-lstm-1-False-12-1-15-1-1] _______\u001b[0m\n",
      "\n",
      "seq_length = 1, num_layers = 1, batch_size = 15, embedding_size = 1\n",
      "hidden_size = 12, init_hidden = False, output_size = 1, seq_model = 'lstm'\n",
      "device = cpu()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\u001b[90m\u001b[39;49;00m\n",
      "                            init_hidden, output_size, seq_model, device):\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      ">       model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "batch_size = 15\n",
      "c0         = needle.Tensor([[[-1.82594037e+00 -3.73861283e-01 -1.42655349e+00  3.29405099e-01\n",
      "   -9.04894769e-01 -5.17461836e-01  1...  3.10770303e-01 -2.63941765e+00 -9.29101743e-03\n",
      "    1.74341476e+00 -7.03704715e-01 -7.93202996e-01  9.93147075e-01]]])\n",
      "device     = cpu()\n",
      "embedding_size = 1\n",
      "h0         = needle.Tensor([[[ 0.16021752 -1.0872879  -1.8854682   0.05288259 -0.15721428\n",
      "    0.21965285  0.3443068   0.34948835 -0...6   1.2078701   0.41419822\n",
      "   -1.4550362  -0.4457758   0.91003096 -0.52226967  0.9721577\n",
      "   -0.81240755 -0.01244572]]])\n",
      "hidden_size = 12\n",
      "init_hidden = False\n",
      "num_layers = 1\n",
      "output_size = 1\n",
      "seq_length = 1\n",
      "seq_model  = 'lstm'\n",
      "x          = array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "      dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:201: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "self = <models.LanguageModel object at 0x1575c7e00>, embedding_size = 1\n",
      "output_size = 1, hidden_size = 12, num_layers = 1, seq_model = 'lstm'\n",
      "device = cpu(), dtype = 'float32'\n",
      "\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92m__init__\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, embedding_size, output_size, hidden_size, num_layers=\u001b[94m1\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                 seq_model=\u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, device=\u001b[94mNone\u001b[39;49;00m, dtype=\u001b[33m\"\u001b[39;49;00m\u001b[33mfloat32\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"\u001b[39;49;00m\n",
      "    \u001b[33m    Consists of an embedding layer, a sequence model (either RNN or LSTM), and a\u001b[39;49;00m\n",
      "    \u001b[33m    linear layer.\u001b[39;49;00m\n",
      "    \u001b[33m    Parameters:\u001b[39;49;00m\n",
      "    \u001b[33m    output_size: Size of dictionary\u001b[39;49;00m\n",
      "    \u001b[33m    embedding_size: Size of embeddings\u001b[39;49;00m\n",
      "    \u001b[33m    hidden_size: The number of features in the hidden state of LSTM or RNN\u001b[39;49;00m\n",
      "    \u001b[33m    seq_model: 'rnn' or 'lstm', whether to use RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    num_layers: Number of layers in RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    \"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[96msuper\u001b[39;49;00m(LanguageModel, \u001b[96mself\u001b[39;49;00m).\u001b[92m__init__\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m### BEGIN YOUR SOLUTION\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94mraise\u001b[39;49;00m \u001b[96mNotImplementedError\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       NotImplementedError\u001b[0m\n",
      "\n",
      "__class__  = <class 'models.LanguageModel'>\n",
      "device     = cpu()\n",
      "dtype      = 'float32'\n",
      "embedding_size = 1\n",
      "hidden_size = 12\n",
      "num_layers = 1\n",
      "output_size = 1\n",
      "self       = <models.LanguageModel object at 0x1575c7e00>\n",
      "seq_model  = 'lstm'\n",
      "\n",
      "\u001b[1m\u001b[31mapps/models.py\u001b[0m:38: NotImplementedError\n",
      "\u001b[31m\u001b[1m______ test_language_model_implementation[cpu-lstm-1-False-12-1-15-1-13] _______\u001b[0m\n",
      "\n",
      "seq_length = 13, num_layers = 1, batch_size = 15, embedding_size = 1\n",
      "hidden_size = 12, init_hidden = False, output_size = 1, seq_model = 'lstm'\n",
      "device = cpu()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\u001b[90m\u001b[39;49;00m\n",
      "                            init_hidden, output_size, seq_model, device):\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      ">       model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "batch_size = 15\n",
      "c0         = needle.Tensor([[[-0.54631263 -0.3129961   1.2429127  -0.2540315  -0.20368522\n",
      "    0.17865887 -1.141915   -0.5133077   1...666 -0.98236746 -1.0483307\n",
      "    0.03211004  0.54759467 -1.0143025   0.8941929   0.4176953\n",
      "   -0.15406793  0.9253925 ]]])\n",
      "device     = cpu()\n",
      "embedding_size = 1\n",
      "h0         = needle.Tensor([[[-1.5277915  -1.205496   -1.2267427  -1.7192672  -0.09078467\n",
      "    1.3156832  -0.3079554  -1.6948887  -1...33  -1.2470206  -1.662908\n",
      "   -0.08094677  0.7868396  -1.3055694  -0.19450447  0.05366148\n",
      "   -1.3642322   0.07157467]]])\n",
      "hidden_size = 12\n",
      "init_hidden = False\n",
      "num_layers = 1\n",
      "output_size = 1\n",
      "seq_length = 13\n",
      "seq_model  = 'lstm'\n",
      "x          = array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0...0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "      dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:201: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "self = <models.LanguageModel object at 0x15779b530>, embedding_size = 1\n",
      "output_size = 1, hidden_size = 12, num_layers = 1, seq_model = 'lstm'\n",
      "device = cpu(), dtype = 'float32'\n",
      "\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92m__init__\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, embedding_size, output_size, hidden_size, num_layers=\u001b[94m1\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                 seq_model=\u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, device=\u001b[94mNone\u001b[39;49;00m, dtype=\u001b[33m\"\u001b[39;49;00m\u001b[33mfloat32\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"\u001b[39;49;00m\n",
      "    \u001b[33m    Consists of an embedding layer, a sequence model (either RNN or LSTM), and a\u001b[39;49;00m\n",
      "    \u001b[33m    linear layer.\u001b[39;49;00m\n",
      "    \u001b[33m    Parameters:\u001b[39;49;00m\n",
      "    \u001b[33m    output_size: Size of dictionary\u001b[39;49;00m\n",
      "    \u001b[33m    embedding_size: Size of embeddings\u001b[39;49;00m\n",
      "    \u001b[33m    hidden_size: The number of features in the hidden state of LSTM or RNN\u001b[39;49;00m\n",
      "    \u001b[33m    seq_model: 'rnn' or 'lstm', whether to use RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    num_layers: Number of layers in RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    \"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[96msuper\u001b[39;49;00m(LanguageModel, \u001b[96mself\u001b[39;49;00m).\u001b[92m__init__\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m### BEGIN YOUR SOLUTION\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94mraise\u001b[39;49;00m \u001b[96mNotImplementedError\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       NotImplementedError\u001b[0m\n",
      "\n",
      "__class__  = <class 'models.LanguageModel'>\n",
      "device     = cpu()\n",
      "dtype      = 'float32'\n",
      "embedding_size = 1\n",
      "hidden_size = 12\n",
      "num_layers = 1\n",
      "output_size = 1\n",
      "self       = <models.LanguageModel object at 0x15779b530>\n",
      "seq_model  = 'lstm'\n",
      "\n",
      "\u001b[1m\u001b[31mapps/models.py\u001b[0m:38: NotImplementedError\n",
      "\u001b[31m\u001b[1m_______ test_language_model_implementation[cpu-lstm-1-False-12-1-15-2-1] _______\u001b[0m\n",
      "\n",
      "seq_length = 1, num_layers = 2, batch_size = 15, embedding_size = 1\n",
      "hidden_size = 12, init_hidden = False, output_size = 1, seq_model = 'lstm'\n",
      "device = cpu()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\u001b[90m\u001b[39;49;00m\n",
      "                            init_hidden, output_size, seq_model, device):\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      ">       model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "batch_size = 15\n",
      "c0         = needle.Tensor([[[-6.5098608e-01 -1.3955305e+00 -1.3576592e+00  3.4610599e-01\n",
      "   -1.0977430e+00 -1.8275800e+00  3.33225...936e-01 -8.4953105e-01  5.0588894e-01  9.5000279e-01\n",
      "    6.7118197e-03  8.5040867e-01  2.7111463e-02 -4.2133492e-01]]])\n",
      "device     = cpu()\n",
      "embedding_size = 1\n",
      "h0         = needle.Tensor([[[ 1.68157387e+00 -1.19793081e+00  1.35544553e-01 -4.60098743e-01\n",
      "   -4.04604107e-01  7.01358318e-02 -7...  2.07523108e-01  1.63795066e+00  7.56984353e-01\n",
      "   -7.71496832e-01  9.64134693e-01 -1.06197190e+00  1.55507311e-01]]])\n",
      "hidden_size = 12\n",
      "init_hidden = False\n",
      "num_layers = 2\n",
      "output_size = 1\n",
      "seq_length = 1\n",
      "seq_model  = 'lstm'\n",
      "x          = array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "      dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:201: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "self = <models.LanguageModel object at 0x1577c4b00>, embedding_size = 1\n",
      "output_size = 1, hidden_size = 12, num_layers = 2, seq_model = 'lstm'\n",
      "device = cpu(), dtype = 'float32'\n",
      "\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92m__init__\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, embedding_size, output_size, hidden_size, num_layers=\u001b[94m1\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                 seq_model=\u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, device=\u001b[94mNone\u001b[39;49;00m, dtype=\u001b[33m\"\u001b[39;49;00m\u001b[33mfloat32\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"\u001b[39;49;00m\n",
      "    \u001b[33m    Consists of an embedding layer, a sequence model (either RNN or LSTM), and a\u001b[39;49;00m\n",
      "    \u001b[33m    linear layer.\u001b[39;49;00m\n",
      "    \u001b[33m    Parameters:\u001b[39;49;00m\n",
      "    \u001b[33m    output_size: Size of dictionary\u001b[39;49;00m\n",
      "    \u001b[33m    embedding_size: Size of embeddings\u001b[39;49;00m\n",
      "    \u001b[33m    hidden_size: The number of features in the hidden state of LSTM or RNN\u001b[39;49;00m\n",
      "    \u001b[33m    seq_model: 'rnn' or 'lstm', whether to use RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    num_layers: Number of layers in RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    \"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[96msuper\u001b[39;49;00m(LanguageModel, \u001b[96mself\u001b[39;49;00m).\u001b[92m__init__\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m### BEGIN YOUR SOLUTION\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94mraise\u001b[39;49;00m \u001b[96mNotImplementedError\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       NotImplementedError\u001b[0m\n",
      "\n",
      "__class__  = <class 'models.LanguageModel'>\n",
      "device     = cpu()\n",
      "dtype      = 'float32'\n",
      "embedding_size = 1\n",
      "hidden_size = 12\n",
      "num_layers = 2\n",
      "output_size = 1\n",
      "self       = <models.LanguageModel object at 0x1577c4b00>\n",
      "seq_model  = 'lstm'\n",
      "\n",
      "\u001b[1m\u001b[31mapps/models.py\u001b[0m:38: NotImplementedError\n",
      "\u001b[31m\u001b[1m______ test_language_model_implementation[cpu-lstm-1-False-12-1-15-2-13] _______\u001b[0m\n",
      "\n",
      "seq_length = 13, num_layers = 2, batch_size = 15, embedding_size = 1\n",
      "hidden_size = 12, init_hidden = False, output_size = 1, seq_model = 'lstm'\n",
      "device = cpu()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\u001b[90m\u001b[39;49;00m\n",
      "                            init_hidden, output_size, seq_model, device):\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      ">       model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "batch_size = 15\n",
      "c0         = needle.Tensor([[[-5.22904873e-01 -5.04911728e-02 -1.90889642e-01  8.95520031e-01\n",
      "   -1.98681980e-01  8.26198280e-01 -8...  5.28723776e-01 -1.17674875e+00 -1.37184179e+00\n",
      "   -1.55841017e+00  1.45146692e+00  8.59202445e-01  3.09980899e-01]]])\n",
      "device     = cpu()\n",
      "embedding_size = 1\n",
      "h0         = needle.Tensor([[[ 1.36140108e-01 -7.19826579e-01 -1.49299634e+00 -3.60064119e-01\n",
      "    7.62735069e-01  1.47214639e+00  1...  2.75163680e-01 -6.88994586e-01 -7.67156407e-02\n",
      "    5.26447892e-01  5.11453509e-01  6.03700638e-01 -1.11400639e-03]]])\n",
      "hidden_size = 12\n",
      "init_hidden = False\n",
      "num_layers = 2\n",
      "output_size = 1\n",
      "seq_length = 13\n",
      "seq_model  = 'lstm'\n",
      "x          = array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0...0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "      dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:201: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "self = <models.LanguageModel object at 0x1694aa390>, embedding_size = 1\n",
      "output_size = 1, hidden_size = 12, num_layers = 2, seq_model = 'lstm'\n",
      "device = cpu(), dtype = 'float32'\n",
      "\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92m__init__\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, embedding_size, output_size, hidden_size, num_layers=\u001b[94m1\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                 seq_model=\u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, device=\u001b[94mNone\u001b[39;49;00m, dtype=\u001b[33m\"\u001b[39;49;00m\u001b[33mfloat32\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"\u001b[39;49;00m\n",
      "    \u001b[33m    Consists of an embedding layer, a sequence model (either RNN or LSTM), and a\u001b[39;49;00m\n",
      "    \u001b[33m    linear layer.\u001b[39;49;00m\n",
      "    \u001b[33m    Parameters:\u001b[39;49;00m\n",
      "    \u001b[33m    output_size: Size of dictionary\u001b[39;49;00m\n",
      "    \u001b[33m    embedding_size: Size of embeddings\u001b[39;49;00m\n",
      "    \u001b[33m    hidden_size: The number of features in the hidden state of LSTM or RNN\u001b[39;49;00m\n",
      "    \u001b[33m    seq_model: 'rnn' or 'lstm', whether to use RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    num_layers: Number of layers in RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    \"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[96msuper\u001b[39;49;00m(LanguageModel, \u001b[96mself\u001b[39;49;00m).\u001b[92m__init__\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m### BEGIN YOUR SOLUTION\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94mraise\u001b[39;49;00m \u001b[96mNotImplementedError\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       NotImplementedError\u001b[0m\n",
      "\n",
      "__class__  = <class 'models.LanguageModel'>\n",
      "device     = cpu()\n",
      "dtype      = 'float32'\n",
      "embedding_size = 1\n",
      "hidden_size = 12\n",
      "num_layers = 2\n",
      "output_size = 1\n",
      "self       = <models.LanguageModel object at 0x1694aa390>\n",
      "seq_model  = 'lstm'\n",
      "\n",
      "\u001b[1m\u001b[31mapps/models.py\u001b[0m:38: NotImplementedError\n",
      "\u001b[31m\u001b[1m_______ test_language_model_implementation[cpu-lstm-1-False-12-34-1-1-1] _______\u001b[0m\n",
      "\n",
      "seq_length = 1, num_layers = 1, batch_size = 1, embedding_size = 34\n",
      "hidden_size = 12, init_hidden = False, output_size = 1, seq_model = 'lstm'\n",
      "device = cpu()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\u001b[90m\u001b[39;49;00m\n",
      "                            init_hidden, output_size, seq_model, device):\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      ">       model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "batch_size = 1\n",
      "c0         = needle.Tensor([[[-1.1019264   0.76148397 -0.9903364   0.41917804 -1.6545599\n",
      "   -1.0273691  -0.3537915   1.0107207  -0.9959153   0.4743059\n",
      "   -1.3171139   0.39194712]]])\n",
      "device     = cpu()\n",
      "embedding_size = 34\n",
      "h0         = needle.Tensor([[[-0.37028503 -0.73006445  0.5605461  -0.4327868   0.2929365\n",
      "    0.90938544 -0.07698828  0.56889695 -0.13182339 -0.54457575\n",
      "    2.1325738  -1.2394477 ]]])\n",
      "hidden_size = 12\n",
      "init_hidden = False\n",
      "num_layers = 1\n",
      "output_size = 1\n",
      "seq_length = 1\n",
      "seq_model  = 'lstm'\n",
      "x          = array([[0.]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:201: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "self = <models.LanguageModel object at 0x1694aaf00>, embedding_size = 34\n",
      "output_size = 1, hidden_size = 12, num_layers = 1, seq_model = 'lstm'\n",
      "device = cpu(), dtype = 'float32'\n",
      "\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92m__init__\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, embedding_size, output_size, hidden_size, num_layers=\u001b[94m1\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                 seq_model=\u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, device=\u001b[94mNone\u001b[39;49;00m, dtype=\u001b[33m\"\u001b[39;49;00m\u001b[33mfloat32\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"\u001b[39;49;00m\n",
      "    \u001b[33m    Consists of an embedding layer, a sequence model (either RNN or LSTM), and a\u001b[39;49;00m\n",
      "    \u001b[33m    linear layer.\u001b[39;49;00m\n",
      "    \u001b[33m    Parameters:\u001b[39;49;00m\n",
      "    \u001b[33m    output_size: Size of dictionary\u001b[39;49;00m\n",
      "    \u001b[33m    embedding_size: Size of embeddings\u001b[39;49;00m\n",
      "    \u001b[33m    hidden_size: The number of features in the hidden state of LSTM or RNN\u001b[39;49;00m\n",
      "    \u001b[33m    seq_model: 'rnn' or 'lstm', whether to use RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    num_layers: Number of layers in RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    \"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[96msuper\u001b[39;49;00m(LanguageModel, \u001b[96mself\u001b[39;49;00m).\u001b[92m__init__\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m### BEGIN YOUR SOLUTION\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94mraise\u001b[39;49;00m \u001b[96mNotImplementedError\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       NotImplementedError\u001b[0m\n",
      "\n",
      "__class__  = <class 'models.LanguageModel'>\n",
      "device     = cpu()\n",
      "dtype      = 'float32'\n",
      "embedding_size = 34\n",
      "hidden_size = 12\n",
      "num_layers = 1\n",
      "output_size = 1\n",
      "self       = <models.LanguageModel object at 0x1694aaf00>\n",
      "seq_model  = 'lstm'\n",
      "\n",
      "\u001b[1m\u001b[31mapps/models.py\u001b[0m:38: NotImplementedError\n",
      "\u001b[31m\u001b[1m______ test_language_model_implementation[cpu-lstm-1-False-12-34-1-1-13] _______\u001b[0m\n",
      "\n",
      "seq_length = 13, num_layers = 1, batch_size = 1, embedding_size = 34\n",
      "hidden_size = 12, init_hidden = False, output_size = 1, seq_model = 'lstm'\n",
      "device = cpu()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\u001b[90m\u001b[39;49;00m\n",
      "                            init_hidden, output_size, seq_model, device):\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      ">       model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "batch_size = 1\n",
      "c0         = needle.Tensor([[[ 0.83449477  0.09244004 -1.2077957   0.49734563 -0.035172\n",
      "   -1.3080963   0.82038325  1.2073294  -0.03751603 -1.510423\n",
      "   -0.7999005   0.23626633]]])\n",
      "device     = cpu()\n",
      "embedding_size = 34\n",
      "h0         = needle.Tensor([[[-0.22655141 -0.19438611  0.78636974 -0.92581177  0.46446723\n",
      "    0.14317034  1.763994    0.3924601   0.46634945  1.3827112\n",
      "    0.19899955 -1.587227  ]]])\n",
      "hidden_size = 12\n",
      "init_hidden = False\n",
      "num_layers = 1\n",
      "output_size = 1\n",
      "seq_length = 13\n",
      "seq_model  = 'lstm'\n",
      "x          = array([[0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:201: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "self = <models.LanguageModel object at 0x1694e6e70>, embedding_size = 34\n",
      "output_size = 1, hidden_size = 12, num_layers = 1, seq_model = 'lstm'\n",
      "device = cpu(), dtype = 'float32'\n",
      "\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92m__init__\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, embedding_size, output_size, hidden_size, num_layers=\u001b[94m1\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                 seq_model=\u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, device=\u001b[94mNone\u001b[39;49;00m, dtype=\u001b[33m\"\u001b[39;49;00m\u001b[33mfloat32\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"\u001b[39;49;00m\n",
      "    \u001b[33m    Consists of an embedding layer, a sequence model (either RNN or LSTM), and a\u001b[39;49;00m\n",
      "    \u001b[33m    linear layer.\u001b[39;49;00m\n",
      "    \u001b[33m    Parameters:\u001b[39;49;00m\n",
      "    \u001b[33m    output_size: Size of dictionary\u001b[39;49;00m\n",
      "    \u001b[33m    embedding_size: Size of embeddings\u001b[39;49;00m\n",
      "    \u001b[33m    hidden_size: The number of features in the hidden state of LSTM or RNN\u001b[39;49;00m\n",
      "    \u001b[33m    seq_model: 'rnn' or 'lstm', whether to use RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    num_layers: Number of layers in RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    \"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[96msuper\u001b[39;49;00m(LanguageModel, \u001b[96mself\u001b[39;49;00m).\u001b[92m__init__\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m### BEGIN YOUR SOLUTION\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94mraise\u001b[39;49;00m \u001b[96mNotImplementedError\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       NotImplementedError\u001b[0m\n",
      "\n",
      "__class__  = <class 'models.LanguageModel'>\n",
      "device     = cpu()\n",
      "dtype      = 'float32'\n",
      "embedding_size = 34\n",
      "hidden_size = 12\n",
      "num_layers = 1\n",
      "output_size = 1\n",
      "self       = <models.LanguageModel object at 0x1694e6e70>\n",
      "seq_model  = 'lstm'\n",
      "\n",
      "\u001b[1m\u001b[31mapps/models.py\u001b[0m:38: NotImplementedError\n",
      "\u001b[31m\u001b[1m_______ test_language_model_implementation[cpu-lstm-1-False-12-34-1-2-1] _______\u001b[0m\n",
      "\n",
      "seq_length = 1, num_layers = 2, batch_size = 1, embedding_size = 34\n",
      "hidden_size = 12, init_hidden = False, output_size = 1, seq_model = 'lstm'\n",
      "device = cpu()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\u001b[90m\u001b[39;49;00m\n",
      "                            init_hidden, output_size, seq_model, device):\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      ">       model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "batch_size = 1\n",
      "c0         = needle.Tensor([[[ 0.35409808 -0.53675044 -0.49097854 -0.6978196  -0.08994326\n",
      "    2.4271963  -0.69326353  1.4052595  -0...7  -0.5743027  -0.92027175\n",
      "    1.0598947   0.38107926 -0.10435038  0.19733706 -0.3206056\n",
      "   -1.3076817  -0.2424673 ]]])\n",
      "device     = cpu()\n",
      "embedding_size = 34\n",
      "h0         = needle.Tensor([[[ 0.8008083   0.68687224  0.6343834  -0.141311    0.03650745\n",
      "    0.75198793  0.4964108   0.5509048  -0...324  2.5294628   1.4980354\n",
      "    0.39586914 -1.2885455  -0.64115196  0.240725    1.0962255\n",
      "   -1.5906657   1.7756975 ]]])\n",
      "hidden_size = 12\n",
      "init_hidden = False\n",
      "num_layers = 2\n",
      "output_size = 1\n",
      "seq_length = 1\n",
      "seq_model  = 'lstm'\n",
      "x          = array([[0.]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:201: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "self = <models.LanguageModel object at 0x1694e64e0>, embedding_size = 34\n",
      "output_size = 1, hidden_size = 12, num_layers = 2, seq_model = 'lstm'\n",
      "device = cpu(), dtype = 'float32'\n",
      "\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92m__init__\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, embedding_size, output_size, hidden_size, num_layers=\u001b[94m1\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                 seq_model=\u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, device=\u001b[94mNone\u001b[39;49;00m, dtype=\u001b[33m\"\u001b[39;49;00m\u001b[33mfloat32\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"\u001b[39;49;00m\n",
      "    \u001b[33m    Consists of an embedding layer, a sequence model (either RNN or LSTM), and a\u001b[39;49;00m\n",
      "    \u001b[33m    linear layer.\u001b[39;49;00m\n",
      "    \u001b[33m    Parameters:\u001b[39;49;00m\n",
      "    \u001b[33m    output_size: Size of dictionary\u001b[39;49;00m\n",
      "    \u001b[33m    embedding_size: Size of embeddings\u001b[39;49;00m\n",
      "    \u001b[33m    hidden_size: The number of features in the hidden state of LSTM or RNN\u001b[39;49;00m\n",
      "    \u001b[33m    seq_model: 'rnn' or 'lstm', whether to use RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    num_layers: Number of layers in RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    \"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[96msuper\u001b[39;49;00m(LanguageModel, \u001b[96mself\u001b[39;49;00m).\u001b[92m__init__\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m### BEGIN YOUR SOLUTION\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94mraise\u001b[39;49;00m \u001b[96mNotImplementedError\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       NotImplementedError\u001b[0m\n",
      "\n",
      "__class__  = <class 'models.LanguageModel'>\n",
      "device     = cpu()\n",
      "dtype      = 'float32'\n",
      "embedding_size = 34\n",
      "hidden_size = 12\n",
      "num_layers = 2\n",
      "output_size = 1\n",
      "self       = <models.LanguageModel object at 0x1694e64e0>\n",
      "seq_model  = 'lstm'\n",
      "\n",
      "\u001b[1m\u001b[31mapps/models.py\u001b[0m:38: NotImplementedError\n",
      "\u001b[31m\u001b[1m______ test_language_model_implementation[cpu-lstm-1-False-12-34-1-2-13] _______\u001b[0m\n",
      "\n",
      "seq_length = 13, num_layers = 2, batch_size = 1, embedding_size = 34\n",
      "hidden_size = 12, init_hidden = False, output_size = 1, seq_model = 'lstm'\n",
      "device = cpu()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\u001b[90m\u001b[39;49;00m\n",
      "                            init_hidden, output_size, seq_model, device):\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      ">       model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "batch_size = 1\n",
      "c0         = needle.Tensor([[[-0.05283334 -0.932794   -0.8543386   0.36252818 -0.19666126\n",
      "   -0.6723865  -0.6135193  -0.2696369   0...08   1.2376578  -0.3839364\n",
      "    0.03350095  0.20509768  0.02879325 -0.96996826  2.9630651\n",
      "    0.9353321  -1.1862396 ]]])\n",
      "device     = cpu()\n",
      "embedding_size = 34\n",
      "h0         = needle.Tensor([[[-0.1163356   0.02115646 -0.13385965  1.2137861   1.2011142\n",
      "    0.20313029 -0.94808626 -0.13542661  1....  -0.48153847 -0.33629295\n",
      "    0.8197384  -1.0497911   0.03735531 -0.4832011  -0.12784207\n",
      "    0.82328045  0.5071003 ]]])\n",
      "hidden_size = 12\n",
      "init_hidden = False\n",
      "num_layers = 2\n",
      "output_size = 1\n",
      "seq_length = 13\n",
      "seq_model  = 'lstm'\n",
      "x          = array([[0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:201: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "self = <models.LanguageModel object at 0x1577c55b0>, embedding_size = 34\n",
      "output_size = 1, hidden_size = 12, num_layers = 2, seq_model = 'lstm'\n",
      "device = cpu(), dtype = 'float32'\n",
      "\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92m__init__\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, embedding_size, output_size, hidden_size, num_layers=\u001b[94m1\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                 seq_model=\u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, device=\u001b[94mNone\u001b[39;49;00m, dtype=\u001b[33m\"\u001b[39;49;00m\u001b[33mfloat32\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"\u001b[39;49;00m\n",
      "    \u001b[33m    Consists of an embedding layer, a sequence model (either RNN or LSTM), and a\u001b[39;49;00m\n",
      "    \u001b[33m    linear layer.\u001b[39;49;00m\n",
      "    \u001b[33m    Parameters:\u001b[39;49;00m\n",
      "    \u001b[33m    output_size: Size of dictionary\u001b[39;49;00m\n",
      "    \u001b[33m    embedding_size: Size of embeddings\u001b[39;49;00m\n",
      "    \u001b[33m    hidden_size: The number of features in the hidden state of LSTM or RNN\u001b[39;49;00m\n",
      "    \u001b[33m    seq_model: 'rnn' or 'lstm', whether to use RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    num_layers: Number of layers in RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    \"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[96msuper\u001b[39;49;00m(LanguageModel, \u001b[96mself\u001b[39;49;00m).\u001b[92m__init__\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m### BEGIN YOUR SOLUTION\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94mraise\u001b[39;49;00m \u001b[96mNotImplementedError\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       NotImplementedError\u001b[0m\n",
      "\n",
      "__class__  = <class 'models.LanguageModel'>\n",
      "device     = cpu()\n",
      "dtype      = 'float32'\n",
      "embedding_size = 34\n",
      "hidden_size = 12\n",
      "num_layers = 2\n",
      "output_size = 1\n",
      "self       = <models.LanguageModel object at 0x1577c55b0>\n",
      "seq_model  = 'lstm'\n",
      "\n",
      "\u001b[1m\u001b[31mapps/models.py\u001b[0m:38: NotImplementedError\n",
      "\u001b[31m\u001b[1m______ test_language_model_implementation[cpu-lstm-1-False-12-34-15-1-1] _______\u001b[0m\n",
      "\n",
      "seq_length = 1, num_layers = 1, batch_size = 15, embedding_size = 34\n",
      "hidden_size = 12, init_hidden = False, output_size = 1, seq_model = 'lstm'\n",
      "device = cpu()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\u001b[90m\u001b[39;49;00m\n",
      "                            init_hidden, output_size, seq_model, device):\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      ">       model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "batch_size = 15\n",
      "c0         = needle.Tensor([[[ 1.77442804e-01 -9.33792964e-02  9.20847297e-01 -2.20414296e-01\n",
      "    1.30438888e+00 -2.70079160e+00  3...  7.05662847e-01  3.96974921e-01  9.21815455e-01\n",
      "    2.22985125e+00 -3.10098410e-01  2.90365905e-01  1.57576752e+00]]])\n",
      "device     = cpu()\n",
      "embedding_size = 34\n",
      "h0         = needle.Tensor([[[ 0.5018356   0.3079278   0.11848446 -0.17572029  0.27376804\n",
      "   -1.4365805  -0.28886408 -0.13954586  1...39  -1.4927754  -1.3666577\n",
      "   -0.54822993 -1.470734    1.6693301   0.14704424  1.3538905\n",
      "    2.2396588  -0.17603476]]])\n",
      "hidden_size = 12\n",
      "init_hidden = False\n",
      "num_layers = 1\n",
      "output_size = 1\n",
      "seq_length = 1\n",
      "seq_model  = 'lstm'\n",
      "x          = array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "      dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:201: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "self = <models.LanguageModel object at 0x1575c4680>, embedding_size = 34\n",
      "output_size = 1, hidden_size = 12, num_layers = 1, seq_model = 'lstm'\n",
      "device = cpu(), dtype = 'float32'\n",
      "\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92m__init__\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, embedding_size, output_size, hidden_size, num_layers=\u001b[94m1\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                 seq_model=\u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, device=\u001b[94mNone\u001b[39;49;00m, dtype=\u001b[33m\"\u001b[39;49;00m\u001b[33mfloat32\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"\u001b[39;49;00m\n",
      "    \u001b[33m    Consists of an embedding layer, a sequence model (either RNN or LSTM), and a\u001b[39;49;00m\n",
      "    \u001b[33m    linear layer.\u001b[39;49;00m\n",
      "    \u001b[33m    Parameters:\u001b[39;49;00m\n",
      "    \u001b[33m    output_size: Size of dictionary\u001b[39;49;00m\n",
      "    \u001b[33m    embedding_size: Size of embeddings\u001b[39;49;00m\n",
      "    \u001b[33m    hidden_size: The number of features in the hidden state of LSTM or RNN\u001b[39;49;00m\n",
      "    \u001b[33m    seq_model: 'rnn' or 'lstm', whether to use RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    num_layers: Number of layers in RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    \"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[96msuper\u001b[39;49;00m(LanguageModel, \u001b[96mself\u001b[39;49;00m).\u001b[92m__init__\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m### BEGIN YOUR SOLUTION\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94mraise\u001b[39;49;00m \u001b[96mNotImplementedError\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       NotImplementedError\u001b[0m\n",
      "\n",
      "__class__  = <class 'models.LanguageModel'>\n",
      "device     = cpu()\n",
      "dtype      = 'float32'\n",
      "embedding_size = 34\n",
      "hidden_size = 12\n",
      "num_layers = 1\n",
      "output_size = 1\n",
      "self       = <models.LanguageModel object at 0x1575c4680>\n",
      "seq_model  = 'lstm'\n",
      "\n",
      "\u001b[1m\u001b[31mapps/models.py\u001b[0m:38: NotImplementedError\n",
      "\u001b[31m\u001b[1m______ test_language_model_implementation[cpu-lstm-1-False-12-34-15-1-13] ______\u001b[0m\n",
      "\n",
      "seq_length = 13, num_layers = 1, batch_size = 15, embedding_size = 34\n",
      "hidden_size = 12, init_hidden = False, output_size = 1, seq_model = 'lstm'\n",
      "device = cpu()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\u001b[90m\u001b[39;49;00m\n",
      "                            init_hidden, output_size, seq_model, device):\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      ">       model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "batch_size = 15\n",
      "c0         = needle.Tensor([[[-7.98379421e-01  2.23461166e-01  1.09815188e-01 -4.66720276e-02\n",
      "   -9.00264442e-01 -1.94946969e+00 -1... -5.13476014e-01  1.07242072e+00 -1.26322401e+00\n",
      "    3.06923002e-01  5.58647737e-02  4.94354635e-01  1.44810081e+00]]])\n",
      "device     = cpu()\n",
      "embedding_size = 34\n",
      "h0         = needle.Tensor([[[ 0.36726892 -0.60323673  0.8317267   0.12733503 -0.2605184\n",
      "   -0.71148705  1.3653363   0.3051549  -0....    0.928967   -0.29790103\n",
      "   -1.7787453   1.4012426   2.381957   -1.949191    0.2823318\n",
      "   -0.68671036  0.7699133 ]]])\n",
      "hidden_size = 12\n",
      "init_hidden = False\n",
      "num_layers = 1\n",
      "output_size = 1\n",
      "seq_length = 13\n",
      "seq_model  = 'lstm'\n",
      "x          = array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0...0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "      dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:201: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "self = <models.LanguageModel object at 0x1694a40b0>, embedding_size = 34\n",
      "output_size = 1, hidden_size = 12, num_layers = 1, seq_model = 'lstm'\n",
      "device = cpu(), dtype = 'float32'\n",
      "\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92m__init__\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, embedding_size, output_size, hidden_size, num_layers=\u001b[94m1\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                 seq_model=\u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, device=\u001b[94mNone\u001b[39;49;00m, dtype=\u001b[33m\"\u001b[39;49;00m\u001b[33mfloat32\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"\u001b[39;49;00m\n",
      "    \u001b[33m    Consists of an embedding layer, a sequence model (either RNN or LSTM), and a\u001b[39;49;00m\n",
      "    \u001b[33m    linear layer.\u001b[39;49;00m\n",
      "    \u001b[33m    Parameters:\u001b[39;49;00m\n",
      "    \u001b[33m    output_size: Size of dictionary\u001b[39;49;00m\n",
      "    \u001b[33m    embedding_size: Size of embeddings\u001b[39;49;00m\n",
      "    \u001b[33m    hidden_size: The number of features in the hidden state of LSTM or RNN\u001b[39;49;00m\n",
      "    \u001b[33m    seq_model: 'rnn' or 'lstm', whether to use RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    num_layers: Number of layers in RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    \"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[96msuper\u001b[39;49;00m(LanguageModel, \u001b[96mself\u001b[39;49;00m).\u001b[92m__init__\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m### BEGIN YOUR SOLUTION\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94mraise\u001b[39;49;00m \u001b[96mNotImplementedError\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       NotImplementedError\u001b[0m\n",
      "\n",
      "__class__  = <class 'models.LanguageModel'>\n",
      "device     = cpu()\n",
      "dtype      = 'float32'\n",
      "embedding_size = 34\n",
      "hidden_size = 12\n",
      "num_layers = 1\n",
      "output_size = 1\n",
      "self       = <models.LanguageModel object at 0x1694a40b0>\n",
      "seq_model  = 'lstm'\n",
      "\n",
      "\u001b[1m\u001b[31mapps/models.py\u001b[0m:38: NotImplementedError\n",
      "\u001b[31m\u001b[1m______ test_language_model_implementation[cpu-lstm-1-False-12-34-15-2-1] _______\u001b[0m\n",
      "\n",
      "seq_length = 1, num_layers = 2, batch_size = 15, embedding_size = 34\n",
      "hidden_size = 12, init_hidden = False, output_size = 1, seq_model = 'lstm'\n",
      "device = cpu()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\u001b[90m\u001b[39;49;00m\n",
      "                            init_hidden, output_size, seq_model, device):\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      ">       model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "batch_size = 15\n",
      "c0         = needle.Tensor([[[-1.11494827e+00  1.24934435e-01 -4.68386412e-01  1.16217107e-01\n",
      "    1.78692651e+00  2.88236946e-01  1... -6.79734528e-01  2.78859437e-01 -5.21520436e-01\n",
      "    9.12930787e-01  1.30688000e+00  6.90486610e-01  6.96966827e-01]]])\n",
      "device     = cpu()\n",
      "embedding_size = 34\n",
      "h0         = needle.Tensor([[[ 1.3898135e+00 -7.4017689e-02 -6.2292284e-01  6.7669797e-01\n",
      "   -1.9102553e-01 -9.9565226e-01  1.92630...865e+00 -2.1976457e+00  9.3184447e-01  2.9402515e-01\n",
      "   -1.6433744e-02 -5.5574888e-01  9.5672530e-01  4.8684168e-01]]])\n",
      "hidden_size = 12\n",
      "init_hidden = False\n",
      "num_layers = 2\n",
      "output_size = 1\n",
      "seq_length = 1\n",
      "seq_model  = 'lstm'\n",
      "x          = array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "      dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:201: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "self = <models.LanguageModel object at 0x1577970e0>, embedding_size = 34\n",
      "output_size = 1, hidden_size = 12, num_layers = 2, seq_model = 'lstm'\n",
      "device = cpu(), dtype = 'float32'\n",
      "\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92m__init__\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, embedding_size, output_size, hidden_size, num_layers=\u001b[94m1\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                 seq_model=\u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, device=\u001b[94mNone\u001b[39;49;00m, dtype=\u001b[33m\"\u001b[39;49;00m\u001b[33mfloat32\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"\u001b[39;49;00m\n",
      "    \u001b[33m    Consists of an embedding layer, a sequence model (either RNN or LSTM), and a\u001b[39;49;00m\n",
      "    \u001b[33m    linear layer.\u001b[39;49;00m\n",
      "    \u001b[33m    Parameters:\u001b[39;49;00m\n",
      "    \u001b[33m    output_size: Size of dictionary\u001b[39;49;00m\n",
      "    \u001b[33m    embedding_size: Size of embeddings\u001b[39;49;00m\n",
      "    \u001b[33m    hidden_size: The number of features in the hidden state of LSTM or RNN\u001b[39;49;00m\n",
      "    \u001b[33m    seq_model: 'rnn' or 'lstm', whether to use RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    num_layers: Number of layers in RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    \"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[96msuper\u001b[39;49;00m(LanguageModel, \u001b[96mself\u001b[39;49;00m).\u001b[92m__init__\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m### BEGIN YOUR SOLUTION\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94mraise\u001b[39;49;00m \u001b[96mNotImplementedError\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       NotImplementedError\u001b[0m\n",
      "\n",
      "__class__  = <class 'models.LanguageModel'>\n",
      "device     = cpu()\n",
      "dtype      = 'float32'\n",
      "embedding_size = 34\n",
      "hidden_size = 12\n",
      "num_layers = 2\n",
      "output_size = 1\n",
      "self       = <models.LanguageModel object at 0x1577970e0>\n",
      "seq_model  = 'lstm'\n",
      "\n",
      "\u001b[1m\u001b[31mapps/models.py\u001b[0m:38: NotImplementedError\n",
      "\u001b[31m\u001b[1m______ test_language_model_implementation[cpu-lstm-1-False-12-34-15-2-13] ______\u001b[0m\n",
      "\n",
      "seq_length = 13, num_layers = 2, batch_size = 15, embedding_size = 34\n",
      "hidden_size = 12, init_hidden = False, output_size = 1, seq_model = 'lstm'\n",
      "device = cpu()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\u001b[90m\u001b[39;49;00m\n",
      "                            init_hidden, output_size, seq_model, device):\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      ">       model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "batch_size = 15\n",
      "c0         = needle.Tensor([[[ 1.1007016  -1.2490927  -0.5798827  -1.2104574  -0.6561782\n",
      "   -1.3936652   1.4462062  -2.967794    0....656 -1.5177097  -0.4671387\n",
      "   -0.5830821   0.0419696  -0.12245003  0.25890538  1.3586329\n",
      "    0.77563757  1.2443701 ]]])\n",
      "device     = cpu()\n",
      "embedding_size = 34\n",
      "h0         = needle.Tensor([[[ 0.26353332 -1.4976217   0.7859202   0.25687984  1.2387142\n",
      "    0.07200597 -0.03664548 -1.108188   -0....18  0.30492082 -1.2502502\n",
      "    1.7412282   0.22923799  1.4853911  -1.2752727  -0.26342955\n",
      "   -1.3919249   0.10566806]]])\n",
      "hidden_size = 12\n",
      "init_hidden = False\n",
      "num_layers = 2\n",
      "output_size = 1\n",
      "seq_length = 13\n",
      "seq_model  = 'lstm'\n",
      "x          = array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0...0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "      dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:201: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "self = <models.LanguageModel object at 0x16945b890>, embedding_size = 34\n",
      "output_size = 1, hidden_size = 12, num_layers = 2, seq_model = 'lstm'\n",
      "device = cpu(), dtype = 'float32'\n",
      "\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92m__init__\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, embedding_size, output_size, hidden_size, num_layers=\u001b[94m1\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                 seq_model=\u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, device=\u001b[94mNone\u001b[39;49;00m, dtype=\u001b[33m\"\u001b[39;49;00m\u001b[33mfloat32\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"\u001b[39;49;00m\n",
      "    \u001b[33m    Consists of an embedding layer, a sequence model (either RNN or LSTM), and a\u001b[39;49;00m\n",
      "    \u001b[33m    linear layer.\u001b[39;49;00m\n",
      "    \u001b[33m    Parameters:\u001b[39;49;00m\n",
      "    \u001b[33m    output_size: Size of dictionary\u001b[39;49;00m\n",
      "    \u001b[33m    embedding_size: Size of embeddings\u001b[39;49;00m\n",
      "    \u001b[33m    hidden_size: The number of features in the hidden state of LSTM or RNN\u001b[39;49;00m\n",
      "    \u001b[33m    seq_model: 'rnn' or 'lstm', whether to use RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    num_layers: Number of layers in RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    \"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[96msuper\u001b[39;49;00m(LanguageModel, \u001b[96mself\u001b[39;49;00m).\u001b[92m__init__\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m### BEGIN YOUR SOLUTION\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94mraise\u001b[39;49;00m \u001b[96mNotImplementedError\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       NotImplementedError\u001b[0m\n",
      "\n",
      "__class__  = <class 'models.LanguageModel'>\n",
      "device     = cpu()\n",
      "dtype      = 'float32'\n",
      "embedding_size = 34\n",
      "hidden_size = 12\n",
      "num_layers = 2\n",
      "output_size = 1\n",
      "self       = <models.LanguageModel object at 0x16945b890>\n",
      "seq_model  = 'lstm'\n",
      "\n",
      "\u001b[1m\u001b[31mapps/models.py\u001b[0m:38: NotImplementedError\n",
      "\u001b[31m\u001b[1m_______ test_language_model_implementation[cpu-lstm-1000-True-1-1-1-1-1] _______\u001b[0m\n",
      "\n",
      "seq_length = 1, num_layers = 1, batch_size = 1, embedding_size = 1\n",
      "hidden_size = 1, init_hidden = True, output_size = 1000, seq_model = 'lstm'\n",
      "device = cpu()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\u001b[90m\u001b[39;49;00m\n",
      "                            init_hidden, output_size, seq_model, device):\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      ">       model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "batch_size = 1\n",
      "c0         = needle.Tensor([[[2.6252496]]])\n",
      "device     = cpu()\n",
      "embedding_size = 1\n",
      "h0         = needle.Tensor([[[0.16640204]]])\n",
      "hidden_size = 1\n",
      "init_hidden = True\n",
      "num_layers = 1\n",
      "output_size = 1000\n",
      "seq_length = 1\n",
      "seq_model  = 'lstm'\n",
      "x          = array([[364.]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:201: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "self = <models.LanguageModel object at 0x16945a3f0>, embedding_size = 1\n",
      "output_size = 1000, hidden_size = 1, num_layers = 1, seq_model = 'lstm'\n",
      "device = cpu(), dtype = 'float32'\n",
      "\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92m__init__\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, embedding_size, output_size, hidden_size, num_layers=\u001b[94m1\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                 seq_model=\u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, device=\u001b[94mNone\u001b[39;49;00m, dtype=\u001b[33m\"\u001b[39;49;00m\u001b[33mfloat32\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"\u001b[39;49;00m\n",
      "    \u001b[33m    Consists of an embedding layer, a sequence model (either RNN or LSTM), and a\u001b[39;49;00m\n",
      "    \u001b[33m    linear layer.\u001b[39;49;00m\n",
      "    \u001b[33m    Parameters:\u001b[39;49;00m\n",
      "    \u001b[33m    output_size: Size of dictionary\u001b[39;49;00m\n",
      "    \u001b[33m    embedding_size: Size of embeddings\u001b[39;49;00m\n",
      "    \u001b[33m    hidden_size: The number of features in the hidden state of LSTM or RNN\u001b[39;49;00m\n",
      "    \u001b[33m    seq_model: 'rnn' or 'lstm', whether to use RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    num_layers: Number of layers in RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    \"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[96msuper\u001b[39;49;00m(LanguageModel, \u001b[96mself\u001b[39;49;00m).\u001b[92m__init__\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m### BEGIN YOUR SOLUTION\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94mraise\u001b[39;49;00m \u001b[96mNotImplementedError\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       NotImplementedError\u001b[0m\n",
      "\n",
      "__class__  = <class 'models.LanguageModel'>\n",
      "device     = cpu()\n",
      "dtype      = 'float32'\n",
      "embedding_size = 1\n",
      "hidden_size = 1\n",
      "num_layers = 1\n",
      "output_size = 1000\n",
      "self       = <models.LanguageModel object at 0x16945a3f0>\n",
      "seq_model  = 'lstm'\n",
      "\n",
      "\u001b[1m\u001b[31mapps/models.py\u001b[0m:38: NotImplementedError\n",
      "\u001b[31m\u001b[1m______ test_language_model_implementation[cpu-lstm-1000-True-1-1-1-1-13] _______\u001b[0m\n",
      "\n",
      "seq_length = 13, num_layers = 1, batch_size = 1, embedding_size = 1\n",
      "hidden_size = 1, init_hidden = True, output_size = 1000, seq_model = 'lstm'\n",
      "device = cpu()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\u001b[90m\u001b[39;49;00m\n",
      "                            init_hidden, output_size, seq_model, device):\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      ">       model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "batch_size = 1\n",
      "c0         = needle.Tensor([[[-0.35309672]]])\n",
      "device     = cpu()\n",
      "embedding_size = 1\n",
      "h0         = needle.Tensor([[[-0.6804929]]])\n",
      "hidden_size = 1\n",
      "init_hidden = True\n",
      "num_layers = 1\n",
      "output_size = 1000\n",
      "seq_length = 13\n",
      "seq_model  = 'lstm'\n",
      "x          = array([[971.],\n",
      "       [887.],\n",
      "       [ 37.],\n",
      "       [845.],\n",
      "       [186.],\n",
      "       [981.],\n",
      "       [688.],\n",
      "       [ 50.],\n",
      "       [337.],\n",
      "       [613.],\n",
      "       [129.],\n",
      "       [842.],\n",
      "       [730.]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:201: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "self = <models.LanguageModel object at 0x16945a3c0>, embedding_size = 1\n",
      "output_size = 1000, hidden_size = 1, num_layers = 1, seq_model = 'lstm'\n",
      "device = cpu(), dtype = 'float32'\n",
      "\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92m__init__\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, embedding_size, output_size, hidden_size, num_layers=\u001b[94m1\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                 seq_model=\u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, device=\u001b[94mNone\u001b[39;49;00m, dtype=\u001b[33m\"\u001b[39;49;00m\u001b[33mfloat32\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"\u001b[39;49;00m\n",
      "    \u001b[33m    Consists of an embedding layer, a sequence model (either RNN or LSTM), and a\u001b[39;49;00m\n",
      "    \u001b[33m    linear layer.\u001b[39;49;00m\n",
      "    \u001b[33m    Parameters:\u001b[39;49;00m\n",
      "    \u001b[33m    output_size: Size of dictionary\u001b[39;49;00m\n",
      "    \u001b[33m    embedding_size: Size of embeddings\u001b[39;49;00m\n",
      "    \u001b[33m    hidden_size: The number of features in the hidden state of LSTM or RNN\u001b[39;49;00m\n",
      "    \u001b[33m    seq_model: 'rnn' or 'lstm', whether to use RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    num_layers: Number of layers in RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    \"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[96msuper\u001b[39;49;00m(LanguageModel, \u001b[96mself\u001b[39;49;00m).\u001b[92m__init__\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m### BEGIN YOUR SOLUTION\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94mraise\u001b[39;49;00m \u001b[96mNotImplementedError\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       NotImplementedError\u001b[0m\n",
      "\n",
      "__class__  = <class 'models.LanguageModel'>\n",
      "device     = cpu()\n",
      "dtype      = 'float32'\n",
      "embedding_size = 1\n",
      "hidden_size = 1\n",
      "num_layers = 1\n",
      "output_size = 1000\n",
      "self       = <models.LanguageModel object at 0x16945a3c0>\n",
      "seq_model  = 'lstm'\n",
      "\n",
      "\u001b[1m\u001b[31mapps/models.py\u001b[0m:38: NotImplementedError\n",
      "\u001b[31m\u001b[1m_______ test_language_model_implementation[cpu-lstm-1000-True-1-1-1-2-1] _______\u001b[0m\n",
      "\n",
      "seq_length = 1, num_layers = 2, batch_size = 1, embedding_size = 1\n",
      "hidden_size = 1, init_hidden = True, output_size = 1000, seq_model = 'lstm'\n",
      "device = cpu()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\u001b[90m\u001b[39;49;00m\n",
      "                            init_hidden, output_size, seq_model, device):\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      ">       model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "batch_size = 1\n",
      "c0         = needle.Tensor([[[0.63186616]]\n",
      "\n",
      " [[1.1626437 ]]])\n",
      "device     = cpu()\n",
      "embedding_size = 1\n",
      "h0         = needle.Tensor([[[-0.43359795]]\n",
      "\n",
      " [[-0.813482  ]]])\n",
      "hidden_size = 1\n",
      "init_hidden = True\n",
      "num_layers = 2\n",
      "output_size = 1000\n",
      "seq_length = 1\n",
      "seq_model  = 'lstm'\n",
      "x          = array([[662.]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:201: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "self = <models.LanguageModel object at 0x16945aa20>, embedding_size = 1\n",
      "output_size = 1000, hidden_size = 1, num_layers = 2, seq_model = 'lstm'\n",
      "device = cpu(), dtype = 'float32'\n",
      "\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92m__init__\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, embedding_size, output_size, hidden_size, num_layers=\u001b[94m1\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                 seq_model=\u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, device=\u001b[94mNone\u001b[39;49;00m, dtype=\u001b[33m\"\u001b[39;49;00m\u001b[33mfloat32\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"\u001b[39;49;00m\n",
      "    \u001b[33m    Consists of an embedding layer, a sequence model (either RNN or LSTM), and a\u001b[39;49;00m\n",
      "    \u001b[33m    linear layer.\u001b[39;49;00m\n",
      "    \u001b[33m    Parameters:\u001b[39;49;00m\n",
      "    \u001b[33m    output_size: Size of dictionary\u001b[39;49;00m\n",
      "    \u001b[33m    embedding_size: Size of embeddings\u001b[39;49;00m\n",
      "    \u001b[33m    hidden_size: The number of features in the hidden state of LSTM or RNN\u001b[39;49;00m\n",
      "    \u001b[33m    seq_model: 'rnn' or 'lstm', whether to use RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    num_layers: Number of layers in RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    \"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[96msuper\u001b[39;49;00m(LanguageModel, \u001b[96mself\u001b[39;49;00m).\u001b[92m__init__\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m### BEGIN YOUR SOLUTION\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94mraise\u001b[39;49;00m \u001b[96mNotImplementedError\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       NotImplementedError\u001b[0m\n",
      "\n",
      "__class__  = <class 'models.LanguageModel'>\n",
      "device     = cpu()\n",
      "dtype      = 'float32'\n",
      "embedding_size = 1\n",
      "hidden_size = 1\n",
      "num_layers = 2\n",
      "output_size = 1000\n",
      "self       = <models.LanguageModel object at 0x16945aa20>\n",
      "seq_model  = 'lstm'\n",
      "\n",
      "\u001b[1m\u001b[31mapps/models.py\u001b[0m:38: NotImplementedError\n",
      "\u001b[31m\u001b[1m______ test_language_model_implementation[cpu-lstm-1000-True-1-1-1-2-13] _______\u001b[0m\n",
      "\n",
      "seq_length = 13, num_layers = 2, batch_size = 1, embedding_size = 1\n",
      "hidden_size = 1, init_hidden = True, output_size = 1000, seq_model = 'lstm'\n",
      "device = cpu()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\u001b[90m\u001b[39;49;00m\n",
      "                            init_hidden, output_size, seq_model, device):\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      ">       model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "batch_size = 1\n",
      "c0         = needle.Tensor([[[0.01006261]]\n",
      "\n",
      " [[1.1893759 ]]])\n",
      "device     = cpu()\n",
      "embedding_size = 1\n",
      "h0         = needle.Tensor([[[0.61154145]]\n",
      "\n",
      " [[0.14044774]]])\n",
      "hidden_size = 1\n",
      "init_hidden = True\n",
      "num_layers = 2\n",
      "output_size = 1000\n",
      "seq_length = 13\n",
      "seq_model  = 'lstm'\n",
      "x          = array([[400.],\n",
      "       [743.],\n",
      "       [413.],\n",
      "       [874.],\n",
      "       [929.],\n",
      "       [ 61.],\n",
      "       [240.],\n",
      "       [634.],\n",
      "       [805.],\n",
      "       [543.],\n",
      "       [931.],\n",
      "       [406.],\n",
      "       [796.]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:201: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "self = <models.LanguageModel object at 0x169458290>, embedding_size = 1\n",
      "output_size = 1000, hidden_size = 1, num_layers = 2, seq_model = 'lstm'\n",
      "device = cpu(), dtype = 'float32'\n",
      "\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92m__init__\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, embedding_size, output_size, hidden_size, num_layers=\u001b[94m1\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                 seq_model=\u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, device=\u001b[94mNone\u001b[39;49;00m, dtype=\u001b[33m\"\u001b[39;49;00m\u001b[33mfloat32\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"\u001b[39;49;00m\n",
      "    \u001b[33m    Consists of an embedding layer, a sequence model (either RNN or LSTM), and a\u001b[39;49;00m\n",
      "    \u001b[33m    linear layer.\u001b[39;49;00m\n",
      "    \u001b[33m    Parameters:\u001b[39;49;00m\n",
      "    \u001b[33m    output_size: Size of dictionary\u001b[39;49;00m\n",
      "    \u001b[33m    embedding_size: Size of embeddings\u001b[39;49;00m\n",
      "    \u001b[33m    hidden_size: The number of features in the hidden state of LSTM or RNN\u001b[39;49;00m\n",
      "    \u001b[33m    seq_model: 'rnn' or 'lstm', whether to use RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    num_layers: Number of layers in RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    \"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[96msuper\u001b[39;49;00m(LanguageModel, \u001b[96mself\u001b[39;49;00m).\u001b[92m__init__\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m### BEGIN YOUR SOLUTION\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94mraise\u001b[39;49;00m \u001b[96mNotImplementedError\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       NotImplementedError\u001b[0m\n",
      "\n",
      "__class__  = <class 'models.LanguageModel'>\n",
      "device     = cpu()\n",
      "dtype      = 'float32'\n",
      "embedding_size = 1\n",
      "hidden_size = 1\n",
      "num_layers = 2\n",
      "output_size = 1000\n",
      "self       = <models.LanguageModel object at 0x169458290>\n",
      "seq_model  = 'lstm'\n",
      "\n",
      "\u001b[1m\u001b[31mapps/models.py\u001b[0m:38: NotImplementedError\n",
      "\u001b[31m\u001b[1m______ test_language_model_implementation[cpu-lstm-1000-True-1-1-15-1-1] _______\u001b[0m\n",
      "\n",
      "seq_length = 1, num_layers = 1, batch_size = 15, embedding_size = 1\n",
      "hidden_size = 1, init_hidden = True, output_size = 1000, seq_model = 'lstm'\n",
      "device = cpu()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\u001b[90m\u001b[39;49;00m\n",
      "                            init_hidden, output_size, seq_model, device):\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      ">       model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "batch_size = 15\n",
      "c0         = needle.Tensor([[[-0.97870207]\n",
      "  [-1.5991969 ]\n",
      "  [ 0.10817557]\n",
      "  [ 0.8485555 ]\n",
      "  [ 2.004152  ]\n",
      "  [-0.2788141 ]\n",
      "  [-0.35...88 ]\n",
      "  [-0.36975548]\n",
      "  [-0.47701293]\n",
      "  [-0.4750227 ]\n",
      "  [-0.1591981 ]\n",
      "  [-0.19546118]\n",
      "  [ 1.6449244 ]\n",
      "  [ 0.5804095 ]]])\n",
      "device     = cpu()\n",
      "embedding_size = 1\n",
      "h0         = needle.Tensor([[[-0.32581994]\n",
      "  [ 2.1673872 ]\n",
      "  [ 2.1977417 ]\n",
      "  [-1.6257771 ]\n",
      "  [ 0.45888647]\n",
      "  [-0.31465647]\n",
      "  [ 0.01...61 ]\n",
      "  [ 0.69940424]\n",
      "  [-0.20414792]\n",
      "  [-0.0896888 ]\n",
      "  [ 0.24139948]\n",
      "  [-0.35838136]\n",
      "  [-1.0768535 ]\n",
      "  [ 0.01446469]]])\n",
      "hidden_size = 1\n",
      "init_hidden = True\n",
      "num_layers = 1\n",
      "output_size = 1000\n",
      "seq_length = 1\n",
      "seq_model  = 'lstm'\n",
      "x          = array([[557., 812., 829., 175., 536., 349., 924., 387., 151., 453., 263.,\n",
      "        153., 901., 587., 436.]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:201: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "self = <models.LanguageModel object at 0x1577bf6e0>, embedding_size = 1\n",
      "output_size = 1000, hidden_size = 1, num_layers = 1, seq_model = 'lstm'\n",
      "device = cpu(), dtype = 'float32'\n",
      "\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92m__init__\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, embedding_size, output_size, hidden_size, num_layers=\u001b[94m1\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                 seq_model=\u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, device=\u001b[94mNone\u001b[39;49;00m, dtype=\u001b[33m\"\u001b[39;49;00m\u001b[33mfloat32\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"\u001b[39;49;00m\n",
      "    \u001b[33m    Consists of an embedding layer, a sequence model (either RNN or LSTM), and a\u001b[39;49;00m\n",
      "    \u001b[33m    linear layer.\u001b[39;49;00m\n",
      "    \u001b[33m    Parameters:\u001b[39;49;00m\n",
      "    \u001b[33m    output_size: Size of dictionary\u001b[39;49;00m\n",
      "    \u001b[33m    embedding_size: Size of embeddings\u001b[39;49;00m\n",
      "    \u001b[33m    hidden_size: The number of features in the hidden state of LSTM or RNN\u001b[39;49;00m\n",
      "    \u001b[33m    seq_model: 'rnn' or 'lstm', whether to use RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    num_layers: Number of layers in RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    \"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[96msuper\u001b[39;49;00m(LanguageModel, \u001b[96mself\u001b[39;49;00m).\u001b[92m__init__\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m### BEGIN YOUR SOLUTION\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94mraise\u001b[39;49;00m \u001b[96mNotImplementedError\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       NotImplementedError\u001b[0m\n",
      "\n",
      "__class__  = <class 'models.LanguageModel'>\n",
      "device     = cpu()\n",
      "dtype      = 'float32'\n",
      "embedding_size = 1\n",
      "hidden_size = 1\n",
      "num_layers = 1\n",
      "output_size = 1000\n",
      "self       = <models.LanguageModel object at 0x1577bf6e0>\n",
      "seq_model  = 'lstm'\n",
      "\n",
      "\u001b[1m\u001b[31mapps/models.py\u001b[0m:38: NotImplementedError\n",
      "\u001b[31m\u001b[1m______ test_language_model_implementation[cpu-lstm-1000-True-1-1-15-1-13] ______\u001b[0m\n",
      "\n",
      "seq_length = 13, num_layers = 1, batch_size = 15, embedding_size = 1\n",
      "hidden_size = 1, init_hidden = True, output_size = 1000, seq_model = 'lstm'\n",
      "device = cpu()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\u001b[90m\u001b[39;49;00m\n",
      "                            init_hidden, output_size, seq_model, device):\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      ">       model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "batch_size = 15\n",
      "c0         = needle.Tensor([[[ 1.3484682 ]\n",
      "  [ 0.37694356]\n",
      "  [-0.00676851]\n",
      "  [-0.06687479]\n",
      "  [ 0.89704555]\n",
      "  [ 0.11129376]\n",
      "  [-0.00...76 ]\n",
      "  [ 1.0622888 ]\n",
      "  [ 1.7774262 ]\n",
      "  [ 0.77027106]\n",
      "  [ 0.675411  ]\n",
      "  [-0.18233214]\n",
      "  [ 0.92147106]\n",
      "  [-0.7710484 ]]])\n",
      "device     = cpu()\n",
      "embedding_size = 1\n",
      "h0         = needle.Tensor([[[ 0.34435055]\n",
      "  [-0.67020357]\n",
      "  [ 0.25227076]\n",
      "  [-0.0933988 ]\n",
      "  [ 0.2806269 ]\n",
      "  [-0.5757338 ]\n",
      "  [ 1.67...63 ]\n",
      "  [ 0.6942424 ]\n",
      "  [ 0.20883515]\n",
      "  [ 0.33015037]\n",
      "  [-0.05740876]\n",
      "  [ 1.0249164 ]\n",
      "  [-0.26262966]\n",
      "  [-0.12653992]]])\n",
      "hidden_size = 1\n",
      "init_hidden = True\n",
      "num_layers = 1\n",
      "output_size = 1000\n",
      "seq_length = 13\n",
      "seq_model  = 'lstm'\n",
      "x          = array([[544., 298., 864., 347., 475., 683., 784., 458., 446., 851., 396.,\n",
      "        444., 119., 276., 131.],\n",
      "       [129...    [832., 604.,  88., 824., 662., 550., 574., 364., 108.,  57., 461.,\n",
      "        615.,  22., 324., 942.]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:201: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "self = <models.LanguageModel object at 0x16945a2a0>, embedding_size = 1\n",
      "output_size = 1000, hidden_size = 1, num_layers = 1, seq_model = 'lstm'\n",
      "device = cpu(), dtype = 'float32'\n",
      "\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92m__init__\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, embedding_size, output_size, hidden_size, num_layers=\u001b[94m1\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                 seq_model=\u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, device=\u001b[94mNone\u001b[39;49;00m, dtype=\u001b[33m\"\u001b[39;49;00m\u001b[33mfloat32\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"\u001b[39;49;00m\n",
      "    \u001b[33m    Consists of an embedding layer, a sequence model (either RNN or LSTM), and a\u001b[39;49;00m\n",
      "    \u001b[33m    linear layer.\u001b[39;49;00m\n",
      "    \u001b[33m    Parameters:\u001b[39;49;00m\n",
      "    \u001b[33m    output_size: Size of dictionary\u001b[39;49;00m\n",
      "    \u001b[33m    embedding_size: Size of embeddings\u001b[39;49;00m\n",
      "    \u001b[33m    hidden_size: The number of features in the hidden state of LSTM or RNN\u001b[39;49;00m\n",
      "    \u001b[33m    seq_model: 'rnn' or 'lstm', whether to use RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    num_layers: Number of layers in RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    \"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[96msuper\u001b[39;49;00m(LanguageModel, \u001b[96mself\u001b[39;49;00m).\u001b[92m__init__\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m### BEGIN YOUR SOLUTION\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94mraise\u001b[39;49;00m \u001b[96mNotImplementedError\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       NotImplementedError\u001b[0m\n",
      "\n",
      "__class__  = <class 'models.LanguageModel'>\n",
      "device     = cpu()\n",
      "dtype      = 'float32'\n",
      "embedding_size = 1\n",
      "hidden_size = 1\n",
      "num_layers = 1\n",
      "output_size = 1000\n",
      "self       = <models.LanguageModel object at 0x16945a2a0>\n",
      "seq_model  = 'lstm'\n",
      "\n",
      "\u001b[1m\u001b[31mapps/models.py\u001b[0m:38: NotImplementedError\n",
      "\u001b[31m\u001b[1m______ test_language_model_implementation[cpu-lstm-1000-True-1-1-15-2-1] _______\u001b[0m\n",
      "\n",
      "seq_length = 1, num_layers = 2, batch_size = 15, embedding_size = 1\n",
      "hidden_size = 1, init_hidden = True, output_size = 1000, seq_model = 'lstm'\n",
      "device = cpu()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\u001b[90m\u001b[39;49;00m\n",
      "                            init_hidden, output_size, seq_model, device):\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      ">       model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "batch_size = 15\n",
      "c0         = needle.Tensor([[[ 0.11195047]\n",
      "  [ 0.28724074]\n",
      "  [ 0.69019234]\n",
      "  [ 1.3100948 ]\n",
      "  [-0.0433055 ]\n",
      "  [-0.08245167]\n",
      "  [ 0.39...38 ]\n",
      "  [ 1.1146193 ]\n",
      "  [-0.21635619]\n",
      "  [-0.6474054 ]\n",
      "  [-0.34161788]\n",
      "  [-2.0114532 ]\n",
      "  [ 0.512103  ]\n",
      "  [ 0.41122767]]])\n",
      "device     = cpu()\n",
      "embedding_size = 1\n",
      "h0         = needle.Tensor([[[ 0.7813583 ]\n",
      "  [ 0.2731612 ]\n",
      "  [ 0.75990117]\n",
      "  [ 1.0635823 ]\n",
      "  [ 1.254879  ]\n",
      "  [-0.1686315 ]\n",
      "  [ 2.05...91 ]\n",
      "  [-1.2429444 ]\n",
      "  [ 0.14842874]\n",
      "  [ 2.007961  ]\n",
      "  [-0.27657953]\n",
      "  [-0.3862774 ]\n",
      "  [ 0.15688239]\n",
      "  [-0.46523693]]])\n",
      "hidden_size = 1\n",
      "init_hidden = True\n",
      "num_layers = 2\n",
      "output_size = 1000\n",
      "seq_length = 1\n",
      "seq_model  = 'lstm'\n",
      "x          = array([[ 76., 296., 767.,  83., 392., 957., 397., 867.,  60., 781., 834.,\n",
      "        685., 804., 778., 127.]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:201: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "self = <models.LanguageModel object at 0x1573eca10>, embedding_size = 1\n",
      "output_size = 1000, hidden_size = 1, num_layers = 2, seq_model = 'lstm'\n",
      "device = cpu(), dtype = 'float32'\n",
      "\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92m__init__\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, embedding_size, output_size, hidden_size, num_layers=\u001b[94m1\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                 seq_model=\u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, device=\u001b[94mNone\u001b[39;49;00m, dtype=\u001b[33m\"\u001b[39;49;00m\u001b[33mfloat32\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"\u001b[39;49;00m\n",
      "    \u001b[33m    Consists of an embedding layer, a sequence model (either RNN or LSTM), and a\u001b[39;49;00m\n",
      "    \u001b[33m    linear layer.\u001b[39;49;00m\n",
      "    \u001b[33m    Parameters:\u001b[39;49;00m\n",
      "    \u001b[33m    output_size: Size of dictionary\u001b[39;49;00m\n",
      "    \u001b[33m    embedding_size: Size of embeddings\u001b[39;49;00m\n",
      "    \u001b[33m    hidden_size: The number of features in the hidden state of LSTM or RNN\u001b[39;49;00m\n",
      "    \u001b[33m    seq_model: 'rnn' or 'lstm', whether to use RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    num_layers: Number of layers in RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    \"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[96msuper\u001b[39;49;00m(LanguageModel, \u001b[96mself\u001b[39;49;00m).\u001b[92m__init__\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m### BEGIN YOUR SOLUTION\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94mraise\u001b[39;49;00m \u001b[96mNotImplementedError\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       NotImplementedError\u001b[0m\n",
      "\n",
      "__class__  = <class 'models.LanguageModel'>\n",
      "device     = cpu()\n",
      "dtype      = 'float32'\n",
      "embedding_size = 1\n",
      "hidden_size = 1\n",
      "num_layers = 2\n",
      "output_size = 1000\n",
      "self       = <models.LanguageModel object at 0x1573eca10>\n",
      "seq_model  = 'lstm'\n",
      "\n",
      "\u001b[1m\u001b[31mapps/models.py\u001b[0m:38: NotImplementedError\n",
      "\u001b[31m\u001b[1m______ test_language_model_implementation[cpu-lstm-1000-True-1-1-15-2-13] ______\u001b[0m\n",
      "\n",
      "seq_length = 13, num_layers = 2, batch_size = 15, embedding_size = 1\n",
      "hidden_size = 1, init_hidden = True, output_size = 1000, seq_model = 'lstm'\n",
      "device = cpu()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\u001b[90m\u001b[39;49;00m\n",
      "                            init_hidden, output_size, seq_model, device):\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      ">       model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "batch_size = 15\n",
      "c0         = needle.Tensor([[[ 1.7307206e+00]\n",
      "  [-1.0122739e+00]\n",
      "  [ 2.0274342e-04]\n",
      "  [ 8.2611912e-01]\n",
      "  [ 6.1489737e-01]\n",
      "  [ 7.207...2]\n",
      "  [-2.3683088e-02]\n",
      "  [ 1.1444330e+00]\n",
      "  [ 2.4228954e+00]\n",
      "  [-2.3237927e+00]\n",
      "  [-3.1897229e-01]\n",
      "  [ 1.7151763e-01]]])\n",
      "device     = cpu()\n",
      "embedding_size = 1\n",
      "h0         = needle.Tensor([[[-0.08842459]\n",
      "  [ 1.480817  ]\n",
      "  [-0.6036431 ]\n",
      "  [ 1.0876163 ]\n",
      "  [-0.37701482]\n",
      "  [ 0.2126888 ]\n",
      "  [ 0.66...987]\n",
      "  [-0.5747485 ]\n",
      "  [-0.0951155 ]\n",
      "  [ 1.9223697 ]\n",
      "  [-0.6628513 ]\n",
      "  [ 0.88365775]\n",
      "  [ 0.4742677 ]\n",
      "  [ 0.7850397 ]]])\n",
      "hidden_size = 1\n",
      "init_hidden = True\n",
      "num_layers = 2\n",
      "output_size = 1000\n",
      "seq_length = 13\n",
      "seq_model  = 'lstm'\n",
      "x          = array([[547., 566., 233.,  93., 134., 917., 383., 835., 441., 717., 958.,\n",
      "         97., 626., 890., 912.],\n",
      "       [ 81...    [731., 676.,  38., 759., 773., 242., 632., 625., 652., 882., 503.,\n",
      "        615., 247.,  11., 297.]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:201: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "self = <models.LanguageModel object at 0x1694abd10>, embedding_size = 1\n",
      "output_size = 1000, hidden_size = 1, num_layers = 2, seq_model = 'lstm'\n",
      "device = cpu(), dtype = 'float32'\n",
      "\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92m__init__\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, embedding_size, output_size, hidden_size, num_layers=\u001b[94m1\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                 seq_model=\u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, device=\u001b[94mNone\u001b[39;49;00m, dtype=\u001b[33m\"\u001b[39;49;00m\u001b[33mfloat32\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"\u001b[39;49;00m\n",
      "    \u001b[33m    Consists of an embedding layer, a sequence model (either RNN or LSTM), and a\u001b[39;49;00m\n",
      "    \u001b[33m    linear layer.\u001b[39;49;00m\n",
      "    \u001b[33m    Parameters:\u001b[39;49;00m\n",
      "    \u001b[33m    output_size: Size of dictionary\u001b[39;49;00m\n",
      "    \u001b[33m    embedding_size: Size of embeddings\u001b[39;49;00m\n",
      "    \u001b[33m    hidden_size: The number of features in the hidden state of LSTM or RNN\u001b[39;49;00m\n",
      "    \u001b[33m    seq_model: 'rnn' or 'lstm', whether to use RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    num_layers: Number of layers in RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    \"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[96msuper\u001b[39;49;00m(LanguageModel, \u001b[96mself\u001b[39;49;00m).\u001b[92m__init__\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m### BEGIN YOUR SOLUTION\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94mraise\u001b[39;49;00m \u001b[96mNotImplementedError\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       NotImplementedError\u001b[0m\n",
      "\n",
      "__class__  = <class 'models.LanguageModel'>\n",
      "device     = cpu()\n",
      "dtype      = 'float32'\n",
      "embedding_size = 1\n",
      "hidden_size = 1\n",
      "num_layers = 2\n",
      "output_size = 1000\n",
      "self       = <models.LanguageModel object at 0x1694abd10>\n",
      "seq_model  = 'lstm'\n",
      "\n",
      "\u001b[1m\u001b[31mapps/models.py\u001b[0m:38: NotImplementedError\n",
      "\u001b[31m\u001b[1m______ test_language_model_implementation[cpu-lstm-1000-True-1-34-1-1-1] _______\u001b[0m\n",
      "\n",
      "seq_length = 1, num_layers = 1, batch_size = 1, embedding_size = 34\n",
      "hidden_size = 1, init_hidden = True, output_size = 1000, seq_model = 'lstm'\n",
      "device = cpu()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\u001b[90m\u001b[39;49;00m\n",
      "                            init_hidden, output_size, seq_model, device):\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      ">       model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "batch_size = 1\n",
      "c0         = needle.Tensor([[[-0.8426824]]])\n",
      "device     = cpu()\n",
      "embedding_size = 34\n",
      "h0         = needle.Tensor([[[1.5713953]]])\n",
      "hidden_size = 1\n",
      "init_hidden = True\n",
      "num_layers = 1\n",
      "output_size = 1000\n",
      "seq_length = 1\n",
      "seq_model  = 'lstm'\n",
      "x          = array([[614.]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:201: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "self = <models.LanguageModel object at 0x169459070>, embedding_size = 34\n",
      "output_size = 1000, hidden_size = 1, num_layers = 1, seq_model = 'lstm'\n",
      "device = cpu(), dtype = 'float32'\n",
      "\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92m__init__\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, embedding_size, output_size, hidden_size, num_layers=\u001b[94m1\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                 seq_model=\u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, device=\u001b[94mNone\u001b[39;49;00m, dtype=\u001b[33m\"\u001b[39;49;00m\u001b[33mfloat32\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"\u001b[39;49;00m\n",
      "    \u001b[33m    Consists of an embedding layer, a sequence model (either RNN or LSTM), and a\u001b[39;49;00m\n",
      "    \u001b[33m    linear layer.\u001b[39;49;00m\n",
      "    \u001b[33m    Parameters:\u001b[39;49;00m\n",
      "    \u001b[33m    output_size: Size of dictionary\u001b[39;49;00m\n",
      "    \u001b[33m    embedding_size: Size of embeddings\u001b[39;49;00m\n",
      "    \u001b[33m    hidden_size: The number of features in the hidden state of LSTM or RNN\u001b[39;49;00m\n",
      "    \u001b[33m    seq_model: 'rnn' or 'lstm', whether to use RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    num_layers: Number of layers in RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    \"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[96msuper\u001b[39;49;00m(LanguageModel, \u001b[96mself\u001b[39;49;00m).\u001b[92m__init__\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m### BEGIN YOUR SOLUTION\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94mraise\u001b[39;49;00m \u001b[96mNotImplementedError\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       NotImplementedError\u001b[0m\n",
      "\n",
      "__class__  = <class 'models.LanguageModel'>\n",
      "device     = cpu()\n",
      "dtype      = 'float32'\n",
      "embedding_size = 34\n",
      "hidden_size = 1\n",
      "num_layers = 1\n",
      "output_size = 1000\n",
      "self       = <models.LanguageModel object at 0x169459070>\n",
      "seq_model  = 'lstm'\n",
      "\n",
      "\u001b[1m\u001b[31mapps/models.py\u001b[0m:38: NotImplementedError\n",
      "\u001b[31m\u001b[1m______ test_language_model_implementation[cpu-lstm-1000-True-1-34-1-1-13] ______\u001b[0m\n",
      "\n",
      "seq_length = 13, num_layers = 1, batch_size = 1, embedding_size = 34\n",
      "hidden_size = 1, init_hidden = True, output_size = 1000, seq_model = 'lstm'\n",
      "device = cpu()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\u001b[90m\u001b[39;49;00m\n",
      "                            init_hidden, output_size, seq_model, device):\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      ">       model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "batch_size = 1\n",
      "c0         = needle.Tensor([[[0.6724411]]])\n",
      "device     = cpu()\n",
      "embedding_size = 34\n",
      "h0         = needle.Tensor([[[0.7551467]]])\n",
      "hidden_size = 1\n",
      "init_hidden = True\n",
      "num_layers = 1\n",
      "output_size = 1000\n",
      "seq_length = 13\n",
      "seq_model  = 'lstm'\n",
      "x          = array([[989.],\n",
      "       [ 11.],\n",
      "       [187.],\n",
      "       [ 88.],\n",
      "       [257.],\n",
      "       [206.],\n",
      "       [780.],\n",
      "       [754.],\n",
      "       [911.],\n",
      "       [391.],\n",
      "       [  2.],\n",
      "       [790.],\n",
      "       [377.]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:201: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "self = <models.LanguageModel object at 0x1694e7fb0>, embedding_size = 34\n",
      "output_size = 1000, hidden_size = 1, num_layers = 1, seq_model = 'lstm'\n",
      "device = cpu(), dtype = 'float32'\n",
      "\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92m__init__\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, embedding_size, output_size, hidden_size, num_layers=\u001b[94m1\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                 seq_model=\u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, device=\u001b[94mNone\u001b[39;49;00m, dtype=\u001b[33m\"\u001b[39;49;00m\u001b[33mfloat32\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"\u001b[39;49;00m\n",
      "    \u001b[33m    Consists of an embedding layer, a sequence model (either RNN or LSTM), and a\u001b[39;49;00m\n",
      "    \u001b[33m    linear layer.\u001b[39;49;00m\n",
      "    \u001b[33m    Parameters:\u001b[39;49;00m\n",
      "    \u001b[33m    output_size: Size of dictionary\u001b[39;49;00m\n",
      "    \u001b[33m    embedding_size: Size of embeddings\u001b[39;49;00m\n",
      "    \u001b[33m    hidden_size: The number of features in the hidden state of LSTM or RNN\u001b[39;49;00m\n",
      "    \u001b[33m    seq_model: 'rnn' or 'lstm', whether to use RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    num_layers: Number of layers in RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    \"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[96msuper\u001b[39;49;00m(LanguageModel, \u001b[96mself\u001b[39;49;00m).\u001b[92m__init__\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m### BEGIN YOUR SOLUTION\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94mraise\u001b[39;49;00m \u001b[96mNotImplementedError\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       NotImplementedError\u001b[0m\n",
      "\n",
      "__class__  = <class 'models.LanguageModel'>\n",
      "device     = cpu()\n",
      "dtype      = 'float32'\n",
      "embedding_size = 34\n",
      "hidden_size = 1\n",
      "num_layers = 1\n",
      "output_size = 1000\n",
      "self       = <models.LanguageModel object at 0x1694e7fb0>\n",
      "seq_model  = 'lstm'\n",
      "\n",
      "\u001b[1m\u001b[31mapps/models.py\u001b[0m:38: NotImplementedError\n",
      "\u001b[31m\u001b[1m______ test_language_model_implementation[cpu-lstm-1000-True-1-34-1-2-1] _______\u001b[0m\n",
      "\n",
      "seq_length = 1, num_layers = 2, batch_size = 1, embedding_size = 34\n",
      "hidden_size = 1, init_hidden = True, output_size = 1000, seq_model = 'lstm'\n",
      "device = cpu()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\u001b[90m\u001b[39;49;00m\n",
      "                            init_hidden, output_size, seq_model, device):\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      ">       model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "batch_size = 1\n",
      "c0         = needle.Tensor([[[ 0.73891366]]\n",
      "\n",
      " [[-0.02506699]]])\n",
      "device     = cpu()\n",
      "embedding_size = 34\n",
      "h0         = needle.Tensor([[[ 0.56500226]]\n",
      "\n",
      " [[-0.6281327 ]]])\n",
      "hidden_size = 1\n",
      "init_hidden = True\n",
      "num_layers = 2\n",
      "output_size = 1000\n",
      "seq_length = 1\n",
      "seq_model  = 'lstm'\n",
      "x          = array([[195.]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:201: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "self = <models.LanguageModel object at 0x1694e79b0>, embedding_size = 34\n",
      "output_size = 1000, hidden_size = 1, num_layers = 2, seq_model = 'lstm'\n",
      "device = cpu(), dtype = 'float32'\n",
      "\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92m__init__\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, embedding_size, output_size, hidden_size, num_layers=\u001b[94m1\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                 seq_model=\u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, device=\u001b[94mNone\u001b[39;49;00m, dtype=\u001b[33m\"\u001b[39;49;00m\u001b[33mfloat32\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"\u001b[39;49;00m\n",
      "    \u001b[33m    Consists of an embedding layer, a sequence model (either RNN or LSTM), and a\u001b[39;49;00m\n",
      "    \u001b[33m    linear layer.\u001b[39;49;00m\n",
      "    \u001b[33m    Parameters:\u001b[39;49;00m\n",
      "    \u001b[33m    output_size: Size of dictionary\u001b[39;49;00m\n",
      "    \u001b[33m    embedding_size: Size of embeddings\u001b[39;49;00m\n",
      "    \u001b[33m    hidden_size: The number of features in the hidden state of LSTM or RNN\u001b[39;49;00m\n",
      "    \u001b[33m    seq_model: 'rnn' or 'lstm', whether to use RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    num_layers: Number of layers in RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    \"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[96msuper\u001b[39;49;00m(LanguageModel, \u001b[96mself\u001b[39;49;00m).\u001b[92m__init__\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m### BEGIN YOUR SOLUTION\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94mraise\u001b[39;49;00m \u001b[96mNotImplementedError\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       NotImplementedError\u001b[0m\n",
      "\n",
      "__class__  = <class 'models.LanguageModel'>\n",
      "device     = cpu()\n",
      "dtype      = 'float32'\n",
      "embedding_size = 34\n",
      "hidden_size = 1\n",
      "num_layers = 2\n",
      "output_size = 1000\n",
      "self       = <models.LanguageModel object at 0x1694e79b0>\n",
      "seq_model  = 'lstm'\n",
      "\n",
      "\u001b[1m\u001b[31mapps/models.py\u001b[0m:38: NotImplementedError\n",
      "\u001b[31m\u001b[1m______ test_language_model_implementation[cpu-lstm-1000-True-1-34-1-2-13] ______\u001b[0m\n",
      "\n",
      "seq_length = 13, num_layers = 2, batch_size = 1, embedding_size = 34\n",
      "hidden_size = 1, init_hidden = True, output_size = 1000, seq_model = 'lstm'\n",
      "device = cpu()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\u001b[90m\u001b[39;49;00m\n",
      "                            init_hidden, output_size, seq_model, device):\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      ">       model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "batch_size = 1\n",
      "c0         = needle.Tensor([[[ 0.29700986]]\n",
      "\n",
      " [[-0.801466  ]]])\n",
      "device     = cpu()\n",
      "embedding_size = 34\n",
      "h0         = needle.Tensor([[[-0.49748555]]\n",
      "\n",
      " [[ 1.0004433 ]]])\n",
      "hidden_size = 1\n",
      "init_hidden = True\n",
      "num_layers = 2\n",
      "output_size = 1000\n",
      "seq_length = 13\n",
      "seq_model  = 'lstm'\n",
      "x          = array([[680.],\n",
      "       [862.],\n",
      "       [804.],\n",
      "       [129.],\n",
      "       [861.],\n",
      "       [871.],\n",
      "       [648.],\n",
      "       [612.],\n",
      "       [634.],\n",
      "       [384.],\n",
      "       [270.],\n",
      "       [407.],\n",
      "       [214.]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:201: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "self = <models.LanguageModel object at 0x1694cd5b0>, embedding_size = 34\n",
      "output_size = 1000, hidden_size = 1, num_layers = 2, seq_model = 'lstm'\n",
      "device = cpu(), dtype = 'float32'\n",
      "\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92m__init__\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, embedding_size, output_size, hidden_size, num_layers=\u001b[94m1\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                 seq_model=\u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, device=\u001b[94mNone\u001b[39;49;00m, dtype=\u001b[33m\"\u001b[39;49;00m\u001b[33mfloat32\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"\u001b[39;49;00m\n",
      "    \u001b[33m    Consists of an embedding layer, a sequence model (either RNN or LSTM), and a\u001b[39;49;00m\n",
      "    \u001b[33m    linear layer.\u001b[39;49;00m\n",
      "    \u001b[33m    Parameters:\u001b[39;49;00m\n",
      "    \u001b[33m    output_size: Size of dictionary\u001b[39;49;00m\n",
      "    \u001b[33m    embedding_size: Size of embeddings\u001b[39;49;00m\n",
      "    \u001b[33m    hidden_size: The number of features in the hidden state of LSTM or RNN\u001b[39;49;00m\n",
      "    \u001b[33m    seq_model: 'rnn' or 'lstm', whether to use RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    num_layers: Number of layers in RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    \"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[96msuper\u001b[39;49;00m(LanguageModel, \u001b[96mself\u001b[39;49;00m).\u001b[92m__init__\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m### BEGIN YOUR SOLUTION\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94mraise\u001b[39;49;00m \u001b[96mNotImplementedError\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       NotImplementedError\u001b[0m\n",
      "\n",
      "__class__  = <class 'models.LanguageModel'>\n",
      "device     = cpu()\n",
      "dtype      = 'float32'\n",
      "embedding_size = 34\n",
      "hidden_size = 1\n",
      "num_layers = 2\n",
      "output_size = 1000\n",
      "self       = <models.LanguageModel object at 0x1694cd5b0>\n",
      "seq_model  = 'lstm'\n",
      "\n",
      "\u001b[1m\u001b[31mapps/models.py\u001b[0m:38: NotImplementedError\n",
      "\u001b[31m\u001b[1m______ test_language_model_implementation[cpu-lstm-1000-True-1-34-15-1-1] ______\u001b[0m\n",
      "\n",
      "seq_length = 1, num_layers = 1, batch_size = 15, embedding_size = 34\n",
      "hidden_size = 1, init_hidden = True, output_size = 1000, seq_model = 'lstm'\n",
      "device = cpu()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\u001b[90m\u001b[39;49;00m\n",
      "                            init_hidden, output_size, seq_model, device):\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      ">       model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "batch_size = 15\n",
      "c0         = needle.Tensor([[[ 0.6488213 ]\n",
      "  [ 1.6335733 ]\n",
      "  [ 0.7681146 ]\n",
      "  [-0.5275573 ]\n",
      "  [-1.2065059 ]\n",
      "  [ 0.19315545]\n",
      "  [-1.07...1  ]\n",
      "  [ 0.21240683]\n",
      "  [ 0.07781766]\n",
      "  [-0.9138031 ]\n",
      "  [-1.4161202 ]\n",
      "  [-0.84067166]\n",
      "  [-0.4582403 ]\n",
      "  [-0.5575242 ]]])\n",
      "device     = cpu()\n",
      "embedding_size = 34\n",
      "h0         = needle.Tensor([[[-1.0905384 ]\n",
      "  [-0.9115526 ]\n",
      "  [-0.9954999 ]\n",
      "  [-1.4730076 ]\n",
      "  [-0.9028013 ]\n",
      "  [ 0.749631  ]\n",
      "  [ 0.23...666]\n",
      "  [ 0.38339293]\n",
      "  [ 1.0052677 ]\n",
      "  [-0.19030803]\n",
      "  [ 2.0922136 ]\n",
      "  [ 1.5349325 ]\n",
      "  [-1.2937868 ]\n",
      "  [-1.3264107 ]]])\n",
      "hidden_size = 1\n",
      "init_hidden = True\n",
      "num_layers = 1\n",
      "output_size = 1000\n",
      "seq_length = 1\n",
      "seq_model  = 'lstm'\n",
      "x          = array([[445., 112., 727., 920., 344., 942., 137., 911., 818., 100., 162.,\n",
      "        226., 338., 802., 463.]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:201: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "self = <models.LanguageModel object at 0x1694ce120>, embedding_size = 34\n",
      "output_size = 1000, hidden_size = 1, num_layers = 1, seq_model = 'lstm'\n",
      "device = cpu(), dtype = 'float32'\n",
      "\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92m__init__\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, embedding_size, output_size, hidden_size, num_layers=\u001b[94m1\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                 seq_model=\u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, device=\u001b[94mNone\u001b[39;49;00m, dtype=\u001b[33m\"\u001b[39;49;00m\u001b[33mfloat32\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"\u001b[39;49;00m\n",
      "    \u001b[33m    Consists of an embedding layer, a sequence model (either RNN or LSTM), and a\u001b[39;49;00m\n",
      "    \u001b[33m    linear layer.\u001b[39;49;00m\n",
      "    \u001b[33m    Parameters:\u001b[39;49;00m\n",
      "    \u001b[33m    output_size: Size of dictionary\u001b[39;49;00m\n",
      "    \u001b[33m    embedding_size: Size of embeddings\u001b[39;49;00m\n",
      "    \u001b[33m    hidden_size: The number of features in the hidden state of LSTM or RNN\u001b[39;49;00m\n",
      "    \u001b[33m    seq_model: 'rnn' or 'lstm', whether to use RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    num_layers: Number of layers in RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    \"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[96msuper\u001b[39;49;00m(LanguageModel, \u001b[96mself\u001b[39;49;00m).\u001b[92m__init__\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m### BEGIN YOUR SOLUTION\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94mraise\u001b[39;49;00m \u001b[96mNotImplementedError\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       NotImplementedError\u001b[0m\n",
      "\n",
      "__class__  = <class 'models.LanguageModel'>\n",
      "device     = cpu()\n",
      "dtype      = 'float32'\n",
      "embedding_size = 34\n",
      "hidden_size = 1\n",
      "num_layers = 1\n",
      "output_size = 1000\n",
      "self       = <models.LanguageModel object at 0x1694ce120>\n",
      "seq_model  = 'lstm'\n",
      "\n",
      "\u001b[1m\u001b[31mapps/models.py\u001b[0m:38: NotImplementedError\n",
      "\u001b[31m\u001b[1m_____ test_language_model_implementation[cpu-lstm-1000-True-1-34-15-1-13] ______\u001b[0m\n",
      "\n",
      "seq_length = 13, num_layers = 1, batch_size = 15, embedding_size = 34\n",
      "hidden_size = 1, init_hidden = True, output_size = 1000, seq_model = 'lstm'\n",
      "device = cpu()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\u001b[90m\u001b[39;49;00m\n",
      "                            init_hidden, output_size, seq_model, device):\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      ">       model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "batch_size = 15\n",
      "c0         = needle.Tensor([[[ 0.3645304 ]\n",
      "  [-1.1083202 ]\n",
      "  [-1.1194359 ]\n",
      "  [-0.52730817]\n",
      "  [ 0.3615897 ]\n",
      "  [-0.17214154]\n",
      "  [ 0.52...89 ]\n",
      "  [-0.14026716]\n",
      "  [ 0.39274812]\n",
      "  [ 1.1982305 ]\n",
      "  [ 0.06170572]\n",
      "  [ 0.72392744]\n",
      "  [ 0.6169845 ]\n",
      "  [-0.21122997]]])\n",
      "device     = cpu()\n",
      "embedding_size = 34\n",
      "h0         = needle.Tensor([[[ 0.24590163]\n",
      "  [-0.5011409 ]\n",
      "  [-1.0283473 ]\n",
      "  [-0.8410345 ]\n",
      "  [-0.7333616 ]\n",
      "  [ 0.42580214]\n",
      "  [ 0.49...7  ]\n",
      "  [ 1.8418219 ]\n",
      "  [ 1.6597534 ]\n",
      "  [-0.04526264]\n",
      "  [ 0.5278393 ]\n",
      "  [ 0.09178467]\n",
      "  [ 0.51203513]\n",
      "  [ 1.9477061 ]]])\n",
      "hidden_size = 1\n",
      "init_hidden = True\n",
      "num_layers = 1\n",
      "output_size = 1000\n",
      "seq_length = 13\n",
      "seq_model  = 'lstm'\n",
      "x          = array([[542., 588., 922., 965.,  57., 536., 163., 489., 411., 837., 402.,\n",
      "        489., 291., 976., 637.],\n",
      "       [376...    [790., 315., 598., 430., 342., 974., 763., 861., 539., 438., 807.,\n",
      "         38., 804.,  54., 788.]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:201: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "self = <models.LanguageModel object at 0x1694cecc0>, embedding_size = 34\n",
      "output_size = 1000, hidden_size = 1, num_layers = 1, seq_model = 'lstm'\n",
      "device = cpu(), dtype = 'float32'\n",
      "\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92m__init__\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, embedding_size, output_size, hidden_size, num_layers=\u001b[94m1\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                 seq_model=\u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, device=\u001b[94mNone\u001b[39;49;00m, dtype=\u001b[33m\"\u001b[39;49;00m\u001b[33mfloat32\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"\u001b[39;49;00m\n",
      "    \u001b[33m    Consists of an embedding layer, a sequence model (either RNN or LSTM), and a\u001b[39;49;00m\n",
      "    \u001b[33m    linear layer.\u001b[39;49;00m\n",
      "    \u001b[33m    Parameters:\u001b[39;49;00m\n",
      "    \u001b[33m    output_size: Size of dictionary\u001b[39;49;00m\n",
      "    \u001b[33m    embedding_size: Size of embeddings\u001b[39;49;00m\n",
      "    \u001b[33m    hidden_size: The number of features in the hidden state of LSTM or RNN\u001b[39;49;00m\n",
      "    \u001b[33m    seq_model: 'rnn' or 'lstm', whether to use RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    num_layers: Number of layers in RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    \"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[96msuper\u001b[39;49;00m(LanguageModel, \u001b[96mself\u001b[39;49;00m).\u001b[92m__init__\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m### BEGIN YOUR SOLUTION\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94mraise\u001b[39;49;00m \u001b[96mNotImplementedError\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       NotImplementedError\u001b[0m\n",
      "\n",
      "__class__  = <class 'models.LanguageModel'>\n",
      "device     = cpu()\n",
      "dtype      = 'float32'\n",
      "embedding_size = 34\n",
      "hidden_size = 1\n",
      "num_layers = 1\n",
      "output_size = 1000\n",
      "self       = <models.LanguageModel object at 0x1694cecc0>\n",
      "seq_model  = 'lstm'\n",
      "\n",
      "\u001b[1m\u001b[31mapps/models.py\u001b[0m:38: NotImplementedError\n",
      "\u001b[31m\u001b[1m______ test_language_model_implementation[cpu-lstm-1000-True-1-34-15-2-1] ______\u001b[0m\n",
      "\n",
      "seq_length = 1, num_layers = 2, batch_size = 15, embedding_size = 34\n",
      "hidden_size = 1, init_hidden = True, output_size = 1000, seq_model = 'lstm'\n",
      "device = cpu()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\u001b[90m\u001b[39;49;00m\n",
      "                            init_hidden, output_size, seq_model, device):\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      ">       model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "batch_size = 15\n",
      "c0         = needle.Tensor([[[ 0.2603259 ]\n",
      "  [-0.25847405]\n",
      "  [-0.06545122]\n",
      "  [-1.416763  ]\n",
      "  [ 0.44424313]\n",
      "  [-1.9088888 ]\n",
      "  [-1.15...605]\n",
      "  [ 0.67931336]\n",
      "  [ 1.0651625 ]\n",
      "  [ 0.8648409 ]\n",
      "  [-1.0448287 ]\n",
      "  [ 0.277424  ]\n",
      "  [ 0.75103   ]\n",
      "  [ 1.4110541 ]]])\n",
      "device     = cpu()\n",
      "embedding_size = 34\n",
      "h0         = needle.Tensor([[[ 1.0403854 ]\n",
      "  [-1.2236773 ]\n",
      "  [-0.5302217 ]\n",
      "  [-0.8037857 ]\n",
      "  [ 2.1739972 ]\n",
      "  [ 0.45088983]\n",
      "  [ 1.81...97 ]\n",
      "  [-0.00463049]\n",
      "  [-0.3760988 ]\n",
      "  [-0.83728915]\n",
      "  [-0.63899916]\n",
      "  [ 0.37067607]\n",
      "  [-1.1179041 ]\n",
      "  [ 1.2638972 ]]])\n",
      "hidden_size = 1\n",
      "init_hidden = True\n",
      "num_layers = 2\n",
      "output_size = 1000\n",
      "seq_length = 1\n",
      "seq_model  = 'lstm'\n",
      "x          = array([[745., 295.,  61., 892., 596., 141., 404., 325., 392., 537., 143.,\n",
      "        354., 922., 797., 119.]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:201: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "self = <models.LanguageModel object at 0x169481460>, embedding_size = 34\n",
      "output_size = 1000, hidden_size = 1, num_layers = 2, seq_model = 'lstm'\n",
      "device = cpu(), dtype = 'float32'\n",
      "\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92m__init__\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, embedding_size, output_size, hidden_size, num_layers=\u001b[94m1\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                 seq_model=\u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, device=\u001b[94mNone\u001b[39;49;00m, dtype=\u001b[33m\"\u001b[39;49;00m\u001b[33mfloat32\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"\u001b[39;49;00m\n",
      "    \u001b[33m    Consists of an embedding layer, a sequence model (either RNN or LSTM), and a\u001b[39;49;00m\n",
      "    \u001b[33m    linear layer.\u001b[39;49;00m\n",
      "    \u001b[33m    Parameters:\u001b[39;49;00m\n",
      "    \u001b[33m    output_size: Size of dictionary\u001b[39;49;00m\n",
      "    \u001b[33m    embedding_size: Size of embeddings\u001b[39;49;00m\n",
      "    \u001b[33m    hidden_size: The number of features in the hidden state of LSTM or RNN\u001b[39;49;00m\n",
      "    \u001b[33m    seq_model: 'rnn' or 'lstm', whether to use RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    num_layers: Number of layers in RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    \"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[96msuper\u001b[39;49;00m(LanguageModel, \u001b[96mself\u001b[39;49;00m).\u001b[92m__init__\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m### BEGIN YOUR SOLUTION\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94mraise\u001b[39;49;00m \u001b[96mNotImplementedError\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       NotImplementedError\u001b[0m\n",
      "\n",
      "__class__  = <class 'models.LanguageModel'>\n",
      "device     = cpu()\n",
      "dtype      = 'float32'\n",
      "embedding_size = 34\n",
      "hidden_size = 1\n",
      "num_layers = 2\n",
      "output_size = 1000\n",
      "self       = <models.LanguageModel object at 0x169481460>\n",
      "seq_model  = 'lstm'\n",
      "\n",
      "\u001b[1m\u001b[31mapps/models.py\u001b[0m:38: NotImplementedError\n",
      "\u001b[31m\u001b[1m_____ test_language_model_implementation[cpu-lstm-1000-True-1-34-15-2-13] ______\u001b[0m\n",
      "\n",
      "seq_length = 13, num_layers = 2, batch_size = 15, embedding_size = 34\n",
      "hidden_size = 1, init_hidden = True, output_size = 1000, seq_model = 'lstm'\n",
      "device = cpu()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\u001b[90m\u001b[39;49;00m\n",
      "                            init_hidden, output_size, seq_model, device):\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      ">       model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "batch_size = 15\n",
      "c0         = needle.Tensor([[[-2.02318788e+00]\n",
      "  [ 8.45555127e-01]\n",
      "  [ 1.13986671e+00]\n",
      "  [ 3.32453132e-01]\n",
      "  [ 1.33380339e-01]\n",
      "  [ ...-4.17570889e-01]\n",
      "  [-8.51391315e-01]\n",
      "  [-3.07705671e-01]\n",
      "  [-8.58038962e-01]\n",
      "  [ 2.43027043e+00]\n",
      "  [-4.93023306e-01]]])\n",
      "device     = cpu()\n",
      "embedding_size = 34\n",
      "h0         = needle.Tensor([[[-0.12383869]\n",
      "  [ 0.8544548 ]\n",
      "  [-2.7958705 ]\n",
      "  [ 0.76751816]\n",
      "  [-0.73638195]\n",
      "  [ 1.6215707 ]\n",
      "  [ 0.59...73 ]\n",
      "  [-0.11630902]\n",
      "  [-2.2022166 ]\n",
      "  [-1.3921492 ]\n",
      "  [-0.5515103 ]\n",
      "  [ 1.3919462 ]\n",
      "  [-1.6313331 ]\n",
      "  [-1.1441429 ]]])\n",
      "hidden_size = 1\n",
      "init_hidden = True\n",
      "num_layers = 2\n",
      "output_size = 1000\n",
      "seq_length = 13\n",
      "seq_model  = 'lstm'\n",
      "x          = array([[ 25., 790., 221., 276., 948., 668., 339., 861.,  12.,  77., 144.,\n",
      "        358., 778., 433., 580.],\n",
      "       [445...    [675., 652., 755., 140., 638., 951., 308., 236., 801., 321., 828.,\n",
      "        715., 862., 799., 804.]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:201: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "self = <models.LanguageModel object at 0x1694826c0>, embedding_size = 34\n",
      "output_size = 1000, hidden_size = 1, num_layers = 2, seq_model = 'lstm'\n",
      "device = cpu(), dtype = 'float32'\n",
      "\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92m__init__\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, embedding_size, output_size, hidden_size, num_layers=\u001b[94m1\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                 seq_model=\u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, device=\u001b[94mNone\u001b[39;49;00m, dtype=\u001b[33m\"\u001b[39;49;00m\u001b[33mfloat32\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"\u001b[39;49;00m\n",
      "    \u001b[33m    Consists of an embedding layer, a sequence model (either RNN or LSTM), and a\u001b[39;49;00m\n",
      "    \u001b[33m    linear layer.\u001b[39;49;00m\n",
      "    \u001b[33m    Parameters:\u001b[39;49;00m\n",
      "    \u001b[33m    output_size: Size of dictionary\u001b[39;49;00m\n",
      "    \u001b[33m    embedding_size: Size of embeddings\u001b[39;49;00m\n",
      "    \u001b[33m    hidden_size: The number of features in the hidden state of LSTM or RNN\u001b[39;49;00m\n",
      "    \u001b[33m    seq_model: 'rnn' or 'lstm', whether to use RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    num_layers: Number of layers in RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    \"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[96msuper\u001b[39;49;00m(LanguageModel, \u001b[96mself\u001b[39;49;00m).\u001b[92m__init__\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m### BEGIN YOUR SOLUTION\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94mraise\u001b[39;49;00m \u001b[96mNotImplementedError\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       NotImplementedError\u001b[0m\n",
      "\n",
      "__class__  = <class 'models.LanguageModel'>\n",
      "device     = cpu()\n",
      "dtype      = 'float32'\n",
      "embedding_size = 34\n",
      "hidden_size = 1\n",
      "num_layers = 2\n",
      "output_size = 1000\n",
      "self       = <models.LanguageModel object at 0x1694826c0>\n",
      "seq_model  = 'lstm'\n",
      "\n",
      "\u001b[1m\u001b[31mapps/models.py\u001b[0m:38: NotImplementedError\n",
      "\u001b[31m\u001b[1m______ test_language_model_implementation[cpu-lstm-1000-True-12-1-1-1-1] _______\u001b[0m\n",
      "\n",
      "seq_length = 1, num_layers = 1, batch_size = 1, embedding_size = 1\n",
      "hidden_size = 12, init_hidden = True, output_size = 1000, seq_model = 'lstm'\n",
      "device = cpu()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\u001b[90m\u001b[39;49;00m\n",
      "                            init_hidden, output_size, seq_model, device):\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      ">       model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "batch_size = 1\n",
      "c0         = needle.Tensor([[[-0.96542287 -1.0208354   1.5720199  -0.4015426   1.9288232\n",
      "   -0.6896514   0.5446      0.2490189   0.21123172  0.57610774\n",
      "    0.6263445  -1.5909195 ]]])\n",
      "device     = cpu()\n",
      "embedding_size = 1\n",
      "h0         = needle.Tensor([[[ 0.60787517  1.325704    1.0046941   1.9479581   1.0868742\n",
      "   -0.7078516   1.7067242   0.380586    0.49443293  0.61755764\n",
      "    1.4512892   0.6284962 ]]])\n",
      "hidden_size = 12\n",
      "init_hidden = True\n",
      "num_layers = 1\n",
      "output_size = 1000\n",
      "seq_length = 1\n",
      "seq_model  = 'lstm'\n",
      "x          = array([[168.]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:201: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "self = <models.LanguageModel object at 0x1694ce570>, embedding_size = 1\n",
      "output_size = 1000, hidden_size = 12, num_layers = 1, seq_model = 'lstm'\n",
      "device = cpu(), dtype = 'float32'\n",
      "\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92m__init__\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, embedding_size, output_size, hidden_size, num_layers=\u001b[94m1\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                 seq_model=\u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, device=\u001b[94mNone\u001b[39;49;00m, dtype=\u001b[33m\"\u001b[39;49;00m\u001b[33mfloat32\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"\u001b[39;49;00m\n",
      "    \u001b[33m    Consists of an embedding layer, a sequence model (either RNN or LSTM), and a\u001b[39;49;00m\n",
      "    \u001b[33m    linear layer.\u001b[39;49;00m\n",
      "    \u001b[33m    Parameters:\u001b[39;49;00m\n",
      "    \u001b[33m    output_size: Size of dictionary\u001b[39;49;00m\n",
      "    \u001b[33m    embedding_size: Size of embeddings\u001b[39;49;00m\n",
      "    \u001b[33m    hidden_size: The number of features in the hidden state of LSTM or RNN\u001b[39;49;00m\n",
      "    \u001b[33m    seq_model: 'rnn' or 'lstm', whether to use RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    num_layers: Number of layers in RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    \"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[96msuper\u001b[39;49;00m(LanguageModel, \u001b[96mself\u001b[39;49;00m).\u001b[92m__init__\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m### BEGIN YOUR SOLUTION\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94mraise\u001b[39;49;00m \u001b[96mNotImplementedError\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       NotImplementedError\u001b[0m\n",
      "\n",
      "__class__  = <class 'models.LanguageModel'>\n",
      "device     = cpu()\n",
      "dtype      = 'float32'\n",
      "embedding_size = 1\n",
      "hidden_size = 12\n",
      "num_layers = 1\n",
      "output_size = 1000\n",
      "self       = <models.LanguageModel object at 0x1694ce570>\n",
      "seq_model  = 'lstm'\n",
      "\n",
      "\u001b[1m\u001b[31mapps/models.py\u001b[0m:38: NotImplementedError\n",
      "\u001b[31m\u001b[1m______ test_language_model_implementation[cpu-lstm-1000-True-12-1-1-1-13] ______\u001b[0m\n",
      "\n",
      "seq_length = 13, num_layers = 1, batch_size = 1, embedding_size = 1\n",
      "hidden_size = 12, init_hidden = True, output_size = 1000, seq_model = 'lstm'\n",
      "device = cpu()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\u001b[90m\u001b[39;49;00m\n",
      "                            init_hidden, output_size, seq_model, device):\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      ">       model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "batch_size = 1\n",
      "c0         = needle.Tensor([[[-1.7421775   1.683199    0.90922403 -0.52461904  0.74043036\n",
      "    1.5397112  -1.4111096   1.080864   -0.9833001   0.3844375\n",
      "   -1.1964872   1.3225154 ]]])\n",
      "device     = cpu()\n",
      "embedding_size = 1\n",
      "h0         = needle.Tensor([[[-2.7240968   1.70901     0.7952217   1.0747108   0.9073893\n",
      "   -0.13513874  0.6952436   0.28015772 -0.1612126  -0.63363665\n",
      "    0.58193606  1.694829  ]]])\n",
      "hidden_size = 12\n",
      "init_hidden = True\n",
      "num_layers = 1\n",
      "output_size = 1000\n",
      "seq_length = 13\n",
      "seq_model  = 'lstm'\n",
      "x          = array([[116.],\n",
      "       [744.],\n",
      "       [255.],\n",
      "       [381.],\n",
      "       [383.],\n",
      "       [187.],\n",
      "       [511.],\n",
      "       [156.],\n",
      "       [ 23.],\n",
      "       [249.],\n",
      "       [240.],\n",
      "       [147.],\n",
      "       [747.]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:201: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "self = <models.LanguageModel object at 0x1694ab980>, embedding_size = 1\n",
      "output_size = 1000, hidden_size = 12, num_layers = 1, seq_model = 'lstm'\n",
      "device = cpu(), dtype = 'float32'\n",
      "\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92m__init__\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, embedding_size, output_size, hidden_size, num_layers=\u001b[94m1\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                 seq_model=\u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, device=\u001b[94mNone\u001b[39;49;00m, dtype=\u001b[33m\"\u001b[39;49;00m\u001b[33mfloat32\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"\u001b[39;49;00m\n",
      "    \u001b[33m    Consists of an embedding layer, a sequence model (either RNN or LSTM), and a\u001b[39;49;00m\n",
      "    \u001b[33m    linear layer.\u001b[39;49;00m\n",
      "    \u001b[33m    Parameters:\u001b[39;49;00m\n",
      "    \u001b[33m    output_size: Size of dictionary\u001b[39;49;00m\n",
      "    \u001b[33m    embedding_size: Size of embeddings\u001b[39;49;00m\n",
      "    \u001b[33m    hidden_size: The number of features in the hidden state of LSTM or RNN\u001b[39;49;00m\n",
      "    \u001b[33m    seq_model: 'rnn' or 'lstm', whether to use RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    num_layers: Number of layers in RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    \"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[96msuper\u001b[39;49;00m(LanguageModel, \u001b[96mself\u001b[39;49;00m).\u001b[92m__init__\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m### BEGIN YOUR SOLUTION\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94mraise\u001b[39;49;00m \u001b[96mNotImplementedError\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       NotImplementedError\u001b[0m\n",
      "\n",
      "__class__  = <class 'models.LanguageModel'>\n",
      "device     = cpu()\n",
      "dtype      = 'float32'\n",
      "embedding_size = 1\n",
      "hidden_size = 12\n",
      "num_layers = 1\n",
      "output_size = 1000\n",
      "self       = <models.LanguageModel object at 0x1694ab980>\n",
      "seq_model  = 'lstm'\n",
      "\n",
      "\u001b[1m\u001b[31mapps/models.py\u001b[0m:38: NotImplementedError\n",
      "\u001b[31m\u001b[1m______ test_language_model_implementation[cpu-lstm-1000-True-12-1-1-2-1] _______\u001b[0m\n",
      "\n",
      "seq_length = 1, num_layers = 2, batch_size = 1, embedding_size = 1\n",
      "hidden_size = 12, init_hidden = True, output_size = 1000, seq_model = 'lstm'\n",
      "device = cpu()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\u001b[90m\u001b[39;49;00m\n",
      "                            init_hidden, output_size, seq_model, device):\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      ">       model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "batch_size = 1\n",
      "c0         = needle.Tensor([[[ 1.0163457   0.0119452  -1.6453918  -0.25561854 -1.0555367\n",
      "   -1.263596    1.2205502  -0.20935778 -1....1  -0.09967314  0.34670252\n",
      "   -0.9425199   0.09868238  0.68721247  1.7227247   0.9579272\n",
      "   -1.2617402  -0.12325425]]])\n",
      "device     = cpu()\n",
      "embedding_size = 1\n",
      "h0         = needle.Tensor([[[-1.0322049   1.963482   -0.59184355  0.6328566   2.138019\n",
      "   -0.6296773   0.45913857  0.47780797  0.1...8   -1.1791778  -1.8366872\n",
      "   -1.0598422   2.1579874   1.4600338  -1.6050204  -1.0277467\n",
      "    0.08745942 -1.5380318 ]]])\n",
      "hidden_size = 12\n",
      "init_hidden = True\n",
      "num_layers = 2\n",
      "output_size = 1000\n",
      "seq_length = 1\n",
      "seq_model  = 'lstm'\n",
      "x          = array([[39.]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:201: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "self = <models.LanguageModel object at 0x1573ece30>, embedding_size = 1\n",
      "output_size = 1000, hidden_size = 12, num_layers = 2, seq_model = 'lstm'\n",
      "device = cpu(), dtype = 'float32'\n",
      "\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92m__init__\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, embedding_size, output_size, hidden_size, num_layers=\u001b[94m1\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                 seq_model=\u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, device=\u001b[94mNone\u001b[39;49;00m, dtype=\u001b[33m\"\u001b[39;49;00m\u001b[33mfloat32\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"\u001b[39;49;00m\n",
      "    \u001b[33m    Consists of an embedding layer, a sequence model (either RNN or LSTM), and a\u001b[39;49;00m\n",
      "    \u001b[33m    linear layer.\u001b[39;49;00m\n",
      "    \u001b[33m    Parameters:\u001b[39;49;00m\n",
      "    \u001b[33m    output_size: Size of dictionary\u001b[39;49;00m\n",
      "    \u001b[33m    embedding_size: Size of embeddings\u001b[39;49;00m\n",
      "    \u001b[33m    hidden_size: The number of features in the hidden state of LSTM or RNN\u001b[39;49;00m\n",
      "    \u001b[33m    seq_model: 'rnn' or 'lstm', whether to use RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    num_layers: Number of layers in RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    \"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[96msuper\u001b[39;49;00m(LanguageModel, \u001b[96mself\u001b[39;49;00m).\u001b[92m__init__\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m### BEGIN YOUR SOLUTION\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94mraise\u001b[39;49;00m \u001b[96mNotImplementedError\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       NotImplementedError\u001b[0m\n",
      "\n",
      "__class__  = <class 'models.LanguageModel'>\n",
      "device     = cpu()\n",
      "dtype      = 'float32'\n",
      "embedding_size = 1\n",
      "hidden_size = 12\n",
      "num_layers = 2\n",
      "output_size = 1000\n",
      "self       = <models.LanguageModel object at 0x1573ece30>\n",
      "seq_model  = 'lstm'\n",
      "\n",
      "\u001b[1m\u001b[31mapps/models.py\u001b[0m:38: NotImplementedError\n",
      "\u001b[31m\u001b[1m______ test_language_model_implementation[cpu-lstm-1000-True-12-1-1-2-13] ______\u001b[0m\n",
      "\n",
      "seq_length = 13, num_layers = 2, batch_size = 1, embedding_size = 1\n",
      "hidden_size = 12, init_hidden = True, output_size = 1000, seq_model = 'lstm'\n",
      "device = cpu()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\u001b[90m\u001b[39;49;00m\n",
      "                            init_hidden, output_size, seq_model, device):\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      ">       model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "batch_size = 1\n",
      "c0         = needle.Tensor([[[-1.7785512  -0.6418964  -0.5601151   0.96914124 -0.48445085\n",
      "   -1.046194   -0.2995975  -0.5111062  -1...87 -0.9211885   0.96521115\n",
      "    0.30444592  0.30693844  0.09215555  2.3426507   0.6624587\n",
      "   -1.4570725  -1.8952372 ]]])\n",
      "device     = cpu()\n",
      "embedding_size = 1\n",
      "h0         = needle.Tensor([[[-0.0465025   0.49516955  0.7391088   1.0508567   1.5285046\n",
      "   -0.3811806  -0.7054121  -0.13203886  1....25 -0.9530151   0.02973706\n",
      "    0.08697944  0.8911553   0.7228402   0.28712514 -1.2162541\n",
      "    0.6564625   1.1872989 ]]])\n",
      "hidden_size = 12\n",
      "init_hidden = True\n",
      "num_layers = 2\n",
      "output_size = 1000\n",
      "seq_length = 13\n",
      "seq_model  = 'lstm'\n",
      "x          = array([[993.],\n",
      "       [665.],\n",
      "       [708.],\n",
      "       [555.],\n",
      "       [176.],\n",
      "       [720.],\n",
      "       [933.],\n",
      "       [632.],\n",
      "       [977.],\n",
      "       [745.],\n",
      "       [886.],\n",
      "       [ 10.],\n",
      "       [783.]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:201: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "self = <models.LanguageModel object at 0x16945a120>, embedding_size = 1\n",
      "output_size = 1000, hidden_size = 12, num_layers = 2, seq_model = 'lstm'\n",
      "device = cpu(), dtype = 'float32'\n",
      "\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92m__init__\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, embedding_size, output_size, hidden_size, num_layers=\u001b[94m1\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                 seq_model=\u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, device=\u001b[94mNone\u001b[39;49;00m, dtype=\u001b[33m\"\u001b[39;49;00m\u001b[33mfloat32\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"\u001b[39;49;00m\n",
      "    \u001b[33m    Consists of an embedding layer, a sequence model (either RNN or LSTM), and a\u001b[39;49;00m\n",
      "    \u001b[33m    linear layer.\u001b[39;49;00m\n",
      "    \u001b[33m    Parameters:\u001b[39;49;00m\n",
      "    \u001b[33m    output_size: Size of dictionary\u001b[39;49;00m\n",
      "    \u001b[33m    embedding_size: Size of embeddings\u001b[39;49;00m\n",
      "    \u001b[33m    hidden_size: The number of features in the hidden state of LSTM or RNN\u001b[39;49;00m\n",
      "    \u001b[33m    seq_model: 'rnn' or 'lstm', whether to use RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    num_layers: Number of layers in RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    \"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[96msuper\u001b[39;49;00m(LanguageModel, \u001b[96mself\u001b[39;49;00m).\u001b[92m__init__\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m### BEGIN YOUR SOLUTION\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94mraise\u001b[39;49;00m \u001b[96mNotImplementedError\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       NotImplementedError\u001b[0m\n",
      "\n",
      "__class__  = <class 'models.LanguageModel'>\n",
      "device     = cpu()\n",
      "dtype      = 'float32'\n",
      "embedding_size = 1\n",
      "hidden_size = 12\n",
      "num_layers = 2\n",
      "output_size = 1000\n",
      "self       = <models.LanguageModel object at 0x16945a120>\n",
      "seq_model  = 'lstm'\n",
      "\n",
      "\u001b[1m\u001b[31mapps/models.py\u001b[0m:38: NotImplementedError\n",
      "\u001b[31m\u001b[1m______ test_language_model_implementation[cpu-lstm-1000-True-12-1-15-1-1] ______\u001b[0m\n",
      "\n",
      "seq_length = 1, num_layers = 1, batch_size = 15, embedding_size = 1\n",
      "hidden_size = 12, init_hidden = True, output_size = 1000, seq_model = 'lstm'\n",
      "device = cpu()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\u001b[90m\u001b[39;49;00m\n",
      "                            init_hidden, output_size, seq_model, device):\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      ">       model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "batch_size = 15\n",
      "c0         = needle.Tensor([[[ 0.22065839 -0.03571644 -1.2943506   0.6930955   0.07454839\n",
      "   -0.00535185 -2.0524504   0.57853097 -1...2    0.2884431  -1.6985626\n",
      "   -0.45223832 -1.0670356   0.16483696  0.24571803  0.8374408\n",
      "   -0.8659744  -0.12019321]]])\n",
      "device     = cpu()\n",
      "embedding_size = 1\n",
      "h0         = needle.Tensor([[[-0.21985193  1.8235346  -2.769883    0.47726128 -0.61491525\n",
      "    0.4905015   0.08480223 -0.42521608 -1...44 -0.25610363 -1.1019657\n",
      "    0.2307988   0.42798615 -0.4067095   1.1887932   0.20311089\n",
      "   -1.8526398  -0.817026  ]]])\n",
      "hidden_size = 12\n",
      "init_hidden = True\n",
      "num_layers = 1\n",
      "output_size = 1000\n",
      "seq_length = 1\n",
      "seq_model  = 'lstm'\n",
      "x          = array([[720., 201., 550., 908.,   6., 297., 356., 724.,   0., 398., 699.,\n",
      "        479., 323., 528., 196.]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:201: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "self = <models.LanguageModel object at 0x1694ceb40>, embedding_size = 1\n",
      "output_size = 1000, hidden_size = 12, num_layers = 1, seq_model = 'lstm'\n",
      "device = cpu(), dtype = 'float32'\n",
      "\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92m__init__\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, embedding_size, output_size, hidden_size, num_layers=\u001b[94m1\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                 seq_model=\u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, device=\u001b[94mNone\u001b[39;49;00m, dtype=\u001b[33m\"\u001b[39;49;00m\u001b[33mfloat32\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"\u001b[39;49;00m\n",
      "    \u001b[33m    Consists of an embedding layer, a sequence model (either RNN or LSTM), and a\u001b[39;49;00m\n",
      "    \u001b[33m    linear layer.\u001b[39;49;00m\n",
      "    \u001b[33m    Parameters:\u001b[39;49;00m\n",
      "    \u001b[33m    output_size: Size of dictionary\u001b[39;49;00m\n",
      "    \u001b[33m    embedding_size: Size of embeddings\u001b[39;49;00m\n",
      "    \u001b[33m    hidden_size: The number of features in the hidden state of LSTM or RNN\u001b[39;49;00m\n",
      "    \u001b[33m    seq_model: 'rnn' or 'lstm', whether to use RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    num_layers: Number of layers in RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    \"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[96msuper\u001b[39;49;00m(LanguageModel, \u001b[96mself\u001b[39;49;00m).\u001b[92m__init__\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m### BEGIN YOUR SOLUTION\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94mraise\u001b[39;49;00m \u001b[96mNotImplementedError\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       NotImplementedError\u001b[0m\n",
      "\n",
      "__class__  = <class 'models.LanguageModel'>\n",
      "device     = cpu()\n",
      "dtype      = 'float32'\n",
      "embedding_size = 1\n",
      "hidden_size = 12\n",
      "num_layers = 1\n",
      "output_size = 1000\n",
      "self       = <models.LanguageModel object at 0x1694ceb40>\n",
      "seq_model  = 'lstm'\n",
      "\n",
      "\u001b[1m\u001b[31mapps/models.py\u001b[0m:38: NotImplementedError\n",
      "\u001b[31m\u001b[1m_____ test_language_model_implementation[cpu-lstm-1000-True-12-1-15-1-13] ______\u001b[0m\n",
      "\n",
      "seq_length = 13, num_layers = 1, batch_size = 15, embedding_size = 1\n",
      "hidden_size = 12, init_hidden = True, output_size = 1000, seq_model = 'lstm'\n",
      "device = cpu()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\u001b[90m\u001b[39;49;00m\n",
      "                            init_hidden, output_size, seq_model, device):\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      ">       model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "batch_size = 15\n",
      "c0         = needle.Tensor([[[-0.14733979  0.5854487  -1.320089    1.2867305  -1.5155421\n",
      "   -0.09306496 -0.3396715  -0.42329657  0....51   0.30650583 -1.9380018\n",
      "   -0.44589868 -0.51816165  0.21127193  0.6800507   2.1946528\n",
      "    0.63606703  0.9431549 ]]])\n",
      "device     = cpu()\n",
      "embedding_size = 1\n",
      "h0         = needle.Tensor([[[ 1.63074613e+00  1.04417849e+00 -1.67078245e+00  1.81466654e-01\n",
      "   -1.55098486e+00  6.62630796e-01  7... -1.94397414e+00 -9.04864550e-01 -7.26647854e-01\n",
      "    2.13882589e+00  6.26416504e-02 -1.23399392e-01 -1.20978904e+00]]])\n",
      "hidden_size = 12\n",
      "init_hidden = True\n",
      "num_layers = 1\n",
      "output_size = 1000\n",
      "seq_length = 13\n",
      "seq_model  = 'lstm'\n",
      "x          = array([[  0., 675., 453.,  17., 174., 125., 544., 495., 560., 764., 366.,\n",
      "        216., 537., 927., 897.],\n",
      "       [169...    [416., 831., 268., 264., 746., 628., 596., 136., 810., 275., 824.,\n",
      "         94.,  41., 969., 264.]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:201: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "self = <models.LanguageModel object at 0x1694cd760>, embedding_size = 1\n",
      "output_size = 1000, hidden_size = 12, num_layers = 1, seq_model = 'lstm'\n",
      "device = cpu(), dtype = 'float32'\n",
      "\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92m__init__\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, embedding_size, output_size, hidden_size, num_layers=\u001b[94m1\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                 seq_model=\u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, device=\u001b[94mNone\u001b[39;49;00m, dtype=\u001b[33m\"\u001b[39;49;00m\u001b[33mfloat32\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"\u001b[39;49;00m\n",
      "    \u001b[33m    Consists of an embedding layer, a sequence model (either RNN or LSTM), and a\u001b[39;49;00m\n",
      "    \u001b[33m    linear layer.\u001b[39;49;00m\n",
      "    \u001b[33m    Parameters:\u001b[39;49;00m\n",
      "    \u001b[33m    output_size: Size of dictionary\u001b[39;49;00m\n",
      "    \u001b[33m    embedding_size: Size of embeddings\u001b[39;49;00m\n",
      "    \u001b[33m    hidden_size: The number of features in the hidden state of LSTM or RNN\u001b[39;49;00m\n",
      "    \u001b[33m    seq_model: 'rnn' or 'lstm', whether to use RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    num_layers: Number of layers in RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    \"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[96msuper\u001b[39;49;00m(LanguageModel, \u001b[96mself\u001b[39;49;00m).\u001b[92m__init__\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m### BEGIN YOUR SOLUTION\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94mraise\u001b[39;49;00m \u001b[96mNotImplementedError\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       NotImplementedError\u001b[0m\n",
      "\n",
      "__class__  = <class 'models.LanguageModel'>\n",
      "device     = cpu()\n",
      "dtype      = 'float32'\n",
      "embedding_size = 1\n",
      "hidden_size = 12\n",
      "num_layers = 1\n",
      "output_size = 1000\n",
      "self       = <models.LanguageModel object at 0x1694cd760>\n",
      "seq_model  = 'lstm'\n",
      "\n",
      "\u001b[1m\u001b[31mapps/models.py\u001b[0m:38: NotImplementedError\n",
      "\u001b[31m\u001b[1m______ test_language_model_implementation[cpu-lstm-1000-True-12-1-15-2-1] ______\u001b[0m\n",
      "\n",
      "seq_length = 1, num_layers = 2, batch_size = 15, embedding_size = 1\n",
      "hidden_size = 12, init_hidden = True, output_size = 1000, seq_model = 'lstm'\n",
      "device = cpu()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\u001b[90m\u001b[39;49;00m\n",
      "                            init_hidden, output_size, seq_model, device):\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      ">       model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "batch_size = 15\n",
      "c0         = needle.Tensor([[[-1.09136832e+00 -1.25114596e+00 -6.97986960e-01  1.01142225e-03\n",
      "   -8.75771224e-01  4.71846640e-01 -4...  1.70701921e-01 -1.22278750e+00  2.44124651e-01\n",
      "    1.05294514e+00  3.12892854e-01 -1.50691330e+00  2.42937326e-01]]])\n",
      "device     = cpu()\n",
      "embedding_size = 1\n",
      "h0         = needle.Tensor([[[ 2.84057677e-01  2.12531388e-01 -5.86164951e-01 -7.07049072e-02\n",
      "    1.35152674e+00 -1.12548816e+00  2... -7.48524219e-02 -5.86910248e-01 -3.79425704e-01\n",
      "   -8.44053328e-02 -4.19356257e-01 -1.41400784e-01 -3.52604389e-01]]])\n",
      "hidden_size = 12\n",
      "init_hidden = True\n",
      "num_layers = 2\n",
      "output_size = 1000\n",
      "seq_length = 1\n",
      "seq_model  = 'lstm'\n",
      "x          = array([[831., 842., 891., 887., 382., 172., 176., 142., 622., 795., 546.,\n",
      "        650., 688., 602., 651.]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:201: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "self = <models.LanguageModel object at 0x169480650>, embedding_size = 1\n",
      "output_size = 1000, hidden_size = 12, num_layers = 2, seq_model = 'lstm'\n",
      "device = cpu(), dtype = 'float32'\n",
      "\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92m__init__\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, embedding_size, output_size, hidden_size, num_layers=\u001b[94m1\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                 seq_model=\u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, device=\u001b[94mNone\u001b[39;49;00m, dtype=\u001b[33m\"\u001b[39;49;00m\u001b[33mfloat32\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"\u001b[39;49;00m\n",
      "    \u001b[33m    Consists of an embedding layer, a sequence model (either RNN or LSTM), and a\u001b[39;49;00m\n",
      "    \u001b[33m    linear layer.\u001b[39;49;00m\n",
      "    \u001b[33m    Parameters:\u001b[39;49;00m\n",
      "    \u001b[33m    output_size: Size of dictionary\u001b[39;49;00m\n",
      "    \u001b[33m    embedding_size: Size of embeddings\u001b[39;49;00m\n",
      "    \u001b[33m    hidden_size: The number of features in the hidden state of LSTM or RNN\u001b[39;49;00m\n",
      "    \u001b[33m    seq_model: 'rnn' or 'lstm', whether to use RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    num_layers: Number of layers in RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    \"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[96msuper\u001b[39;49;00m(LanguageModel, \u001b[96mself\u001b[39;49;00m).\u001b[92m__init__\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m### BEGIN YOUR SOLUTION\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94mraise\u001b[39;49;00m \u001b[96mNotImplementedError\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       NotImplementedError\u001b[0m\n",
      "\n",
      "__class__  = <class 'models.LanguageModel'>\n",
      "device     = cpu()\n",
      "dtype      = 'float32'\n",
      "embedding_size = 1\n",
      "hidden_size = 12\n",
      "num_layers = 2\n",
      "output_size = 1000\n",
      "self       = <models.LanguageModel object at 0x169480650>\n",
      "seq_model  = 'lstm'\n",
      "\n",
      "\u001b[1m\u001b[31mapps/models.py\u001b[0m:38: NotImplementedError\n",
      "\u001b[31m\u001b[1m_____ test_language_model_implementation[cpu-lstm-1000-True-12-1-15-2-13] ______\u001b[0m\n",
      "\n",
      "seq_length = 13, num_layers = 2, batch_size = 15, embedding_size = 1\n",
      "hidden_size = 12, init_hidden = True, output_size = 1000, seq_model = 'lstm'\n",
      "device = cpu()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\u001b[90m\u001b[39;49;00m\n",
      "                            init_hidden, output_size, seq_model, device):\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      ">       model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "batch_size = 15\n",
      "c0         = needle.Tensor([[[-1.15532613e+00  1.66099894e+00  1.10093641e+00  2.22143114e-01\n",
      "    2.00376794e-01 -1.08746898e+00 -4...  1.00046694e+00  7.09533632e-01 -2.21698737e+00\n",
      "   -1.44659960e+00 -7.05396295e-01 -4.68404442e-02  1.23063016e+00]]])\n",
      "device     = cpu()\n",
      "embedding_size = 1\n",
      "h0         = needle.Tensor([[[ 1.5022478  -0.6850891   1.2995796  -2.7341847   0.57571447\n",
      "    0.42573568 -0.747967   -1.5320766   0...67   0.15401615 -0.776794\n",
      "    0.90850306  0.16670147  0.46670112  0.01205941  0.36788383\n",
      "   -0.8219413  -1.0783122 ]]])\n",
      "hidden_size = 12\n",
      "init_hidden = True\n",
      "num_layers = 2\n",
      "output_size = 1000\n",
      "seq_length = 13\n",
      "seq_model  = 'lstm'\n",
      "x          = array([[893., 486., 267., 732., 790., 723., 295., 467., 157., 959., 883.,\n",
      "        981., 964., 118., 188.],\n",
      "       [379...    [551., 235.,   7., 731., 346., 184., 795., 409., 543.,  78., 388.,\n",
      "        612., 856., 926., 872.]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:201: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "self = <models.LanguageModel object at 0x1694c74a0>, embedding_size = 1\n",
      "output_size = 1000, hidden_size = 12, num_layers = 2, seq_model = 'lstm'\n",
      "device = cpu(), dtype = 'float32'\n",
      "\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92m__init__\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, embedding_size, output_size, hidden_size, num_layers=\u001b[94m1\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                 seq_model=\u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, device=\u001b[94mNone\u001b[39;49;00m, dtype=\u001b[33m\"\u001b[39;49;00m\u001b[33mfloat32\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"\u001b[39;49;00m\n",
      "    \u001b[33m    Consists of an embedding layer, a sequence model (either RNN or LSTM), and a\u001b[39;49;00m\n",
      "    \u001b[33m    linear layer.\u001b[39;49;00m\n",
      "    \u001b[33m    Parameters:\u001b[39;49;00m\n",
      "    \u001b[33m    output_size: Size of dictionary\u001b[39;49;00m\n",
      "    \u001b[33m    embedding_size: Size of embeddings\u001b[39;49;00m\n",
      "    \u001b[33m    hidden_size: The number of features in the hidden state of LSTM or RNN\u001b[39;49;00m\n",
      "    \u001b[33m    seq_model: 'rnn' or 'lstm', whether to use RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    num_layers: Number of layers in RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    \"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[96msuper\u001b[39;49;00m(LanguageModel, \u001b[96mself\u001b[39;49;00m).\u001b[92m__init__\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m### BEGIN YOUR SOLUTION\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94mraise\u001b[39;49;00m \u001b[96mNotImplementedError\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       NotImplementedError\u001b[0m\n",
      "\n",
      "__class__  = <class 'models.LanguageModel'>\n",
      "device     = cpu()\n",
      "dtype      = 'float32'\n",
      "embedding_size = 1\n",
      "hidden_size = 12\n",
      "num_layers = 2\n",
      "output_size = 1000\n",
      "self       = <models.LanguageModel object at 0x1694c74a0>\n",
      "seq_model  = 'lstm'\n",
      "\n",
      "\u001b[1m\u001b[31mapps/models.py\u001b[0m:38: NotImplementedError\n",
      "\u001b[31m\u001b[1m______ test_language_model_implementation[cpu-lstm-1000-True-12-34-1-1-1] ______\u001b[0m\n",
      "\n",
      "seq_length = 1, num_layers = 1, batch_size = 1, embedding_size = 34\n",
      "hidden_size = 12, init_hidden = True, output_size = 1000, seq_model = 'lstm'\n",
      "device = cpu()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\u001b[90m\u001b[39;49;00m\n",
      "                            init_hidden, output_size, seq_model, device):\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      ">       model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "batch_size = 1\n",
      "c0         = needle.Tensor([[[ 0.22713563  0.82040894  0.6096021   0.5678977  -1.167985\n",
      "   -0.5699323   1.0607738  -1.0669854   0.43091738  0.15660828\n",
      "    0.3766966   1.9521573 ]]])\n",
      "device     = cpu()\n",
      "embedding_size = 34\n",
      "h0         = needle.Tensor([[[ 0.00928227  1.413077   -0.07166059 -0.14463603  0.7873913\n",
      "   -0.03876292  1.0733743   0.15311915  0.76527476  1.756298\n",
      "    1.9459356   0.25401473]]])\n",
      "hidden_size = 12\n",
      "init_hidden = True\n",
      "num_layers = 1\n",
      "output_size = 1000\n",
      "seq_length = 1\n",
      "seq_model  = 'lstm'\n",
      "x          = array([[635.]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:201: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "self = <models.LanguageModel object at 0x1694829c0>, embedding_size = 34\n",
      "output_size = 1000, hidden_size = 12, num_layers = 1, seq_model = 'lstm'\n",
      "device = cpu(), dtype = 'float32'\n",
      "\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92m__init__\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, embedding_size, output_size, hidden_size, num_layers=\u001b[94m1\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                 seq_model=\u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, device=\u001b[94mNone\u001b[39;49;00m, dtype=\u001b[33m\"\u001b[39;49;00m\u001b[33mfloat32\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"\u001b[39;49;00m\n",
      "    \u001b[33m    Consists of an embedding layer, a sequence model (either RNN or LSTM), and a\u001b[39;49;00m\n",
      "    \u001b[33m    linear layer.\u001b[39;49;00m\n",
      "    \u001b[33m    Parameters:\u001b[39;49;00m\n",
      "    \u001b[33m    output_size: Size of dictionary\u001b[39;49;00m\n",
      "    \u001b[33m    embedding_size: Size of embeddings\u001b[39;49;00m\n",
      "    \u001b[33m    hidden_size: The number of features in the hidden state of LSTM or RNN\u001b[39;49;00m\n",
      "    \u001b[33m    seq_model: 'rnn' or 'lstm', whether to use RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    num_layers: Number of layers in RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    \"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[96msuper\u001b[39;49;00m(LanguageModel, \u001b[96mself\u001b[39;49;00m).\u001b[92m__init__\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m### BEGIN YOUR SOLUTION\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94mraise\u001b[39;49;00m \u001b[96mNotImplementedError\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       NotImplementedError\u001b[0m\n",
      "\n",
      "__class__  = <class 'models.LanguageModel'>\n",
      "device     = cpu()\n",
      "dtype      = 'float32'\n",
      "embedding_size = 34\n",
      "hidden_size = 12\n",
      "num_layers = 1\n",
      "output_size = 1000\n",
      "self       = <models.LanguageModel object at 0x1694829c0>\n",
      "seq_model  = 'lstm'\n",
      "\n",
      "\u001b[1m\u001b[31mapps/models.py\u001b[0m:38: NotImplementedError\n",
      "\u001b[31m\u001b[1m_____ test_language_model_implementation[cpu-lstm-1000-True-12-34-1-1-13] ______\u001b[0m\n",
      "\n",
      "seq_length = 13, num_layers = 1, batch_size = 1, embedding_size = 34\n",
      "hidden_size = 12, init_hidden = True, output_size = 1000, seq_model = 'lstm'\n",
      "device = cpu()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\u001b[90m\u001b[39;49;00m\n",
      "                            init_hidden, output_size, seq_model, device):\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      ">       model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "batch_size = 1\n",
      "c0         = needle.Tensor([[[ 1.0931958  -0.15723075 -0.36744484  0.24229388 -1.0016499\n",
      "    1.0634257  -0.9927687  -1.9861281   0.10939378 -0.5612862\n",
      "   -0.7365147   0.30281764]]])\n",
      "device     = cpu()\n",
      "embedding_size = 34\n",
      "h0         = needle.Tensor([[[ 1.6516788   0.53105086 -0.8669395  -1.3117429  -0.34456816\n",
      "   -0.3849805  -0.79416573  1.6412354  -0.58684474  0.73738706\n",
      "   -0.79262435  0.05807985]]])\n",
      "hidden_size = 12\n",
      "init_hidden = True\n",
      "num_layers = 1\n",
      "output_size = 1000\n",
      "seq_length = 13\n",
      "seq_model  = 'lstm'\n",
      "x          = array([[610.],\n",
      "       [405.],\n",
      "       [741.],\n",
      "       [760.],\n",
      "       [773.],\n",
      "       [852.],\n",
      "       [396.],\n",
      "       [721.],\n",
      "       [ 85.],\n",
      "       [528.],\n",
      "       [287.],\n",
      "       [781.],\n",
      "       [872.]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:201: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "self = <models.LanguageModel object at 0x1694828d0>, embedding_size = 34\n",
      "output_size = 1000, hidden_size = 12, num_layers = 1, seq_model = 'lstm'\n",
      "device = cpu(), dtype = 'float32'\n",
      "\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92m__init__\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, embedding_size, output_size, hidden_size, num_layers=\u001b[94m1\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                 seq_model=\u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, device=\u001b[94mNone\u001b[39;49;00m, dtype=\u001b[33m\"\u001b[39;49;00m\u001b[33mfloat32\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"\u001b[39;49;00m\n",
      "    \u001b[33m    Consists of an embedding layer, a sequence model (either RNN or LSTM), and a\u001b[39;49;00m\n",
      "    \u001b[33m    linear layer.\u001b[39;49;00m\n",
      "    \u001b[33m    Parameters:\u001b[39;49;00m\n",
      "    \u001b[33m    output_size: Size of dictionary\u001b[39;49;00m\n",
      "    \u001b[33m    embedding_size: Size of embeddings\u001b[39;49;00m\n",
      "    \u001b[33m    hidden_size: The number of features in the hidden state of LSTM or RNN\u001b[39;49;00m\n",
      "    \u001b[33m    seq_model: 'rnn' or 'lstm', whether to use RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    num_layers: Number of layers in RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    \"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[96msuper\u001b[39;49;00m(LanguageModel, \u001b[96mself\u001b[39;49;00m).\u001b[92m__init__\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m### BEGIN YOUR SOLUTION\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94mraise\u001b[39;49;00m \u001b[96mNotImplementedError\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       NotImplementedError\u001b[0m\n",
      "\n",
      "__class__  = <class 'models.LanguageModel'>\n",
      "device     = cpu()\n",
      "dtype      = 'float32'\n",
      "embedding_size = 34\n",
      "hidden_size = 12\n",
      "num_layers = 1\n",
      "output_size = 1000\n",
      "self       = <models.LanguageModel object at 0x1694828d0>\n",
      "seq_model  = 'lstm'\n",
      "\n",
      "\u001b[1m\u001b[31mapps/models.py\u001b[0m:38: NotImplementedError\n",
      "\u001b[31m\u001b[1m______ test_language_model_implementation[cpu-lstm-1000-True-12-34-1-2-1] ______\u001b[0m\n",
      "\n",
      "seq_length = 1, num_layers = 2, batch_size = 1, embedding_size = 34\n",
      "hidden_size = 12, init_hidden = True, output_size = 1000, seq_model = 'lstm'\n",
      "device = cpu()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\u001b[90m\u001b[39;49;00m\n",
      "                            init_hidden, output_size, seq_model, device):\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      ">       model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "batch_size = 1\n",
      "c0         = needle.Tensor([[[ 0.5123134   0.2176644  -0.2632462   0.68773866  1.3031183\n",
      "   -0.7018905  -0.75736344 -0.38232628  1....6 -1.0690248   0.42708156\n",
      "   -1.2419488  -0.5781549  -0.2847764   1.0357318  -0.28947482\n",
      "   -0.6519426   0.1738371 ]]])\n",
      "device     = cpu()\n",
      "embedding_size = 34\n",
      "h0         = needle.Tensor([[[ 0.1570869   3.3775132  -0.46581233  0.41276932 -2.068489\n",
      "    0.19229868 -1.1760994  -1.454801    0.9...6  -0.1974825   1.8073211\n",
      "   -0.83278805  0.4861051  -1.1636841   2.478073   -0.20479414\n",
      "    0.33678493  1.345977  ]]])\n",
      "hidden_size = 12\n",
      "init_hidden = True\n",
      "num_layers = 2\n",
      "output_size = 1000\n",
      "seq_length = 1\n",
      "seq_model  = 'lstm'\n",
      "x          = array([[851.]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:201: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "self = <models.LanguageModel object at 0x1694826c0>, embedding_size = 34\n",
      "output_size = 1000, hidden_size = 12, num_layers = 2, seq_model = 'lstm'\n",
      "device = cpu(), dtype = 'float32'\n",
      "\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92m__init__\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, embedding_size, output_size, hidden_size, num_layers=\u001b[94m1\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                 seq_model=\u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, device=\u001b[94mNone\u001b[39;49;00m, dtype=\u001b[33m\"\u001b[39;49;00m\u001b[33mfloat32\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"\u001b[39;49;00m\n",
      "    \u001b[33m    Consists of an embedding layer, a sequence model (either RNN or LSTM), and a\u001b[39;49;00m\n",
      "    \u001b[33m    linear layer.\u001b[39;49;00m\n",
      "    \u001b[33m    Parameters:\u001b[39;49;00m\n",
      "    \u001b[33m    output_size: Size of dictionary\u001b[39;49;00m\n",
      "    \u001b[33m    embedding_size: Size of embeddings\u001b[39;49;00m\n",
      "    \u001b[33m    hidden_size: The number of features in the hidden state of LSTM or RNN\u001b[39;49;00m\n",
      "    \u001b[33m    seq_model: 'rnn' or 'lstm', whether to use RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    num_layers: Number of layers in RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    \"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[96msuper\u001b[39;49;00m(LanguageModel, \u001b[96mself\u001b[39;49;00m).\u001b[92m__init__\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m### BEGIN YOUR SOLUTION\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94mraise\u001b[39;49;00m \u001b[96mNotImplementedError\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       NotImplementedError\u001b[0m\n",
      "\n",
      "__class__  = <class 'models.LanguageModel'>\n",
      "device     = cpu()\n",
      "dtype      = 'float32'\n",
      "embedding_size = 34\n",
      "hidden_size = 12\n",
      "num_layers = 2\n",
      "output_size = 1000\n",
      "self       = <models.LanguageModel object at 0x1694826c0>\n",
      "seq_model  = 'lstm'\n",
      "\n",
      "\u001b[1m\u001b[31mapps/models.py\u001b[0m:38: NotImplementedError\n",
      "\u001b[31m\u001b[1m_____ test_language_model_implementation[cpu-lstm-1000-True-12-34-1-2-13] ______\u001b[0m\n",
      "\n",
      "seq_length = 13, num_layers = 2, batch_size = 1, embedding_size = 34\n",
      "hidden_size = 12, init_hidden = True, output_size = 1000, seq_model = 'lstm'\n",
      "device = cpu()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\u001b[90m\u001b[39;49;00m\n",
      "                            init_hidden, output_size, seq_model, device):\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      ">       model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "batch_size = 1\n",
      "c0         = needle.Tensor([[[-1.2205148   0.15709212 -0.1864649  -1.6345128   0.19821884\n",
      "   -0.24955502  0.62792104  0.0307171  -0...2  -0.98387176  0.4204015\n",
      "    0.25418776 -0.10846464 -1.7644924   0.21217144 -0.06240453\n",
      "    0.20717116 -0.6733402 ]]])\n",
      "device     = cpu()\n",
      "embedding_size = 34\n",
      "h0         = needle.Tensor([[[-0.079143    0.39361385  1.2635006   1.9538321   0.7909866\n",
      "   -0.9816973   0.89338636 -1.0709132  -1....  -1.9229085  -0.58543694\n",
      "   -0.34514192  1.2885009  -0.16586879  0.41122776  0.91392845\n",
      "   -1.1570565  -1.468937  ]]])\n",
      "hidden_size = 12\n",
      "init_hidden = True\n",
      "num_layers = 2\n",
      "output_size = 1000\n",
      "seq_length = 13\n",
      "seq_model  = 'lstm'\n",
      "x          = array([[239.],\n",
      "       [915.],\n",
      "       [659.],\n",
      "       [921.],\n",
      "       [282.],\n",
      "       [297.],\n",
      "       [561.],\n",
      "       [368.],\n",
      "       [535.],\n",
      "       [821.],\n",
      "       [787.],\n",
      "       [972.],\n",
      "       [799.]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:201: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "self = <models.LanguageModel object at 0x1575c7650>, embedding_size = 34\n",
      "output_size = 1000, hidden_size = 12, num_layers = 2, seq_model = 'lstm'\n",
      "device = cpu(), dtype = 'float32'\n",
      "\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92m__init__\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, embedding_size, output_size, hidden_size, num_layers=\u001b[94m1\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                 seq_model=\u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, device=\u001b[94mNone\u001b[39;49;00m, dtype=\u001b[33m\"\u001b[39;49;00m\u001b[33mfloat32\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"\u001b[39;49;00m\n",
      "    \u001b[33m    Consists of an embedding layer, a sequence model (either RNN or LSTM), and a\u001b[39;49;00m\n",
      "    \u001b[33m    linear layer.\u001b[39;49;00m\n",
      "    \u001b[33m    Parameters:\u001b[39;49;00m\n",
      "    \u001b[33m    output_size: Size of dictionary\u001b[39;49;00m\n",
      "    \u001b[33m    embedding_size: Size of embeddings\u001b[39;49;00m\n",
      "    \u001b[33m    hidden_size: The number of features in the hidden state of LSTM or RNN\u001b[39;49;00m\n",
      "    \u001b[33m    seq_model: 'rnn' or 'lstm', whether to use RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    num_layers: Number of layers in RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    \"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[96msuper\u001b[39;49;00m(LanguageModel, \u001b[96mself\u001b[39;49;00m).\u001b[92m__init__\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m### BEGIN YOUR SOLUTION\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94mraise\u001b[39;49;00m \u001b[96mNotImplementedError\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       NotImplementedError\u001b[0m\n",
      "\n",
      "__class__  = <class 'models.LanguageModel'>\n",
      "device     = cpu()\n",
      "dtype      = 'float32'\n",
      "embedding_size = 34\n",
      "hidden_size = 12\n",
      "num_layers = 2\n",
      "output_size = 1000\n",
      "self       = <models.LanguageModel object at 0x1575c7650>\n",
      "seq_model  = 'lstm'\n",
      "\n",
      "\u001b[1m\u001b[31mapps/models.py\u001b[0m:38: NotImplementedError\n",
      "\u001b[31m\u001b[1m_____ test_language_model_implementation[cpu-lstm-1000-True-12-34-15-1-1] ______\u001b[0m\n",
      "\n",
      "seq_length = 1, num_layers = 1, batch_size = 15, embedding_size = 34\n",
      "hidden_size = 12, init_hidden = True, output_size = 1000, seq_model = 'lstm'\n",
      "device = cpu()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\u001b[90m\u001b[39;49;00m\n",
      "                            init_hidden, output_size, seq_model, device):\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      ">       model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "batch_size = 15\n",
      "c0         = needle.Tensor([[[ 2.5545626   0.5391044  -2.1493425   0.768204    0.44433764\n",
      "   -1.4663206  -1.6200329  -0.14572081 -0...  -0.3279769  -0.40000403\n",
      "    0.92121136  1.9877312  -1.03758     1.7765111  -0.12348695\n",
      "   -0.9845021   0.03780233]]])\n",
      "device     = cpu()\n",
      "embedding_size = 34\n",
      "h0         = needle.Tensor([[[-0.7097973   0.2497105  -0.40503058 -0.4713671  -2.104011\n",
      "    0.35328078  0.57164836  0.56998265 -0.9...645 -0.1829064   1.9301805\n",
      "    0.29801944 -0.45285746 -0.6280679   0.13327356  1.0579246\n",
      "   -1.5572096   2.7769265 ]]])\n",
      "hidden_size = 12\n",
      "init_hidden = True\n",
      "num_layers = 1\n",
      "output_size = 1000\n",
      "seq_length = 1\n",
      "seq_model  = 'lstm'\n",
      "x          = array([[182., 818., 855., 164., 143.,  98., 860., 974., 550., 466., 489.,\n",
      "        945., 108.,  48., 282.]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:201: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "self = <models.LanguageModel object at 0x16945ab70>, embedding_size = 34\n",
      "output_size = 1000, hidden_size = 12, num_layers = 1, seq_model = 'lstm'\n",
      "device = cpu(), dtype = 'float32'\n",
      "\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92m__init__\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, embedding_size, output_size, hidden_size, num_layers=\u001b[94m1\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                 seq_model=\u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, device=\u001b[94mNone\u001b[39;49;00m, dtype=\u001b[33m\"\u001b[39;49;00m\u001b[33mfloat32\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"\u001b[39;49;00m\n",
      "    \u001b[33m    Consists of an embedding layer, a sequence model (either RNN or LSTM), and a\u001b[39;49;00m\n",
      "    \u001b[33m    linear layer.\u001b[39;49;00m\n",
      "    \u001b[33m    Parameters:\u001b[39;49;00m\n",
      "    \u001b[33m    output_size: Size of dictionary\u001b[39;49;00m\n",
      "    \u001b[33m    embedding_size: Size of embeddings\u001b[39;49;00m\n",
      "    \u001b[33m    hidden_size: The number of features in the hidden state of LSTM or RNN\u001b[39;49;00m\n",
      "    \u001b[33m    seq_model: 'rnn' or 'lstm', whether to use RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    num_layers: Number of layers in RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    \"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[96msuper\u001b[39;49;00m(LanguageModel, \u001b[96mself\u001b[39;49;00m).\u001b[92m__init__\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m### BEGIN YOUR SOLUTION\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94mraise\u001b[39;49;00m \u001b[96mNotImplementedError\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       NotImplementedError\u001b[0m\n",
      "\n",
      "__class__  = <class 'models.LanguageModel'>\n",
      "device     = cpu()\n",
      "dtype      = 'float32'\n",
      "embedding_size = 34\n",
      "hidden_size = 12\n",
      "num_layers = 1\n",
      "output_size = 1000\n",
      "self       = <models.LanguageModel object at 0x16945ab70>\n",
      "seq_model  = 'lstm'\n",
      "\n",
      "\u001b[1m\u001b[31mapps/models.py\u001b[0m:38: NotImplementedError\n",
      "\u001b[31m\u001b[1m_____ test_language_model_implementation[cpu-lstm-1000-True-12-34-15-1-13] _____\u001b[0m\n",
      "\n",
      "seq_length = 13, num_layers = 1, batch_size = 15, embedding_size = 34\n",
      "hidden_size = 12, init_hidden = True, output_size = 1000, seq_model = 'lstm'\n",
      "device = cpu()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\u001b[90m\u001b[39;49;00m\n",
      "                            init_hidden, output_size, seq_model, device):\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      ">       model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "batch_size = 15\n",
      "c0         = needle.Tensor([[[ 0.48164004  0.37358508 -2.0570328  -0.3646551  -0.6942516\n",
      "    0.5032014  -1.9392459   0.2518694   0....94  1.0873079  -0.1414841\n",
      "   -0.17751646 -0.7494268   0.49820974 -0.4217049  -0.45866415\n",
      "    1.2123926   1.9050637 ]]])\n",
      "device     = cpu()\n",
      "embedding_size = 34\n",
      "h0         = needle.Tensor([[[-1.25293577e+00  1.68385494e+00 -1.56502795e+00 -2.27661061e+00\n",
      "    1.60977626e+00 -1.02860606e+00 -1... -3.77003878e-01  1.29117799e+00 -3.02451539e+00\n",
      "    3.39636415e-01  1.22385406e+00  3.38082045e-01 -3.40989977e-01]]])\n",
      "hidden_size = 12\n",
      "init_hidden = True\n",
      "num_layers = 1\n",
      "output_size = 1000\n",
      "seq_length = 13\n",
      "seq_model  = 'lstm'\n",
      "x          = array([[150., 785.,  71., 402., 119., 995., 311., 662., 430., 904., 806.,\n",
      "        454., 407., 740., 768.],\n",
      "       [180...    [954.,  40., 209., 905., 276., 850., 174.,  19., 581., 565., 228.,\n",
      "        664., 581., 276., 392.]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:201: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "self = <models.LanguageModel object at 0x169483a40>, embedding_size = 34\n",
      "output_size = 1000, hidden_size = 12, num_layers = 1, seq_model = 'lstm'\n",
      "device = cpu(), dtype = 'float32'\n",
      "\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92m__init__\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, embedding_size, output_size, hidden_size, num_layers=\u001b[94m1\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                 seq_model=\u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, device=\u001b[94mNone\u001b[39;49;00m, dtype=\u001b[33m\"\u001b[39;49;00m\u001b[33mfloat32\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"\u001b[39;49;00m\n",
      "    \u001b[33m    Consists of an embedding layer, a sequence model (either RNN or LSTM), and a\u001b[39;49;00m\n",
      "    \u001b[33m    linear layer.\u001b[39;49;00m\n",
      "    \u001b[33m    Parameters:\u001b[39;49;00m\n",
      "    \u001b[33m    output_size: Size of dictionary\u001b[39;49;00m\n",
      "    \u001b[33m    embedding_size: Size of embeddings\u001b[39;49;00m\n",
      "    \u001b[33m    hidden_size: The number of features in the hidden state of LSTM or RNN\u001b[39;49;00m\n",
      "    \u001b[33m    seq_model: 'rnn' or 'lstm', whether to use RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    num_layers: Number of layers in RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    \"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[96msuper\u001b[39;49;00m(LanguageModel, \u001b[96mself\u001b[39;49;00m).\u001b[92m__init__\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m### BEGIN YOUR SOLUTION\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94mraise\u001b[39;49;00m \u001b[96mNotImplementedError\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       NotImplementedError\u001b[0m\n",
      "\n",
      "__class__  = <class 'models.LanguageModel'>\n",
      "device     = cpu()\n",
      "dtype      = 'float32'\n",
      "embedding_size = 34\n",
      "hidden_size = 12\n",
      "num_layers = 1\n",
      "output_size = 1000\n",
      "self       = <models.LanguageModel object at 0x169483a40>\n",
      "seq_model  = 'lstm'\n",
      "\n",
      "\u001b[1m\u001b[31mapps/models.py\u001b[0m:38: NotImplementedError\n",
      "\u001b[31m\u001b[1m_____ test_language_model_implementation[cpu-lstm-1000-True-12-34-15-2-1] ______\u001b[0m\n",
      "\n",
      "seq_length = 1, num_layers = 2, batch_size = 15, embedding_size = 34\n",
      "hidden_size = 12, init_hidden = True, output_size = 1000, seq_model = 'lstm'\n",
      "device = cpu()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\u001b[90m\u001b[39;49;00m\n",
      "                            init_hidden, output_size, seq_model, device):\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      ">       model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "batch_size = 15\n",
      "c0         = needle.Tensor([[[ 1.2715173   1.093151    0.3191477  -1.9269942  -0.07783595\n",
      "   -0.17263715  0.09556258 -1.0826547   2...  -0.10433201  0.03749333\n",
      "   -0.44548634  1.9482437  -0.30266067  0.3451587   0.01401039\n",
      "   -1.3038025   0.2376386 ]]])\n",
      "device     = cpu()\n",
      "embedding_size = 34\n",
      "h0         = needle.Tensor([[[ 6.86154008e-01  1.70623279e+00 -4.91046011e-01 -3.92827570e-01\n",
      "   -6.18420899e-01  9.07421205e-03 -8... -3.94999951e-01  9.51178074e-01 -1.23074353e+00\n",
      "   -3.16210061e-01  5.64375222e-01  7.45835125e-01 -3.43266428e-01]]])\n",
      "hidden_size = 12\n",
      "init_hidden = True\n",
      "num_layers = 2\n",
      "output_size = 1000\n",
      "seq_length = 1\n",
      "seq_model  = 'lstm'\n",
      "x          = array([[131., 267., 728., 848., 327., 306., 824., 747., 173., 632., 373.,\n",
      "        275., 119., 586., 211.]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:201: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "self = <models.LanguageModel object at 0x169483140>, embedding_size = 34\n",
      "output_size = 1000, hidden_size = 12, num_layers = 2, seq_model = 'lstm'\n",
      "device = cpu(), dtype = 'float32'\n",
      "\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92m__init__\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, embedding_size, output_size, hidden_size, num_layers=\u001b[94m1\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                 seq_model=\u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, device=\u001b[94mNone\u001b[39;49;00m, dtype=\u001b[33m\"\u001b[39;49;00m\u001b[33mfloat32\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"\u001b[39;49;00m\n",
      "    \u001b[33m    Consists of an embedding layer, a sequence model (either RNN or LSTM), and a\u001b[39;49;00m\n",
      "    \u001b[33m    linear layer.\u001b[39;49;00m\n",
      "    \u001b[33m    Parameters:\u001b[39;49;00m\n",
      "    \u001b[33m    output_size: Size of dictionary\u001b[39;49;00m\n",
      "    \u001b[33m    embedding_size: Size of embeddings\u001b[39;49;00m\n",
      "    \u001b[33m    hidden_size: The number of features in the hidden state of LSTM or RNN\u001b[39;49;00m\n",
      "    \u001b[33m    seq_model: 'rnn' or 'lstm', whether to use RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    num_layers: Number of layers in RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    \"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[96msuper\u001b[39;49;00m(LanguageModel, \u001b[96mself\u001b[39;49;00m).\u001b[92m__init__\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m### BEGIN YOUR SOLUTION\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94mraise\u001b[39;49;00m \u001b[96mNotImplementedError\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       NotImplementedError\u001b[0m\n",
      "\n",
      "__class__  = <class 'models.LanguageModel'>\n",
      "device     = cpu()\n",
      "dtype      = 'float32'\n",
      "embedding_size = 34\n",
      "hidden_size = 12\n",
      "num_layers = 2\n",
      "output_size = 1000\n",
      "self       = <models.LanguageModel object at 0x169483140>\n",
      "seq_model  = 'lstm'\n",
      "\n",
      "\u001b[1m\u001b[31mapps/models.py\u001b[0m:38: NotImplementedError\n",
      "\u001b[31m\u001b[1m_____ test_language_model_implementation[cpu-lstm-1000-True-12-34-15-2-13] _____\u001b[0m\n",
      "\n",
      "seq_length = 13, num_layers = 2, batch_size = 15, embedding_size = 34\n",
      "hidden_size = 12, init_hidden = True, output_size = 1000, seq_model = 'lstm'\n",
      "device = cpu()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\u001b[90m\u001b[39;49;00m\n",
      "                            init_hidden, output_size, seq_model, device):\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      ">       model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "batch_size = 15\n",
      "c0         = needle.Tensor([[[-0.1503473  -0.6520831  -0.05319167  1.2715675  -0.37749615\n",
      "   -0.20959385  1.8803328  -0.41004863  0...79  0.7730453  -1.0163959\n",
      "    0.6020121  -0.15162243 -0.2198769   0.1115665  -0.71863884\n",
      "    0.6342656   1.5570732 ]]])\n",
      "device     = cpu()\n",
      "embedding_size = 34\n",
      "h0         = needle.Tensor([[[-6.74140692e-01 -7.66433656e-01  5.42511046e-01 -6.69894278e-01\n",
      "    2.06965089e+00 -6.22409284e-02 -6... -9.27305162e-01 -1.09442091e+00 -2.47700840e-01\n",
      "    1.65370062e-01  6.49236679e-01  1.05884492e+00  1.90294087e+00]]])\n",
      "hidden_size = 12\n",
      "init_hidden = True\n",
      "num_layers = 2\n",
      "output_size = 1000\n",
      "seq_length = 13\n",
      "seq_model  = 'lstm'\n",
      "x          = array([[776., 594., 931., 138., 178., 668., 796., 647.,  97., 694., 798.,\n",
      "         61., 401., 645., 317.],\n",
      "       [885...    [425.,  39., 256.,  22., 363., 997., 582., 766., 997., 536., 996.,\n",
      "        461.,  86., 227., 697.]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:201: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "self = <models.LanguageModel object at 0x1694820f0>, embedding_size = 34\n",
      "output_size = 1000, hidden_size = 12, num_layers = 2, seq_model = 'lstm'\n",
      "device = cpu(), dtype = 'float32'\n",
      "\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92m__init__\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, embedding_size, output_size, hidden_size, num_layers=\u001b[94m1\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                 seq_model=\u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, device=\u001b[94mNone\u001b[39;49;00m, dtype=\u001b[33m\"\u001b[39;49;00m\u001b[33mfloat32\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"\u001b[39;49;00m\n",
      "    \u001b[33m    Consists of an embedding layer, a sequence model (either RNN or LSTM), and a\u001b[39;49;00m\n",
      "    \u001b[33m    linear layer.\u001b[39;49;00m\n",
      "    \u001b[33m    Parameters:\u001b[39;49;00m\n",
      "    \u001b[33m    output_size: Size of dictionary\u001b[39;49;00m\n",
      "    \u001b[33m    embedding_size: Size of embeddings\u001b[39;49;00m\n",
      "    \u001b[33m    hidden_size: The number of features in the hidden state of LSTM or RNN\u001b[39;49;00m\n",
      "    \u001b[33m    seq_model: 'rnn' or 'lstm', whether to use RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    num_layers: Number of layers in RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    \"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[96msuper\u001b[39;49;00m(LanguageModel, \u001b[96mself\u001b[39;49;00m).\u001b[92m__init__\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m### BEGIN YOUR SOLUTION\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94mraise\u001b[39;49;00m \u001b[96mNotImplementedError\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       NotImplementedError\u001b[0m\n",
      "\n",
      "__class__  = <class 'models.LanguageModel'>\n",
      "device     = cpu()\n",
      "dtype      = 'float32'\n",
      "embedding_size = 34\n",
      "hidden_size = 12\n",
      "num_layers = 2\n",
      "output_size = 1000\n",
      "self       = <models.LanguageModel object at 0x1694820f0>\n",
      "seq_model  = 'lstm'\n",
      "\n",
      "\u001b[1m\u001b[31mapps/models.py\u001b[0m:38: NotImplementedError\n",
      "\u001b[31m\u001b[1m______ test_language_model_implementation[cpu-lstm-1000-False-1-1-1-1-1] _______\u001b[0m\n",
      "\n",
      "seq_length = 1, num_layers = 1, batch_size = 1, embedding_size = 1\n",
      "hidden_size = 1, init_hidden = False, output_size = 1000, seq_model = 'lstm'\n",
      "device = cpu()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\u001b[90m\u001b[39;49;00m\n",
      "                            init_hidden, output_size, seq_model, device):\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      ">       model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "batch_size = 1\n",
      "c0         = needle.Tensor([[[1.9130898]]])\n",
      "device     = cpu()\n",
      "embedding_size = 1\n",
      "h0         = needle.Tensor([[[-1.2138698]]])\n",
      "hidden_size = 1\n",
      "init_hidden = False\n",
      "num_layers = 1\n",
      "output_size = 1000\n",
      "seq_length = 1\n",
      "seq_model  = 'lstm'\n",
      "x          = array([[886.]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:201: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "self = <models.LanguageModel object at 0x1694733b0>, embedding_size = 1\n",
      "output_size = 1000, hidden_size = 1, num_layers = 1, seq_model = 'lstm'\n",
      "device = cpu(), dtype = 'float32'\n",
      "\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92m__init__\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, embedding_size, output_size, hidden_size, num_layers=\u001b[94m1\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                 seq_model=\u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, device=\u001b[94mNone\u001b[39;49;00m, dtype=\u001b[33m\"\u001b[39;49;00m\u001b[33mfloat32\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"\u001b[39;49;00m\n",
      "    \u001b[33m    Consists of an embedding layer, a sequence model (either RNN or LSTM), and a\u001b[39;49;00m\n",
      "    \u001b[33m    linear layer.\u001b[39;49;00m\n",
      "    \u001b[33m    Parameters:\u001b[39;49;00m\n",
      "    \u001b[33m    output_size: Size of dictionary\u001b[39;49;00m\n",
      "    \u001b[33m    embedding_size: Size of embeddings\u001b[39;49;00m\n",
      "    \u001b[33m    hidden_size: The number of features in the hidden state of LSTM or RNN\u001b[39;49;00m\n",
      "    \u001b[33m    seq_model: 'rnn' or 'lstm', whether to use RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    num_layers: Number of layers in RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    \"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[96msuper\u001b[39;49;00m(LanguageModel, \u001b[96mself\u001b[39;49;00m).\u001b[92m__init__\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m### BEGIN YOUR SOLUTION\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94mraise\u001b[39;49;00m \u001b[96mNotImplementedError\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       NotImplementedError\u001b[0m\n",
      "\n",
      "__class__  = <class 'models.LanguageModel'>\n",
      "device     = cpu()\n",
      "dtype      = 'float32'\n",
      "embedding_size = 1\n",
      "hidden_size = 1\n",
      "num_layers = 1\n",
      "output_size = 1000\n",
      "self       = <models.LanguageModel object at 0x1694733b0>\n",
      "seq_model  = 'lstm'\n",
      "\n",
      "\u001b[1m\u001b[31mapps/models.py\u001b[0m:38: NotImplementedError\n",
      "\u001b[31m\u001b[1m______ test_language_model_implementation[cpu-lstm-1000-False-1-1-1-1-13] ______\u001b[0m\n",
      "\n",
      "seq_length = 13, num_layers = 1, batch_size = 1, embedding_size = 1\n",
      "hidden_size = 1, init_hidden = False, output_size = 1000, seq_model = 'lstm'\n",
      "device = cpu()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\u001b[90m\u001b[39;49;00m\n",
      "                            init_hidden, output_size, seq_model, device):\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      ">       model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "batch_size = 1\n",
      "c0         = needle.Tensor([[[0.18872532]]])\n",
      "device     = cpu()\n",
      "embedding_size = 1\n",
      "h0         = needle.Tensor([[[1.8092284]]])\n",
      "hidden_size = 1\n",
      "init_hidden = False\n",
      "num_layers = 1\n",
      "output_size = 1000\n",
      "seq_length = 13\n",
      "seq_model  = 'lstm'\n",
      "x          = array([[360.],\n",
      "       [647.],\n",
      "       [ 94.],\n",
      "       [299.],\n",
      "       [590.],\n",
      "       [921.],\n",
      "       [981.],\n",
      "       [112.],\n",
      "       [ 64.],\n",
      "       [912.],\n",
      "       [399.],\n",
      "       [214.],\n",
      "       [180.]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:201: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "self = <models.LanguageModel object at 0x169472510>, embedding_size = 1\n",
      "output_size = 1000, hidden_size = 1, num_layers = 1, seq_model = 'lstm'\n",
      "device = cpu(), dtype = 'float32'\n",
      "\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92m__init__\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, embedding_size, output_size, hidden_size, num_layers=\u001b[94m1\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                 seq_model=\u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, device=\u001b[94mNone\u001b[39;49;00m, dtype=\u001b[33m\"\u001b[39;49;00m\u001b[33mfloat32\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"\u001b[39;49;00m\n",
      "    \u001b[33m    Consists of an embedding layer, a sequence model (either RNN or LSTM), and a\u001b[39;49;00m\n",
      "    \u001b[33m    linear layer.\u001b[39;49;00m\n",
      "    \u001b[33m    Parameters:\u001b[39;49;00m\n",
      "    \u001b[33m    output_size: Size of dictionary\u001b[39;49;00m\n",
      "    \u001b[33m    embedding_size: Size of embeddings\u001b[39;49;00m\n",
      "    \u001b[33m    hidden_size: The number of features in the hidden state of LSTM or RNN\u001b[39;49;00m\n",
      "    \u001b[33m    seq_model: 'rnn' or 'lstm', whether to use RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    num_layers: Number of layers in RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    \"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[96msuper\u001b[39;49;00m(LanguageModel, \u001b[96mself\u001b[39;49;00m).\u001b[92m__init__\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m### BEGIN YOUR SOLUTION\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94mraise\u001b[39;49;00m \u001b[96mNotImplementedError\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       NotImplementedError\u001b[0m\n",
      "\n",
      "__class__  = <class 'models.LanguageModel'>\n",
      "device     = cpu()\n",
      "dtype      = 'float32'\n",
      "embedding_size = 1\n",
      "hidden_size = 1\n",
      "num_layers = 1\n",
      "output_size = 1000\n",
      "self       = <models.LanguageModel object at 0x169472510>\n",
      "seq_model  = 'lstm'\n",
      "\n",
      "\u001b[1m\u001b[31mapps/models.py\u001b[0m:38: NotImplementedError\n",
      "\u001b[31m\u001b[1m______ test_language_model_implementation[cpu-lstm-1000-False-1-1-1-2-1] _______\u001b[0m\n",
      "\n",
      "seq_length = 1, num_layers = 2, batch_size = 1, embedding_size = 1\n",
      "hidden_size = 1, init_hidden = False, output_size = 1000, seq_model = 'lstm'\n",
      "device = cpu()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\u001b[90m\u001b[39;49;00m\n",
      "                            init_hidden, output_size, seq_model, device):\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      ">       model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "batch_size = 1\n",
      "c0         = needle.Tensor([[[0.7634617 ]]\n",
      "\n",
      " [[0.32094985]]])\n",
      "device     = cpu()\n",
      "embedding_size = 1\n",
      "h0         = needle.Tensor([[[-0.1915467 ]]\n",
      "\n",
      " [[-0.21399128]]])\n",
      "hidden_size = 1\n",
      "init_hidden = False\n",
      "num_layers = 2\n",
      "output_size = 1000\n",
      "seq_length = 1\n",
      "seq_model  = 'lstm'\n",
      "x          = array([[134.]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:201: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "self = <models.LanguageModel object at 0x1694704d0>, embedding_size = 1\n",
      "output_size = 1000, hidden_size = 1, num_layers = 2, seq_model = 'lstm'\n",
      "device = cpu(), dtype = 'float32'\n",
      "\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92m__init__\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, embedding_size, output_size, hidden_size, num_layers=\u001b[94m1\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                 seq_model=\u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, device=\u001b[94mNone\u001b[39;49;00m, dtype=\u001b[33m\"\u001b[39;49;00m\u001b[33mfloat32\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"\u001b[39;49;00m\n",
      "    \u001b[33m    Consists of an embedding layer, a sequence model (either RNN or LSTM), and a\u001b[39;49;00m\n",
      "    \u001b[33m    linear layer.\u001b[39;49;00m\n",
      "    \u001b[33m    Parameters:\u001b[39;49;00m\n",
      "    \u001b[33m    output_size: Size of dictionary\u001b[39;49;00m\n",
      "    \u001b[33m    embedding_size: Size of embeddings\u001b[39;49;00m\n",
      "    \u001b[33m    hidden_size: The number of features in the hidden state of LSTM or RNN\u001b[39;49;00m\n",
      "    \u001b[33m    seq_model: 'rnn' or 'lstm', whether to use RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    num_layers: Number of layers in RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    \"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[96msuper\u001b[39;49;00m(LanguageModel, \u001b[96mself\u001b[39;49;00m).\u001b[92m__init__\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m### BEGIN YOUR SOLUTION\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94mraise\u001b[39;49;00m \u001b[96mNotImplementedError\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       NotImplementedError\u001b[0m\n",
      "\n",
      "__class__  = <class 'models.LanguageModel'>\n",
      "device     = cpu()\n",
      "dtype      = 'float32'\n",
      "embedding_size = 1\n",
      "hidden_size = 1\n",
      "num_layers = 2\n",
      "output_size = 1000\n",
      "self       = <models.LanguageModel object at 0x1694704d0>\n",
      "seq_model  = 'lstm'\n",
      "\n",
      "\u001b[1m\u001b[31mapps/models.py\u001b[0m:38: NotImplementedError\n",
      "\u001b[31m\u001b[1m______ test_language_model_implementation[cpu-lstm-1000-False-1-1-1-2-13] ______\u001b[0m\n",
      "\n",
      "seq_length = 13, num_layers = 2, batch_size = 1, embedding_size = 1\n",
      "hidden_size = 1, init_hidden = False, output_size = 1000, seq_model = 'lstm'\n",
      "device = cpu()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\u001b[90m\u001b[39;49;00m\n",
      "                            init_hidden, output_size, seq_model, device):\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      ">       model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "batch_size = 1\n",
      "c0         = needle.Tensor([[[ 1.1654634]]\n",
      "\n",
      " [[-2.444129 ]]])\n",
      "device     = cpu()\n",
      "embedding_size = 1\n",
      "h0         = needle.Tensor([[[1.318721 ]]\n",
      "\n",
      " [[1.0550106]]])\n",
      "hidden_size = 1\n",
      "init_hidden = False\n",
      "num_layers = 2\n",
      "output_size = 1000\n",
      "seq_length = 13\n",
      "seq_model  = 'lstm'\n",
      "x          = array([[715.],\n",
      "       [295.],\n",
      "       [235.],\n",
      "       [289.],\n",
      "       [666.],\n",
      "       [325.],\n",
      "       [867.],\n",
      "       [362.],\n",
      "       [666.],\n",
      "       [ 53.],\n",
      "       [451.],\n",
      "       [194.],\n",
      "       [174.]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:201: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "self = <models.LanguageModel object at 0x169471c70>, embedding_size = 1\n",
      "output_size = 1000, hidden_size = 1, num_layers = 2, seq_model = 'lstm'\n",
      "device = cpu(), dtype = 'float32'\n",
      "\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92m__init__\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, embedding_size, output_size, hidden_size, num_layers=\u001b[94m1\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                 seq_model=\u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, device=\u001b[94mNone\u001b[39;49;00m, dtype=\u001b[33m\"\u001b[39;49;00m\u001b[33mfloat32\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"\u001b[39;49;00m\n",
      "    \u001b[33m    Consists of an embedding layer, a sequence model (either RNN or LSTM), and a\u001b[39;49;00m\n",
      "    \u001b[33m    linear layer.\u001b[39;49;00m\n",
      "    \u001b[33m    Parameters:\u001b[39;49;00m\n",
      "    \u001b[33m    output_size: Size of dictionary\u001b[39;49;00m\n",
      "    \u001b[33m    embedding_size: Size of embeddings\u001b[39;49;00m\n",
      "    \u001b[33m    hidden_size: The number of features in the hidden state of LSTM or RNN\u001b[39;49;00m\n",
      "    \u001b[33m    seq_model: 'rnn' or 'lstm', whether to use RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    num_layers: Number of layers in RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    \"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[96msuper\u001b[39;49;00m(LanguageModel, \u001b[96mself\u001b[39;49;00m).\u001b[92m__init__\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m### BEGIN YOUR SOLUTION\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94mraise\u001b[39;49;00m \u001b[96mNotImplementedError\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       NotImplementedError\u001b[0m\n",
      "\n",
      "__class__  = <class 'models.LanguageModel'>\n",
      "device     = cpu()\n",
      "dtype      = 'float32'\n",
      "embedding_size = 1\n",
      "hidden_size = 1\n",
      "num_layers = 2\n",
      "output_size = 1000\n",
      "self       = <models.LanguageModel object at 0x169471c70>\n",
      "seq_model  = 'lstm'\n",
      "\n",
      "\u001b[1m\u001b[31mapps/models.py\u001b[0m:38: NotImplementedError\n",
      "\u001b[31m\u001b[1m______ test_language_model_implementation[cpu-lstm-1000-False-1-1-15-1-1] ______\u001b[0m\n",
      "\n",
      "seq_length = 1, num_layers = 1, batch_size = 15, embedding_size = 1\n",
      "hidden_size = 1, init_hidden = False, output_size = 1000, seq_model = 'lstm'\n",
      "device = cpu()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\u001b[90m\u001b[39;49;00m\n",
      "                            init_hidden, output_size, seq_model, device):\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      ">       model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "batch_size = 15\n",
      "c0         = needle.Tensor([[[ 1.8909613 ]\n",
      "  [-0.5482929 ]\n",
      "  [ 0.18397388]\n",
      "  [-1.1646154 ]\n",
      "  [ 0.1774528 ]\n",
      "  [-1.9327788 ]\n",
      "  [-0.48...631]\n",
      "  [ 0.15251017]\n",
      "  [-0.43220255]\n",
      "  [ 1.4733672 ]\n",
      "  [ 1.4360205 ]\n",
      "  [ 0.6539853 ]\n",
      "  [-0.5285718 ]\n",
      "  [ 0.00356346]]])\n",
      "device     = cpu()\n",
      "embedding_size = 1\n",
      "h0         = needle.Tensor([[[-0.32906514]\n",
      "  [-0.9630935 ]\n",
      "  [ 2.7667377 ]\n",
      "  [-2.0422304 ]\n",
      "  [ 0.41694188]\n",
      "  [-0.2812683 ]\n",
      "  [ 2.72...093]\n",
      "  [ 0.3676105 ]\n",
      "  [-0.03789825]\n",
      "  [ 1.1063377 ]\n",
      "  [-0.5817751 ]\n",
      "  [-2.038037  ]\n",
      "  [-1.2526397 ]\n",
      "  [ 0.65933293]]])\n",
      "hidden_size = 1\n",
      "init_hidden = False\n",
      "num_layers = 1\n",
      "output_size = 1000\n",
      "seq_length = 1\n",
      "seq_model  = 'lstm'\n",
      "x          = array([[369., 116., 570., 444., 966., 540., 367., 834.,  49., 973., 420.,\n",
      "        839.,  95.,  47., 121.]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:201: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "self = <models.LanguageModel object at 0x1694739e0>, embedding_size = 1\n",
      "output_size = 1000, hidden_size = 1, num_layers = 1, seq_model = 'lstm'\n",
      "device = cpu(), dtype = 'float32'\n",
      "\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92m__init__\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, embedding_size, output_size, hidden_size, num_layers=\u001b[94m1\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                 seq_model=\u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, device=\u001b[94mNone\u001b[39;49;00m, dtype=\u001b[33m\"\u001b[39;49;00m\u001b[33mfloat32\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"\u001b[39;49;00m\n",
      "    \u001b[33m    Consists of an embedding layer, a sequence model (either RNN or LSTM), and a\u001b[39;49;00m\n",
      "    \u001b[33m    linear layer.\u001b[39;49;00m\n",
      "    \u001b[33m    Parameters:\u001b[39;49;00m\n",
      "    \u001b[33m    output_size: Size of dictionary\u001b[39;49;00m\n",
      "    \u001b[33m    embedding_size: Size of embeddings\u001b[39;49;00m\n",
      "    \u001b[33m    hidden_size: The number of features in the hidden state of LSTM or RNN\u001b[39;49;00m\n",
      "    \u001b[33m    seq_model: 'rnn' or 'lstm', whether to use RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    num_layers: Number of layers in RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    \"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[96msuper\u001b[39;49;00m(LanguageModel, \u001b[96mself\u001b[39;49;00m).\u001b[92m__init__\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m### BEGIN YOUR SOLUTION\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94mraise\u001b[39;49;00m \u001b[96mNotImplementedError\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       NotImplementedError\u001b[0m\n",
      "\n",
      "__class__  = <class 'models.LanguageModel'>\n",
      "device     = cpu()\n",
      "dtype      = 'float32'\n",
      "embedding_size = 1\n",
      "hidden_size = 1\n",
      "num_layers = 1\n",
      "output_size = 1000\n",
      "self       = <models.LanguageModel object at 0x1694739e0>\n",
      "seq_model  = 'lstm'\n",
      "\n",
      "\u001b[1m\u001b[31mapps/models.py\u001b[0m:38: NotImplementedError\n",
      "\u001b[31m\u001b[1m_____ test_language_model_implementation[cpu-lstm-1000-False-1-1-15-1-13] ______\u001b[0m\n",
      "\n",
      "seq_length = 13, num_layers = 1, batch_size = 15, embedding_size = 1\n",
      "hidden_size = 1, init_hidden = False, output_size = 1000, seq_model = 'lstm'\n",
      "device = cpu()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\u001b[90m\u001b[39;49;00m\n",
      "                            init_hidden, output_size, seq_model, device):\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      ">       model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "batch_size = 15\n",
      "c0         = needle.Tensor([[[ 1.016948  ]\n",
      "  [ 1.2433056 ]\n",
      "  [-1.166642  ]\n",
      "  [-0.5336969 ]\n",
      "  [-0.10610594]\n",
      "  [ 0.1366253 ]\n",
      "  [ 1.10...35 ]\n",
      "  [ 0.2170518 ]\n",
      "  [ 0.42514944]\n",
      "  [ 0.3990564 ]\n",
      "  [ 0.3739713 ]\n",
      "  [-0.10901232]\n",
      "  [ 0.32766306]\n",
      "  [ 1.0305952 ]]])\n",
      "device     = cpu()\n",
      "embedding_size = 1\n",
      "h0         = needle.Tensor([[[ 0.85118467]\n",
      "  [ 0.12977378]\n",
      "  [ 1.2088102 ]\n",
      "  [-0.65431434]\n",
      "  [ 1.0824876 ]\n",
      "  [ 1.8060055 ]\n",
      "  [ 1.51...06 ]\n",
      "  [ 0.01612642]\n",
      "  [ 0.58066946]\n",
      "  [ 0.03743792]\n",
      "  [-1.0451698 ]\n",
      "  [ 1.251286  ]\n",
      "  [ 1.0522945 ]\n",
      "  [-1.7355148 ]]])\n",
      "hidden_size = 1\n",
      "init_hidden = False\n",
      "num_layers = 1\n",
      "output_size = 1000\n",
      "seq_length = 13\n",
      "seq_model  = 'lstm'\n",
      "x          = array([[926., 434., 967., 295., 470., 152., 789.,  33., 534., 203., 711.,\n",
      "        567., 178.,  95.,  11.],\n",
      "       [544...    [111., 549., 337., 633., 124., 873., 629., 998., 276., 885., 550.,\n",
      "        665., 716., 314., 343.]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:201: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "self = <models.LanguageModel object at 0x169483a40>, embedding_size = 1\n",
      "output_size = 1000, hidden_size = 1, num_layers = 1, seq_model = 'lstm'\n",
      "device = cpu(), dtype = 'float32'\n",
      "\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92m__init__\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, embedding_size, output_size, hidden_size, num_layers=\u001b[94m1\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                 seq_model=\u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, device=\u001b[94mNone\u001b[39;49;00m, dtype=\u001b[33m\"\u001b[39;49;00m\u001b[33mfloat32\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"\u001b[39;49;00m\n",
      "    \u001b[33m    Consists of an embedding layer, a sequence model (either RNN or LSTM), and a\u001b[39;49;00m\n",
      "    \u001b[33m    linear layer.\u001b[39;49;00m\n",
      "    \u001b[33m    Parameters:\u001b[39;49;00m\n",
      "    \u001b[33m    output_size: Size of dictionary\u001b[39;49;00m\n",
      "    \u001b[33m    embedding_size: Size of embeddings\u001b[39;49;00m\n",
      "    \u001b[33m    hidden_size: The number of features in the hidden state of LSTM or RNN\u001b[39;49;00m\n",
      "    \u001b[33m    seq_model: 'rnn' or 'lstm', whether to use RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    num_layers: Number of layers in RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    \"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[96msuper\u001b[39;49;00m(LanguageModel, \u001b[96mself\u001b[39;49;00m).\u001b[92m__init__\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m### BEGIN YOUR SOLUTION\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94mraise\u001b[39;49;00m \u001b[96mNotImplementedError\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       NotImplementedError\u001b[0m\n",
      "\n",
      "__class__  = <class 'models.LanguageModel'>\n",
      "device     = cpu()\n",
      "dtype      = 'float32'\n",
      "embedding_size = 1\n",
      "hidden_size = 1\n",
      "num_layers = 1\n",
      "output_size = 1000\n",
      "self       = <models.LanguageModel object at 0x169483a40>\n",
      "seq_model  = 'lstm'\n",
      "\n",
      "\u001b[1m\u001b[31mapps/models.py\u001b[0m:38: NotImplementedError\n",
      "\u001b[31m\u001b[1m______ test_language_model_implementation[cpu-lstm-1000-False-1-1-15-2-1] ______\u001b[0m\n",
      "\n",
      "seq_length = 1, num_layers = 2, batch_size = 15, embedding_size = 1\n",
      "hidden_size = 1, init_hidden = False, output_size = 1000, seq_model = 'lstm'\n",
      "device = cpu()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\u001b[90m\u001b[39;49;00m\n",
      "                            init_hidden, output_size, seq_model, device):\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      ">       model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "batch_size = 15\n",
      "c0         = needle.Tensor([[[-0.554799  ]\n",
      "  [-0.6727041 ]\n",
      "  [-0.8699289 ]\n",
      "  [ 0.02944838]\n",
      "  [ 0.878585  ]\n",
      "  [-1.0894352 ]\n",
      "  [ 1.01...03 ]\n",
      "  [-0.38406226]\n",
      "  [-1.2183132 ]\n",
      "  [-0.8983658 ]\n",
      "  [ 0.17972367]\n",
      "  [-0.83190304]\n",
      "  [-0.55892056]\n",
      "  [ 0.90963423]]])\n",
      "device     = cpu()\n",
      "embedding_size = 1\n",
      "h0         = needle.Tensor([[[ 0.98444813]\n",
      "  [-1.4374923 ]\n",
      "  [ 0.34894922]\n",
      "  [ 0.21060556]\n",
      "  [-1.3317184 ]\n",
      "  [-0.9620578 ]\n",
      "  [-1.28...875]\n",
      "  [-0.49900544]\n",
      "  [ 0.70699024]\n",
      "  [ 0.03950534]\n",
      "  [ 0.5473272 ]\n",
      "  [-1.2061355 ]\n",
      "  [ 0.7243495 ]\n",
      "  [-1.5272179 ]]])\n",
      "hidden_size = 1\n",
      "init_hidden = False\n",
      "num_layers = 2\n",
      "output_size = 1000\n",
      "seq_length = 1\n",
      "seq_model  = 'lstm'\n",
      "x          = array([[151., 588., 447., 298., 453., 393., 314., 927., 661., 705.,  20.,\n",
      "        188., 621., 781.,  86.]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:201: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "self = <models.LanguageModel object at 0x169471e80>, embedding_size = 1\n",
      "output_size = 1000, hidden_size = 1, num_layers = 2, seq_model = 'lstm'\n",
      "device = cpu(), dtype = 'float32'\n",
      "\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92m__init__\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, embedding_size, output_size, hidden_size, num_layers=\u001b[94m1\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                 seq_model=\u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, device=\u001b[94mNone\u001b[39;49;00m, dtype=\u001b[33m\"\u001b[39;49;00m\u001b[33mfloat32\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"\u001b[39;49;00m\n",
      "    \u001b[33m    Consists of an embedding layer, a sequence model (either RNN or LSTM), and a\u001b[39;49;00m\n",
      "    \u001b[33m    linear layer.\u001b[39;49;00m\n",
      "    \u001b[33m    Parameters:\u001b[39;49;00m\n",
      "    \u001b[33m    output_size: Size of dictionary\u001b[39;49;00m\n",
      "    \u001b[33m    embedding_size: Size of embeddings\u001b[39;49;00m\n",
      "    \u001b[33m    hidden_size: The number of features in the hidden state of LSTM or RNN\u001b[39;49;00m\n",
      "    \u001b[33m    seq_model: 'rnn' or 'lstm', whether to use RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    num_layers: Number of layers in RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    \"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[96msuper\u001b[39;49;00m(LanguageModel, \u001b[96mself\u001b[39;49;00m).\u001b[92m__init__\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m### BEGIN YOUR SOLUTION\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94mraise\u001b[39;49;00m \u001b[96mNotImplementedError\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       NotImplementedError\u001b[0m\n",
      "\n",
      "__class__  = <class 'models.LanguageModel'>\n",
      "device     = cpu()\n",
      "dtype      = 'float32'\n",
      "embedding_size = 1\n",
      "hidden_size = 1\n",
      "num_layers = 2\n",
      "output_size = 1000\n",
      "self       = <models.LanguageModel object at 0x169471e80>\n",
      "seq_model  = 'lstm'\n",
      "\n",
      "\u001b[1m\u001b[31mapps/models.py\u001b[0m:38: NotImplementedError\n",
      "\u001b[31m\u001b[1m_____ test_language_model_implementation[cpu-lstm-1000-False-1-1-15-2-13] ______\u001b[0m\n",
      "\n",
      "seq_length = 13, num_layers = 2, batch_size = 15, embedding_size = 1\n",
      "hidden_size = 1, init_hidden = False, output_size = 1000, seq_model = 'lstm'\n",
      "device = cpu()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\u001b[90m\u001b[39;49;00m\n",
      "                            init_hidden, output_size, seq_model, device):\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      ">       model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "batch_size = 15\n",
      "c0         = needle.Tensor([[[-0.09068882]\n",
      "  [-0.40889415]\n",
      "  [-1.6533495 ]\n",
      "  [-0.08719462]\n",
      "  [ 0.9652261 ]\n",
      "  [ 1.338467  ]\n",
      "  [ 0.09...96 ]\n",
      "  [-2.6201572 ]\n",
      "  [ 0.41624555]\n",
      "  [-0.89741325]\n",
      "  [-1.3156899 ]\n",
      "  [-1.2603712 ]\n",
      "  [ 1.1170052 ]\n",
      "  [ 0.43149993]]])\n",
      "device     = cpu()\n",
      "embedding_size = 1\n",
      "h0         = needle.Tensor([[[-1.8638917 ]\n",
      "  [ 0.06918348]\n",
      "  [ 0.6181451 ]\n",
      "  [-1.1276888 ]\n",
      "  [-1.3207765 ]\n",
      "  [-1.3335205 ]\n",
      "  [-0.05...184]\n",
      "  [ 0.5671878 ]\n",
      "  [ 0.15902519]\n",
      "  [-0.6579299 ]\n",
      "  [-0.44278607]\n",
      "  [-0.18295938]\n",
      "  [ 1.1283628 ]\n",
      "  [-0.23657013]]])\n",
      "hidden_size = 1\n",
      "init_hidden = False\n",
      "num_layers = 2\n",
      "output_size = 1000\n",
      "seq_length = 13\n",
      "seq_model  = 'lstm'\n",
      "x          = array([[234., 461., 709., 875., 695., 627., 398., 953.,  68., 191., 809.,\n",
      "        434., 842., 758., 290.],\n",
      "       [ 66...    [927., 120.,  54., 943., 893.,  25., 851., 861., 132., 443., 132.,\n",
      "        335., 319., 561., 207.]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:201: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "self = <models.LanguageModel object at 0x169471130>, embedding_size = 1\n",
      "output_size = 1000, hidden_size = 1, num_layers = 2, seq_model = 'lstm'\n",
      "device = cpu(), dtype = 'float32'\n",
      "\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92m__init__\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, embedding_size, output_size, hidden_size, num_layers=\u001b[94m1\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                 seq_model=\u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, device=\u001b[94mNone\u001b[39;49;00m, dtype=\u001b[33m\"\u001b[39;49;00m\u001b[33mfloat32\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"\u001b[39;49;00m\n",
      "    \u001b[33m    Consists of an embedding layer, a sequence model (either RNN or LSTM), and a\u001b[39;49;00m\n",
      "    \u001b[33m    linear layer.\u001b[39;49;00m\n",
      "    \u001b[33m    Parameters:\u001b[39;49;00m\n",
      "    \u001b[33m    output_size: Size of dictionary\u001b[39;49;00m\n",
      "    \u001b[33m    embedding_size: Size of embeddings\u001b[39;49;00m\n",
      "    \u001b[33m    hidden_size: The number of features in the hidden state of LSTM or RNN\u001b[39;49;00m\n",
      "    \u001b[33m    seq_model: 'rnn' or 'lstm', whether to use RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    num_layers: Number of layers in RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    \"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[96msuper\u001b[39;49;00m(LanguageModel, \u001b[96mself\u001b[39;49;00m).\u001b[92m__init__\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m### BEGIN YOUR SOLUTION\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94mraise\u001b[39;49;00m \u001b[96mNotImplementedError\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       NotImplementedError\u001b[0m\n",
      "\n",
      "__class__  = <class 'models.LanguageModel'>\n",
      "device     = cpu()\n",
      "dtype      = 'float32'\n",
      "embedding_size = 1\n",
      "hidden_size = 1\n",
      "num_layers = 2\n",
      "output_size = 1000\n",
      "self       = <models.LanguageModel object at 0x169471130>\n",
      "seq_model  = 'lstm'\n",
      "\n",
      "\u001b[1m\u001b[31mapps/models.py\u001b[0m:38: NotImplementedError\n",
      "\u001b[31m\u001b[1m______ test_language_model_implementation[cpu-lstm-1000-False-1-34-1-1-1] ______\u001b[0m\n",
      "\n",
      "seq_length = 1, num_layers = 1, batch_size = 1, embedding_size = 34\n",
      "hidden_size = 1, init_hidden = False, output_size = 1000, seq_model = 'lstm'\n",
      "device = cpu()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\u001b[90m\u001b[39;49;00m\n",
      "                            init_hidden, output_size, seq_model, device):\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      ">       model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "batch_size = 1\n",
      "c0         = needle.Tensor([[[0.2391685]]])\n",
      "device     = cpu()\n",
      "embedding_size = 34\n",
      "h0         = needle.Tensor([[[0.34319884]]])\n",
      "hidden_size = 1\n",
      "init_hidden = False\n",
      "num_layers = 1\n",
      "output_size = 1000\n",
      "seq_length = 1\n",
      "seq_model  = 'lstm'\n",
      "x          = array([[145.]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:201: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "self = <models.LanguageModel object at 0x1694c5d00>, embedding_size = 34\n",
      "output_size = 1000, hidden_size = 1, num_layers = 1, seq_model = 'lstm'\n",
      "device = cpu(), dtype = 'float32'\n",
      "\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92m__init__\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, embedding_size, output_size, hidden_size, num_layers=\u001b[94m1\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                 seq_model=\u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, device=\u001b[94mNone\u001b[39;49;00m, dtype=\u001b[33m\"\u001b[39;49;00m\u001b[33mfloat32\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"\u001b[39;49;00m\n",
      "    \u001b[33m    Consists of an embedding layer, a sequence model (either RNN or LSTM), and a\u001b[39;49;00m\n",
      "    \u001b[33m    linear layer.\u001b[39;49;00m\n",
      "    \u001b[33m    Parameters:\u001b[39;49;00m\n",
      "    \u001b[33m    output_size: Size of dictionary\u001b[39;49;00m\n",
      "    \u001b[33m    embedding_size: Size of embeddings\u001b[39;49;00m\n",
      "    \u001b[33m    hidden_size: The number of features in the hidden state of LSTM or RNN\u001b[39;49;00m\n",
      "    \u001b[33m    seq_model: 'rnn' or 'lstm', whether to use RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    num_layers: Number of layers in RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    \"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[96msuper\u001b[39;49;00m(LanguageModel, \u001b[96mself\u001b[39;49;00m).\u001b[92m__init__\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m### BEGIN YOUR SOLUTION\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94mraise\u001b[39;49;00m \u001b[96mNotImplementedError\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       NotImplementedError\u001b[0m\n",
      "\n",
      "__class__  = <class 'models.LanguageModel'>\n",
      "device     = cpu()\n",
      "dtype      = 'float32'\n",
      "embedding_size = 34\n",
      "hidden_size = 1\n",
      "num_layers = 1\n",
      "output_size = 1000\n",
      "self       = <models.LanguageModel object at 0x1694c5d00>\n",
      "seq_model  = 'lstm'\n",
      "\n",
      "\u001b[1m\u001b[31mapps/models.py\u001b[0m:38: NotImplementedError\n",
      "\u001b[31m\u001b[1m_____ test_language_model_implementation[cpu-lstm-1000-False-1-34-1-1-13] ______\u001b[0m\n",
      "\n",
      "seq_length = 13, num_layers = 1, batch_size = 1, embedding_size = 34\n",
      "hidden_size = 1, init_hidden = False, output_size = 1000, seq_model = 'lstm'\n",
      "device = cpu()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\u001b[90m\u001b[39;49;00m\n",
      "                            init_hidden, output_size, seq_model, device):\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      ">       model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "batch_size = 1\n",
      "c0         = needle.Tensor([[[0.18169968]]])\n",
      "device     = cpu()\n",
      "embedding_size = 34\n",
      "h0         = needle.Tensor([[[1.5199517]]])\n",
      "hidden_size = 1\n",
      "init_hidden = False\n",
      "num_layers = 1\n",
      "output_size = 1000\n",
      "seq_length = 13\n",
      "seq_model  = 'lstm'\n",
      "x          = array([[716.],\n",
      "       [168.],\n",
      "       [722.],\n",
      "       [ 78.],\n",
      "       [316.],\n",
      "       [175.],\n",
      "       [989.],\n",
      "       [494.],\n",
      "       [277.],\n",
      "       [227.],\n",
      "       [506.],\n",
      "       [597.],\n",
      "       [217.]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:201: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "self = <models.LanguageModel object at 0x1694c7290>, embedding_size = 34\n",
      "output_size = 1000, hidden_size = 1, num_layers = 1, seq_model = 'lstm'\n",
      "device = cpu(), dtype = 'float32'\n",
      "\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92m__init__\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, embedding_size, output_size, hidden_size, num_layers=\u001b[94m1\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                 seq_model=\u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, device=\u001b[94mNone\u001b[39;49;00m, dtype=\u001b[33m\"\u001b[39;49;00m\u001b[33mfloat32\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"\u001b[39;49;00m\n",
      "    \u001b[33m    Consists of an embedding layer, a sequence model (either RNN or LSTM), and a\u001b[39;49;00m\n",
      "    \u001b[33m    linear layer.\u001b[39;49;00m\n",
      "    \u001b[33m    Parameters:\u001b[39;49;00m\n",
      "    \u001b[33m    output_size: Size of dictionary\u001b[39;49;00m\n",
      "    \u001b[33m    embedding_size: Size of embeddings\u001b[39;49;00m\n",
      "    \u001b[33m    hidden_size: The number of features in the hidden state of LSTM or RNN\u001b[39;49;00m\n",
      "    \u001b[33m    seq_model: 'rnn' or 'lstm', whether to use RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    num_layers: Number of layers in RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    \"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[96msuper\u001b[39;49;00m(LanguageModel, \u001b[96mself\u001b[39;49;00m).\u001b[92m__init__\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m### BEGIN YOUR SOLUTION\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94mraise\u001b[39;49;00m \u001b[96mNotImplementedError\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       NotImplementedError\u001b[0m\n",
      "\n",
      "__class__  = <class 'models.LanguageModel'>\n",
      "device     = cpu()\n",
      "dtype      = 'float32'\n",
      "embedding_size = 34\n",
      "hidden_size = 1\n",
      "num_layers = 1\n",
      "output_size = 1000\n",
      "self       = <models.LanguageModel object at 0x1694c7290>\n",
      "seq_model  = 'lstm'\n",
      "\n",
      "\u001b[1m\u001b[31mapps/models.py\u001b[0m:38: NotImplementedError\n",
      "\u001b[31m\u001b[1m______ test_language_model_implementation[cpu-lstm-1000-False-1-34-1-2-1] ______\u001b[0m\n",
      "\n",
      "seq_length = 1, num_layers = 2, batch_size = 1, embedding_size = 34\n",
      "hidden_size = 1, init_hidden = False, output_size = 1000, seq_model = 'lstm'\n",
      "device = cpu()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\u001b[90m\u001b[39;49;00m\n",
      "                            init_hidden, output_size, seq_model, device):\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      ">       model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "batch_size = 1\n",
      "c0         = needle.Tensor([[[-0.9051394]]\n",
      "\n",
      " [[ 0.7680879]]])\n",
      "device     = cpu()\n",
      "embedding_size = 34\n",
      "h0         = needle.Tensor([[[-0.6675006]]\n",
      "\n",
      " [[-0.677499 ]]])\n",
      "hidden_size = 1\n",
      "init_hidden = False\n",
      "num_layers = 2\n",
      "output_size = 1000\n",
      "seq_length = 1\n",
      "seq_model  = 'lstm'\n",
      "x          = array([[871.]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:201: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "self = <models.LanguageModel object at 0x1694c42c0>, embedding_size = 34\n",
      "output_size = 1000, hidden_size = 1, num_layers = 2, seq_model = 'lstm'\n",
      "device = cpu(), dtype = 'float32'\n",
      "\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92m__init__\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, embedding_size, output_size, hidden_size, num_layers=\u001b[94m1\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                 seq_model=\u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, device=\u001b[94mNone\u001b[39;49;00m, dtype=\u001b[33m\"\u001b[39;49;00m\u001b[33mfloat32\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"\u001b[39;49;00m\n",
      "    \u001b[33m    Consists of an embedding layer, a sequence model (either RNN or LSTM), and a\u001b[39;49;00m\n",
      "    \u001b[33m    linear layer.\u001b[39;49;00m\n",
      "    \u001b[33m    Parameters:\u001b[39;49;00m\n",
      "    \u001b[33m    output_size: Size of dictionary\u001b[39;49;00m\n",
      "    \u001b[33m    embedding_size: Size of embeddings\u001b[39;49;00m\n",
      "    \u001b[33m    hidden_size: The number of features in the hidden state of LSTM or RNN\u001b[39;49;00m\n",
      "    \u001b[33m    seq_model: 'rnn' or 'lstm', whether to use RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    num_layers: Number of layers in RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    \"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[96msuper\u001b[39;49;00m(LanguageModel, \u001b[96mself\u001b[39;49;00m).\u001b[92m__init__\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m### BEGIN YOUR SOLUTION\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94mraise\u001b[39;49;00m \u001b[96mNotImplementedError\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       NotImplementedError\u001b[0m\n",
      "\n",
      "__class__  = <class 'models.LanguageModel'>\n",
      "device     = cpu()\n",
      "dtype      = 'float32'\n",
      "embedding_size = 34\n",
      "hidden_size = 1\n",
      "num_layers = 2\n",
      "output_size = 1000\n",
      "self       = <models.LanguageModel object at 0x1694c42c0>\n",
      "seq_model  = 'lstm'\n",
      "\n",
      "\u001b[1m\u001b[31mapps/models.py\u001b[0m:38: NotImplementedError\n",
      "\u001b[31m\u001b[1m_____ test_language_model_implementation[cpu-lstm-1000-False-1-34-1-2-13] ______\u001b[0m\n",
      "\n",
      "seq_length = 13, num_layers = 2, batch_size = 1, embedding_size = 34\n",
      "hidden_size = 1, init_hidden = False, output_size = 1000, seq_model = 'lstm'\n",
      "device = cpu()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\u001b[90m\u001b[39;49;00m\n",
      "                            init_hidden, output_size, seq_model, device):\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      ">       model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "batch_size = 1\n",
      "c0         = needle.Tensor([[[ 0.9060514 ]]\n",
      "\n",
      " [[-0.68222415]]])\n",
      "device     = cpu()\n",
      "embedding_size = 34\n",
      "h0         = needle.Tensor([[[-0.68256396]]\n",
      "\n",
      " [[-0.72536355]]])\n",
      "hidden_size = 1\n",
      "init_hidden = False\n",
      "num_layers = 2\n",
      "output_size = 1000\n",
      "seq_length = 13\n",
      "seq_model  = 'lstm'\n",
      "x          = array([[814.],\n",
      "       [605.],\n",
      "       [255.],\n",
      "       [613.],\n",
      "       [208.],\n",
      "       [801.],\n",
      "       [  4.],\n",
      "       [580.],\n",
      "       [120.],\n",
      "       [754.],\n",
      "       [838.],\n",
      "       [483.],\n",
      "       [172.]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:201: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "self = <models.LanguageModel object at 0x1694c7e00>, embedding_size = 34\n",
      "output_size = 1000, hidden_size = 1, num_layers = 2, seq_model = 'lstm'\n",
      "device = cpu(), dtype = 'float32'\n",
      "\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92m__init__\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, embedding_size, output_size, hidden_size, num_layers=\u001b[94m1\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                 seq_model=\u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, device=\u001b[94mNone\u001b[39;49;00m, dtype=\u001b[33m\"\u001b[39;49;00m\u001b[33mfloat32\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"\u001b[39;49;00m\n",
      "    \u001b[33m    Consists of an embedding layer, a sequence model (either RNN or LSTM), and a\u001b[39;49;00m\n",
      "    \u001b[33m    linear layer.\u001b[39;49;00m\n",
      "    \u001b[33m    Parameters:\u001b[39;49;00m\n",
      "    \u001b[33m    output_size: Size of dictionary\u001b[39;49;00m\n",
      "    \u001b[33m    embedding_size: Size of embeddings\u001b[39;49;00m\n",
      "    \u001b[33m    hidden_size: The number of features in the hidden state of LSTM or RNN\u001b[39;49;00m\n",
      "    \u001b[33m    seq_model: 'rnn' or 'lstm', whether to use RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    num_layers: Number of layers in RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    \"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[96msuper\u001b[39;49;00m(LanguageModel, \u001b[96mself\u001b[39;49;00m).\u001b[92m__init__\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m### BEGIN YOUR SOLUTION\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94mraise\u001b[39;49;00m \u001b[96mNotImplementedError\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       NotImplementedError\u001b[0m\n",
      "\n",
      "__class__  = <class 'models.LanguageModel'>\n",
      "device     = cpu()\n",
      "dtype      = 'float32'\n",
      "embedding_size = 34\n",
      "hidden_size = 1\n",
      "num_layers = 2\n",
      "output_size = 1000\n",
      "self       = <models.LanguageModel object at 0x1694c7e00>\n",
      "seq_model  = 'lstm'\n",
      "\n",
      "\u001b[1m\u001b[31mapps/models.py\u001b[0m:38: NotImplementedError\n",
      "\u001b[31m\u001b[1m_____ test_language_model_implementation[cpu-lstm-1000-False-1-34-15-1-1] ______\u001b[0m\n",
      "\n",
      "seq_length = 1, num_layers = 1, batch_size = 15, embedding_size = 34\n",
      "hidden_size = 1, init_hidden = False, output_size = 1000, seq_model = 'lstm'\n",
      "device = cpu()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\u001b[90m\u001b[39;49;00m\n",
      "                            init_hidden, output_size, seq_model, device):\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      ">       model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "batch_size = 15\n",
      "c0         = needle.Tensor([[[-0.35691053]\n",
      "  [ 1.6709709 ]\n",
      "  [ 1.2618017 ]\n",
      "  [ 0.3661522 ]\n",
      "  [-1.067476  ]\n",
      "  [ 1.0301126 ]\n",
      "  [-0.93...494]\n",
      "  [ 0.366896  ]\n",
      "  [-2.0895178 ]\n",
      "  [ 0.56934345]\n",
      "  [ 1.5575541 ]\n",
      "  [ 0.02924612]\n",
      "  [ 0.4111572 ]\n",
      "  [ 1.6329743 ]]])\n",
      "device     = cpu()\n",
      "embedding_size = 34\n",
      "h0         = needle.Tensor([[[ 0.71591073]\n",
      "  [-1.6433662 ]\n",
      "  [ 0.90483046]\n",
      "  [-0.08465993]\n",
      "  [-0.44284225]\n",
      "  [ 0.11353725]\n",
      "  [ 2.25...36 ]\n",
      "  [ 0.01302509]\n",
      "  [ 0.8975534 ]\n",
      "  [ 0.27401257]\n",
      "  [-0.06515121]\n",
      "  [ 1.0847017 ]\n",
      "  [-0.91224205]\n",
      "  [-0.09148073]]])\n",
      "hidden_size = 1\n",
      "init_hidden = False\n",
      "num_layers = 1\n",
      "output_size = 1000\n",
      "seq_length = 1\n",
      "seq_model  = 'lstm'\n",
      "x          = array([[718., 584., 866.,  32.,  95., 293., 472., 909.,  34.,  10., 353.,\n",
      "        140., 570., 255., 928.]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:201: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "self = <models.LanguageModel object at 0x1694cec90>, embedding_size = 34\n",
      "output_size = 1000, hidden_size = 1, num_layers = 1, seq_model = 'lstm'\n",
      "device = cpu(), dtype = 'float32'\n",
      "\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92m__init__\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, embedding_size, output_size, hidden_size, num_layers=\u001b[94m1\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                 seq_model=\u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, device=\u001b[94mNone\u001b[39;49;00m, dtype=\u001b[33m\"\u001b[39;49;00m\u001b[33mfloat32\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"\u001b[39;49;00m\n",
      "    \u001b[33m    Consists of an embedding layer, a sequence model (either RNN or LSTM), and a\u001b[39;49;00m\n",
      "    \u001b[33m    linear layer.\u001b[39;49;00m\n",
      "    \u001b[33m    Parameters:\u001b[39;49;00m\n",
      "    \u001b[33m    output_size: Size of dictionary\u001b[39;49;00m\n",
      "    \u001b[33m    embedding_size: Size of embeddings\u001b[39;49;00m\n",
      "    \u001b[33m    hidden_size: The number of features in the hidden state of LSTM or RNN\u001b[39;49;00m\n",
      "    \u001b[33m    seq_model: 'rnn' or 'lstm', whether to use RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    num_layers: Number of layers in RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    \"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[96msuper\u001b[39;49;00m(LanguageModel, \u001b[96mself\u001b[39;49;00m).\u001b[92m__init__\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m### BEGIN YOUR SOLUTION\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94mraise\u001b[39;49;00m \u001b[96mNotImplementedError\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       NotImplementedError\u001b[0m\n",
      "\n",
      "__class__  = <class 'models.LanguageModel'>\n",
      "device     = cpu()\n",
      "dtype      = 'float32'\n",
      "embedding_size = 34\n",
      "hidden_size = 1\n",
      "num_layers = 1\n",
      "output_size = 1000\n",
      "self       = <models.LanguageModel object at 0x1694cec90>\n",
      "seq_model  = 'lstm'\n",
      "\n",
      "\u001b[1m\u001b[31mapps/models.py\u001b[0m:38: NotImplementedError\n",
      "\u001b[31m\u001b[1m_____ test_language_model_implementation[cpu-lstm-1000-False-1-34-15-1-13] _____\u001b[0m\n",
      "\n",
      "seq_length = 13, num_layers = 1, batch_size = 15, embedding_size = 34\n",
      "hidden_size = 1, init_hidden = False, output_size = 1000, seq_model = 'lstm'\n",
      "device = cpu()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\u001b[90m\u001b[39;49;00m\n",
      "                            init_hidden, output_size, seq_model, device):\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      ">       model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "batch_size = 15\n",
      "c0         = needle.Tensor([[[ 0.37148985]\n",
      "  [-1.5909481 ]\n",
      "  [ 0.21606648]\n",
      "  [-0.07520302]\n",
      "  [ 1.0217813 ]\n",
      "  [-0.48494124]\n",
      "  [-1.80...902]\n",
      "  [ 1.5521944 ]\n",
      "  [ 0.13998032]\n",
      "  [-0.1860017 ]\n",
      "  [ 1.8870659 ]\n",
      "  [-0.4234941 ]\n",
      "  [ 0.3909541 ]\n",
      "  [-0.38817638]]])\n",
      "device     = cpu()\n",
      "embedding_size = 34\n",
      "h0         = needle.Tensor([[[-1.1473879 ]\n",
      "  [ 2.0699863 ]\n",
      "  [ 0.69498426]\n",
      "  [ 1.6638839 ]\n",
      "  [ 0.11212321]\n",
      "  [-2.00329   ]\n",
      "  [ 1.79...11 ]\n",
      "  [ 0.2820498 ]\n",
      "  [ 0.7033562 ]\n",
      "  [ 1.564895  ]\n",
      "  [-2.079236  ]\n",
      "  [-1.6981148 ]\n",
      "  [ 2.0434272 ]\n",
      "  [ 0.53226256]]])\n",
      "hidden_size = 1\n",
      "init_hidden = False\n",
      "num_layers = 1\n",
      "output_size = 1000\n",
      "seq_length = 13\n",
      "seq_model  = 'lstm'\n",
      "x          = array([[564., 438.,  95.,  59., 799., 510., 477., 522.,  83., 981., 199.,\n",
      "        368., 497., 659., 142.],\n",
      "       [607...    [ 46., 831., 313., 260., 487., 669.,  87.,  72.,  39., 187., 291.,\n",
      "        791., 658., 504., 910.]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:201: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "self = <models.LanguageModel object at 0x169470290>, embedding_size = 34\n",
      "output_size = 1000, hidden_size = 1, num_layers = 1, seq_model = 'lstm'\n",
      "device = cpu(), dtype = 'float32'\n",
      "\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92m__init__\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, embedding_size, output_size, hidden_size, num_layers=\u001b[94m1\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                 seq_model=\u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, device=\u001b[94mNone\u001b[39;49;00m, dtype=\u001b[33m\"\u001b[39;49;00m\u001b[33mfloat32\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"\u001b[39;49;00m\n",
      "    \u001b[33m    Consists of an embedding layer, a sequence model (either RNN or LSTM), and a\u001b[39;49;00m\n",
      "    \u001b[33m    linear layer.\u001b[39;49;00m\n",
      "    \u001b[33m    Parameters:\u001b[39;49;00m\n",
      "    \u001b[33m    output_size: Size of dictionary\u001b[39;49;00m\n",
      "    \u001b[33m    embedding_size: Size of embeddings\u001b[39;49;00m\n",
      "    \u001b[33m    hidden_size: The number of features in the hidden state of LSTM or RNN\u001b[39;49;00m\n",
      "    \u001b[33m    seq_model: 'rnn' or 'lstm', whether to use RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    num_layers: Number of layers in RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    \"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[96msuper\u001b[39;49;00m(LanguageModel, \u001b[96mself\u001b[39;49;00m).\u001b[92m__init__\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m### BEGIN YOUR SOLUTION\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94mraise\u001b[39;49;00m \u001b[96mNotImplementedError\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       NotImplementedError\u001b[0m\n",
      "\n",
      "__class__  = <class 'models.LanguageModel'>\n",
      "device     = cpu()\n",
      "dtype      = 'float32'\n",
      "embedding_size = 34\n",
      "hidden_size = 1\n",
      "num_layers = 1\n",
      "output_size = 1000\n",
      "self       = <models.LanguageModel object at 0x169470290>\n",
      "seq_model  = 'lstm'\n",
      "\n",
      "\u001b[1m\u001b[31mapps/models.py\u001b[0m:38: NotImplementedError\n",
      "\u001b[31m\u001b[1m_____ test_language_model_implementation[cpu-lstm-1000-False-1-34-15-2-1] ______\u001b[0m\n",
      "\n",
      "seq_length = 1, num_layers = 2, batch_size = 15, embedding_size = 34\n",
      "hidden_size = 1, init_hidden = False, output_size = 1000, seq_model = 'lstm'\n",
      "device = cpu()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\u001b[90m\u001b[39;49;00m\n",
      "                            init_hidden, output_size, seq_model, device):\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      ">       model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "batch_size = 15\n",
      "c0         = needle.Tensor([[[-0.4356433 ]\n",
      "  [ 0.58725816]\n",
      "  [-0.5213558 ]\n",
      "  [-1.7028165 ]\n",
      "  [-0.0287107 ]\n",
      "  [ 0.26102442]\n",
      "  [ 1.13...495]\n",
      "  [-0.10665481]\n",
      "  [-0.34624243]\n",
      "  [-0.24547443]\n",
      "  [-0.5892026 ]\n",
      "  [-1.3015003 ]\n",
      "  [-0.68683296]\n",
      "  [ 0.78637654]]])\n",
      "device     = cpu()\n",
      "embedding_size = 34\n",
      "h0         = needle.Tensor([[[ 0.17498605]\n",
      "  [ 0.7956722 ]\n",
      "  [-0.03244403]\n",
      "  [ 0.22042727]\n",
      "  [ 2.0450466 ]\n",
      "  [ 0.70827633]\n",
      "  [-0.90...876]\n",
      "  [-0.2127981 ]\n",
      "  [-0.46412605]\n",
      "  [-0.39506188]\n",
      "  [ 0.5138813 ]\n",
      "  [-0.21886419]\n",
      "  [-0.76646274]\n",
      "  [-0.02336199]]])\n",
      "hidden_size = 1\n",
      "init_hidden = False\n",
      "num_layers = 2\n",
      "output_size = 1000\n",
      "seq_length = 1\n",
      "seq_model  = 'lstm'\n",
      "x          = array([[237., 450., 560., 344.,  15., 183.,  62., 368., 635., 746., 100.,\n",
      "        921., 562., 165.,  44.]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:201: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "self = <models.LanguageModel object at 0x169538aa0>, embedding_size = 34\n",
      "output_size = 1000, hidden_size = 1, num_layers = 2, seq_model = 'lstm'\n",
      "device = cpu(), dtype = 'float32'\n",
      "\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92m__init__\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, embedding_size, output_size, hidden_size, num_layers=\u001b[94m1\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                 seq_model=\u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, device=\u001b[94mNone\u001b[39;49;00m, dtype=\u001b[33m\"\u001b[39;49;00m\u001b[33mfloat32\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"\u001b[39;49;00m\n",
      "    \u001b[33m    Consists of an embedding layer, a sequence model (either RNN or LSTM), and a\u001b[39;49;00m\n",
      "    \u001b[33m    linear layer.\u001b[39;49;00m\n",
      "    \u001b[33m    Parameters:\u001b[39;49;00m\n",
      "    \u001b[33m    output_size: Size of dictionary\u001b[39;49;00m\n",
      "    \u001b[33m    embedding_size: Size of embeddings\u001b[39;49;00m\n",
      "    \u001b[33m    hidden_size: The number of features in the hidden state of LSTM or RNN\u001b[39;49;00m\n",
      "    \u001b[33m    seq_model: 'rnn' or 'lstm', whether to use RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    num_layers: Number of layers in RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    \"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[96msuper\u001b[39;49;00m(LanguageModel, \u001b[96mself\u001b[39;49;00m).\u001b[92m__init__\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m### BEGIN YOUR SOLUTION\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94mraise\u001b[39;49;00m \u001b[96mNotImplementedError\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       NotImplementedError\u001b[0m\n",
      "\n",
      "__class__  = <class 'models.LanguageModel'>\n",
      "device     = cpu()\n",
      "dtype      = 'float32'\n",
      "embedding_size = 34\n",
      "hidden_size = 1\n",
      "num_layers = 2\n",
      "output_size = 1000\n",
      "self       = <models.LanguageModel object at 0x169538aa0>\n",
      "seq_model  = 'lstm'\n",
      "\n",
      "\u001b[1m\u001b[31mapps/models.py\u001b[0m:38: NotImplementedError\n",
      "\u001b[31m\u001b[1m_____ test_language_model_implementation[cpu-lstm-1000-False-1-34-15-2-13] _____\u001b[0m\n",
      "\n",
      "seq_length = 13, num_layers = 2, batch_size = 15, embedding_size = 34\n",
      "hidden_size = 1, init_hidden = False, output_size = 1000, seq_model = 'lstm'\n",
      "device = cpu()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\u001b[90m\u001b[39;49;00m\n",
      "                            init_hidden, output_size, seq_model, device):\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      ">       model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "batch_size = 15\n",
      "c0         = needle.Tensor([[[-0.82075846]\n",
      "  [ 1.1279051 ]\n",
      "  [ 0.67637044]\n",
      "  [-1.1500831 ]\n",
      "  [-0.08659871]\n",
      "  [-1.3106792 ]\n",
      "  [-1.54...17 ]\n",
      "  [ 0.51664424]\n",
      "  [ 0.4341024 ]\n",
      "  [-1.9630339 ]\n",
      "  [ 1.1933551 ]\n",
      "  [-2.0909379 ]\n",
      "  [ 1.1639233 ]\n",
      "  [ 1.8025659 ]]])\n",
      "device     = cpu()\n",
      "embedding_size = 34\n",
      "h0         = needle.Tensor([[[ 1.2226944 ]\n",
      "  [ 1.0931854 ]\n",
      "  [ 0.22599179]\n",
      "  [-0.05267728]\n",
      "  [ 1.3148245 ]\n",
      "  [ 0.6316563 ]\n",
      "  [-0.59...56 ]\n",
      "  [-0.0767646 ]\n",
      "  [ 1.7583652 ]\n",
      "  [ 0.3682212 ]\n",
      "  [ 1.6150949 ]\n",
      "  [ 2.4950504 ]\n",
      "  [-0.47510955]\n",
      "  [-0.08029788]]])\n",
      "hidden_size = 1\n",
      "init_hidden = False\n",
      "num_layers = 2\n",
      "output_size = 1000\n",
      "seq_length = 13\n",
      "seq_model  = 'lstm'\n",
      "x          = array([[994., 784., 916., 329., 231., 199., 984., 363., 595., 829., 234.,\n",
      "        124., 207., 117., 260.],\n",
      "       [397...    [472., 962., 346., 470., 906., 521., 809., 371., 175.,   7., 860.,\n",
      "         35., 433., 711., 276.]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:201: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "self = <models.LanguageModel object at 0x16953bfb0>, embedding_size = 34\n",
      "output_size = 1000, hidden_size = 1, num_layers = 2, seq_model = 'lstm'\n",
      "device = cpu(), dtype = 'float32'\n",
      "\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92m__init__\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, embedding_size, output_size, hidden_size, num_layers=\u001b[94m1\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                 seq_model=\u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, device=\u001b[94mNone\u001b[39;49;00m, dtype=\u001b[33m\"\u001b[39;49;00m\u001b[33mfloat32\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"\u001b[39;49;00m\n",
      "    \u001b[33m    Consists of an embedding layer, a sequence model (either RNN or LSTM), and a\u001b[39;49;00m\n",
      "    \u001b[33m    linear layer.\u001b[39;49;00m\n",
      "    \u001b[33m    Parameters:\u001b[39;49;00m\n",
      "    \u001b[33m    output_size: Size of dictionary\u001b[39;49;00m\n",
      "    \u001b[33m    embedding_size: Size of embeddings\u001b[39;49;00m\n",
      "    \u001b[33m    hidden_size: The number of features in the hidden state of LSTM or RNN\u001b[39;49;00m\n",
      "    \u001b[33m    seq_model: 'rnn' or 'lstm', whether to use RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    num_layers: Number of layers in RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    \"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[96msuper\u001b[39;49;00m(LanguageModel, \u001b[96mself\u001b[39;49;00m).\u001b[92m__init__\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m### BEGIN YOUR SOLUTION\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94mraise\u001b[39;49;00m \u001b[96mNotImplementedError\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       NotImplementedError\u001b[0m\n",
      "\n",
      "__class__  = <class 'models.LanguageModel'>\n",
      "device     = cpu()\n",
      "dtype      = 'float32'\n",
      "embedding_size = 34\n",
      "hidden_size = 1\n",
      "num_layers = 2\n",
      "output_size = 1000\n",
      "self       = <models.LanguageModel object at 0x16953bfb0>\n",
      "seq_model  = 'lstm'\n",
      "\n",
      "\u001b[1m\u001b[31mapps/models.py\u001b[0m:38: NotImplementedError\n",
      "\u001b[31m\u001b[1m______ test_language_model_implementation[cpu-lstm-1000-False-12-1-1-1-1] ______\u001b[0m\n",
      "\n",
      "seq_length = 1, num_layers = 1, batch_size = 1, embedding_size = 1\n",
      "hidden_size = 12, init_hidden = False, output_size = 1000, seq_model = 'lstm'\n",
      "device = cpu()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\u001b[90m\u001b[39;49;00m\n",
      "                            init_hidden, output_size, seq_model, device):\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      ">       model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "batch_size = 1\n",
      "c0         = needle.Tensor([[[-0.26910818 -0.9382206   1.7396939  -0.36370555  0.6712331\n",
      "   -0.1165602   0.20543526 -1.0669171  -0.99015105 -1.3720298\n",
      "    0.747337   -0.50699764]]])\n",
      "device     = cpu()\n",
      "embedding_size = 1\n",
      "h0         = needle.Tensor([[[-0.7247959   0.5509144   0.79211825 -0.07715701 -1.1898648\n",
      "    0.7081817   0.23254722 -2.106438   -0.68356586  0.17458613\n",
      "   -0.08497954  0.98558235]]])\n",
      "hidden_size = 12\n",
      "init_hidden = False\n",
      "num_layers = 1\n",
      "output_size = 1000\n",
      "seq_length = 1\n",
      "seq_model  = 'lstm'\n",
      "x          = array([[384.]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:201: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "self = <models.LanguageModel object at 0x169621040>, embedding_size = 1\n",
      "output_size = 1000, hidden_size = 12, num_layers = 1, seq_model = 'lstm'\n",
      "device = cpu(), dtype = 'float32'\n",
      "\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92m__init__\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, embedding_size, output_size, hidden_size, num_layers=\u001b[94m1\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                 seq_model=\u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, device=\u001b[94mNone\u001b[39;49;00m, dtype=\u001b[33m\"\u001b[39;49;00m\u001b[33mfloat32\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"\u001b[39;49;00m\n",
      "    \u001b[33m    Consists of an embedding layer, a sequence model (either RNN or LSTM), and a\u001b[39;49;00m\n",
      "    \u001b[33m    linear layer.\u001b[39;49;00m\n",
      "    \u001b[33m    Parameters:\u001b[39;49;00m\n",
      "    \u001b[33m    output_size: Size of dictionary\u001b[39;49;00m\n",
      "    \u001b[33m    embedding_size: Size of embeddings\u001b[39;49;00m\n",
      "    \u001b[33m    hidden_size: The number of features in the hidden state of LSTM or RNN\u001b[39;49;00m\n",
      "    \u001b[33m    seq_model: 'rnn' or 'lstm', whether to use RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    num_layers: Number of layers in RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    \"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[96msuper\u001b[39;49;00m(LanguageModel, \u001b[96mself\u001b[39;49;00m).\u001b[92m__init__\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m### BEGIN YOUR SOLUTION\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94mraise\u001b[39;49;00m \u001b[96mNotImplementedError\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       NotImplementedError\u001b[0m\n",
      "\n",
      "__class__  = <class 'models.LanguageModel'>\n",
      "device     = cpu()\n",
      "dtype      = 'float32'\n",
      "embedding_size = 1\n",
      "hidden_size = 12\n",
      "num_layers = 1\n",
      "output_size = 1000\n",
      "self       = <models.LanguageModel object at 0x169621040>\n",
      "seq_model  = 'lstm'\n",
      "\n",
      "\u001b[1m\u001b[31mapps/models.py\u001b[0m:38: NotImplementedError\n",
      "\u001b[31m\u001b[1m_____ test_language_model_implementation[cpu-lstm-1000-False-12-1-1-1-13] ______\u001b[0m\n",
      "\n",
      "seq_length = 13, num_layers = 1, batch_size = 1, embedding_size = 1\n",
      "hidden_size = 12, init_hidden = False, output_size = 1000, seq_model = 'lstm'\n",
      "device = cpu()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\u001b[90m\u001b[39;49;00m\n",
      "                            init_hidden, output_size, seq_model, device):\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      ">       model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "batch_size = 1\n",
      "c0         = needle.Tensor([[[-0.7081256   1.3511949   0.6898121  -0.31074148  1.0427699\n",
      "   -1.1205328  -0.6962065  -0.69847333  0.87678677 -0.6059073\n",
      "   -0.18202832 -1.5201043 ]]])\n",
      "device     = cpu()\n",
      "embedding_size = 1\n",
      "h0         = needle.Tensor([[[-0.16431578 -0.06561235 -0.33618498 -0.18534923 -1.8055727\n",
      "    0.7668524   0.74874187 -0.48215923  1.0961666   0.75328493\n",
      "    0.35671815 -0.26649052]]])\n",
      "hidden_size = 12\n",
      "init_hidden = False\n",
      "num_layers = 1\n",
      "output_size = 1000\n",
      "seq_length = 13\n",
      "seq_model  = 'lstm'\n",
      "x          = array([[682.],\n",
      "       [175.],\n",
      "       [ 45.],\n",
      "       [804.],\n",
      "       [567.],\n",
      "       [409.],\n",
      "       [258.],\n",
      "       [636.],\n",
      "       [639.],\n",
      "       [410.],\n",
      "       [ 51.],\n",
      "       [739.],\n",
      "       [990.]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:201: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "self = <models.LanguageModel object at 0x1694c6a80>, embedding_size = 1\n",
      "output_size = 1000, hidden_size = 12, num_layers = 1, seq_model = 'lstm'\n",
      "device = cpu(), dtype = 'float32'\n",
      "\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92m__init__\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, embedding_size, output_size, hidden_size, num_layers=\u001b[94m1\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                 seq_model=\u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, device=\u001b[94mNone\u001b[39;49;00m, dtype=\u001b[33m\"\u001b[39;49;00m\u001b[33mfloat32\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"\u001b[39;49;00m\n",
      "    \u001b[33m    Consists of an embedding layer, a sequence model (either RNN or LSTM), and a\u001b[39;49;00m\n",
      "    \u001b[33m    linear layer.\u001b[39;49;00m\n",
      "    \u001b[33m    Parameters:\u001b[39;49;00m\n",
      "    \u001b[33m    output_size: Size of dictionary\u001b[39;49;00m\n",
      "    \u001b[33m    embedding_size: Size of embeddings\u001b[39;49;00m\n",
      "    \u001b[33m    hidden_size: The number of features in the hidden state of LSTM or RNN\u001b[39;49;00m\n",
      "    \u001b[33m    seq_model: 'rnn' or 'lstm', whether to use RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    num_layers: Number of layers in RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    \"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[96msuper\u001b[39;49;00m(LanguageModel, \u001b[96mself\u001b[39;49;00m).\u001b[92m__init__\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m### BEGIN YOUR SOLUTION\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94mraise\u001b[39;49;00m \u001b[96mNotImplementedError\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       NotImplementedError\u001b[0m\n",
      "\n",
      "__class__  = <class 'models.LanguageModel'>\n",
      "device     = cpu()\n",
      "dtype      = 'float32'\n",
      "embedding_size = 1\n",
      "hidden_size = 12\n",
      "num_layers = 1\n",
      "output_size = 1000\n",
      "self       = <models.LanguageModel object at 0x1694c6a80>\n",
      "seq_model  = 'lstm'\n",
      "\n",
      "\u001b[1m\u001b[31mapps/models.py\u001b[0m:38: NotImplementedError\n",
      "\u001b[31m\u001b[1m______ test_language_model_implementation[cpu-lstm-1000-False-12-1-1-2-1] ______\u001b[0m\n",
      "\n",
      "seq_length = 1, num_layers = 2, batch_size = 1, embedding_size = 1\n",
      "hidden_size = 12, init_hidden = False, output_size = 1000, seq_model = 'lstm'\n",
      "device = cpu()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\u001b[90m\u001b[39;49;00m\n",
      "                            init_hidden, output_size, seq_model, device):\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      ">       model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "batch_size = 1\n",
      "c0         = needle.Tensor([[[-0.8271048  -0.9582567   1.2681272   1.4665205  -1.8387982\n",
      "   -0.32421404 -1.7998677  -0.7598455   1....2  -1.3007847  -0.44343555\n",
      "    1.2724873  -0.35894746  0.04645066  1.8122576  -1.4341652\n",
      "    0.4510032   1.6946234 ]]])\n",
      "device     = cpu()\n",
      "embedding_size = 1\n",
      "h0         = needle.Tensor([[[-1.1379029  -0.493021    0.28780976 -1.7147018  -1.9328318\n",
      "   -0.59157807  0.9673592  -0.1941472   0....  -0.03015425  0.31647933\n",
      "    0.04664887  1.0885974  -1.6243654  -1.9375889  -0.32306162\n",
      "   -0.05381058 -0.6754187 ]]])\n",
      "hidden_size = 12\n",
      "init_hidden = False\n",
      "num_layers = 2\n",
      "output_size = 1000\n",
      "seq_length = 1\n",
      "seq_model  = 'lstm'\n",
      "x          = array([[731.]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:201: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "self = <models.LanguageModel object at 0x1694c7650>, embedding_size = 1\n",
      "output_size = 1000, hidden_size = 12, num_layers = 2, seq_model = 'lstm'\n",
      "device = cpu(), dtype = 'float32'\n",
      "\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92m__init__\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, embedding_size, output_size, hidden_size, num_layers=\u001b[94m1\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                 seq_model=\u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, device=\u001b[94mNone\u001b[39;49;00m, dtype=\u001b[33m\"\u001b[39;49;00m\u001b[33mfloat32\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"\u001b[39;49;00m\n",
      "    \u001b[33m    Consists of an embedding layer, a sequence model (either RNN or LSTM), and a\u001b[39;49;00m\n",
      "    \u001b[33m    linear layer.\u001b[39;49;00m\n",
      "    \u001b[33m    Parameters:\u001b[39;49;00m\n",
      "    \u001b[33m    output_size: Size of dictionary\u001b[39;49;00m\n",
      "    \u001b[33m    embedding_size: Size of embeddings\u001b[39;49;00m\n",
      "    \u001b[33m    hidden_size: The number of features in the hidden state of LSTM or RNN\u001b[39;49;00m\n",
      "    \u001b[33m    seq_model: 'rnn' or 'lstm', whether to use RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    num_layers: Number of layers in RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    \"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[96msuper\u001b[39;49;00m(LanguageModel, \u001b[96mself\u001b[39;49;00m).\u001b[92m__init__\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m### BEGIN YOUR SOLUTION\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94mraise\u001b[39;49;00m \u001b[96mNotImplementedError\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       NotImplementedError\u001b[0m\n",
      "\n",
      "__class__  = <class 'models.LanguageModel'>\n",
      "device     = cpu()\n",
      "dtype      = 'float32'\n",
      "embedding_size = 1\n",
      "hidden_size = 12\n",
      "num_layers = 2\n",
      "output_size = 1000\n",
      "self       = <models.LanguageModel object at 0x1694c7650>\n",
      "seq_model  = 'lstm'\n",
      "\n",
      "\u001b[1m\u001b[31mapps/models.py\u001b[0m:38: NotImplementedError\n",
      "\u001b[31m\u001b[1m_____ test_language_model_implementation[cpu-lstm-1000-False-12-1-1-2-13] ______\u001b[0m\n",
      "\n",
      "seq_length = 13, num_layers = 2, batch_size = 1, embedding_size = 1\n",
      "hidden_size = 12, init_hidden = False, output_size = 1000, seq_model = 'lstm'\n",
      "device = cpu()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\u001b[90m\u001b[39;49;00m\n",
      "                            init_hidden, output_size, seq_model, device):\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      ">       model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "batch_size = 1\n",
      "c0         = needle.Tensor([[[ 1.1002632  -1.0104886   0.39261907  0.6165764  -0.6232294\n",
      "    0.61869705  0.4844051  -0.9839535   0....1   1.3685205  -0.36414543\n",
      "   -0.20971972 -1.1735867  -1.0164709  -0.9397037  -1.8764237\n",
      "   -0.7745319  -0.15087938]]])\n",
      "device     = cpu()\n",
      "embedding_size = 1\n",
      "h0         = needle.Tensor([[[-2.4922957  -1.231015    0.89597124  0.16988857 -0.15796831\n",
      "    0.43604255  1.7754525   1.3700635   2...91   0.96253526  1.2735103\n",
      "    0.40991753 -0.7084155   0.04680511 -0.86192536 -0.6616973\n",
      "   -0.54115516 -0.56049716]]])\n",
      "hidden_size = 12\n",
      "init_hidden = False\n",
      "num_layers = 2\n",
      "output_size = 1000\n",
      "seq_length = 13\n",
      "seq_model  = 'lstm'\n",
      "x          = array([[667.],\n",
      "       [360.],\n",
      "       [547.],\n",
      "       [885.],\n",
      "       [855.],\n",
      "       [416.],\n",
      "       [503.],\n",
      "       [750.],\n",
      "       [ 18.],\n",
      "       [516.],\n",
      "       [224.],\n",
      "       [521.],\n",
      "       [832.]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:201: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "self = <models.LanguageModel object at 0x169471e50>, embedding_size = 1\n",
      "output_size = 1000, hidden_size = 12, num_layers = 2, seq_model = 'lstm'\n",
      "device = cpu(), dtype = 'float32'\n",
      "\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92m__init__\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, embedding_size, output_size, hidden_size, num_layers=\u001b[94m1\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                 seq_model=\u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, device=\u001b[94mNone\u001b[39;49;00m, dtype=\u001b[33m\"\u001b[39;49;00m\u001b[33mfloat32\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"\u001b[39;49;00m\n",
      "    \u001b[33m    Consists of an embedding layer, a sequence model (either RNN or LSTM), and a\u001b[39;49;00m\n",
      "    \u001b[33m    linear layer.\u001b[39;49;00m\n",
      "    \u001b[33m    Parameters:\u001b[39;49;00m\n",
      "    \u001b[33m    output_size: Size of dictionary\u001b[39;49;00m\n",
      "    \u001b[33m    embedding_size: Size of embeddings\u001b[39;49;00m\n",
      "    \u001b[33m    hidden_size: The number of features in the hidden state of LSTM or RNN\u001b[39;49;00m\n",
      "    \u001b[33m    seq_model: 'rnn' or 'lstm', whether to use RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    num_layers: Number of layers in RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    \"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[96msuper\u001b[39;49;00m(LanguageModel, \u001b[96mself\u001b[39;49;00m).\u001b[92m__init__\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m### BEGIN YOUR SOLUTION\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94mraise\u001b[39;49;00m \u001b[96mNotImplementedError\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       NotImplementedError\u001b[0m\n",
      "\n",
      "__class__  = <class 'models.LanguageModel'>\n",
      "device     = cpu()\n",
      "dtype      = 'float32'\n",
      "embedding_size = 1\n",
      "hidden_size = 12\n",
      "num_layers = 2\n",
      "output_size = 1000\n",
      "self       = <models.LanguageModel object at 0x169471e50>\n",
      "seq_model  = 'lstm'\n",
      "\n",
      "\u001b[1m\u001b[31mapps/models.py\u001b[0m:38: NotImplementedError\n",
      "\u001b[31m\u001b[1m_____ test_language_model_implementation[cpu-lstm-1000-False-12-1-15-1-1] ______\u001b[0m\n",
      "\n",
      "seq_length = 1, num_layers = 1, batch_size = 15, embedding_size = 1\n",
      "hidden_size = 12, init_hidden = False, output_size = 1000, seq_model = 'lstm'\n",
      "device = cpu()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\u001b[90m\u001b[39;49;00m\n",
      "                            init_hidden, output_size, seq_model, device):\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      ">       model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "batch_size = 15\n",
      "c0         = needle.Tensor([[[ 1.1013356e+00  2.3478189e-01 -2.7801371e-01  6.3168949e-01\n",
      "   -3.9414310e-01  8.0409026e-01 -8.67286...803e-01 -1.8140314e+00  5.2857548e-01  2.3887885e-01\n",
      "   -1.2527349e+00 -4.7100368e-01  5.3805345e-01 -5.1829332e-01]]])\n",
      "device     = cpu()\n",
      "embedding_size = 1\n",
      "h0         = needle.Tensor([[[-1.4459594e+00  4.0186420e-01  3.4901312e-01 -8.9175546e-01\n",
      "   -5.5400068e-01  3.0560687e-01  1.24409...503e-01  3.8558072e-01  5.0663143e-01  4.2967382e-01\n",
      "   -1.6667982e+00  1.4158802e+00 -7.0914376e-01 -2.1232424e+00]]])\n",
      "hidden_size = 12\n",
      "init_hidden = False\n",
      "num_layers = 1\n",
      "output_size = 1000\n",
      "seq_length = 1\n",
      "seq_model  = 'lstm'\n",
      "x          = array([[312.,  58., 743., 899., 660., 391., 855., 106.,  64., 842.,  37.,\n",
      "        354., 169., 260., 179.]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:201: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "self = <models.LanguageModel object at 0x169483fb0>, embedding_size = 1\n",
      "output_size = 1000, hidden_size = 12, num_layers = 1, seq_model = 'lstm'\n",
      "device = cpu(), dtype = 'float32'\n",
      "\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92m__init__\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, embedding_size, output_size, hidden_size, num_layers=\u001b[94m1\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                 seq_model=\u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, device=\u001b[94mNone\u001b[39;49;00m, dtype=\u001b[33m\"\u001b[39;49;00m\u001b[33mfloat32\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"\u001b[39;49;00m\n",
      "    \u001b[33m    Consists of an embedding layer, a sequence model (either RNN or LSTM), and a\u001b[39;49;00m\n",
      "    \u001b[33m    linear layer.\u001b[39;49;00m\n",
      "    \u001b[33m    Parameters:\u001b[39;49;00m\n",
      "    \u001b[33m    output_size: Size of dictionary\u001b[39;49;00m\n",
      "    \u001b[33m    embedding_size: Size of embeddings\u001b[39;49;00m\n",
      "    \u001b[33m    hidden_size: The number of features in the hidden state of LSTM or RNN\u001b[39;49;00m\n",
      "    \u001b[33m    seq_model: 'rnn' or 'lstm', whether to use RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    num_layers: Number of layers in RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    \"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[96msuper\u001b[39;49;00m(LanguageModel, \u001b[96mself\u001b[39;49;00m).\u001b[92m__init__\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m### BEGIN YOUR SOLUTION\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94mraise\u001b[39;49;00m \u001b[96mNotImplementedError\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       NotImplementedError\u001b[0m\n",
      "\n",
      "__class__  = <class 'models.LanguageModel'>\n",
      "device     = cpu()\n",
      "dtype      = 'float32'\n",
      "embedding_size = 1\n",
      "hidden_size = 12\n",
      "num_layers = 1\n",
      "output_size = 1000\n",
      "self       = <models.LanguageModel object at 0x169483fb0>\n",
      "seq_model  = 'lstm'\n",
      "\n",
      "\u001b[1m\u001b[31mapps/models.py\u001b[0m:38: NotImplementedError\n",
      "\u001b[31m\u001b[1m_____ test_language_model_implementation[cpu-lstm-1000-False-12-1-15-1-13] _____\u001b[0m\n",
      "\n",
      "seq_length = 13, num_layers = 1, batch_size = 15, embedding_size = 1\n",
      "hidden_size = 12, init_hidden = False, output_size = 1000, seq_model = 'lstm'\n",
      "device = cpu()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\u001b[90m\u001b[39;49;00m\n",
      "                            init_hidden, output_size, seq_model, device):\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      ">       model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "batch_size = 15\n",
      "c0         = needle.Tensor([[[ 0.52304316  1.1125983   0.36907682 -0.30493453  1.3998497\n",
      "    0.75387007  1.9128397  -0.6751202  -0....    0.68786997  0.11149936\n",
      "    1.7308465   0.96638376  1.2843602   1.3166776   0.8136659\n",
      "   -0.4120883  -0.55800724]]])\n",
      "device     = cpu()\n",
      "embedding_size = 1\n",
      "h0         = needle.Tensor([[[-3.01845521e-01  1.45835102e-01  2.34883499e+00  6.94969833e-01\n",
      "   -1.40554404e+00  4.74175811e-01  1...  3.11644878e-02 -1.22008932e+00 -6.92597568e-01\n",
      "   -2.00938773e+00  1.29758704e+00 -3.03195387e-01  1.28022039e+00]]])\n",
      "hidden_size = 12\n",
      "init_hidden = False\n",
      "num_layers = 1\n",
      "output_size = 1000\n",
      "seq_length = 13\n",
      "seq_model  = 'lstm'\n",
      "x          = array([[451., 498.,  48., 422., 780., 872., 475., 861.,   5., 783., 166.,\n",
      "        732., 495., 389., 229.],\n",
      "       [999...    [932.,  90., 343., 953., 537., 357., 452., 158., 909., 651., 292.,\n",
      "        985., 613., 384., 510.]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:201: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "self = <models.LanguageModel object at 0x169622b10>, embedding_size = 1\n",
      "output_size = 1000, hidden_size = 12, num_layers = 1, seq_model = 'lstm'\n",
      "device = cpu(), dtype = 'float32'\n",
      "\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92m__init__\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, embedding_size, output_size, hidden_size, num_layers=\u001b[94m1\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                 seq_model=\u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, device=\u001b[94mNone\u001b[39;49;00m, dtype=\u001b[33m\"\u001b[39;49;00m\u001b[33mfloat32\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"\u001b[39;49;00m\n",
      "    \u001b[33m    Consists of an embedding layer, a sequence model (either RNN or LSTM), and a\u001b[39;49;00m\n",
      "    \u001b[33m    linear layer.\u001b[39;49;00m\n",
      "    \u001b[33m    Parameters:\u001b[39;49;00m\n",
      "    \u001b[33m    output_size: Size of dictionary\u001b[39;49;00m\n",
      "    \u001b[33m    embedding_size: Size of embeddings\u001b[39;49;00m\n",
      "    \u001b[33m    hidden_size: The number of features in the hidden state of LSTM or RNN\u001b[39;49;00m\n",
      "    \u001b[33m    seq_model: 'rnn' or 'lstm', whether to use RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    num_layers: Number of layers in RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    \"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[96msuper\u001b[39;49;00m(LanguageModel, \u001b[96mself\u001b[39;49;00m).\u001b[92m__init__\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m### BEGIN YOUR SOLUTION\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94mraise\u001b[39;49;00m \u001b[96mNotImplementedError\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       NotImplementedError\u001b[0m\n",
      "\n",
      "__class__  = <class 'models.LanguageModel'>\n",
      "device     = cpu()\n",
      "dtype      = 'float32'\n",
      "embedding_size = 1\n",
      "hidden_size = 12\n",
      "num_layers = 1\n",
      "output_size = 1000\n",
      "self       = <models.LanguageModel object at 0x169622b10>\n",
      "seq_model  = 'lstm'\n",
      "\n",
      "\u001b[1m\u001b[31mapps/models.py\u001b[0m:38: NotImplementedError\n",
      "\u001b[31m\u001b[1m_____ test_language_model_implementation[cpu-lstm-1000-False-12-1-15-2-1] ______\u001b[0m\n",
      "\n",
      "seq_length = 1, num_layers = 2, batch_size = 15, embedding_size = 1\n",
      "hidden_size = 12, init_hidden = False, output_size = 1000, seq_model = 'lstm'\n",
      "device = cpu()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\u001b[90m\u001b[39;49;00m\n",
      "                            init_hidden, output_size, seq_model, device):\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      ">       model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "batch_size = 15\n",
      "c0         = needle.Tensor([[[-0.17570592  0.3812921   1.5929314  -0.56831837 -1.2394297\n",
      "   -0.02437881  0.5595061   1.3930435  -0....   0.8937931   0.10279474\n",
      "   -0.23670225 -1.4044385  -1.5482984   1.2742016  -0.86178845\n",
      "   -1.8525538  -1.4232557 ]]])\n",
      "device     = cpu()\n",
      "embedding_size = 1\n",
      "h0         = needle.Tensor([[[ 0.14666308  0.80578333  0.6956846   0.16020761 -1.0560565\n",
      "   -0.39716044 -0.2664585   0.8200577  -1....403 -2.2216232  -1.7982973\n",
      "    0.8172155   1.1229656   0.75928664  1.2397656   1.2137892\n",
      "   -1.8882416  -1.1612862 ]]])\n",
      "hidden_size = 12\n",
      "init_hidden = False\n",
      "num_layers = 2\n",
      "output_size = 1000\n",
      "seq_length = 1\n",
      "seq_model  = 'lstm'\n",
      "x          = array([[878., 566., 103., 642., 913., 864., 915., 487., 641.,  15., 693.,\n",
      "        315., 233., 221., 751.]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:201: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "self = <models.LanguageModel object at 0x16953a450>, embedding_size = 1\n",
      "output_size = 1000, hidden_size = 12, num_layers = 2, seq_model = 'lstm'\n",
      "device = cpu(), dtype = 'float32'\n",
      "\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92m__init__\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, embedding_size, output_size, hidden_size, num_layers=\u001b[94m1\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                 seq_model=\u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, device=\u001b[94mNone\u001b[39;49;00m, dtype=\u001b[33m\"\u001b[39;49;00m\u001b[33mfloat32\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"\u001b[39;49;00m\n",
      "    \u001b[33m    Consists of an embedding layer, a sequence model (either RNN or LSTM), and a\u001b[39;49;00m\n",
      "    \u001b[33m    linear layer.\u001b[39;49;00m\n",
      "    \u001b[33m    Parameters:\u001b[39;49;00m\n",
      "    \u001b[33m    output_size: Size of dictionary\u001b[39;49;00m\n",
      "    \u001b[33m    embedding_size: Size of embeddings\u001b[39;49;00m\n",
      "    \u001b[33m    hidden_size: The number of features in the hidden state of LSTM or RNN\u001b[39;49;00m\n",
      "    \u001b[33m    seq_model: 'rnn' or 'lstm', whether to use RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    num_layers: Number of layers in RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    \"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[96msuper\u001b[39;49;00m(LanguageModel, \u001b[96mself\u001b[39;49;00m).\u001b[92m__init__\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m### BEGIN YOUR SOLUTION\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94mraise\u001b[39;49;00m \u001b[96mNotImplementedError\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       NotImplementedError\u001b[0m\n",
      "\n",
      "__class__  = <class 'models.LanguageModel'>\n",
      "device     = cpu()\n",
      "dtype      = 'float32'\n",
      "embedding_size = 1\n",
      "hidden_size = 12\n",
      "num_layers = 2\n",
      "output_size = 1000\n",
      "self       = <models.LanguageModel object at 0x16953a450>\n",
      "seq_model  = 'lstm'\n",
      "\n",
      "\u001b[1m\u001b[31mapps/models.py\u001b[0m:38: NotImplementedError\n",
      "\u001b[31m\u001b[1m_____ test_language_model_implementation[cpu-lstm-1000-False-12-1-15-2-13] _____\u001b[0m\n",
      "\n",
      "seq_length = 13, num_layers = 2, batch_size = 15, embedding_size = 1\n",
      "hidden_size = 12, init_hidden = False, output_size = 1000, seq_model = 'lstm'\n",
      "device = cpu()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\u001b[90m\u001b[39;49;00m\n",
      "                            init_hidden, output_size, seq_model, device):\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      ">       model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "batch_size = 15\n",
      "c0         = needle.Tensor([[[-1.9204242   0.9025572  -0.7155726   0.57162803  1.8163472\n",
      "   -0.82512903 -0.71790504  0.5254879  -0....4  -1.233425   -0.5200432\n",
      "    2.0145812   0.83406603  0.05674452 -0.06455419  0.20132047\n",
      "    1.6135758  -0.49070644]]])\n",
      "device     = cpu()\n",
      "embedding_size = 1\n",
      "h0         = needle.Tensor([[[ 0.1581036   0.6857692   0.40814573  0.19889109 -1.0774161\n",
      "    0.69692355 -0.5823933  -1.4443383  -1....065  0.7505486   0.6438598\n",
      "    0.8136049   0.5651038  -1.1474246  -1.6661168  -0.9666581\n",
      "    0.54203385  0.22626607]]])\n",
      "hidden_size = 12\n",
      "init_hidden = False\n",
      "num_layers = 2\n",
      "output_size = 1000\n",
      "seq_length = 13\n",
      "seq_model  = 'lstm'\n",
      "x          = array([[872., 201., 812., 575., 179., 362., 579., 494., 347., 143., 528.,\n",
      "          3., 648., 531., 522.],\n",
      "       [152...    [512., 231., 725., 566.,  83., 979., 422., 658., 988., 826., 132.,\n",
      "        473.,  97., 367., 457.]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:201: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "self = <models.LanguageModel object at 0x16953b3b0>, embedding_size = 1\n",
      "output_size = 1000, hidden_size = 12, num_layers = 2, seq_model = 'lstm'\n",
      "device = cpu(), dtype = 'float32'\n",
      "\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92m__init__\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, embedding_size, output_size, hidden_size, num_layers=\u001b[94m1\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                 seq_model=\u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, device=\u001b[94mNone\u001b[39;49;00m, dtype=\u001b[33m\"\u001b[39;49;00m\u001b[33mfloat32\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"\u001b[39;49;00m\n",
      "    \u001b[33m    Consists of an embedding layer, a sequence model (either RNN or LSTM), and a\u001b[39;49;00m\n",
      "    \u001b[33m    linear layer.\u001b[39;49;00m\n",
      "    \u001b[33m    Parameters:\u001b[39;49;00m\n",
      "    \u001b[33m    output_size: Size of dictionary\u001b[39;49;00m\n",
      "    \u001b[33m    embedding_size: Size of embeddings\u001b[39;49;00m\n",
      "    \u001b[33m    hidden_size: The number of features in the hidden state of LSTM or RNN\u001b[39;49;00m\n",
      "    \u001b[33m    seq_model: 'rnn' or 'lstm', whether to use RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    num_layers: Number of layers in RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    \"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[96msuper\u001b[39;49;00m(LanguageModel, \u001b[96mself\u001b[39;49;00m).\u001b[92m__init__\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m### BEGIN YOUR SOLUTION\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94mraise\u001b[39;49;00m \u001b[96mNotImplementedError\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       NotImplementedError\u001b[0m\n",
      "\n",
      "__class__  = <class 'models.LanguageModel'>\n",
      "device     = cpu()\n",
      "dtype      = 'float32'\n",
      "embedding_size = 1\n",
      "hidden_size = 12\n",
      "num_layers = 2\n",
      "output_size = 1000\n",
      "self       = <models.LanguageModel object at 0x16953b3b0>\n",
      "seq_model  = 'lstm'\n",
      "\n",
      "\u001b[1m\u001b[31mapps/models.py\u001b[0m:38: NotImplementedError\n",
      "\u001b[31m\u001b[1m_____ test_language_model_implementation[cpu-lstm-1000-False-12-34-1-1-1] ______\u001b[0m\n",
      "\n",
      "seq_length = 1, num_layers = 1, batch_size = 1, embedding_size = 34\n",
      "hidden_size = 12, init_hidden = False, output_size = 1000, seq_model = 'lstm'\n",
      "device = cpu()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\u001b[90m\u001b[39;49;00m\n",
      "                            init_hidden, output_size, seq_model, device):\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      ">       model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "batch_size = 1\n",
      "c0         = needle.Tensor([[[ 1.7355458  -2.1492152   0.2857726  -1.2848554  -1.6911126\n",
      "   -0.7056883   0.09364432 -1.7022951   1.0701011  -0.7536347\n",
      "    2.207372    0.89649   ]]])\n",
      "device     = cpu()\n",
      "embedding_size = 34\n",
      "h0         = needle.Tensor([[[-0.0459499   1.3419355   0.1032702  -1.6327044  -0.93639416\n",
      "   -0.56794435 -1.1867269  -0.2520652   0.00717259 -0.75249875\n",
      "   -0.15582903 -1.4918392 ]]])\n",
      "hidden_size = 12\n",
      "init_hidden = False\n",
      "num_layers = 1\n",
      "output_size = 1000\n",
      "seq_length = 1\n",
      "seq_model  = 'lstm'\n",
      "x          = array([[550.]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:201: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "self = <models.LanguageModel object at 0x169622f30>, embedding_size = 34\n",
      "output_size = 1000, hidden_size = 12, num_layers = 1, seq_model = 'lstm'\n",
      "device = cpu(), dtype = 'float32'\n",
      "\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92m__init__\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, embedding_size, output_size, hidden_size, num_layers=\u001b[94m1\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                 seq_model=\u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, device=\u001b[94mNone\u001b[39;49;00m, dtype=\u001b[33m\"\u001b[39;49;00m\u001b[33mfloat32\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"\u001b[39;49;00m\n",
      "    \u001b[33m    Consists of an embedding layer, a sequence model (either RNN or LSTM), and a\u001b[39;49;00m\n",
      "    \u001b[33m    linear layer.\u001b[39;49;00m\n",
      "    \u001b[33m    Parameters:\u001b[39;49;00m\n",
      "    \u001b[33m    output_size: Size of dictionary\u001b[39;49;00m\n",
      "    \u001b[33m    embedding_size: Size of embeddings\u001b[39;49;00m\n",
      "    \u001b[33m    hidden_size: The number of features in the hidden state of LSTM or RNN\u001b[39;49;00m\n",
      "    \u001b[33m    seq_model: 'rnn' or 'lstm', whether to use RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    num_layers: Number of layers in RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    \"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[96msuper\u001b[39;49;00m(LanguageModel, \u001b[96mself\u001b[39;49;00m).\u001b[92m__init__\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m### BEGIN YOUR SOLUTION\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94mraise\u001b[39;49;00m \u001b[96mNotImplementedError\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       NotImplementedError\u001b[0m\n",
      "\n",
      "__class__  = <class 'models.LanguageModel'>\n",
      "device     = cpu()\n",
      "dtype      = 'float32'\n",
      "embedding_size = 34\n",
      "hidden_size = 12\n",
      "num_layers = 1\n",
      "output_size = 1000\n",
      "self       = <models.LanguageModel object at 0x169622f30>\n",
      "seq_model  = 'lstm'\n",
      "\n",
      "\u001b[1m\u001b[31mapps/models.py\u001b[0m:38: NotImplementedError\n",
      "\u001b[31m\u001b[1m_____ test_language_model_implementation[cpu-lstm-1000-False-12-34-1-1-13] _____\u001b[0m\n",
      "\n",
      "seq_length = 13, num_layers = 1, batch_size = 1, embedding_size = 34\n",
      "hidden_size = 12, init_hidden = False, output_size = 1000, seq_model = 'lstm'\n",
      "device = cpu()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\u001b[90m\u001b[39;49;00m\n",
      "                            init_hidden, output_size, seq_model, device):\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      ">       model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "batch_size = 1\n",
      "c0         = needle.Tensor([[[-0.42452013 -1.4833795  -0.3802079   0.6875415   1.1778864\n",
      "   -3.9546635   1.1737252   1.1612228  -1.0170339   0.07947209\n",
      "    0.7457606  -0.45551077]]])\n",
      "device     = cpu()\n",
      "embedding_size = 34\n",
      "h0         = needle.Tensor([[[-1.1759375  -0.8066403   0.6124974   0.4053124  -0.80223536\n",
      "   -0.5046183  -0.2850597   1.415724   -0.36546332  0.26367325\n",
      "    0.77596676 -1.1454612 ]]])\n",
      "hidden_size = 12\n",
      "init_hidden = False\n",
      "num_layers = 1\n",
      "output_size = 1000\n",
      "seq_length = 13\n",
      "seq_model  = 'lstm'\n",
      "x          = array([[939.],\n",
      "       [687.],\n",
      "       [368.],\n",
      "       [ 42.],\n",
      "       [785.],\n",
      "       [562.],\n",
      "       [290.],\n",
      "       [557.],\n",
      "       [445.],\n",
      "       [133.],\n",
      "       [322.],\n",
      "       [121.],\n",
      "       [849.]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:201: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "self = <models.LanguageModel object at 0x169622900>, embedding_size = 34\n",
      "output_size = 1000, hidden_size = 12, num_layers = 1, seq_model = 'lstm'\n",
      "device = cpu(), dtype = 'float32'\n",
      "\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92m__init__\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, embedding_size, output_size, hidden_size, num_layers=\u001b[94m1\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                 seq_model=\u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, device=\u001b[94mNone\u001b[39;49;00m, dtype=\u001b[33m\"\u001b[39;49;00m\u001b[33mfloat32\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"\u001b[39;49;00m\n",
      "    \u001b[33m    Consists of an embedding layer, a sequence model (either RNN or LSTM), and a\u001b[39;49;00m\n",
      "    \u001b[33m    linear layer.\u001b[39;49;00m\n",
      "    \u001b[33m    Parameters:\u001b[39;49;00m\n",
      "    \u001b[33m    output_size: Size of dictionary\u001b[39;49;00m\n",
      "    \u001b[33m    embedding_size: Size of embeddings\u001b[39;49;00m\n",
      "    \u001b[33m    hidden_size: The number of features in the hidden state of LSTM or RNN\u001b[39;49;00m\n",
      "    \u001b[33m    seq_model: 'rnn' or 'lstm', whether to use RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    num_layers: Number of layers in RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    \"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[96msuper\u001b[39;49;00m(LanguageModel, \u001b[96mself\u001b[39;49;00m).\u001b[92m__init__\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m### BEGIN YOUR SOLUTION\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94mraise\u001b[39;49;00m \u001b[96mNotImplementedError\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       NotImplementedError\u001b[0m\n",
      "\n",
      "__class__  = <class 'models.LanguageModel'>\n",
      "device     = cpu()\n",
      "dtype      = 'float32'\n",
      "embedding_size = 34\n",
      "hidden_size = 12\n",
      "num_layers = 1\n",
      "output_size = 1000\n",
      "self       = <models.LanguageModel object at 0x169622900>\n",
      "seq_model  = 'lstm'\n",
      "\n",
      "\u001b[1m\u001b[31mapps/models.py\u001b[0m:38: NotImplementedError\n",
      "\u001b[31m\u001b[1m_____ test_language_model_implementation[cpu-lstm-1000-False-12-34-1-2-1] ______\u001b[0m\n",
      "\n",
      "seq_length = 1, num_layers = 2, batch_size = 1, embedding_size = 34\n",
      "hidden_size = 12, init_hidden = False, output_size = 1000, seq_model = 'lstm'\n",
      "device = cpu()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\u001b[90m\u001b[39;49;00m\n",
      "                            init_hidden, output_size, seq_model, device):\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      ">       model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "batch_size = 1\n",
      "c0         = needle.Tensor([[[ 0.54357934 -0.18967722 -0.27697712  1.006857    1.8557106\n",
      "    0.48086086  0.37112054 -0.49720055  1....785 -0.96301454 -0.6205349\n",
      "   -0.39220226 -1.4888606  -1.023722    1.8925563  -0.0248551\n",
      "   -0.5545323  -0.21975091]]])\n",
      "device     = cpu()\n",
      "embedding_size = 34\n",
      "h0         = needle.Tensor([[[ 0.63537955 -0.5672296  -1.1906159   0.34384272  0.05240471\n",
      "    0.493264   -0.49426728  1.2646369  -1...695   0.33662     0.9098809\n",
      "    0.44909793 -1.689841   -1.7523922  -0.7282008  -0.861999\n",
      "   -1.4462104  -1.7293185 ]]])\n",
      "hidden_size = 12\n",
      "init_hidden = False\n",
      "num_layers = 2\n",
      "output_size = 1000\n",
      "seq_length = 1\n",
      "seq_model  = 'lstm'\n",
      "x          = array([[983.]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:201: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "self = <models.LanguageModel object at 0x169620bf0>, embedding_size = 34\n",
      "output_size = 1000, hidden_size = 12, num_layers = 2, seq_model = 'lstm'\n",
      "device = cpu(), dtype = 'float32'\n",
      "\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92m__init__\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, embedding_size, output_size, hidden_size, num_layers=\u001b[94m1\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                 seq_model=\u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, device=\u001b[94mNone\u001b[39;49;00m, dtype=\u001b[33m\"\u001b[39;49;00m\u001b[33mfloat32\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"\u001b[39;49;00m\n",
      "    \u001b[33m    Consists of an embedding layer, a sequence model (either RNN or LSTM), and a\u001b[39;49;00m\n",
      "    \u001b[33m    linear layer.\u001b[39;49;00m\n",
      "    \u001b[33m    Parameters:\u001b[39;49;00m\n",
      "    \u001b[33m    output_size: Size of dictionary\u001b[39;49;00m\n",
      "    \u001b[33m    embedding_size: Size of embeddings\u001b[39;49;00m\n",
      "    \u001b[33m    hidden_size: The number of features in the hidden state of LSTM or RNN\u001b[39;49;00m\n",
      "    \u001b[33m    seq_model: 'rnn' or 'lstm', whether to use RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    num_layers: Number of layers in RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    \"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[96msuper\u001b[39;49;00m(LanguageModel, \u001b[96mself\u001b[39;49;00m).\u001b[92m__init__\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m### BEGIN YOUR SOLUTION\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94mraise\u001b[39;49;00m \u001b[96mNotImplementedError\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       NotImplementedError\u001b[0m\n",
      "\n",
      "__class__  = <class 'models.LanguageModel'>\n",
      "device     = cpu()\n",
      "dtype      = 'float32'\n",
      "embedding_size = 34\n",
      "hidden_size = 12\n",
      "num_layers = 2\n",
      "output_size = 1000\n",
      "self       = <models.LanguageModel object at 0x169620bf0>\n",
      "seq_model  = 'lstm'\n",
      "\n",
      "\u001b[1m\u001b[31mapps/models.py\u001b[0m:38: NotImplementedError\n",
      "\u001b[31m\u001b[1m_____ test_language_model_implementation[cpu-lstm-1000-False-12-34-1-2-13] _____\u001b[0m\n",
      "\n",
      "seq_length = 13, num_layers = 2, batch_size = 1, embedding_size = 34\n",
      "hidden_size = 12, init_hidden = False, output_size = 1000, seq_model = 'lstm'\n",
      "device = cpu()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\u001b[90m\u001b[39;49;00m\n",
      "                            init_hidden, output_size, seq_model, device):\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      ">       model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "batch_size = 1\n",
      "c0         = needle.Tensor([[[ 0.35979787  1.3218231   0.77009636 -0.20321485 -0.5447119\n",
      "   -1.2372553   0.7070381   1.126265   -0....966  0.44609666 -0.7758684\n",
      "    0.36746207  1.4234539  -0.90033954 -0.179208   -1.3343129\n",
      "    0.1257137  -0.30073294]]])\n",
      "device     = cpu()\n",
      "embedding_size = 34\n",
      "h0         = needle.Tensor([[[-0.02696511  1.338571    0.9362866  -0.87297493  0.4561392\n",
      "   -0.25654066 -0.8665231   0.5030864   0....429   1.0693948  -0.494919\n",
      "   -0.09602089  0.4958543  -0.5842235   0.06044396  1.5445354\n",
      "    1.1341861  -1.1717329 ]]])\n",
      "hidden_size = 12\n",
      "init_hidden = False\n",
      "num_layers = 2\n",
      "output_size = 1000\n",
      "seq_length = 13\n",
      "seq_model  = 'lstm'\n",
      "x          = array([[146.],\n",
      "       [100.],\n",
      "       [414.],\n",
      "       [496.],\n",
      "       [362.],\n",
      "       [533.],\n",
      "       [118.],\n",
      "       [620.],\n",
      "       [  8.],\n",
      "       [243.],\n",
      "       [207.],\n",
      "       [448.],\n",
      "       [912.]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:201: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "self = <models.LanguageModel object at 0x1694c5430>, embedding_size = 34\n",
      "output_size = 1000, hidden_size = 12, num_layers = 2, seq_model = 'lstm'\n",
      "device = cpu(), dtype = 'float32'\n",
      "\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92m__init__\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, embedding_size, output_size, hidden_size, num_layers=\u001b[94m1\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                 seq_model=\u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, device=\u001b[94mNone\u001b[39;49;00m, dtype=\u001b[33m\"\u001b[39;49;00m\u001b[33mfloat32\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"\u001b[39;49;00m\n",
      "    \u001b[33m    Consists of an embedding layer, a sequence model (either RNN or LSTM), and a\u001b[39;49;00m\n",
      "    \u001b[33m    linear layer.\u001b[39;49;00m\n",
      "    \u001b[33m    Parameters:\u001b[39;49;00m\n",
      "    \u001b[33m    output_size: Size of dictionary\u001b[39;49;00m\n",
      "    \u001b[33m    embedding_size: Size of embeddings\u001b[39;49;00m\n",
      "    \u001b[33m    hidden_size: The number of features in the hidden state of LSTM or RNN\u001b[39;49;00m\n",
      "    \u001b[33m    seq_model: 'rnn' or 'lstm', whether to use RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    num_layers: Number of layers in RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    \"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[96msuper\u001b[39;49;00m(LanguageModel, \u001b[96mself\u001b[39;49;00m).\u001b[92m__init__\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m### BEGIN YOUR SOLUTION\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94mraise\u001b[39;49;00m \u001b[96mNotImplementedError\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       NotImplementedError\u001b[0m\n",
      "\n",
      "__class__  = <class 'models.LanguageModel'>\n",
      "device     = cpu()\n",
      "dtype      = 'float32'\n",
      "embedding_size = 34\n",
      "hidden_size = 12\n",
      "num_layers = 2\n",
      "output_size = 1000\n",
      "self       = <models.LanguageModel object at 0x1694c5430>\n",
      "seq_model  = 'lstm'\n",
      "\n",
      "\u001b[1m\u001b[31mapps/models.py\u001b[0m:38: NotImplementedError\n",
      "\u001b[31m\u001b[1m_____ test_language_model_implementation[cpu-lstm-1000-False-12-34-15-1-1] _____\u001b[0m\n",
      "\n",
      "seq_length = 1, num_layers = 1, batch_size = 15, embedding_size = 34\n",
      "hidden_size = 12, init_hidden = False, output_size = 1000, seq_model = 'lstm'\n",
      "device = cpu()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\u001b[90m\u001b[39;49;00m\n",
      "                            init_hidden, output_size, seq_model, device):\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      ">       model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "batch_size = 15\n",
      "c0         = needle.Tensor([[[-4.28721815e-01  3.73795023e-03  1.41898513e+00 -2.02162832e-01\n",
      "    7.18927026e-01 -1.96892357e+00 -8... -9.15931821e-01  4.10883725e-01 -2.87539572e-01\n",
      "    3.44766676e-01 -3.61566395e-01  9.06427205e-02 -1.51002181e+00]]])\n",
      "device     = cpu()\n",
      "embedding_size = 34\n",
      "h0         = needle.Tensor([[[ 0.8149944   1.2865977  -0.5577389  -0.038421    1.1314814\n",
      "   -0.02608606  0.6576318   0.08322378 -0....9  -0.8801116   1.4812834\n",
      "   -0.37978354  0.57729924  0.97562206  0.2022563   0.38930938\n",
      "   -1.0024393  -0.07506193]]])\n",
      "hidden_size = 12\n",
      "init_hidden = False\n",
      "num_layers = 1\n",
      "output_size = 1000\n",
      "seq_length = 1\n",
      "seq_model  = 'lstm'\n",
      "x          = array([[968., 750., 960., 989., 795., 294., 141., 913., 709., 791., 326.,\n",
      "        458., 504., 906., 683.]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:201: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "self = <models.LanguageModel object at 0x1694c6cc0>, embedding_size = 34\n",
      "output_size = 1000, hidden_size = 12, num_layers = 1, seq_model = 'lstm'\n",
      "device = cpu(), dtype = 'float32'\n",
      "\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92m__init__\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, embedding_size, output_size, hidden_size, num_layers=\u001b[94m1\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                 seq_model=\u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, device=\u001b[94mNone\u001b[39;49;00m, dtype=\u001b[33m\"\u001b[39;49;00m\u001b[33mfloat32\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"\u001b[39;49;00m\n",
      "    \u001b[33m    Consists of an embedding layer, a sequence model (either RNN or LSTM), and a\u001b[39;49;00m\n",
      "    \u001b[33m    linear layer.\u001b[39;49;00m\n",
      "    \u001b[33m    Parameters:\u001b[39;49;00m\n",
      "    \u001b[33m    output_size: Size of dictionary\u001b[39;49;00m\n",
      "    \u001b[33m    embedding_size: Size of embeddings\u001b[39;49;00m\n",
      "    \u001b[33m    hidden_size: The number of features in the hidden state of LSTM or RNN\u001b[39;49;00m\n",
      "    \u001b[33m    seq_model: 'rnn' or 'lstm', whether to use RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    num_layers: Number of layers in RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    \"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[96msuper\u001b[39;49;00m(LanguageModel, \u001b[96mself\u001b[39;49;00m).\u001b[92m__init__\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m### BEGIN YOUR SOLUTION\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94mraise\u001b[39;49;00m \u001b[96mNotImplementedError\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       NotImplementedError\u001b[0m\n",
      "\n",
      "__class__  = <class 'models.LanguageModel'>\n",
      "device     = cpu()\n",
      "dtype      = 'float32'\n",
      "embedding_size = 34\n",
      "hidden_size = 12\n",
      "num_layers = 1\n",
      "output_size = 1000\n",
      "self       = <models.LanguageModel object at 0x1694c6cc0>\n",
      "seq_model  = 'lstm'\n",
      "\n",
      "\u001b[1m\u001b[31mapps/models.py\u001b[0m:38: NotImplementedError\n",
      "\u001b[31m\u001b[1m____ test_language_model_implementation[cpu-lstm-1000-False-12-34-15-1-13] _____\u001b[0m\n",
      "\n",
      "seq_length = 13, num_layers = 1, batch_size = 15, embedding_size = 34\n",
      "hidden_size = 12, init_hidden = False, output_size = 1000, seq_model = 'lstm'\n",
      "device = cpu()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\u001b[90m\u001b[39;49;00m\n",
      "                            init_hidden, output_size, seq_model, device):\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      ">       model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "batch_size = 15\n",
      "c0         = needle.Tensor([[[ 1.1435522   0.67203313 -0.25652376  0.0124637  -0.67923987\n",
      "    1.5983772  -0.07162088  1.1946748   1...448 -1.1352124  -0.27535486\n",
      "    0.26364973  0.10011166 -1.8224394  -0.42032886 -1.040397\n",
      "    0.0061485   0.6606388 ]]])\n",
      "device     = cpu()\n",
      "embedding_size = 34\n",
      "h0         = needle.Tensor([[[ 1.64371943e+00 -1.26920569e+00 -4.47579287e-02  3.46052557e-01\n",
      "   -2.99575888e-02  9.87219036e-01 -3...  9.49322641e-01  1.19806409e+00  3.21147203e-01\n",
      "    3.80998820e-01  9.00014997e-01 -1.01506364e+00 -2.12863594e-01]]])\n",
      "hidden_size = 12\n",
      "init_hidden = False\n",
      "num_layers = 1\n",
      "output_size = 1000\n",
      "seq_length = 13\n",
      "seq_model  = 'lstm'\n",
      "x          = array([[318., 902.,  15.,  29., 147., 882., 696., 416., 699., 159., 842.,\n",
      "        785., 661., 636., 937.],\n",
      "       [ 68...    [632., 882.,   6., 381., 747., 598., 181., 219., 916., 373., 182.,\n",
      "        261., 101., 596., 397.]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:201: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "self = <models.LanguageModel object at 0x1695398b0>, embedding_size = 34\n",
      "output_size = 1000, hidden_size = 12, num_layers = 1, seq_model = 'lstm'\n",
      "device = cpu(), dtype = 'float32'\n",
      "\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92m__init__\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, embedding_size, output_size, hidden_size, num_layers=\u001b[94m1\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                 seq_model=\u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, device=\u001b[94mNone\u001b[39;49;00m, dtype=\u001b[33m\"\u001b[39;49;00m\u001b[33mfloat32\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"\u001b[39;49;00m\n",
      "    \u001b[33m    Consists of an embedding layer, a sequence model (either RNN or LSTM), and a\u001b[39;49;00m\n",
      "    \u001b[33m    linear layer.\u001b[39;49;00m\n",
      "    \u001b[33m    Parameters:\u001b[39;49;00m\n",
      "    \u001b[33m    output_size: Size of dictionary\u001b[39;49;00m\n",
      "    \u001b[33m    embedding_size: Size of embeddings\u001b[39;49;00m\n",
      "    \u001b[33m    hidden_size: The number of features in the hidden state of LSTM or RNN\u001b[39;49;00m\n",
      "    \u001b[33m    seq_model: 'rnn' or 'lstm', whether to use RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    num_layers: Number of layers in RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    \"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[96msuper\u001b[39;49;00m(LanguageModel, \u001b[96mself\u001b[39;49;00m).\u001b[92m__init__\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m### BEGIN YOUR SOLUTION\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94mraise\u001b[39;49;00m \u001b[96mNotImplementedError\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       NotImplementedError\u001b[0m\n",
      "\n",
      "__class__  = <class 'models.LanguageModel'>\n",
      "device     = cpu()\n",
      "dtype      = 'float32'\n",
      "embedding_size = 34\n",
      "hidden_size = 12\n",
      "num_layers = 1\n",
      "output_size = 1000\n",
      "self       = <models.LanguageModel object at 0x1695398b0>\n",
      "seq_model  = 'lstm'\n",
      "\n",
      "\u001b[1m\u001b[31mapps/models.py\u001b[0m:38: NotImplementedError\n",
      "\u001b[31m\u001b[1m_____ test_language_model_implementation[cpu-lstm-1000-False-12-34-15-2-1] _____\u001b[0m\n",
      "\n",
      "seq_length = 1, num_layers = 2, batch_size = 15, embedding_size = 34\n",
      "hidden_size = 12, init_hidden = False, output_size = 1000, seq_model = 'lstm'\n",
      "device = cpu()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\u001b[90m\u001b[39;49;00m\n",
      "                            init_hidden, output_size, seq_model, device):\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      ">       model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "batch_size = 15\n",
      "c0         = needle.Tensor([[[ 1.31791249e-01  7.94850945e-01 -1.25179803e+00 -7.47220933e-01\n",
      "   -1.66528318e-02  1.89160228e-01 -4...  8.03955138e-01  2.06471443e-01  2.50650465e-01\n",
      "    1.31190097e+00 -1.00451827e+00  5.07038593e-01 -7.56464183e-01]]])\n",
      "device     = cpu()\n",
      "embedding_size = 34\n",
      "h0         = needle.Tensor([[[-1.1093501  -0.46025932  0.5945892   1.3181291   0.48229447\n",
      "   -0.9639801   1.1910287   0.23100898  1...84  0.5769108  -0.0783911\n",
      "   -0.1974402   0.0551968  -0.33272237 -0.02938984 -0.10530129\n",
      "    1.5082991  -0.9792036 ]]])\n",
      "hidden_size = 12\n",
      "init_hidden = False\n",
      "num_layers = 2\n",
      "output_size = 1000\n",
      "seq_length = 1\n",
      "seq_model  = 'lstm'\n",
      "x          = array([[211., 351., 836., 939., 952., 478., 663., 894., 761., 265.,  37.,\n",
      "        408., 817., 243., 245.]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:201: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "self = <models.LanguageModel object at 0x169539280>, embedding_size = 34\n",
      "output_size = 1000, hidden_size = 12, num_layers = 2, seq_model = 'lstm'\n",
      "device = cpu(), dtype = 'float32'\n",
      "\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92m__init__\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, embedding_size, output_size, hidden_size, num_layers=\u001b[94m1\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                 seq_model=\u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, device=\u001b[94mNone\u001b[39;49;00m, dtype=\u001b[33m\"\u001b[39;49;00m\u001b[33mfloat32\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"\u001b[39;49;00m\n",
      "    \u001b[33m    Consists of an embedding layer, a sequence model (either RNN or LSTM), and a\u001b[39;49;00m\n",
      "    \u001b[33m    linear layer.\u001b[39;49;00m\n",
      "    \u001b[33m    Parameters:\u001b[39;49;00m\n",
      "    \u001b[33m    output_size: Size of dictionary\u001b[39;49;00m\n",
      "    \u001b[33m    embedding_size: Size of embeddings\u001b[39;49;00m\n",
      "    \u001b[33m    hidden_size: The number of features in the hidden state of LSTM or RNN\u001b[39;49;00m\n",
      "    \u001b[33m    seq_model: 'rnn' or 'lstm', whether to use RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    num_layers: Number of layers in RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    \"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[96msuper\u001b[39;49;00m(LanguageModel, \u001b[96mself\u001b[39;49;00m).\u001b[92m__init__\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m### BEGIN YOUR SOLUTION\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94mraise\u001b[39;49;00m \u001b[96mNotImplementedError\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       NotImplementedError\u001b[0m\n",
      "\n",
      "__class__  = <class 'models.LanguageModel'>\n",
      "device     = cpu()\n",
      "dtype      = 'float32'\n",
      "embedding_size = 34\n",
      "hidden_size = 12\n",
      "num_layers = 2\n",
      "output_size = 1000\n",
      "self       = <models.LanguageModel object at 0x169539280>\n",
      "seq_model  = 'lstm'\n",
      "\n",
      "\u001b[1m\u001b[31mapps/models.py\u001b[0m:38: NotImplementedError\n",
      "\u001b[31m\u001b[1m____ test_language_model_implementation[cpu-lstm-1000-False-12-34-15-2-13] _____\u001b[0m\n",
      "\n",
      "seq_length = 13, num_layers = 2, batch_size = 15, embedding_size = 34\n",
      "hidden_size = 12, init_hidden = False, output_size = 1000, seq_model = 'lstm'\n",
      "device = cpu()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\u001b[90m\u001b[39;49;00m\n",
      "                            init_hidden, output_size, seq_model, device):\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      ">       model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "batch_size = 15\n",
      "c0         = needle.Tensor([[[-6.39185131e-01 -9.74767506e-01 -5.30700207e-01 -8.32005620e-01\n",
      "    2.50152558e-01  1.32783592e+00 -1...  8.07478845e-01  1.64869440e+00 -1.18103266e+00\n",
      "   -2.10510865e-01  9.57948327e-01 -3.48506600e-01  1.05156696e+00]]])\n",
      "device     = cpu()\n",
      "embedding_size = 34\n",
      "h0         = needle.Tensor([[[-1.4398527  -1.587203   -1.4385642   0.32954615 -0.12200111\n",
      "    1.4132878  -0.5756531  -0.50146496  0...    0.12096214 -0.8845517\n",
      "    0.7114462  -0.38208595  0.0921476   0.60456663 -0.24962491\n",
      "    1.1080132  -0.08584415]]])\n",
      "hidden_size = 12\n",
      "init_hidden = False\n",
      "num_layers = 2\n",
      "output_size = 1000\n",
      "seq_length = 13\n",
      "seq_model  = 'lstm'\n",
      "x          = array([[600., 273., 658., 607.,   1., 682., 821., 554., 844., 422., 916.,\n",
      "         68., 303., 177.,  57.],\n",
      "       [904...    [391., 589.,  42., 409., 195., 116., 378.,  44., 908., 324., 304.,\n",
      "        237., 403., 709., 456.]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:201: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "self = <models.LanguageModel object at 0x1695fd790>, embedding_size = 34\n",
      "output_size = 1000, hidden_size = 12, num_layers = 2, seq_model = 'lstm'\n",
      "device = cpu(), dtype = 'float32'\n",
      "\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92m__init__\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, embedding_size, output_size, hidden_size, num_layers=\u001b[94m1\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                 seq_model=\u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, device=\u001b[94mNone\u001b[39;49;00m, dtype=\u001b[33m\"\u001b[39;49;00m\u001b[33mfloat32\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"\u001b[39;49;00m\n",
      "    \u001b[33m    Consists of an embedding layer, a sequence model (either RNN or LSTM), and a\u001b[39;49;00m\n",
      "    \u001b[33m    linear layer.\u001b[39;49;00m\n",
      "    \u001b[33m    Parameters:\u001b[39;49;00m\n",
      "    \u001b[33m    output_size: Size of dictionary\u001b[39;49;00m\n",
      "    \u001b[33m    embedding_size: Size of embeddings\u001b[39;49;00m\n",
      "    \u001b[33m    hidden_size: The number of features in the hidden state of LSTM or RNN\u001b[39;49;00m\n",
      "    \u001b[33m    seq_model: 'rnn' or 'lstm', whether to use RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    num_layers: Number of layers in RNN or LSTM\u001b[39;49;00m\n",
      "    \u001b[33m    \"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[96msuper\u001b[39;49;00m(LanguageModel, \u001b[96mself\u001b[39;49;00m).\u001b[92m__init__\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m### BEGIN YOUR SOLUTION\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94mraise\u001b[39;49;00m \u001b[96mNotImplementedError\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       NotImplementedError\u001b[0m\n",
      "\n",
      "__class__  = <class 'models.LanguageModel'>\n",
      "device     = cpu()\n",
      "dtype      = 'float32'\n",
      "embedding_size = 34\n",
      "hidden_size = 12\n",
      "num_layers = 2\n",
      "output_size = 1000\n",
      "self       = <models.LanguageModel object at 0x1695fd790>\n",
      "seq_model  = 'lstm'\n",
      "\n",
      "\u001b[1m\u001b[31mapps/models.py\u001b[0m:38: NotImplementedError\n",
      "\u001b[36m\u001b[1m=========================== short test summary info ============================\u001b[0m\n",
      "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_language_model_implementation[cpu-rnn-1-True-1-1-1-1-1]\u001b[0m - NotImplementedError\n",
      "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_language_model_implementation[cpu-rnn-1-True-1-1-1-1-13]\u001b[0m - NotImplementedError\n",
      "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_language_model_implementation[cpu-rnn-1-True-1-1-1-2-1]\u001b[0m - NotImplementedError\n",
      "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_language_model_implementation[cpu-rnn-1-True-1-1-1-2-13]\u001b[0m - NotImplementedError\n",
      "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_language_model_implementation[cpu-rnn-1-True-1-1-15-1-1]\u001b[0m - NotImplementedError\n",
      "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_language_model_implementation[cpu-rnn-1-True-1-1-15-1-13]\u001b[0m - NotImplementedError\n",
      "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_language_model_implementation[cpu-rnn-1-True-1-1-15-2-1]\u001b[0m - NotImplementedError\n",
      "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_language_model_implementation[cpu-rnn-1-True-1-1-15-2-13]\u001b[0m - NotImplementedError\n",
      "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_language_model_implementation[cpu-rnn-1-True-1-34-1-1-1]\u001b[0m - NotImplementedError\n",
      "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_language_model_implementation[cpu-rnn-1-True-1-34-1-1-13]\u001b[0m - NotImplementedError\n",
      "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_language_model_implementation[cpu-rnn-1-True-1-34-1-2-1]\u001b[0m - NotImplementedError\n",
      "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_language_model_implementation[cpu-rnn-1-True-1-34-1-2-13]\u001b[0m - NotImplementedError\n",
      "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_language_model_implementation[cpu-rnn-1-True-1-34-15-1-1]\u001b[0m - NotImplementedError\n",
      "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_language_model_implementation[cpu-rnn-1-True-1-34-15-1-13]\u001b[0m - NotImplementedError\n",
      "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_language_model_implementation[cpu-rnn-1-True-1-34-15-2-1]\u001b[0m - NotImplementedError\n",
      "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_language_model_implementation[cpu-rnn-1-True-1-34-15-2-13]\u001b[0m - NotImplementedError\n",
      "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_language_model_implementation[cpu-rnn-1-True-12-1-1-1-1]\u001b[0m - NotImplementedError\n",
      "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_language_model_implementation[cpu-rnn-1-True-12-1-1-1-13]\u001b[0m - NotImplementedError\n",
      "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_language_model_implementation[cpu-rnn-1-True-12-1-1-2-1]\u001b[0m - NotImplementedError\n",
      "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_language_model_implementation[cpu-rnn-1-True-12-1-1-2-13]\u001b[0m - NotImplementedError\n",
      "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_language_model_implementation[cpu-rnn-1-True-12-1-15-1-1]\u001b[0m - NotImplementedError\n",
      "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_language_model_implementation[cpu-rnn-1-True-12-1-15-1-13]\u001b[0m - NotImplementedError\n",
      "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_language_model_implementation[cpu-rnn-1-True-12-1-15-2-1]\u001b[0m - NotImplementedError\n",
      "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_language_model_implementation[cpu-rnn-1-True-12-1-15-2-13]\u001b[0m - NotImplementedError\n",
      "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_language_model_implementation[cpu-rnn-1-True-12-34-1-1-1]\u001b[0m - NotImplementedError\n",
      "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_language_model_implementation[cpu-rnn-1-True-12-34-1-1-13]\u001b[0m - NotImplementedError\n",
      "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_language_model_implementation[cpu-rnn-1-True-12-34-1-2-1]\u001b[0m - NotImplementedError\n",
      "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_language_model_implementation[cpu-rnn-1-True-12-34-1-2-13]\u001b[0m - NotImplementedError\n",
      "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_language_model_implementation[cpu-rnn-1-True-12-34-15-1-1]\u001b[0m - NotImplementedError\n",
      "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_language_model_implementation[cpu-rnn-1-True-12-34-15-1-13]\u001b[0m - NotImplementedError\n",
      "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_language_model_implementation[cpu-rnn-1-True-12-34-15-2-1]\u001b[0m - NotImplementedError\n",
      "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_language_model_implementation[cpu-rnn-1-True-12-34-15-2-13]\u001b[0m - NotImplementedError\n",
      "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_language_model_implementation[cpu-rnn-1-False-1-1-1-1-1]\u001b[0m - NotImplementedError\n",
      "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_language_model_implementation[cpu-rnn-1-False-1-1-1-1-13]\u001b[0m - NotImplementedError\n",
      "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_language_model_implementation[cpu-rnn-1-False-1-1-1-2-1]\u001b[0m - NotImplementedError\n",
      "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_language_model_implementation[cpu-rnn-1-False-1-1-1-2-13]\u001b[0m - NotImplementedError\n",
      "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_language_model_implementation[cpu-rnn-1-False-1-1-15-1-1]\u001b[0m - NotImplementedError\n",
      "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_language_model_implementation[cpu-rnn-1-False-1-1-15-1-13]\u001b[0m - NotImplementedError\n",
      "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_language_model_implementation[cpu-rnn-1-False-1-1-15-2-1]\u001b[0m - NotImplementedError\n",
      "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_language_model_implementation[cpu-rnn-1-False-1-1-15-2-13]\u001b[0m - NotImplementedError\n",
      "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_language_model_implementation[cpu-rnn-1-False-1-34-1-1-1]\u001b[0m - NotImplementedError\n",
      "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_language_model_implementation[cpu-rnn-1-False-1-34-1-1-13]\u001b[0m - NotImplementedError\n",
      "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_language_model_implementation[cpu-rnn-1-False-1-34-1-2-1]\u001b[0m - NotImplementedError\n",
      "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_language_model_implementation[cpu-rnn-1-False-1-34-1-2-13]\u001b[0m - NotImplementedError\n",
      "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_language_model_implementation[cpu-rnn-1-False-1-34-15-1-1]\u001b[0m - NotImplementedError\n",
      "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_language_model_implementation[cpu-rnn-1-False-1-34-15-1-13]\u001b[0m - NotImplementedError\n",
      "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_language_model_implementation[cpu-rnn-1-False-1-34-15-2-1]\u001b[0m - NotImplementedError\n",
      "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_language_model_implementation[cpu-rnn-1-False-1-34-15-2-13]\u001b[0m - NotImplementedError\n",
      "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_language_model_implementation[cpu-rnn-1-False-12-1-1-1-1]\u001b[0m - NotImplementedError\n",
      "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_language_model_implementation[cpu-rnn-1-False-12-1-1-1-13]\u001b[0m - NotImplementedError\n",
      "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_language_model_implementation[cpu-rnn-1-False-12-1-1-2-1]\u001b[0m - NotImplementedError\n",
      "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_language_model_implementation[cpu-rnn-1-False-12-1-1-2-13]\u001b[0m - NotImplementedError\n",
      "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_language_model_implementation[cpu-rnn-1-False-12-1-15-1-1]\u001b[0m - NotImplementedError\n",
      "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_language_model_implementation[cpu-rnn-1-False-12-1-15-1-13]\u001b[0m - NotImplementedError\n",
      "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_language_model_implementation[cpu-rnn-1-False-12-1-15-2-1]\u001b[0m - NotImplementedError\n",
      "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_language_model_implementation[cpu-rnn-1-False-12-1-15-2-13]\u001b[0m - NotImplementedError\n",
      "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_language_model_implementation[cpu-rnn-1-False-12-34-1-1-1]\u001b[0m - NotImplementedError\n",
      "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_language_model_implementation[cpu-rnn-1-False-12-34-1-1-13]\u001b[0m - NotImplementedError\n",
      "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_language_model_implementation[cpu-rnn-1-False-12-34-1-2-1]\u001b[0m - NotImplementedError\n",
      "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_language_model_implementation[cpu-rnn-1-False-12-34-1-2-13]\u001b[0m - NotImplementedError\n",
      "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_language_model_implementation[cpu-rnn-1-False-12-34-15-1-1]\u001b[0m - NotImplementedError\n",
      "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_language_model_implementation[cpu-rnn-1-False-12-34-15-1-13]\u001b[0m - NotImplementedError\n",
      "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_language_model_implementation[cpu-rnn-1-False-12-34-15-2-1]\u001b[0m - NotImplementedError\n",
      "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_language_model_implementation[cpu-rnn-1-False-12-34-15-2-13]\u001b[0m - NotImplementedError\n",
      "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_language_model_implementation[cpu-rnn-1000-True-1-1-1-1-1]\u001b[0m - NotImplementedError\n",
      "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_language_model_implementation[cpu-rnn-1000-True-1-1-1-1-13]\u001b[0m - NotImplementedError\n",
      "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_language_model_implementation[cpu-rnn-1000-True-1-1-1-2-1]\u001b[0m - NotImplementedError\n",
      "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_language_model_implementation[cpu-rnn-1000-True-1-1-1-2-13]\u001b[0m - NotImplementedError\n",
      "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_language_model_implementation[cpu-rnn-1000-True-1-1-15-1-1]\u001b[0m - NotImplementedError\n",
      "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_language_model_implementation[cpu-rnn-1000-True-1-1-15-1-13]\u001b[0m - NotImplementedError\n",
      "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_language_model_implementation[cpu-rnn-1000-True-1-1-15-2-1]\u001b[0m - NotImplementedError\n",
      "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_language_model_implementation[cpu-rnn-1000-True-1-1-15-2-13]\u001b[0m - NotImplementedError\n",
      "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_language_model_implementation[cpu-rnn-1000-True-1-34-1-1-1]\u001b[0m - NotImplementedError\n",
      "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_language_model_implementation[cpu-rnn-1000-True-1-34-1-1-13]\u001b[0m - NotImplementedError\n",
      "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_language_model_implementation[cpu-rnn-1000-True-1-34-1-2-1]\u001b[0m - NotImplementedError\n",
      "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_language_model_implementation[cpu-rnn-1000-True-1-34-1-2-13]\u001b[0m - NotImplementedError\n",
      "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_language_model_implementation[cpu-rnn-1000-True-1-34-15-1-1]\u001b[0m - NotImplementedError\n",
      "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_language_model_implementation[cpu-rnn-1000-True-1-34-15-1-13]\u001b[0m - NotImplementedError\n",
      "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_language_model_implementation[cpu-rnn-1000-True-1-34-15-2-1]\u001b[0m - NotImplementedError\n",
      "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_language_model_implementation[cpu-rnn-1000-True-1-34-15-2-13]\u001b[0m - NotImplementedError\n",
      "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_language_model_implementation[cpu-rnn-1000-True-12-1-1-1-1]\u001b[0m - NotImplementedError\n",
      "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_language_model_implementation[cpu-rnn-1000-True-12-1-1-1-13]\u001b[0m - NotImplementedError\n",
      "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_language_model_implementation[cpu-rnn-1000-True-12-1-1-2-1]\u001b[0m - NotImplementedError\n",
      "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_language_model_implementation[cpu-rnn-1000-True-12-1-1-2-13]\u001b[0m - NotImplementedError\n",
      "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_language_model_implementation[cpu-rnn-1000-True-12-1-15-1-1]\u001b[0m - NotImplementedError\n",
      "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_language_model_implementation[cpu-rnn-1000-True-12-1-15-1-13]\u001b[0m - NotImplementedError\n",
      "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_language_model_implementation[cpu-rnn-1000-True-12-1-15-2-1]\u001b[0m - NotImplementedError\n",
      "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_language_model_implementation[cpu-rnn-1000-True-12-1-15-2-13]\u001b[0m - NotImplementedError\n",
      "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_language_model_implementation[cpu-rnn-1000-True-12-34-1-1-1]\u001b[0m - NotImplementedError\n",
      "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_language_model_implementation[cpu-rnn-1000-True-12-34-1-1-13]\u001b[0m - NotImplementedError\n",
      "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_language_model_implementation[cpu-rnn-1000-True-12-34-1-2-1]\u001b[0m - NotImplementedError\n",
      "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_language_model_implementation[cpu-rnn-1000-True-12-34-1-2-13]\u001b[0m - NotImplementedError\n",
      "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_language_model_implementation[cpu-rnn-1000-True-12-34-15-1-1]\u001b[0m - NotImplementedError\n",
      "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_language_model_implementation[cpu-rnn-1000-True-12-34-15-1-13]\u001b[0m - NotImplementedError\n",
      "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_language_model_implementation[cpu-rnn-1000-True-12-34-15-2-1]\u001b[0m - NotImplementedError\n",
      "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_language_model_implementation[cpu-rnn-1000-True-12-34-15-2-13]\u001b[0m - NotImplementedError\n",
      "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_language_model_implementation[cpu-rnn-1000-False-1-1-1-1-1]\u001b[0m - NotImplementedError\n",
      "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_language_model_implementation[cpu-rnn-1000-False-1-1-1-1-13]\u001b[0m - NotImplementedError\n",
      "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_language_model_implementation[cpu-rnn-1000-False-1-1-1-2-1]\u001b[0m - NotImplementedError\n",
      "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_language_model_implementation[cpu-rnn-1000-False-1-1-1-2-13]\u001b[0m - NotImplementedError\n",
      "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_language_model_implementation[cpu-rnn-1000-False-1-1-15-1-1]\u001b[0m - NotImplementedError\n",
      "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_language_model_implementation[cpu-rnn-1000-False-1-1-15-1-13]\u001b[0m - NotImplementedError\n",
      "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_language_model_implementation[cpu-rnn-1000-False-1-1-15-2-1]\u001b[0m - NotImplementedError\n",
      "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_language_model_implementation[cpu-rnn-1000-False-1-1-15-2-13]\u001b[0m - NotImplementedError\n",
      "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_language_model_implementation[cpu-rnn-1000-False-1-34-1-1-1]\u001b[0m - NotImplementedError\n",
      "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_language_model_implementation[cpu-rnn-1000-False-1-34-1-1-13]\u001b[0m - NotImplementedError\n",
      "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_language_model_implementation[cpu-rnn-1000-False-1-34-1-2-1]\u001b[0m - NotImplementedError\n",
      "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_language_model_implementation[cpu-rnn-1000-False-1-34-1-2-13]\u001b[0m - NotImplementedError\n",
      "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_language_model_implementation[cpu-rnn-1000-False-1-34-15-1-1]\u001b[0m - NotImplementedError\n",
      "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_language_model_implementation[cpu-rnn-1000-False-1-34-15-1-13]\u001b[0m - NotImplementedError\n",
      "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_language_model_implementation[cpu-rnn-1000-False-1-34-15-2-1]\u001b[0m - NotImplementedError\n",
      "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_language_model_implementation[cpu-rnn-1000-False-1-34-15-2-13]\u001b[0m - NotImplementedError\n",
      "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_language_model_implementation[cpu-rnn-1000-False-12-1-1-1-1]\u001b[0m - NotImplementedError\n",
      "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_language_model_implementation[cpu-rnn-1000-False-12-1-1-1-13]\u001b[0m - NotImplementedError\n",
      "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_language_model_implementation[cpu-rnn-1000-False-12-1-1-2-1]\u001b[0m - NotImplementedError\n",
      "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_language_model_implementation[cpu-rnn-1000-False-12-1-1-2-13]\u001b[0m - NotImplementedError\n",
      "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_language_model_implementation[cpu-rnn-1000-False-12-1-15-1-1]\u001b[0m - NotImplementedError\n",
      "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_language_model_implementation[cpu-rnn-1000-False-12-1-15-1-13]\u001b[0m - NotImplementedError\n",
      "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_language_model_implementation[cpu-rnn-1000-False-12-1-15-2-1]\u001b[0m - NotImplementedError\n",
      "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_language_model_implementation[cpu-rnn-1000-False-12-1-15-2-13]\u001b[0m - NotImplementedError\n",
      "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_language_model_implementation[cpu-rnn-1000-False-12-34-1-1-1]\u001b[0m - NotImplementedError\n",
      "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_language_model_implementation[cpu-rnn-1000-False-12-34-1-1-13]\u001b[0m - NotImplementedError\n",
      "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_language_model_implementation[cpu-rnn-1000-False-12-34-1-2-1]\u001b[0m - NotImplementedError\n",
      "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_language_model_implementation[cpu-rnn-1000-False-12-34-1-2-13]\u001b[0m - NotImplementedError\n",
      "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_language_model_implementation[cpu-rnn-1000-False-12-34-15-1-1]\u001b[0m - NotImplementedError\n",
      "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_language_model_implementation[cpu-rnn-1000-False-12-34-15-1-13]\u001b[0m - NotImplementedError\n",
      "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_language_model_implementation[cpu-rnn-1000-False-12-34-15-2-1]\u001b[0m - NotImplementedError\n",
      "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_language_model_implementation[cpu-rnn-1000-False-12-34-15-2-13]\u001b[0m - NotImplementedError\n",
      "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_language_model_implementation[cpu-lstm-1-True-1-1-1-1-1]\u001b[0m - NotImplementedError\n",
      "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_language_model_implementation[cpu-lstm-1-True-1-1-1-1-13]\u001b[0m - NotImplementedError\n",
      "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_language_model_implementation[cpu-lstm-1-True-1-1-1-2-1]\u001b[0m - NotImplementedError\n",
      "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_language_model_implementation[cpu-lstm-1-True-1-1-1-2-13]\u001b[0m - NotImplementedError\n",
      "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_language_model_implementation[cpu-lstm-1-True-1-1-15-1-1]\u001b[0m - NotImplementedError\n",
      "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_language_model_implementation[cpu-lstm-1-True-1-1-15-1-13]\u001b[0m - NotImplementedError\n",
      "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_language_model_implementation[cpu-lstm-1-True-1-1-15-2-1]\u001b[0m - NotImplementedError\n",
      "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_language_model_implementation[cpu-lstm-1-True-1-1-15-2-13]\u001b[0m - NotImplementedError\n",
      "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_language_model_implementation[cpu-lstm-1-True-1-34-1-1-1]\u001b[0m - NotImplementedError\n",
      "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_language_model_implementation[cpu-lstm-1-True-1-34-1-1-13]\u001b[0m - NotImplementedError\n",
      "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_language_model_implementation[cpu-lstm-1-True-1-34-1-2-1]\u001b[0m - NotImplementedError\n",
      "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_language_model_implementation[cpu-lstm-1-True-1-34-1-2-13]\u001b[0m - NotImplementedError\n",
      "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_language_model_implementation[cpu-lstm-1-True-1-34-15-1-1]\u001b[0m - NotImplementedError\n",
      "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_language_model_implementation[cpu-lstm-1-True-1-34-15-1-13]\u001b[0m - NotImplementedError\n",
      "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_language_model_implementation[cpu-lstm-1-True-1-34-15-2-1]\u001b[0m - NotImplementedError\n",
      "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_language_model_implementation[cpu-lstm-1-True-1-34-15-2-13]\u001b[0m - NotImplementedError\n",
      "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_language_model_implementation[cpu-lstm-1-True-12-1-1-1-1]\u001b[0m - NotImplementedError\n",
      "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_language_model_implementation[cpu-lstm-1-True-12-1-1-1-13]\u001b[0m - NotImplementedError\n",
      "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_language_model_implementation[cpu-lstm-1-True-12-1-1-2-1]\u001b[0m - NotImplementedError\n",
      "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_language_model_implementation[cpu-lstm-1-True-12-1-1-2-13]\u001b[0m - NotImplementedError\n",
      "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_language_model_implementation[cpu-lstm-1-True-12-1-15-1-1]\u001b[0m - NotImplementedError\n",
      "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_language_model_implementation[cpu-lstm-1-True-12-1-15-1-13]\u001b[0m - NotImplementedError\n",
      "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_language_model_implementation[cpu-lstm-1-True-12-1-15-2-1]\u001b[0m - NotImplementedError\n",
      "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_language_model_implementation[cpu-lstm-1-True-12-1-15-2-13]\u001b[0m - NotImplementedError\n",
      "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_language_model_implementation[cpu-lstm-1-True-12-34-1-1-1]\u001b[0m - NotImplementedError\n",
      "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_language_model_implementation[cpu-lstm-1-True-12-34-1-1-13]\u001b[0m - NotImplementedError\n",
      "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_language_model_implementation[cpu-lstm-1-True-12-34-1-2-1]\u001b[0m - NotImplementedError\n",
      "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_language_model_implementation[cpu-lstm-1-True-12-34-1-2-13]\u001b[0m - NotImplementedError\n",
      "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_language_model_implementation[cpu-lstm-1-True-12-34-15-1-1]\u001b[0m - NotImplementedError\n",
      "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_language_model_implementation[cpu-lstm-1-True-12-34-15-1-13]\u001b[0m - NotImplementedError\n",
      "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_language_model_implementation[cpu-lstm-1-True-12-34-15-2-1]\u001b[0m - NotImplementedError\n",
      "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_language_model_implementation[cpu-lstm-1-True-12-34-15-2-13]\u001b[0m - NotImplementedError\n",
      "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_language_model_implementation[cpu-lstm-1-False-1-1-1-1-1]\u001b[0m - NotImplementedError\n",
      "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_language_model_implementation[cpu-lstm-1-False-1-1-1-1-13]\u001b[0m - NotImplementedError\n",
      "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_language_model_implementation[cpu-lstm-1-False-1-1-1-2-1]\u001b[0m - NotImplementedError\n",
      "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_language_model_implementation[cpu-lstm-1-False-1-1-1-2-13]\u001b[0m - NotImplementedError\n",
      "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_language_model_implementation[cpu-lstm-1-False-1-1-15-1-1]\u001b[0m - NotImplementedError\n",
      "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_language_model_implementation[cpu-lstm-1-False-1-1-15-1-13]\u001b[0m - NotImplementedError\n",
      "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_language_model_implementation[cpu-lstm-1-False-1-1-15-2-1]\u001b[0m - NotImplementedError\n",
      "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_language_model_implementation[cpu-lstm-1-False-1-1-15-2-13]\u001b[0m - NotImplementedError\n",
      "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_language_model_implementation[cpu-lstm-1-False-1-34-1-1-1]\u001b[0m - NotImplementedError\n",
      "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_language_model_implementation[cpu-lstm-1-False-1-34-1-1-13]\u001b[0m - NotImplementedError\n",
      "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_language_model_implementation[cpu-lstm-1-False-1-34-1-2-1]\u001b[0m - NotImplementedError\n",
      "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_language_model_implementation[cpu-lstm-1-False-1-34-1-2-13]\u001b[0m - NotImplementedError\n",
      "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_language_model_implementation[cpu-lstm-1-False-1-34-15-1-1]\u001b[0m - NotImplementedError\n",
      "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_language_model_implementation[cpu-lstm-1-False-1-34-15-1-13]\u001b[0m - NotImplementedError\n",
      "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_language_model_implementation[cpu-lstm-1-False-1-34-15-2-1]\u001b[0m - NotImplementedError\n",
      "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_language_model_implementation[cpu-lstm-1-False-1-34-15-2-13]\u001b[0m - NotImplementedError\n",
      "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_language_model_implementation[cpu-lstm-1-False-12-1-1-1-1]\u001b[0m - NotImplementedError\n",
      "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_language_model_implementation[cpu-lstm-1-False-12-1-1-1-13]\u001b[0m - NotImplementedError\n",
      "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_language_model_implementation[cpu-lstm-1-False-12-1-1-2-1]\u001b[0m - NotImplementedError\n",
      "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_language_model_implementation[cpu-lstm-1-False-12-1-1-2-13]\u001b[0m - NotImplementedError\n",
      "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_language_model_implementation[cpu-lstm-1-False-12-1-15-1-1]\u001b[0m - NotImplementedError\n",
      "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_language_model_implementation[cpu-lstm-1-False-12-1-15-1-13]\u001b[0m - NotImplementedError\n",
      "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_language_model_implementation[cpu-lstm-1-False-12-1-15-2-1]\u001b[0m - NotImplementedError\n",
      "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_language_model_implementation[cpu-lstm-1-False-12-1-15-2-13]\u001b[0m - NotImplementedError\n",
      "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_language_model_implementation[cpu-lstm-1-False-12-34-1-1-1]\u001b[0m - NotImplementedError\n",
      "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_language_model_implementation[cpu-lstm-1-False-12-34-1-1-13]\u001b[0m - NotImplementedError\n",
      "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_language_model_implementation[cpu-lstm-1-False-12-34-1-2-1]\u001b[0m - NotImplementedError\n",
      "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_language_model_implementation[cpu-lstm-1-False-12-34-1-2-13]\u001b[0m - NotImplementedError\n",
      "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_language_model_implementation[cpu-lstm-1-False-12-34-15-1-1]\u001b[0m - NotImplementedError\n",
      "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_language_model_implementation[cpu-lstm-1-False-12-34-15-1-13]\u001b[0m - NotImplementedError\n",
      "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_language_model_implementation[cpu-lstm-1-False-12-34-15-2-1]\u001b[0m - NotImplementedError\n",
      "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_language_model_implementation[cpu-lstm-1-False-12-34-15-2-13]\u001b[0m - NotImplementedError\n",
      "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_language_model_implementation[cpu-lstm-1000-True-1-1-1-1-1]\u001b[0m - NotImplementedError\n",
      "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_language_model_implementation[cpu-lstm-1000-True-1-1-1-1-13]\u001b[0m - NotImplementedError\n",
      "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_language_model_implementation[cpu-lstm-1000-True-1-1-1-2-1]\u001b[0m - NotImplementedError\n",
      "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_language_model_implementation[cpu-lstm-1000-True-1-1-1-2-13]\u001b[0m - NotImplementedError\n",
      "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_language_model_implementation[cpu-lstm-1000-True-1-1-15-1-1]\u001b[0m - NotImplementedError\n",
      "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_language_model_implementation[cpu-lstm-1000-True-1-1-15-1-13]\u001b[0m - NotImplementedError\n",
      "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_language_model_implementation[cpu-lstm-1000-True-1-1-15-2-1]\u001b[0m - NotImplementedError\n",
      "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_language_model_implementation[cpu-lstm-1000-True-1-1-15-2-13]\u001b[0m - NotImplementedError\n",
      "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_language_model_implementation[cpu-lstm-1000-True-1-34-1-1-1]\u001b[0m - NotImplementedError\n",
      "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_language_model_implementation[cpu-lstm-1000-True-1-34-1-1-13]\u001b[0m - NotImplementedError\n",
      "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_language_model_implementation[cpu-lstm-1000-True-1-34-1-2-1]\u001b[0m - NotImplementedError\n",
      "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_language_model_implementation[cpu-lstm-1000-True-1-34-1-2-13]\u001b[0m - NotImplementedError\n",
      "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_language_model_implementation[cpu-lstm-1000-True-1-34-15-1-1]\u001b[0m - NotImplementedError\n",
      "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_language_model_implementation[cpu-lstm-1000-True-1-34-15-1-13]\u001b[0m - NotImplementedError\n",
      "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_language_model_implementation[cpu-lstm-1000-True-1-34-15-2-1]\u001b[0m - NotImplementedError\n",
      "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_language_model_implementation[cpu-lstm-1000-True-1-34-15-2-13]\u001b[0m - NotImplementedError\n",
      "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_language_model_implementation[cpu-lstm-1000-True-12-1-1-1-1]\u001b[0m - NotImplementedError\n",
      "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_language_model_implementation[cpu-lstm-1000-True-12-1-1-1-13]\u001b[0m - NotImplementedError\n",
      "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_language_model_implementation[cpu-lstm-1000-True-12-1-1-2-1]\u001b[0m - NotImplementedError\n",
      "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_language_model_implementation[cpu-lstm-1000-True-12-1-1-2-13]\u001b[0m - NotImplementedError\n",
      "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_language_model_implementation[cpu-lstm-1000-True-12-1-15-1-1]\u001b[0m - NotImplementedError\n",
      "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_language_model_implementation[cpu-lstm-1000-True-12-1-15-1-13]\u001b[0m - NotImplementedError\n",
      "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_language_model_implementation[cpu-lstm-1000-True-12-1-15-2-1]\u001b[0m - NotImplementedError\n",
      "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_language_model_implementation[cpu-lstm-1000-True-12-1-15-2-13]\u001b[0m - NotImplementedError\n",
      "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_language_model_implementation[cpu-lstm-1000-True-12-34-1-1-1]\u001b[0m - NotImplementedError\n",
      "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_language_model_implementation[cpu-lstm-1000-True-12-34-1-1-13]\u001b[0m - NotImplementedError\n",
      "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_language_model_implementation[cpu-lstm-1000-True-12-34-1-2-1]\u001b[0m - NotImplementedError\n",
      "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_language_model_implementation[cpu-lstm-1000-True-12-34-1-2-13]\u001b[0m - NotImplementedError\n",
      "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_language_model_implementation[cpu-lstm-1000-True-12-34-15-1-1]\u001b[0m - NotImplementedError\n",
      "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_language_model_implementation[cpu-lstm-1000-True-12-34-15-1-13]\u001b[0m - NotImplementedError\n",
      "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_language_model_implementation[cpu-lstm-1000-True-12-34-15-2-1]\u001b[0m - NotImplementedError\n",
      "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_language_model_implementation[cpu-lstm-1000-True-12-34-15-2-13]\u001b[0m - NotImplementedError\n",
      "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_language_model_implementation[cpu-lstm-1000-False-1-1-1-1-1]\u001b[0m - NotImplementedError\n",
      "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_language_model_implementation[cpu-lstm-1000-False-1-1-1-1-13]\u001b[0m - NotImplementedError\n",
      "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_language_model_implementation[cpu-lstm-1000-False-1-1-1-2-1]\u001b[0m - NotImplementedError\n",
      "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_language_model_implementation[cpu-lstm-1000-False-1-1-1-2-13]\u001b[0m - NotImplementedError\n",
      "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_language_model_implementation[cpu-lstm-1000-False-1-1-15-1-1]\u001b[0m - NotImplementedError\n",
      "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_language_model_implementation[cpu-lstm-1000-False-1-1-15-1-13]\u001b[0m - NotImplementedError\n",
      "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_language_model_implementation[cpu-lstm-1000-False-1-1-15-2-1]\u001b[0m - NotImplementedError\n",
      "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_language_model_implementation[cpu-lstm-1000-False-1-1-15-2-13]\u001b[0m - NotImplementedError\n",
      "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_language_model_implementation[cpu-lstm-1000-False-1-34-1-1-1]\u001b[0m - NotImplementedError\n",
      "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_language_model_implementation[cpu-lstm-1000-False-1-34-1-1-13]\u001b[0m - NotImplementedError\n",
      "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_language_model_implementation[cpu-lstm-1000-False-1-34-1-2-1]\u001b[0m - NotImplementedError\n",
      "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_language_model_implementation[cpu-lstm-1000-False-1-34-1-2-13]\u001b[0m - NotImplementedError\n",
      "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_language_model_implementation[cpu-lstm-1000-False-1-34-15-1-1]\u001b[0m - NotImplementedError\n",
      "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_language_model_implementation[cpu-lstm-1000-False-1-34-15-1-13]\u001b[0m - NotImplementedError\n",
      "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_language_model_implementation[cpu-lstm-1000-False-1-34-15-2-1]\u001b[0m - NotImplementedError\n",
      "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_language_model_implementation[cpu-lstm-1000-False-1-34-15-2-13]\u001b[0m - NotImplementedError\n",
      "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_language_model_implementation[cpu-lstm-1000-False-12-1-1-1-1]\u001b[0m - NotImplementedError\n",
      "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_language_model_implementation[cpu-lstm-1000-False-12-1-1-1-13]\u001b[0m - NotImplementedError\n",
      "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_language_model_implementation[cpu-lstm-1000-False-12-1-1-2-1]\u001b[0m - NotImplementedError\n",
      "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_language_model_implementation[cpu-lstm-1000-False-12-1-1-2-13]\u001b[0m - NotImplementedError\n",
      "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_language_model_implementation[cpu-lstm-1000-False-12-1-15-1-1]\u001b[0m - NotImplementedError\n",
      "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_language_model_implementation[cpu-lstm-1000-False-12-1-15-1-13]\u001b[0m - NotImplementedError\n",
      "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_language_model_implementation[cpu-lstm-1000-False-12-1-15-2-1]\u001b[0m - NotImplementedError\n",
      "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_language_model_implementation[cpu-lstm-1000-False-12-1-15-2-13]\u001b[0m - NotImplementedError\n",
      "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_language_model_implementation[cpu-lstm-1000-False-12-34-1-1-1]\u001b[0m - NotImplementedError\n",
      "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_language_model_implementation[cpu-lstm-1000-False-12-34-1-1-13]\u001b[0m - NotImplementedError\n",
      "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_language_model_implementation[cpu-lstm-1000-False-12-34-1-2-1]\u001b[0m - NotImplementedError\n",
      "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_language_model_implementation[cpu-lstm-1000-False-12-34-1-2-13]\u001b[0m - NotImplementedError\n",
      "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_language_model_implementation[cpu-lstm-1000-False-12-34-15-1-1]\u001b[0m - NotImplementedError\n",
      "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_language_model_implementation[cpu-lstm-1000-False-12-34-15-1-13]\u001b[0m - NotImplementedError\n",
      "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_language_model_implementation[cpu-lstm-1000-False-12-34-15-2-1]\u001b[0m - NotImplementedError\n",
      "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_language_model_implementation[cpu-lstm-1000-False-12-34-15-2-13]\u001b[0m - NotImplementedError\n",
      "\u001b[31m============== \u001b[31m\u001b[1m256 failed\u001b[0m, \u001b[33m256 skipped\u001b[0m, \u001b[33m1291 deselected\u001b[0m\u001b[31m in 5.98s\u001b[0m\u001b[31m ===============\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python3 -m pytest -l -v -k \"language_model_implementation\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 -m pytest -l -v -k \"language_model_training\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 -m mugrade submit \"YOUR KEY HERE\" -k \"language_model\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, you can train your language model on the Penn Treebank dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import needle as ndl\n",
    "sys.path.append('./apps')\n",
    "from models import LanguageModel\n",
    "from simple_ml import train_ptb, evaluate_ptb\n",
    "\n",
    "device = ndl.cpu()\n",
    "corpus = ndl.data.Corpus(\"data/ptb\")\n",
    "train_data = ndl.data.batchify(corpus.train, batch_size=16, device=ndl.cpu(), dtype=\"float32\")\n",
    "model = LanguageModel(30, len(corpus.dictionary), hidden_size=10, num_layers=2, seq_model='rnn', device=ndl.cpu())\n",
    "train_ptb(model, train_data, seq_len=1, n_epochs=1, device=device)\n",
    "evaluate_ptb(model, train_data, seq_len=40, device=device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
